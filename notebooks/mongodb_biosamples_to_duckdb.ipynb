{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T15:12:17.314453Z",
     "start_time": "2024-12-09T15:12:16.718869Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pymongo import MongoClient\n",
    "\n",
    "import duckdb\n",
    "# import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "import pprint\n",
    "\n",
    "import time\n",
    "\n",
    "import pyarrow as pa\n",
    "import pyarrow.compute as pc\n",
    "\n",
    "import cProfile\n",
    "import pstats\n",
    "\n"
   ],
   "id": "e68dcd943609255",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T15:12:17.320036Z",
     "start_time": "2024-12-09T15:12:17.316648Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_duckdb_file(filename):\n",
    "    \"\"\"\n",
    "    Creates a file-based DuckDB database and returns the connection.\n",
    "  \n",
    "    Args:\n",
    "      filename: The name of the DuckDB database file to create.\n",
    "  \n",
    "    Returns:\n",
    "      duckdb.DuckDBPyConnection: The DuckDB connection object.\n",
    "    \"\"\"\n",
    "    conn = duckdb.connect(database=filename)\n",
    "    return conn\n"
   ],
   "id": "e32bd2653ce252d5",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T15:12:17.330860Z",
     "start_time": "2024-12-09T15:12:17.322363Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Example usage:\n",
    "filename = \"biosamples.duckdb\"\n",
    "duckdb_conn = create_duckdb_file(filename)"
   ],
   "id": "e9f0e4e3acc0babb",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T15:12:17.346941Z",
     "start_time": "2024-12-09T15:12:17.333628Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# MongoDB connection details\n",
    "connection_string = \"mongodb://localhost:27017/\"\n",
    "db_name = \"biosamples\"\n",
    "collection_name = \"biosamples\"\n",
    "\n",
    "# Connect to MongoDB\n",
    "client = MongoClient(connection_string)\n",
    "db = client[db_name]\n",
    "collection = db[collection_name]"
   ],
   "id": "8bc12c0a82a5b072",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T15:12:17.353544Z",
     "start_time": "2024-12-09T15:12:17.348941Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Retrieve the first document\n",
    "first_document = collection.find_one()\n"
   ],
   "id": "efcac4a393739da5",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T15:12:17.357908Z",
     "start_time": "2024-12-09T15:12:17.355174Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # Print the document\n",
    "# pprint.pprint(first_document)"
   ],
   "id": "ae7f62c60dea697b",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T15:12:17.362782Z",
     "start_time": "2024-12-09T15:12:17.359556Z"
    }
   },
   "cell_type": "code",
   "source": "# df['content'].value_counts()",
   "id": "39749d18f30ade87",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T15:12:17.423084Z",
     "start_time": "2024-12-09T15:12:17.365036Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def extract_biosample_data_arrow(collection, conn, paths, max_docs=None, batch_size=5000):\n",
    "    \"\"\"\n",
    "    Extracts scalar data from multiple BioSample paths, dynamically identifies columns,\n",
    "    and loads data into DuckDB using PyArrow for performance.\n",
    "\n",
    "    Args:\n",
    "        collection: pymongo collection object\n",
    "        conn: duckdb connection object\n",
    "        paths: list of paths to extract data from.\n",
    "        max_docs: Maximum number of documents to process.\n",
    "        batch_size: Number of documents to process per batch.\n",
    "    \"\"\"\n",
    "    total_docs = max_docs or collection.estimated_document_count()\n",
    "    processed_docs = 0\n",
    "    all_columns = {path: set() for path in paths}\n",
    "\n",
    "    # Create empty tables for each path in DuckDB\n",
    "    for path in paths:\n",
    "        table_name = path.split(\".\")[-1].lower()\n",
    "        conn.execute(f\"CREATE OR REPLACE TABLE {table_name} (id TEXT)\")\n",
    "\n",
    "    cursor = collection.find({}).batch_size(batch_size)\n",
    "\n",
    "    start_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    print(f\"[{start_time}] Starting extraction for paths: {paths}\")\n",
    "    for doc in cursor:\n",
    "        if max_docs and processed_docs >= max_docs:\n",
    "            break\n",
    "\n",
    "        for path in paths:\n",
    "            path_parts = path.split(\".\")[1:] if path != \"BioSample\" else []\n",
    "            current_data = doc\n",
    "\n",
    "            for part in path_parts:\n",
    "                current_data = current_data.get(part)\n",
    "                if current_data is None:\n",
    "                    break\n",
    "\n",
    "            if current_data:\n",
    "                if isinstance(current_data, dict):\n",
    "                    scalar_data = {\n",
    "                        k: [v] for k, v in current_data.items() if isinstance(v, (str, int, float, bool))\n",
    "                    }\n",
    "                    scalar_data[\"id\"] = [doc[\"id\"]]\n",
    "                    arrow_table = pa.Table.from_pydict(scalar_data)\n",
    "                elif isinstance(current_data, list) and all(isinstance(item, dict) for item in current_data):\n",
    "                    keys = set(key for item in current_data for key in item.keys())\n",
    "                    scalar_data = {\n",
    "                        k: [item.get(k, None) for item in current_data] for k in keys\n",
    "                    }\n",
    "                    scalar_data[\"id\"] = [doc[\"id\"]] * len(current_data)\n",
    "                    arrow_table = pa.Table.from_pydict(scalar_data)\n",
    "                else:\n",
    "                    print(f\"Skipping unexpected data structure for path '{path}': {current_data}\")\n",
    "                    continue\n",
    "\n",
    "                # Track columns for the path\n",
    "                all_columns[path].update(arrow_table.schema.names)\n",
    "\n",
    "                # Adjust DuckDB schema dynamically\n",
    "                table_name = path.split(\".\")[-1].lower()\n",
    "                existing_columns = conn.execute(f\"PRAGMA table_info({table_name})\").fetchall()\n",
    "                existing_column_names = {col[1] for col in existing_columns}\n",
    "\n",
    "                # Add missing columns to DuckDB\n",
    "                for col in arrow_table.schema.names:\n",
    "                    if col not in existing_column_names:\n",
    "                        col_escaped = f'\"{col}\"'  # Escape column name\n",
    "                        # print(f\"Adding missing column '{col}' to table '{table_name}'.\")\n",
    "                        col_type = (\n",
    "                            \"INTEGER\" if pa.types.is_integer(arrow_table.schema.field(col).type) else\n",
    "                            \"DOUBLE\" if pa.types.is_floating(arrow_table.schema.field(col).type) else\n",
    "                            \"TEXT\"\n",
    "                        )\n",
    "                        conn.execute(f\"ALTER TABLE {table_name} ADD COLUMN {col_escaped} {col_type}\")\n",
    "\n",
    "                # Fill missing columns in PyArrow table\n",
    "                for col in existing_column_names:\n",
    "                    if col not in arrow_table.schema.names:\n",
    "                        # print(f\"Filling missing column '{col}' with NULL values for table '{table_name}'.\")\n",
    "                        arrow_table = arrow_table.append_column(col, pa.nulls(len(arrow_table)))\n",
    "\n",
    "                # Insert data into DuckDB\n",
    "                conn.register(\"arrow_table\", arrow_table)\n",
    "                columns = \", \".join([f'\"{col}\"' for col in existing_column_names])\n",
    "                conn.execute(f\"INSERT INTO {table_name} ({columns}) SELECT {columns} FROM arrow_table\")\n",
    "\n",
    "        processed_docs += 1\n",
    "        if processed_docs % 1000 == 0:\n",
    "            current_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            print(f\"[{current_time}] Processed {processed_docs}/{total_docs} documents.\")\n",
    "\n",
    "    end_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    print(f\"[{end_time}] Completed processing {processed_docs} documents.\")"
   ],
   "id": "9169b89b35072e8",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T15:12:17.430335Z",
     "start_time": "2024-12-09T15:12:17.424969Z"
    }
   },
   "cell_type": "code",
   "source": [
    "paths = [\n",
    "    \"BioSample\",\n",
    "    \"BioSample.Attributes.Attribute\",\n",
    "    \"BioSample.Curation\",\n",
    "    \"BioSample.Description.Comment.Paragraph\",\n",
    "    \"BioSample.Description.Organism\",\n",
    "    \"BioSample.Description.Organism.OrganismName\",\n",
    "    \"BioSample.Description.Synonym\",\n",
    "    \"BioSample.Description.Title\",\n",
    "    \"BioSample.Ids.Id\",\n",
    "    \"BioSample.Links.Link\",\n",
    "    \"BioSample.Models.Model\",\n",
    "    \"BioSample.Owner.Name\",\n",
    "    \"BioSample.Package\",\n",
    "    \"BioSample.Status\"\n",
    "]\n",
    "\n",
    "max_docs =  10_000\n",
    "batch_size = 10_000\n",
    "\n",
    "# extract_all_paths_data(collection, duckdb_conn, paths, max_docs=max_docs, client=client, batch_size=batch_size)\n",
    "\n",
    "# extract_biosample_data_arrow(collection, duckdb_conn, paths, max_docs=max_docs, batch_size=batch_size)\n"
   ],
   "id": "389b7a0188a7261b",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T15:12:17.439911Z",
     "start_time": "2024-12-09T15:12:17.435366Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def profile_extraction(collection, conn, paths, max_docs=None, batch_size=5000):\n",
    "    \"\"\"\n",
    "    Profiles the extract_biosample_data_arrow function.\n",
    "    \"\"\"\n",
    "    profiler = cProfile.Profile()\n",
    "    profiler.enable()\n",
    "    extract_biosample_data_arrow(collection, conn, paths, max_docs=max_docs, batch_size=batch_size)\n",
    "    profiler.disable()\n",
    "    stats = pstats.Stats(profiler).sort_stats('cumulative')\n",
    "    stats.print_stats(10)  # Show the top 10 time-consuming calls\n"
   ],
   "id": "f44efbb0ebd867d1",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T15:15:20.274821Z",
     "start_time": "2024-12-09T15:12:17.442633Z"
    }
   },
   "cell_type": "code",
   "source": "profile_extraction(collection, duckdb_conn, paths, max_docs=max_docs, batch_size=batch_size)",
   "id": "d68b228375758849",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-12-09 10:12:17] Starting extraction for paths: ['BioSample', 'BioSample.Attributes.Attribute', 'BioSample.Curation', 'BioSample.Description.Comment.Paragraph', 'BioSample.Description.Organism', 'BioSample.Description.Organism.OrganismName', 'BioSample.Description.Synonym', 'BioSample.Description.Title', 'BioSample.Ids.Id', 'BioSample.Links.Link', 'BioSample.Models.Model', 'BioSample.Owner.Name', 'BioSample.Package', 'BioSample.Status']\n",
      "[2024-12-09 10:12:36] Processed 1000/10000 documents.\n",
      "[2024-12-09 10:12:56] Processed 2000/10000 documents.\n",
      "[2024-12-09 10:13:14] Processed 3000/10000 documents.\n",
      "[2024-12-09 10:13:30] Processed 4000/10000 documents.\n",
      "[2024-12-09 10:13:48] Processed 5000/10000 documents.\n",
      "[2024-12-09 10:14:06] Processed 6000/10000 documents.\n",
      "[2024-12-09 10:14:24] Processed 7000/10000 documents.\n",
      "[2024-12-09 10:14:43] Processed 8000/10000 documents.\n",
      "[2024-12-09 10:15:02] Processed 9000/10000 documents.\n",
      "[2024-12-09 10:15:20] Processed 10000/10000 documents.\n",
      "[2024-12-09 10:15:20] Completed processing 10000 documents.\n",
      "         6883527 function calls (6879940 primitive calls) in 182.755 seconds\n",
      "\n",
      "   Ordered by: cumulative time\n",
      "   List reduced from 1796 to 10 due to restriction <10>\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        1  175.824  175.824  182.755  182.755 /var/folders/vt/f297tpjn6n1b6dwkcwhhnmxm0000gp/T/ipykernel_31710/863202721.py:1(extract_biosample_data_arrow)\n",
      "    39052    0.417    0.000    1.469    0.000 /Users/MAM/Documents/gitrepos/external-metadata-awareness/.venv/lib/python3.10/site-packages/pyarrow/dataset.py:584(dataset)\n",
      "   345327    0.403    0.000    1.440    0.000 /Users/MAM/.pyenv/versions/3.10.13/lib/python3.10/_collections_abc.py:821(get)\n",
      "   345328    0.592    0.000    1.037    0.000 /Users/MAM/.pyenv/versions/3.10.13/lib/python3.10/os.py:675(__getitem__)\n",
      "   752105    0.371    0.000    0.918    0.000 /Users/MAM/.pyenv/versions/3.10.13/lib/python3.10/abc.py:117(__instancecheck__)\n",
      "    10001    0.019    0.000    0.899    0.000 /Users/MAM/Documents/gitrepos/external-metadata-awareness/.venv/lib/python3.10/site-packages/pymongo/synchronous/cursor.py:1280(__next__)\n",
      "    10001    0.031    0.000    0.880    0.000 /Users/MAM/Documents/gitrepos/external-metadata-awareness/.venv/lib/python3.10/site-packages/pymongo/synchronous/cursor.py:1250(next)\n",
      "        2    0.000    0.000    0.837    0.419 /Users/MAM/Documents/gitrepos/external-metadata-awareness/.venv/lib/python3.10/site-packages/pymongo/synchronous/cursor.py:1168(_refresh)\n",
      "        2    0.001    0.000    0.837    0.418 /Users/MAM/Documents/gitrepos/external-metadata-awareness/.venv/lib/python3.10/site-packages/pymongo/synchronous/cursor.py:1085(_send_message)\n",
      "      4/2    0.000    0.000    0.836    0.418 /Users/MAM/Documents/gitrepos/external-metadata-awareness/.venv/lib/python3.10/site-packages/pymongo/_csot.py:112(csot_wrapper)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T15:15:20.545603Z",
     "start_time": "2024-12-09T15:15:20.277808Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Close the connection when you're finished\n",
    "duckdb_conn.close()\n",
    "\n",
    "# close the pymongo connection\n",
    "client.close()"
   ],
   "id": "d0ff040778d26d07",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "3370.4docs/min. much slower than the pandas approach.",
   "id": "ed531de1ec15675c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
