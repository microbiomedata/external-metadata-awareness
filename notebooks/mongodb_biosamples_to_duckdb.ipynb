{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T13:48:50.642877Z",
     "start_time": "2024-12-09T13:48:49.178040Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pymongo import MongoClient\n",
    "\n",
    "import duckdb\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "import pprint\n",
    "\n",
    "import time\n"
   ],
   "id": "e68dcd943609255",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T13:48:50.648836Z",
     "start_time": "2024-12-09T13:48:50.645066Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_duckdb_file(filename):\n",
    "    \"\"\"\n",
    "    Creates a file-based DuckDB database and returns the connection.\n",
    "  \n",
    "    Args:\n",
    "      filename: The name of the DuckDB database file to create.\n",
    "  \n",
    "    Returns:\n",
    "      duckdb.DuckDBPyConnection: The DuckDB connection object.\n",
    "    \"\"\"\n",
    "    conn = duckdb.connect(database=filename)\n",
    "    return conn\n"
   ],
   "id": "e32bd2653ce252d5",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T13:48:50.659612Z",
     "start_time": "2024-12-09T13:48:50.650313Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Example usage:\n",
    "filename = \"biosamples.duckdb\"\n",
    "duckdb_conn = create_duckdb_file(filename)"
   ],
   "id": "e9f0e4e3acc0babb",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T13:48:50.675861Z",
     "start_time": "2024-12-09T13:48:50.661107Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# MongoDB connection details\n",
    "connection_string = \"mongodb://localhost:27017/\"\n",
    "db_name = \"biosamples\"\n",
    "collection_name = \"biosamples\"\n",
    "\n",
    "# Connect to MongoDB\n",
    "client = MongoClient(connection_string)\n",
    "db = client[db_name]\n",
    "collection = db[collection_name]"
   ],
   "id": "8bc12c0a82a5b072",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T13:48:50.684279Z",
     "start_time": "2024-12-09T13:48:50.679624Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Retrieve the first document\n",
    "first_document = collection.find_one()\n"
   ],
   "id": "efcac4a393739da5",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T13:48:50.688492Z",
     "start_time": "2024-12-09T13:48:50.685778Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # Print the document\n",
    "# pprint.pprint(first_document)"
   ],
   "id": "ae7f62c60dea697b",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T13:48:50.694009Z",
     "start_time": "2024-12-09T13:48:50.690055Z"
    }
   },
   "cell_type": "code",
   "source": "# df['content'].value_counts()",
   "id": "39749d18f30ade87",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T13:48:50.719264Z",
     "start_time": "2024-12-09T13:48:50.696029Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def infer_duckdb_type(series, col_name):\n",
    "    if col_name.lower() == \"id\":\n",
    "        return \"BIGINT\"\n",
    "    if pd.api.types.is_integer_dtype(series):\n",
    "        return \"BIGINT\"\n",
    "    elif pd.api.types.is_float_dtype(series):\n",
    "        return \"DOUBLE\"\n",
    "    elif pd.api.types.is_bool_dtype(series):\n",
    "        return \"BOOLEAN\"\n",
    "    return \"TEXT\"\n",
    "\n",
    "def ensure_columns_exist(conn, table_name, df):\n",
    "    table_info = conn.execute(f\"PRAGMA table_info({table_name})\").fetchall()\n",
    "    existing_columns = {col[1].lower() for col in table_info}\n",
    "    new_columns = [c for c in df.columns if c.lower() not in existing_columns]\n",
    "    if new_columns:\n",
    "        print(f\"{datetime.now().isoformat()}: Adding {len(new_columns)} new column(s) to {table_name}.\")\n",
    "    for col in new_columns:\n",
    "        dtype = infer_duckdb_type(df[col], col)\n",
    "        alter_sql = f'ALTER TABLE {table_name} ADD COLUMN \"{col}\" {dtype}'\n",
    "        conn.execute(alter_sql)\n",
    "\n",
    "def insert_df(conn, table_name, df):\n",
    "    table_info = conn.execute(f\"PRAGMA table_info({table_name})\").fetchall()\n",
    "    existing_columns = [col[1] for col in table_info]\n",
    "\n",
    "    for col in existing_columns:\n",
    "        if col not in df.columns:\n",
    "            df[col] = None\n",
    "\n",
    "    df = df[existing_columns]\n",
    "\n",
    "    conn.register(\"temp_df\", df)\n",
    "    conn.execute(f\"INSERT INTO {table_name} SELECT * FROM temp_df\")\n",
    "    conn.unregister(\"temp_df\")\n",
    "\n",
    "def process_data(data, id_value):\n",
    "    if isinstance(data, dict):\n",
    "        scalar_data = {k: v for k, v in data.items() if isinstance(v, (str, int, float, bool))}\n",
    "        scalar_data[\"id\"] = int(id_value) if id_value is not None else None\n",
    "        return pd.DataFrame([scalar_data])\n",
    "    elif isinstance(data, list) and all(isinstance(item, dict) for item in data):\n",
    "        all_scalar_data = []\n",
    "        for item in data:\n",
    "            scalar_data = {k: v for k, v in item.items() if isinstance(v, (str, int, float, bool))}\n",
    "            scalar_data[\"id\"] = int(id_value) if id_value is not None else None\n",
    "            all_scalar_data.append(scalar_data)\n",
    "        if all_scalar_data:\n",
    "            return pd.DataFrame(all_scalar_data)\n",
    "        else:\n",
    "            return None\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def extract_all_paths_data(collection, conn, paths, max_docs=None, client=None, batch_size=10000):\n",
    "    \"\"\"\n",
    "    Process multiple paths in a single scan of the MongoDB collection.\n",
    "    Provides verbose status updates:\n",
    "      - A start message at the beginning.\n",
    "      - Roughly every minute, prints how many docs have been processed so far.\n",
    "      - Messages when flushing batches and at the end.\n",
    "    \"\"\"\n",
    "\n",
    "    if client is None:\n",
    "        raise ValueError(\"Client must be provided to start a session for no_cursor_timeout.\")\n",
    "\n",
    "    # Data structures to track per-path info\n",
    "    path_info = {}\n",
    "    for path in paths:\n",
    "        table_name = path.split(\".\")[-1].replace(\"-\", \"_\").replace(\".\", \"_\").lower()\n",
    "        path_info[path] = {\n",
    "            \"table_name\": table_name,\n",
    "            \"table_created\": False,\n",
    "            \"batch\": [],\n",
    "            \"processed_docs\": 0  # how many docs contributed rows for this path\n",
    "        }\n",
    "\n",
    "    def flush_batch(path, combined_df):\n",
    "        info = path_info[path]\n",
    "        if not info[\"table_created\"]:\n",
    "            # Create table from the first batch\n",
    "            schema_parts = []\n",
    "            for col in combined_df.columns:\n",
    "                dtype = infer_duckdb_type(combined_df[col], col)\n",
    "                schema_parts.append(f'\"{col}\" {dtype}')\n",
    "            schema_sql = \", \".join(schema_parts)\n",
    "            conn.execute(f\"CREATE TABLE {info['table_name']} ({schema_sql})\")\n",
    "            info[\"table_created\"] = True\n",
    "        else:\n",
    "            ensure_columns_exist(conn, info['table_name'], combined_df)\n",
    "\n",
    "        insert_df(conn, info['table_name'], combined_df)\n",
    "        print(f\"{datetime.now().isoformat()}: Flushed batch for {info['table_name']}, total {info['processed_docs']} docs processed for this path so far.\")\n",
    "        info[\"batch\"].clear()\n",
    "\n",
    "    # Print a start message\n",
    "    print(f\"{datetime.now().isoformat()}: Starting extraction for paths: {paths}\")\n",
    "    start_time = time.time()\n",
    "    last_status_time = start_time\n",
    "\n",
    "    with client.start_session() as session:\n",
    "        cursor = collection.find({}, no_cursor_timeout=True, session=session)\n",
    "        doc_count = 0\n",
    "        for doc in cursor:\n",
    "            if max_docs is not None and doc_count >= max_docs:\n",
    "                break\n",
    "            doc_count += 1\n",
    "\n",
    "            # Extract data for each path\n",
    "            for path in paths:\n",
    "                if path == \"BioSample\":\n",
    "                    # top-level\n",
    "                    scalar_data = {k: v for k, v in doc.items() if isinstance(v, (str, int, float, bool))}\n",
    "                    scalar_data[\"id\"] = int(doc[\"id\"]) if \"id\" in doc else None\n",
    "                    df = pd.DataFrame([scalar_data]) if scalar_data else None\n",
    "                else:\n",
    "                    path_parts = path.split(\".\")[1:]\n",
    "                    current_data = doc\n",
    "                    for part in path_parts:\n",
    "                        current_data = current_data.get(part)\n",
    "                        if current_data is None:\n",
    "                            break\n",
    "                    if current_data is not None:\n",
    "                        df = process_data(current_data, doc.get('id'))\n",
    "                    else:\n",
    "                        df = None\n",
    "\n",
    "                if df is not None and not df.empty:\n",
    "                    info = path_info[path]\n",
    "                    info[\"batch\"].append(df)\n",
    "                    info[\"processed_docs\"] += 1\n",
    "\n",
    "                    # Check if we need to flush for this path\n",
    "                    if len(info[\"batch\"]) >= batch_size:\n",
    "                        combined_df = pd.concat(info[\"batch\"], ignore_index=True)\n",
    "                        flush_batch(path, combined_df)\n",
    "\n",
    "            # Periodic status update roughly every minute\n",
    "            current_time = time.time()\n",
    "            if (current_time - last_status_time) > 60:\n",
    "                # Print a status message\n",
    "                print(f\"{datetime.now().isoformat()}: Processed {doc_count} documents so far.\")\n",
    "                for p, info in path_info.items():\n",
    "                    print(f\"  Path: {p}, Table: {info['table_name']}, Docs for path: {info['processed_docs']}, Batch size: {len(info['batch'])}\")\n",
    "                last_status_time = current_time\n",
    "\n",
    "        cursor.close()\n",
    "\n",
    "    # Flush remaining batches\n",
    "    for path, info in path_info.items():\n",
    "        if info[\"batch\"]:\n",
    "            combined_df = pd.concat(info[\"batch\"], ignore_index=True)\n",
    "            flush_batch(path, combined_df)\n",
    "            print(f\"{datetime.now().isoformat()}: Final flush - total {info['processed_docs']} documents processed for {info['table_name']}.\")\n",
    "\n",
    "    # Print a completion message\n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"{datetime.now().isoformat()}: Completed extraction. Processed {doc_count} documents in {total_time:.2f} seconds.\")\n",
    "    for p, info in path_info.items():\n",
    "        print(f\"  Path: {p}, Table: {info['table_name']}, Total Docs: {info['processed_docs']}\")\n"
   ],
   "id": "9169b89b35072e8",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T13:48:51.705711Z",
     "start_time": "2024-12-09T13:48:50.720545Z"
    }
   },
   "cell_type": "code",
   "source": [
    "paths = [\n",
    "    \"BioSample\",\n",
    "    \"BioSample.Attributes.Attribute\",\n",
    "    \"BioSample.Curation\",\n",
    "    \"BioSample.Description.Comment.Paragraph\",\n",
    "    \"BioSample.Description.Organism\",\n",
    "    \"BioSample.Description.Organism.OrganismName\",\n",
    "    \"BioSample.Description.Synonym\",\n",
    "    \"BioSample.Description.Title\",\n",
    "    \"BioSample.Ids.Id\",\n",
    "    \"BioSample.Links.Link\",\n",
    "    \"BioSample.Models.Model\",\n",
    "    \"BioSample.Owner.Name\",\n",
    "    \"BioSample.Package\",\n",
    "    \"BioSample.Status\"\n",
    "]\n",
    "\n",
    "max_docs = 1_000_000\n",
    "batch_size =  10_000\n",
    "\n",
    "extract_all_paths_data(collection, duckdb_conn, paths, max_docs=max_docs, client=client, batch_size=batch_size)\n"
   ],
   "id": "389b7a0188a7261b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-09T08:48:50.722528: Starting extraction for paths: ['BioSample', 'BioSample.Attributes.Attribute', 'BioSample.Curation', 'BioSample.Description.Comment.Paragraph', 'BioSample.Description.Organism', 'BioSample.Description.Organism.OrganismName', 'BioSample.Description.Synonym', 'BioSample.Description.Title', 'BioSample.Ids.Id', 'BioSample.Links.Link', 'BioSample.Models.Model', 'BioSample.Owner.Name', 'BioSample.Package', 'BioSample.Status']\n",
      "2024-12-09T08:48:50.805247: Flushed batch for biosample, total 10 docs processed for this path so far.\n",
      "2024-12-09T08:48:50.815271: Flushed batch for paragraph, total 10 docs processed for this path so far.\n",
      "2024-12-09T08:48:50.821451: Flushed batch for organism, total 10 docs processed for this path so far.\n",
      "2024-12-09T08:48:50.827214: Flushed batch for title, total 10 docs processed for this path so far.\n",
      "2024-12-09T08:48:50.837004: Flushed batch for id, total 10 docs processed for this path so far.\n",
      "2024-12-09T08:48:50.842359: Flushed batch for model, total 10 docs processed for this path so far.\n",
      "2024-12-09T08:48:50.848507: Flushed batch for name, total 10 docs processed for this path so far.\n",
      "2024-12-09T08:48:50.854060: Flushed batch for package, total 10 docs processed for this path so far.\n",
      "2024-12-09T08:48:50.859962: Flushed batch for status, total 10 docs processed for this path so far.\n",
      "2024-12-09T08:48:50.883598: Flushed batch for attribute, total 10 docs processed for this path so far.\n",
      "2024-12-09T08:48:50.900484: Flushed batch for link, total 10 docs processed for this path so far.\n",
      "2024-12-09T08:48:50.926747: Flushed batch for biosample, total 20 docs processed for this path so far.\n",
      "2024-12-09T08:48:50.933108: Flushed batch for paragraph, total 20 docs processed for this path so far.\n",
      "2024-12-09T08:48:50.938539: Flushed batch for organism, total 20 docs processed for this path so far.\n",
      "2024-12-09T08:48:50.945422: Flushed batch for title, total 20 docs processed for this path so far.\n",
      "2024-12-09T08:48:50.953614: Flushed batch for id, total 20 docs processed for this path so far.\n",
      "2024-12-09T08:48:50.961284: Flushed batch for model, total 20 docs processed for this path so far.\n",
      "2024-12-09T08:48:50.967269: Flushed batch for name, total 20 docs processed for this path so far.\n",
      "2024-12-09T08:48:50.972670: Flushed batch for package, total 20 docs processed for this path so far.\n",
      "2024-12-09T08:48:50.980380: Flushed batch for status, total 20 docs processed for this path so far.\n",
      "2024-12-09T08:48:51.007639: Flushed batch for attribute, total 20 docs processed for this path so far.\n",
      "2024-12-09T08:48:51.025975: Flushed batch for link, total 20 docs processed for this path so far.\n",
      "2024-12-09T08:48:51.037041: Flushed batch for biosample, total 30 docs processed for this path so far.\n",
      "2024-12-09T08:48:51.042726: Flushed batch for paragraph, total 30 docs processed for this path so far.\n",
      "2024-12-09T08:48:51.047405: Flushed batch for organism, total 30 docs processed for this path so far.\n",
      "2024-12-09T08:48:51.051832: Flushed batch for title, total 30 docs processed for this path so far.\n",
      "2024-12-09T08:48:51.058115: Flushed batch for id, total 30 docs processed for this path so far.\n",
      "2024-12-09T08:48:51.062067: Flushed batch for model, total 30 docs processed for this path so far.\n",
      "2024-12-09T08:48:51.066554: Flushed batch for name, total 30 docs processed for this path so far.\n",
      "2024-12-09T08:48:51.073064: Flushed batch for package, total 30 docs processed for this path so far.\n",
      "2024-12-09T08:48:51.078678: Flushed batch for status, total 30 docs processed for this path so far.\n",
      "2024-12-09T08:48:51.097979: Flushed batch for attribute, total 30 docs processed for this path so far.\n",
      "2024-12-09T08:48:51.114576: Flushed batch for biosample, total 40 docs processed for this path so far.\n",
      "2024-12-09T08:48:51.119027: Flushed batch for paragraph, total 40 docs processed for this path so far.\n",
      "2024-12-09T08:48:51.123641: Flushed batch for organism, total 40 docs processed for this path so far.\n",
      "2024-12-09T08:48:51.127866: Flushed batch for title, total 40 docs processed for this path so far.\n",
      "2024-12-09T08:48:51.133549: Flushed batch for id, total 40 docs processed for this path so far.\n",
      "2024-12-09T08:48:51.138716: Flushed batch for model, total 40 docs processed for this path so far.\n",
      "2024-12-09T08:48:51.144810: Flushed batch for name, total 40 docs processed for this path so far.\n",
      "2024-12-09T08:48:51.149990: Flushed batch for package, total 40 docs processed for this path so far.\n",
      "2024-12-09T08:48:51.155277: Flushed batch for status, total 40 docs processed for this path so far.\n",
      "2024-12-09T08:48:51.180679: Flushed batch for attribute, total 40 docs processed for this path so far.\n",
      "2024-12-09T08:48:51.198380: Flushed batch for biosample, total 50 docs processed for this path so far.\n",
      "2024-12-09T08:48:51.203616: Flushed batch for paragraph, total 50 docs processed for this path so far.\n",
      "2024-12-09T08:48:51.209169: Flushed batch for organism, total 50 docs processed for this path so far.\n",
      "2024-12-09T08:48:51.216021: Flushed batch for title, total 50 docs processed for this path so far.\n",
      "2024-12-09T08:48:51.223467: Flushed batch for id, total 50 docs processed for this path so far.\n",
      "2024-12-09T08:48:51.228281: Flushed batch for model, total 50 docs processed for this path so far.\n",
      "2024-12-09T08:48:51.233268: Flushed batch for name, total 50 docs processed for this path so far.\n",
      "2024-12-09T08:48:51.238320: Flushed batch for package, total 50 docs processed for this path so far.\n",
      "2024-12-09T08:48:51.243762: Flushed batch for status, total 50 docs processed for this path so far.\n",
      "2024-12-09T08:48:51.317170: Flushed batch for biosample, total 60 docs processed for this path so far.\n",
      "2024-12-09T08:48:51.322694: Flushed batch for paragraph, total 60 docs processed for this path so far.\n",
      "2024-12-09T08:48:51.327632: Flushed batch for organism, total 60 docs processed for this path so far.\n",
      "2024-12-09T08:48:51.331981: Flushed batch for title, total 60 docs processed for this path so far.\n",
      "2024-12-09T08:48:51.337953: Flushed batch for id, total 60 docs processed for this path so far.\n",
      "2024-12-09T08:48:51.342377: Flushed batch for model, total 60 docs processed for this path so far.\n",
      "2024-12-09T08:48:51.346811: Flushed batch for name, total 60 docs processed for this path so far.\n",
      "2024-12-09T08:48:51.351033: Flushed batch for package, total 60 docs processed for this path so far.\n",
      "2024-12-09T08:48:51.355331: Flushed batch for status, total 60 docs processed for this path so far.\n",
      "2024-12-09T08:48:51.372791: Flushed batch for attribute, total 50 docs processed for this path so far.\n",
      "2024-12-09T08:48:51.390442: Flushed batch for biosample, total 70 docs processed for this path so far.\n",
      "2024-12-09T08:48:51.398040: Flushed batch for paragraph, total 70 docs processed for this path so far.\n",
      "2024-12-09T08:48:51.402924: Flushed batch for organism, total 70 docs processed for this path so far.\n",
      "2024-12-09T08:48:51.407390: Flushed batch for title, total 70 docs processed for this path so far.\n",
      "2024-12-09T08:48:51.414619: Flushed batch for id, total 70 docs processed for this path so far.\n",
      "2024-12-09T08:48:51.419873: Flushed batch for model, total 70 docs processed for this path so far.\n",
      "2024-12-09T08:48:51.425209: Flushed batch for name, total 70 docs processed for this path so far.\n",
      "2024-12-09T08:48:51.430909: Flushed batch for package, total 70 docs processed for this path so far.\n",
      "2024-12-09T08:48:51.435468: Flushed batch for status, total 70 docs processed for this path so far.\n",
      "2024-12-09T08:48:51.456889: Flushed batch for attribute, total 60 docs processed for this path so far.\n",
      "2024-12-09T08:48:51.468955: Flushed batch for biosample, total 80 docs processed for this path so far.\n",
      "2024-12-09T08:48:51.473013: Flushed batch for paragraph, total 80 docs processed for this path so far.\n",
      "2024-12-09T08:48:51.476874: Flushed batch for organism, total 80 docs processed for this path so far.\n",
      "2024-12-09T08:48:51.480460: Flushed batch for title, total 80 docs processed for this path so far.\n",
      "2024-12-09T08:48:51.485507: Flushed batch for id, total 80 docs processed for this path so far.\n",
      "2024-12-09T08:48:51.489860: Flushed batch for model, total 80 docs processed for this path so far.\n",
      "2024-12-09T08:48:51.495884: Flushed batch for name, total 80 docs processed for this path so far.\n",
      "2024-12-09T08:48:51.500500: Flushed batch for package, total 80 docs processed for this path so far.\n",
      "2024-12-09T08:48:51.505232: Flushed batch for status, total 80 docs processed for this path so far.\n",
      "2024-12-09T08:48:51.535526: Flushed batch for biosample, total 90 docs processed for this path so far.\n",
      "2024-12-09T08:48:51.540966: Flushed batch for paragraph, total 90 docs processed for this path so far.\n",
      "2024-12-09T08:48:51.547615: Flushed batch for organism, total 90 docs processed for this path so far.\n",
      "2024-12-09T08:48:51.552831: Flushed batch for title, total 90 docs processed for this path so far.\n",
      "2024-12-09T08:48:51.559355: Flushed batch for id, total 90 docs processed for this path so far.\n",
      "2024-12-09T08:48:51.566374: Flushed batch for model, total 90 docs processed for this path so far.\n",
      "2024-12-09T08:48:51.572390: Flushed batch for name, total 90 docs processed for this path so far.\n",
      "2024-12-09T08:48:51.578106: Flushed batch for package, total 90 docs processed for this path so far.\n",
      "2024-12-09T08:48:51.586548: Flushed batch for status, total 90 docs processed for this path so far.\n",
      "2024-12-09T08:48:51.596410: Adding 1 new column(s) to attribute.\n",
      "2024-12-09T08:48:51.605890: Flushed batch for attribute, total 70 docs processed for this path so far.\n",
      "2024-12-09T08:48:51.638907: Flushed batch for biosample, total 100 docs processed for this path so far.\n",
      "2024-12-09T08:48:51.645302: Flushed batch for paragraph, total 100 docs processed for this path so far.\n",
      "2024-12-09T08:48:51.651947: Flushed batch for organism, total 100 docs processed for this path so far.\n",
      "2024-12-09T08:48:51.657225: Flushed batch for title, total 100 docs processed for this path so far.\n",
      "2024-12-09T08:48:51.667259: Flushed batch for id, total 100 docs processed for this path so far.\n",
      "2024-12-09T08:48:51.672908: Flushed batch for model, total 100 docs processed for this path so far.\n",
      "2024-12-09T08:48:51.679702: Flushed batch for name, total 100 docs processed for this path so far.\n",
      "2024-12-09T08:48:51.685257: Flushed batch for package, total 100 docs processed for this path so far.\n",
      "2024-12-09T08:48:51.690955: Flushed batch for status, total 100 docs processed for this path so far.\n",
      "2024-12-09T08:48:51.698886: Flushed batch for attribute, total 71 docs processed for this path so far.\n",
      "2024-12-09T08:48:51.698933: Final flush - total 71 documents processed for attribute.\n",
      "2024-12-09T08:48:51.703623: Flushed batch for organismname, total 4 docs processed for this path so far.\n",
      "2024-12-09T08:48:51.703701: Final flush - total 4 documents processed for organismname.\n",
      "2024-12-09T08:48:51.703722: Completed extraction. Processed 100 documents in 0.98 seconds.\n",
      "  Path: BioSample, Table: biosample, Total Docs: 100\n",
      "  Path: BioSample.Attributes.Attribute, Table: attribute, Total Docs: 71\n",
      "  Path: BioSample.Curation, Table: curation, Total Docs: 0\n",
      "  Path: BioSample.Description.Comment.Paragraph, Table: paragraph, Total Docs: 100\n",
      "  Path: BioSample.Description.Organism, Table: organism, Total Docs: 100\n",
      "  Path: BioSample.Description.Organism.OrganismName, Table: organismname, Total Docs: 4\n",
      "  Path: BioSample.Description.Synonym, Table: synonym, Total Docs: 0\n",
      "  Path: BioSample.Description.Title, Table: title, Total Docs: 100\n",
      "  Path: BioSample.Ids.Id, Table: id, Total Docs: 100\n",
      "  Path: BioSample.Links.Link, Table: link, Total Docs: 20\n",
      "  Path: BioSample.Models.Model, Table: model, Total Docs: 100\n",
      "  Path: BioSample.Owner.Name, Table: name, Total Docs: 100\n",
      "  Path: BioSample.Package, Table: package, Total Docs: 100\n",
      "  Path: BioSample.Status, Table: status, Total Docs: 100\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T13:48:51.772652Z",
     "start_time": "2024-12-09T13:48:51.707483Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Close the connection when you're finished\n",
    "duckdb_conn.close()\n",
    "\n",
    "# close the pymongo connection\n",
    "client.close()"
   ],
   "id": "d0ff040778d26d07",
   "outputs": [],
   "execution_count": 10
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
