"body": "Re: https://github.com/microbiomedata/issues/issues/83. Basically we have at least one publication out there with links in it to https://microbiomedata.github.io/nmdc-metadata/. There are two issues: first, that URL currently doesn't resolve to anything because GitHub made private repos (such as this one) ineligible for hosting GitHub Pages sites. Second, if we simply made this repo public again, the `gh-pages` branch currently holds a bunch of old, outdated auto-generated schema docs.\r\n\r\nThese changes replace the old, outdated auto-generated schema docs in the `gh-pages` branch with an HTML-file redirect to https://microbiomedata.github.io/nmdc-schema/. \r\n\r\nOnce these changes are merged two things need to happen:\r\n\r\n* A repo admin needs to make this repo public again (or give me admin privileges to do the same)\r\n* I will go into the `main` branch and remove the workflow file that publishes to GitHub Pages so that the redirect isn't accidentally overwritten if someone happens to push changes to this repo in the future",
"body": null,
"body": "Biosample IDs have been made & most EMSL & JGI data are mapped. There's some metaT samples that aren't linked to the metaTs.  Map the datasets to 1 biosample where they match",
"body": "Emailed Donny requesting either a file I can work with to update or a meeting with him to discuss. \r\nPlease move to June Sprint\r\n",
"body": "The samples that needed mapped should not be on the data portal @ssarrafan , can you see if there's already a ticket for removing these SPRUCE biosamples? If not, can you make one?",
"body": "> The samples that needed mapped should not be on the data portal @ssarrafan , can you see if there's already a ticket for removing these SPRUCE biosamples? If not, can you make one?\r\n\r\nWould this be something that's on Donny's radar to remove?  Can we use the Change Sheets training on Wednesday to do this?  ",
"body": null,
"body": "Once I provide the sample matching they will need updated / correct on the portal\r\n",
"body": "@emileyfadrosh moving this to the backlog. Let me know if it should be assigned to someone else. \r\nFYI @dehays ",
"body": "I'm working on this one, as a priority for summer school. Can we move this back into the June Sprint?\r\n\r\nI've identified the biosample corrections. Next is to just correct the IDs.\r\n@emileyfadrosh \r\n@ssarrafan ",
"body": "Sure it's back in the June sprint @mslarae13 ",
"body": "The metaG and metaT samples that needed linked need removed from the portal. These are not part of Chris Schadt's project. \r\nSee https://github.com/microbiomedata/nmdc-runtime/issues/128 for correction",
"body": null,
"body": "Once I provide the metaG fractions that are linked to like biosamples we will need to correct them on the portal.\r\n\r\nAdditionally, we should see about getting a line of text added that indicates \"SIP MetaG fraction\" and \"NOM-Water Extract (Methanol, Chloroform)\" added to the portal somewhere so it's understood WHY there's 3 metaGs for 1 biosamples",
"body": "Duplicated https://github.com/microbiomedata/nmdc-metadata/issues/440",
"body": null,
"body": "Data for EMSL proteomics and NOM have been mapped to common biosamples.\r\nNeed to add the metaG maps",
"body": "Not much progress this month. Please move to June.\r\nWill need the same data compilation from the DB with Donny's help as I need for SPRUCE",
"body": "> Not much progress this month. Please move to June.\r\n> Will need the same data compilation from the DB with Donny's help as I need for SPRUCE\r\n\r\n@dwinston FYI",
"body": "@mslarae13 should I move this issue to July? IS it still priority?  ",
"body": "Yes, but other tickets are dependent upon this. I recommend backlog for now",
"body": null,
"body": "Need to add a comment or some indicator / line of text added that indicates \"SIP MetaG fraction\" and \"NOM-Water Extract (Methanol, Chloroform)\" to the portal somewhere so it's understood WHY there's 3 metaGs for 1 biosamples",
"body": "@emileyfadrosh moving this to the backlog. Let me know if it should be assigned to someone else. \r\nFYI @dehays ",
"body": "Finally looked at these. Are we going to leave the metaG data that is linked to the same biosample separate for the review? Do we want to have this fixed for the review? I am guessing nothing happened on this while I was out?\r\n@emileyfadrosh \r\n@ssarrafan ",
"body": "@emileyfadrosh  @mslarae13 can this be closed or there is work to be done here?",
"body": "There's still work to be done. The added preparation metadata for NOM will solve that problem when the refactoring work is merged in. \r\n\r\nBut we haven't identified how we want to do this for sequencing.",
"body": null,
"body": "I don't know what the current plans are involving MP samples.  Assigning to Montana as I think she is most involved in that.",
"body": "IN the short term (June 2022) we want searchable biosamples that are common to potentially 3 sequencing project, 3 NOM instrument runs and ~25 metaP\r\n\r\nProcess discussed involves creating new nmdc: biosamples that replace the 3 DNA biosamples that were imported from GOLD.  Input on NMDC omics_processing will need to be updated.\r\n\r\n@mslarae13 ",
"body": "Here are 20 omics_processing docs that point to data objects via has_output that do not exist in data_object_set:\r\n\r\nemsl:598506\r\nemsl:598508\r\nemsl:598509\r\nemsl:598510\r\nemsl:598511\r\nemsl:598512\r\nemsl:598513\r\nemsl:598515\r\nemsl:598516\r\nemsl:598517\r\nemsl:598520\r\nemsl:598846\r\nemsl:598847\r\nemsl:598848\r\nemsl:598849\r\nemsl:598850\r\nemsl:598851\r\nemsl:598852\r\nemsl:598853\r\ngold:Gp0208380",
"body": "An omics processing doc references it as output:\r\n\r\nhttps://api.dev.microbiomedata.org/activities?filter=has_output:emsl:output_598506\r\n\r\nbut it is not in the data objects collection:\r\n\r\nhttps://api.dev.microbiomedata.org/data_objects?filter=id:emsl:output_598506\r\n\r\nfor reference, data objects with the \"emsl:output_\" prefix:\r\n\r\nhttps://api.dev.microbiomedata.org/data_objects?filter=id.search:^emsl:output_\r\n\r\n@dehays who to assign?\r\n\r\n",
"body": "Goal is to include 19 SPRUCE study metaproteomics analysis activities.  Status is that these exist and have been added to NMDC Mongo - but failed ingest to NMDC Postgres because they referred to instrument process (omics_processing_ records that do not exist.\r\n\r\nSam working to create those omics_processing records.\r\n\r\n`[\r\n{\r\n    \"id\": \"emsl:598849\",\r\n    \"name\": \"SpruceW_P10_15_22Jun17_Pippin_17-04-06\",\r\n    \"description\": \"High res MS with high res HCD MSn\",\r\n    \"has_input\": [\"gold:Gb0153621\"],\r\n    \"has_output\": [\"emsl:output_598849\"],\r\n    \"part_of\": [\"gold:Gs0110138\"],\r\n    \"instrument_name\": \"QExactHF03\",\r\n    \"omics_type\": {\r\n        \"has_raw_value\": \"Proteomics\"\r\n    },\r\n    \"processing_institution\": \"Environmental Molecular Sciences Lab\",\r\n    \"type\": \"nmdc:OmicsProcessing\"\r\n}\r\n{\r\n    \"id\": \"emsl:598852\",\r\n    \"name\": \"SpruceW_P10_45_22Jun17_Pippin_17-04-06\",\r\n    \"description\": \"High res MS with high res HCD MSn\",\r\n    \"has_input\": [\"gold:Gb0153622\"],\r\n    \"has_output\": [\"emsl:output_598852\"],\r\n    \"part_of\": [\"gold:Gs0110138\"],\r\n    \"instrument_name\": \"QExactHF03\",\r\n    \"omics_type\": {\r\n        \"has_raw_value\": \"Proteomics\"\r\n    },\r\n    \"processing_institution\": \"Environmental Molecular Sciences Lab\",\r\n    \"type\": \"nmdc:OmicsProcessing\"\r\n}\r\n{\r\n    \"id\": \"emsl:598515\",\r\n    \"name\": \"SpruceW_P10_87_22Jun17_Pippin_17-04-06\",\r\n    \"description\": \"High res MS with high res HCD MSn\",\r\n    \"has_input\": [\"gold:Gb0153623\"],\r\n    \"has_output\": [\"emsl:output_598515\"],\r\n    \"part_of\": [\"gold:Gs0110138\"],\r\n    \"instrument_name\": \"QExactHF03\",\r\n    \"omics_type\": {\r\n        \"has_raw_value\": \"Proteomics\"\r\n    },\r\n    \"processing_institution\": \"Environmental Molecular Sciences Lab\",\r\n    \"type\": \"nmdc:OmicsProcessing\"\r\n}\r\n{\r\n    \"id\": \"emsl:598853\",\r\n    \"name\": \"SpruceW_P13_15_22Jun17_Pippin_17-04-06\",\r\n    \"description\": \"High res MS with high res HCD MSn\",\r\n    \"has_input\": [\"gold:Gb0153629\"],\r\n    \"has_output\": [\"emsl:output_598853\"],\r\n    \"part_of\": [\"gold:Gs0110138\"],\r\n    \"instrument_name\": \"QExactHF03\",\r\n    \"omics_type\": {\r\n        \"has_raw_value\": \"Proteomics\"\r\n    },\r\n    \"processing_institution\": \"Environmental Molecular Sciences Lab\",\r\n    \"type\": \"nmdc:OmicsProcessing\"\r\n}\r\n{\r\n    \"id\": \"emsl:598850\",\r\n    \"name\": \"SpruceW_P13_87A_22Jun17_Pippin_17-04-06\",\r\n    \"description\": \"High res MS with high res HCD MSn\",\r\n    \"has_input\": [\"gold:Gb0153631\"],\r\n    \"has_output\": [\"emsl:output_598850\"],\r\n    \"part_of\": [\"gold:Gs0110138\"],\r\n    \"instrument_name\": \"QExactHF03\",\r\n    \"omics_type\": {\r\n        \"has_raw_value\": \"Proteomics\"\r\n    },\r\n    \"processing_institution\": \"Environmental Molecular Sciences Lab\",\r\n    \"type\": \"nmdc:OmicsProcessing\"\r\n}\r\n{\r\n    \"id\": \"emsl:598509\",\r\n    \"name\": \"SpruceW_P13_87B_22Jun17_Pippin_17-04-06\",\r\n    \"description\": \"High res MS with high res HCD MSn\",\r\n    \"has_input\": [\"gold:Gb0153631\"],\r\n    \"has_output\": [\"emsl:output_598509\"],\r\n    \"part_of\": [\"gold:Gs0110138\"],\r\n    \"instrument_name\": \"QExactHF03\",\r\n    \"omics_type\": {\r\n        \"has_raw_value\": \"Proteomics\"\r\n    },\r\n    \"processing_institution\": \"Environmental Molecular Sciences Lab\",\r\n    \"type\": \"nmdc:OmicsProcessing\"\r\n}\r\n{\r\n    \"id\": \"emsl:598517\",\r\n    \"name\": \"SpruceW_P17_15_22Jun17_Pippin_17-04-06\",\r\n    \"description\": \"High res MS with high res HCD MSn\",\r\n    \"has_input\": [\"gold:Gb0153637\"],\r\n    \"has_output\": [\"emsl:output_598517\"],\r\n    \"part_of\": [\"gold:Gs0110138\"],\r\n    \"instrument_name\": \"QExactHF03\",\r\n    \"omics_type\": {\r\n        \"has_raw_value\": \"Proteomics\"\r\n    },\r\n    \"processing_institution\": \"Environmental Molecular Sciences Lab\",\r\n    \"type\": \"nmdc:OmicsProcessing\"\r\n}\r\n{\r\n    \"id\": \"emsl:598847\",\r\n    \"name\": \"SpruceW_P17_45_22Jun17_Pippin_17-04-06\",\r\n    \"description\": \"High res MS with high res HCD MSn\",\r\n    \"has_input\": [\"gold:Gb0153638\"],\r\n    \"has_output\": [\"emsl:output_598847\"],\r\n    \"part_of\": [\"gold:Gs0110138\"],\r\n    \"instrument_name\": \"QExactHF03\",\r\n    \"omics_type\": {\r\n        \"has_raw_value\": \"Proteomics\"\r\n    },\r\n    \"processing_institution\": \"Environmental Molecular Sciences Lab\",\r\n    \"type\": \"nmdc:OmicsProcessing\"\r\n}\r\n{\r\n    \"id\": \"emsl:598511\",\r\n    \"name\": \"SpruceW_P17_87_22Jun17_Pippin_17-04-06\",\r\n    \"description\": \"High res MS with high res HCD MSn\",\r\n    \"has_input\": [\"gold:Gb0153639\"],\r\n    \"has_output\": [\"emsl:output_598511\"],\r\n    \"part_of\": [\"gold:Gs0110138\"],\r\n    \"instrument_name\": \"QExactHF03\",\r\n    \"omics_type\": {\r\n        \"has_raw_value\": \"Proteomics\"\r\n    },\r\n    \"processing_institution\": \"Environmental Molecular Sciences Lab\",\r\n    \"type\": \"nmdc:OmicsProcessing\"\r\n}\r\n{\r\n    \"id\": \"emsl:598506\",\r\n    \"name\": \"SpruceW_P19_15_22Jun17_Pippin_17-04-06\",\r\n    \"description\": \"High res MS with high res HCD MSn\",\r\n    \"has_input\": [\"gold:Gb0153641\"],\r\n    \"has_output\": [\"emsl:output_598506\"],\r\n    \"part_of\": [\"gold:Gs0110138\"],\r\n    \"instrument_name\": \"QExactHF03\",\r\n    \"omics_type\": {\r\n        \"has_raw_value\": \"Proteomics\"\r\n    },\r\n    \"processing_institution\": \"Environmental Molecular Sciences Lab\",\r\n    \"type\": \"nmdc:OmicsProcessing\"\r\n}\r\n{\r\n    \"id\": \"emsl:598846\",\r\n    \"name\": \"SpruceW_P19_45_22Jun17_Pippin_17-04-06\",\r\n    \"description\": \"High res MS with high res HCD MSn\",\r\n    \"has_input\": [\"gold:Gb0153638\"],\r\n    \"has_output\": [\"emsl:output_598846\"],\r\n    \"part_of\": [\"gold:Gs0110138\"],\r\n    \"instrument_name\": \"QExactHF03\",\r\n    \"omics_type\": {\r\n        \"has_raw_value\": \"Proteomics\"\r\n    },\r\n    \"processing_institution\": \"Environmental Molecular Sciences Lab\",\r\n    \"type\": \"nmdc:OmicsProcessing\"\r\n}\r\n{\r\n    \"id\": \"emsl:598516\",\r\n    \"name\": \"SpruceW_P19_87_22Jun17_Pippin_17-04-06\",\r\n    \"description\": \"High res MS with high res HCD MSn\",\r\n    \"has_input\": [\"gold:Gb0153639\"],\r\n    \"has_output\": [\"emsl:output_598516\"],\r\n    \"part_of\": [\"gold:Gs0110138\"],\r\n    \"instrument_name\": \"QExactHF03\",\r\n    \"omics_type\": {\r\n        \"has_raw_value\": \"Proteomics\"\r\n    },\r\n    \"processing_institution\": \"Environmental Molecular Sciences Lab\",\r\n    \"type\": \"nmdc:OmicsProcessing\"\r\n}\r\n{\r\n    \"id\": \"emsl:598513\",\r\n    \"name\": \"SpruceW_P4_15A_22Jun17_Pippin_17-04-06\",\r\n    \"description\": \"High res MS with high res HCD MSn\",\r\n    \"has_input\": [\"gold:Gb0153609\"],\r\n    \"has_output\": [\"emsl:output_598513\"],\r\n    \"part_of\": [\"gold:Gs0110138\"],\r\n    \"instrument_name\": \"QExactHF03\",\r\n    \"omics_type\": {\r\n        \"has_raw_value\": \"Proteomics\"\r\n    },\r\n    \"processing_institution\": \"Environmental Molecular Sciences Lab\",\r\n    \"type\": \"nmdc:OmicsProcessing\"\r\n}\r\n{\r\n    \"id\": \"emsl:598520\",\r\n    \"name\": \"SpruceW_P4_15B_22Jun17_Pippin_17-04-06\",\r\n    \"description\": \"High res MS with high res HCD MSn\",\r\n    \"has_input\": [\"gold:Gb0153609\"],\r\n    \"has_output\": [\"emsl:output_598520\"],\r\n    \"part_of\": [\"gold:Gs0110138\"],\r\n    \"instrument_name\": \"QExactHF03\",\r\n    \"omics_type\": {\r\n        \"has_raw_value\": \"Proteomics\"\r\n    },\r\n    \"processing_institution\": \"Environmental Molecular Sciences Lab\",\r\n    \"type\": \"nmdc:OmicsProcessing\"\r\n}\r\n{\r\n    \"id\": \"emsl:598848\",\r\n    \"name\": \"SpruceW_P4_45_22Jun17_Pippin_17-04-06\",\r\n    \"description\": \"High res MS with high res HCD MSn\",\r\n    \"has_input\": [\"gold:Gb0153610\"],\r\n    \"has_output\": [\"emsl:output_598848\"],\r\n    \"part_of\": [\"gold:Gs0110138\"],\r\n    \"instrument_name\": \"QExactHF03\",\r\n    \"omics_type\": {\r\n        \"has_raw_value\": \"Proteomics\"\r\n    },\r\n    \"processing_institution\": \"Environmental Molecular Sciences Lab\",\r\n    \"type\": \"nmdc:OmicsProcessing\"\r\n}\r\n{\r\n    \"id\": \"emsl:598851\",\r\n    \"name\": \"SpruceW_P4_87_22Jun17_Pippin_17-04-06\",\r\n    \"description\": \"High res MS with high res HCD MSn\",\r\n    \"has_input\": [\"gold:Gb0153611\"],\r\n    \"has_output\": [\"emsl:output_598851\"],\r\n    \"part_of\": [\"gold:Gs0110138\"],\r\n    \"instrument_name\": \"QExactHF03\",\r\n    \"omics_type\": {\r\n        \"has_raw_value\": \"Proteomics\"\r\n    },\r\n    \"processing_institution\": \"Environmental Molecular Sciences Lab\",\r\n    \"type\": \"nmdc:OmicsProcessing\"\r\n}\r\n{\r\n    \"id\": \"emsl:598512\",\r\n    \"name\": \"SpruceW_P6_15_22Jun17_Pippin_17-04-06\",\r\n    \"description\": \"High res MS with high res HCD MSn\",\r\n    \"has_input\": [\"gold:Gb0153613\"],\r\n    \"has_output\": [\"emsl:output_598512\"],\r\n    \"part_of\": [\"gold:Gs0110138\"],\r\n    \"instrument_name\": \"QExactHF03\",\r\n    \"omics_type\": {\r\n        \"has_raw_value\": \"Proteomics\"\r\n    },\r\n    \"processing_institution\": \"Environmental Molecular Sciences Lab\",\r\n    \"type\": \"nmdc:OmicsProcessing\"\r\n}\r\n{\r\n    \"id\": \"emsl:598508\",\r\n    \"name\": \"SpruceW_P6_45_22Jun17_Pippin_17-04-06\",\r\n    \"description\": \"High res MS with high res HCD MSn\",\r\n    \"has_input\": [\"gold:Gb0153614\"],\r\n    \"has_output\": [\"emsl:output_598508\"],\r\n    \"part_of\": [\"gold:Gs0110138\"],\r\n    \"instrument_name\": \"QExactHF03\",\r\n    \"omics_type\": {\r\n        \"has_raw_value\": \"Proteomics\"\r\n    },\r\n    \"processing_institution\": \"Environmental Molecular Sciences Lab\",\r\n    \"type\": \"nmdc:OmicsProcessing\"\r\n}\r\n{\r\n    \"id\": \"emsl:598510\",\r\n    \"name\": \"SpruceW_P6_87_22Jun17_Pippin_17-04-06\",\r\n    \"description\": \"High res MS with high res HCD MSn\",\r\n    \"has_input\": [\"gold:Gb0153615\"],\r\n    \"has_output\": [\"emsl:output_598510\"],\r\n    \"part_of\": [\"gold:Gs0110138\"],\r\n    \"instrument_name\": \"QExactHF03\",\r\n    \"omics_type\": {\r\n        \"has_raw_value\": \"Proteomics\"\r\n    },\r\n    \"processing_institution\": \"Environmental Molecular Sciences Lab\",\r\n    \"type\": \"nmdc:OmicsProcessing\"\r\n}\r\n]`",
"body": "SPRUCE site is located at the Marcelle Experimental Forest in Minnesota... Which is MN... \r\n\r\nThere's a Spruce lane in Houghton, MI but that's not the research site. I bet these are actually the ones Chris was saying are to the wrong site.\r\n\r\nAlso, @pvangay  the link you shared shows me Stegen's Riverbed study... \r\n\r\nhttps://goo.gl/maps/fEBCp7jWqtU14CVdA\r\n\r\nhttps://mnspruce.ornl.gov/",
"body": "WEIRD. see if [this link](https://data.microbiomedata.org/?q=Ci0IARAGGAQiJVs0Ny4xMTQ4NTg4MTk5NTgwMSw0Ny4xMTQ5NDA5NTk1NjYzOV0KLggBEAcYBCImWy04OC41NDc3NTA3ODU5NDY4NSwtODguNTQ3NDQ5MzcyNzA4OF0=) is any better.",
"body": "@pvangay \r\n\r\nI had to click \"Search this area\" on the map. because it wasn't filtering the samples... real weird.",
"body": "Might be a good case for using a change sheet update.  Assigning to Montana as I believe she understands what needs to be updated.",
"body": "All the SPRUCE samples that say Michigan should be deleted from the portal. These are Eric Liskov's samples & need deleted. \r\nSee https://github.com/microbiomedata/nmdc-runtime/issues/128 \r\nClosing this issue since they no longer need renamed.",
"body": "This errors appears in both EBI and IMG, so may have been erroneously entered early on. SPRUCE samples were collected in Houghton, MI (both geographic location name and lat/lon confirms MI) but the biosample names are labeled as Houghton, **MN**. \r\n\r\n[Set of 40 samples](https://data.microbiomedata.org/?q=Ci0IARAGGAQiJVs0Ni4zMjc5NjQ5NDA0MDc0OCw0Ny42NzY0ODQ0NDIyMTMyMV0KLggBEAcYBCImWy05Mi4wMzI0NzA3MDMxMjUwMSwtODcuMDk0MTE2MjEwOTM3NV0=)\r\n\r\n@dehays can you help with this? Should we ask Reddy for help too? Not sure who best to start with.",
"body": "@dehays can you update this issue, let me know if it should go to backlog or to the March sprint. Thank you",
"body": "Moving to March but please let me know if you're not actively working on this @dehays ",
"body": "Can handle this with a change sheet modifying all BioScale biosamples",
"body": "Discussed with David and he'll either close today or move to May",
"body": "@dehays said he will close or work on in May so I'm moving to May sprint.",
"body": "Updated 217 BioScales biosamples populating the list value of GOLD_sample_identifiers.  Change sheet generated from: [GOLD sample identifiers change sheet](https://docs.google.com/spreadsheets/d/1MsXhBRkv45urbcEdalODuf6ShSZu18dBhkusUTIP8yU)",
"body": "These 217 biosamples currently use the GOLD ID as their primary NMDC ID.  This value just needs to be added to the GOLD_sample_identifiers attribute list value.  (In addition to supporting the linking to GOLD record in the search portal, this change is needed before minting NMDC IDs to use as the primary ID of all NMDC biosamples.)",
"body": "It is the moose rumen sample:\r\n\r\n`LMS cellobiose enrichment; Rumen fluid biosample from rumen-fistulated moose that consumed three seasonal natural vegetation diets (spring, summer and fall/winter)`\r\n\r\nThe biosample was removed, but not the sequencing project (omics_processing).",
"body": "Both sequencing project (omics_processing gold:Gp0119870) and the data object for the raw read file have been removed",
"body": "Saw this logged during Postgres ingest:\r\n\r\n`missing biosample:\r\ngold:Gb0119280`\r\n\r\nThis indicates that an omics_processing (sequencing project) lists that biosample ID as input, but there is no corresponding biosample in the biosample set.\r\n\r\nIt is a Kelly Wrighton study biosample and the input of this SP:\r\n\r\n`{\r\n    \"id\": \"gold:Gp0119870\",\r\n    \"name\": \"Enriched soil microbial communities from Old Woman Creek wetland in Ohio, USA - LMS_cellobiose_enrichment\",\r\n    \"description\": \"Microbial controls on biogeochemical cycling in deep subsurface shale carbon reservoirs\",\r\n    \"has_input\": [\"gold:Gb0119280\"],\r\n    \"has_output\": [\"jgi:56a6899c0d878559e286ce66\"],\r\n    \"part_of\": [\"gold:Gs0114675\"],\r\n    \"add_date\": \"2015-08-15\",\r\n    \"mod_date\": \"2021-06-15\",\r\n    \"ncbi_project_name\": \"Deep subsurface shale carbon reservoir microbial communities from Ohio, USA - LMS_cellobiose_enrichment\",\r\n    \"omics_type\": {\r\n        \"has_raw_value\": \"Metagenome\"\r\n    },\r\n    \"principal_investigator\": {\r\n        \"has_raw_value\": \"Kelly Wrighton\"\r\n    },\r\n    \"processing_institution\": \"Joint Genome Institute\",\r\n    \"type\": \"nmdc:OmicsProcessing\"\r\n}`",
"body": "I am assuming this issue can be closed, can you please confirm @dehays? ",
"body": "Closing this as this was supposed to be done for the GSP workshop today.  @dehays let me know if it should not be closed.  ",
"body": "This is an item from the DH usability insights that David said he can do for GSP.  ",
"body": "done via changesheets",
"body": "set multiple roles per researcher with PI provided info [Research team metadata](https://drive.google.com/drive/folders/1_FXYnTcgwiYcjEjL8C6oO678mtmsn0V8)",
"body": "Done via changesheet",
"body": "Also noticed that these 17 biosamples are missing '\"part_of\" attributes.\r\n\r\nid:\"emsl:2f7107d6-5dd1-11ec-bf63-0242ac130002\"\r\nid:\"emsl:2f710cae-5dd1-11ec-bf63-0242ac130002\"\r\nid:\"emsl:2f7109ac-5dd1-11ec-bf63-0242ac130002\"\r\nid:\"emsl:2f710d8a-5dd1-11ec-bf63-0242ac130002\"\r\nid:\"emsl:2f7116fe-5dd1-11ec-bf63-0242ac130002\"\r\nid:\"emsl:2f710a92-5dd1-11ec-bf63-0242ac130002\"\r\nid:\"emsl:2f711028-5dd1-11ec-bf63-0242ac130002\"\r\nid:\"emsl:2f7118c0-5dd1-11ec-bf63-0242ac130002\"\r\nid:\"emsl:2f7105c4-5dd1-11ec-bf63-0242ac130002\"\r\nid:\"emsl:2f7108d0-5dd1-11ec-bf63-0242ac130002\"\r\nid:\"emsl:2f711514-5dd1-11ec-bf63-0242ac130002\"\r\nid:\"emsl:2f710f4c-5dd1-11ec-bf63-0242ac130002\"\r\nid:\"emsl:2f7117ee-5dd1-11ec-bf63-0242ac130002\"\r\nid:\"emsl:2f711bfe-5dd1-11ec-bf63-0242ac130002\"\r\nid:\"emsl:2f71038a-5dd1-11ec-bf63-0242ac130002\"\r\nid:\"emsl:2f711992-5dd1-11ec-bf63-0242ac130002\"\r\nid:\"emsl:2f710e70-5dd1-11ec-bf63-0242ac130002\"\r\n\r\nshould all have \"part_of\": [\"gold:Gs0110138\"]\r\n\r\nand\r\n\r\n\"ecosystem\": \"Environmental\",\r\n    \"ecosystem_category\": \"Terrestrial\",\r\n    \"ecosystem_type\": \"Soil\",\r\n    \"ecosystem_subtype\": \"Peat\",\r\n    \"specific_ecosystem\": \"Unclassified\",",
"body": "added rna_collect_site & dna_collect_site",
"body": "add collection site field for JGI & use MIxS growth conditions",
"body": "@turbomam , @cmungall , @dehays , @wdduncan \r\n\r\nJust bringing this to your attention because it was new to me. If it doesn't matter at all, we can just close this ticket.",
"body": "Thanks, @mslarae13 \r\n\r\nI **am** pulling `geo_loc_name`'s string serialization from [@cmungall and my MIxS LinkML](https://github.com/cmungall/mixs-source/blob/fb6d8c2f01fecb1a251f08a3d3696ba85bd72d3c/model/schema/terms.yaml#L207-L222) because it appears with disposition 'use as-is' on the [`mixs_packages_x_slots` tab](https://github.com/cmungall/mixs-source/blob/1a71a2a6f1517992ab48e1895d4e56f66d7236dd/model/schema/terms.yaml#L207-L222)\r\n\r\nNote that the slot is still called `pattern` in the main branch of MIxS LinkML above, but that will soon be re-implemented as a `string_serialization`\r\n\r\nOur MIxS LinkML currently has the string_serialization `{term}: {term}, {text}` and will only change when there's a change in the [upstream Google Sheet](https://docs.google.com/spreadsheets/d/1QDeeUcDqXes69Y2RjU2aWgOpCVWo5OVsBX9MKmMqi_o/edit#gid=178015749)\r\n",
"body": "Thanks, @mslarae13 \r\n\r\nI **am** pulling `geo_loc_name`'s string serialization from [@cmungall and my MIxS LinkML](https://github.com/cmungall/mixs-source/blob/fb6d8c2f01fecb1a251f08a3d3696ba85bd72d3c/model/schema/terms.yaml#L207-L222) because it appears with disposition 'use as-is' on the [`mixs_packages_x_slots` tab](https://github.com/cmungall/mixs-source/blob/1a71a2a6f1517992ab48e1895d4e56f66d7236dd/model/schema/terms.yaml#L207-L222)\r\n\r\nNote that the slot is still called `pattern` in the main branch of MIxS LinkML above, but that will soon be re-implemented as a `string_serialization`\r\n\r\nOur MIxS LinkML currently has the string_serialization `{term}: {term}, {text}` and will only change when there's a change in the [upstream Google Sheet](https://docs.google.com/spreadsheets/d/1QDeeUcDqXes69Y2RjU2aWgOpCVWo5OVsBX9MKmMqi_o/edit#gid=178015749)\r\n",
"body": "See https://github.com/GenomicsStandardsConsortium/mixs/issues/79\r\n\r\nGSC has changed the syntax for geo_loc_name to \r\n{text}:{text}, {text}\r\n\r\nThis is more aligned with INSDC. \r\n\r\nTerm name = geo_loc_name\r\nTerm ID = MIXS:0000010\r\nStructured comment name = geographic location (country and/or sea,region)\r\nDefinition = The geographical origin of the sample as defined by the country or sea name followed by a specific region and/or a location name. Country or sea names should be chosen from the INSDC country list (http://insdc.org/country.html), or the GAZ ontology (v 1.512) (http://purl.bioontology.org/ontology/GAZ)\r\nExpected value = SeaOrCountry:Region, Specific location\r\nValue syntax = {text}:{text}, {text}\r\nExample = Belgium:Ghent, Bourgoyen nature reserve\r\nPreferred unit = none\r\nPackage(s) = MIxS Core\r\n\r\nI assume NMDC will make the same change, since @turbomam pulls the details for each term straight from MIxS.\r\nDoes this affect any other downstream uses of this term?",
"body": "`make all` in this repo includes a test that reports the differences in enum names and enum permissible values. It's also saved `target/test.log`, but that's not checked into the repo for people to browse via the GH web interface.",
"body": "@turbomam can I close this issue?  ",
"body": "Consider done per @turbomam ",
"body": "Related to DH tasks for Jan/Feb 2022",
"body": "Looks like this is done per Montana so I'll close it",
"body": "Related to DH tasks for Jan/Feb 2022\r\n",
"body": "@turbomam reported this is done and issue can be closed during mid-sprint check-in today.",
"body": "Validations\u2026 \r\n- [ ] validation against formatting requirements for metadata terms\r\n- [ ] Regex checks for complex, predefined string formats\r\nExample: lat_lon, depth, temp, collection_date, store_cond, geo_loc_name\r\n- [ ] Checks for values with defined ranges\r\nExample: pH\r\n- [ ] Additional checks for valid data types\r\n- [ ] Additional controlled vocabularies\r\n",
"body": "On `Terms` tab",
"body": "on `Terms` tab",
"body": "Ignoring the TERMS tab, all tabs should only appear once.",
"body": "I think this one is over comeb by events. We don't use this compiled file anymore",
"body": "Maybe I don't understand the intention of `Terms-New Terms` and `MIxS Terms Replaced`\r\n\r\nWould it be possible to communicate everything about eh use of this term in our DataHarmonizer template in just one worksheet tab?\r\n\r\n- `Terms` row with `Column Header` = \"collection date\"\r\n- `Terms-New Terms` with `Column Header` = \"collection date\"\r\n- `MIxS Terms Replaced` with `MIxS Term` = \"collection_date\"",
"body": "added to MIxS Terms Skipped tab",
"body": "@turbomam what is left to accomplish here?",
"body": "I was expecting to see all MIxS Soil slots mentioned in either `Terms`, `MIxS Terms Skipped`, `MIxS Terms Replaced`",
"body": "I'm good with it!",
"body": "Cell B3 in [Soil-NMDC-Template_Compiled](https://docs.google.com/spreadsheets/d/1pSmxX6XGOxmoA7S7rKyj5OaEl3PmAl4jAOlROuNHrU0/edit#gid=0) is 'sample name '\r\n\r\nI removed the trailing whitespace. \r\n\r\n@mslarae13, if that's OK with you, we can close the issue.",
"body": "See also #418 ",
"body": "Currently, [linkml_to_dh_light](https://github.com/turbomam/linkml-round-trips/blob/main/linkml_round_trips/linkml_to_dh_light.py) determines DH sections by examining the LinkML `is_a` parents of NMDC biosample and MIxS soil slots. When one of those slots doesn't have an asserted `is_a` parent, a default section value is used. The default default section name is 'default'.\r\n\r\nThe `is_a` values mentioned above are prefixed with the prefix portion of the slots' URIs. \r\n\r\nTherefore, the sections have both a categorical/hierarchical component and a source/authority component. See this [sample DH template](https://turbomam.github.io/DataHarmonizer/main.html).\r\n\r\nWhat changes should be made to these rules when determining sections from [Soil-NMDC-Template_Compiled](https://docs.google.com/spreadsheets/d/1pSmxX6XGOxmoA7S7rKyj5OaEl3PmAl4jAOlROuNHrU0/edit#gid=0)?\r\n\r\nAre any of the columns below relevant? Where do these values come from? (Ie are all of the `Section` values  MIxS package names? I haven't checked yet.) Are they intended to replace or supplement values that come from the MIxS (or NMDC) schemas?\r\n\r\nI recommend omitting the optional/required etc. values from the section organization, since that is also captured in the `requirement status` column, and communicated with the yellow/magenta DH column colors.\r\n \r\n- Category\r\n  - biogeochemistry\r\n  - optional\r\n  - required\r\n  - required where applicable\r\n  - sample identification\r\n  - treatment\r\n- Origin\r\n  - EMSL\r\n  - MIxS\r\n- Section\r\n  - agriculture\r\n  - environment\r\n  - investigation\r\n  - mixs extension\r\n  - plant-associated\r\n  - sediment\r\n  - soil\r\n  - water\r\n\r\n\r\n\r\n  \r\n\r\n",
"body": "I have been creating several DataHarmonizer issues and assigning them to @mslarae13 \r\n\r\n@mslarae13 alone shouldn't be responsible for these issues, but I can't see how to assign multiple people in this repo.\r\n\r\nCan we please enable multiple assignees?\r\n\r\nI'm \"assigning\" this one to @kfagnan, but maybe other people want to weigh in on the single/multiple assignee issue? @cmungall ? @dehays ?",
"body": "For multi-values columns following an enumeration, DH will paste the values together with some delimiter. For columns that require typing in a response, we should instruct the user to separate multiple values with the same delimiter.\r\n\r\n@turbomam responsible for looking up that DH delimiter.",
"body": "Soil-NMDC-Template_Compiled should have a `multivalued` column, to indicate whether multiple values are allowed in a DH template based on [Soil-NMDC-Template_Compiled](https://docs.google.com/spreadsheets/d/1pSmxX6XGOxmoA7S7rKyj5OaEl3PmAl4jAOlROuNHrU0/edit#gid=0).\r\n\r\nWe could trust MIxS and NMDC's `multivalued` annotations, but we don't currently have anything analogous for EMSL or JGI fields.",
"body": "I also think this can be closed and has deprecated?\r\n",
"body": "Currently, [linkml_to_dh_light](https://github.com/turbomam/linkml-round-trips/blob/main/linkml_round_trips/linkml_to_dh_light.py) arranges DH sections in alphabetical order, and arranges columns alphabetically within those sections based on their `Column Header` (which becomes their LinkML `title`s)\r\n\r\nThere is one exception: any column that is asserted to be an identifier within LinkML will be put first/leftmost in it's section, and sections with any identifier are arranged first/leftmost within the DH template.\r\n\r\nTo what extent should the row order in [Soil-NMDC-Template_Compiled](https://docs.google.com/spreadsheets/d/1pSmxX6XGOxmoA7S7rKyj5OaEl3PmAl4jAOlROuNHrU0/edit#gid=0) determine column order within our DH templates?\r\n\r\n@mslarae13 it looks like only one person can be assigned to an issue in microbiomedata/nmdc-metadata?! I also consider myself an assignee for this one. I guess we can just @-mention other people to get their attention. \r\n\r\nSee also: \r\n- This sample [DH template](https://turbomam.github.io/DataHarmonizer/main.html)\r\n- #417 ",
"body": "Some time ago, I added the column that appears on the far left of the `Terms` sheet in [row_ord column in Soil-NMDC-Template_Compiled](https://docs.google.com/spreadsheets/d/1pSmxX6XGOxmoA7S7rKyj5OaEl3PmAl4jAOlROuNHrU0/edit#gid=0). Either I did not include a column header, or it got deleted at some point.\r\n\r\nI just updated this column with the header `row_ord`, for row order. I also refreshed the values in that column to be 1, 2, 3 etc. That way the rows can be restored to their intended order, in case I or anybody else sorts them.\r\n\r\n@mslarae13, if you think this is a bad idea, I would support removing this column. But in that case, I would ask that we lock the sheet, or come to an agreement that row order doesn't matter.\r\n\r\n",
"body": "This would be necessary for persisting submitted metadata - as would an API for the browser application (surrounding the DH interface) to use to write, retrieve, update records in such a DB.\r\n\r\nBut functional design for metadata submission is still under discussion with Kitware.",
"body": "Based on some discussions at the sync meeting I'm re-assigning to @subdavis but please correct if I'm wrong @dehays ",
"body": "@ssarrafan Yes - Brandon is doing the submit / persistence.  Sounds like he intends to use a table in the existing Postgres DB.  Could close this issue or replace it with an nmdc-server issue for  saving study and biosample metadata submitted through the DH editor.",
"body": "Ok closing and this issue created for February: https://github.com/microbiomedata/nmdc-server/issues/592 ",
"body": null,
"body": "@pvangay prioritized the list and we started to go through it with Kitware but so far only got through the high priority items.  Will continue to discuss with Kitware. \r\n\r\nhttps://docs.google.com/spreadsheets/d/1WKSYjh4kHSrYra3kvBNlGcYcTgPo6GhEPf8Epeh1Yw8/edit#gid=0\r\n\r\n@subdavis ",
"body": "Finished going through the list of insights with Brandon, Mark M., David, and Set. Colored rows that I think Brandon will be moving forward with for Jan release. \r\n\r\n@ssarrafan can you create a new issue assigned to Brandon for the Jan release with all of the color coded rows? (I think 1 issue with all the insights as checkboxes should work but I'll let @subdavis confirm what he prefers). ",
"body": null,
"body": "We've split some of these terms up into 2 fields. See https://docs.google.com/spreadsheets/d/1pSmxX6XGOxmoA7S7rKyj5OaEl3PmAl4jAOlROuNHrU0/edit?usp=sharing\r\n\r\nValidation is a new level of difficulty for this.\r\nAs @turbomam works through the terms I've provided we can evaluate if any terms need changed or added.",
"body": "Date & time, 2 fields\r\ndepth\r\nlat long, 1 field, NMDC can split it",
"body": "Decision completed and confirmed. See above & check the google doc for additional terms.\r\n",
"body": null,
"body": "From a DH meeting, @cmungall  would like thus to limit this.\r\nDepth = meters {value} m\r\nelevation = meters {value} m\r\n\r\nso it's assumed people will provide this information in the correct units. \r\n\r\nTo be decided / determined\r\n- Do we still want users to write in the unit? Should they wrote 0-.1 m or just 0-0.1\r\n- Can DH validate this? or is this a human spot check\r\n- MIxS has not settled on how to handle this, but there's an open ticket.\r\n\r\n",
"body": "0-0.1 m so the format is consistent with MIxS, but we constrain to m\r\n5 cm = WRONG needs to be 0.5 m < flag as invalid\r\n{upper depth - lower depth} m .. Mark and Chris will sort out how to parse & validation\r\n",
"body": "Required units have been decided. Validation of these required units is being worked on by Mark.",
"body": null,
"body": "Is _formatting criteria_ the same thing as DH validation rules?\r\n\r\nMIxS slots, as defined by `mixs-source`, can have a range and/or a string serialization. \r\n\r\nThe slots/columns @mslarae13 defined in SNTC can have string serializations, which appear in a column called 'pattern'.\r\n\r\nConversions between these rules and rules that DH understands (datatype or regular expression pattern) are currently hard coded into XXX but are being migrated to the [validation_converter tab in Soil-NMDC-Template_Compiled](https://docs.google.com/spreadsheets/d/1pSmxX6XGOxmoA7S7rKyj5OaEl3PmAl4jAOlROuNHrU0/edit?pli=1#gid=1734989760)\r\n\r\n40 out of 49 rules have been converted to datatypes or regular expression patterns. \r\n\r\nShould we work on the remaining 9?\r\n\r\n\r\n- {{text}\\|{float} {unit}};{float} {unit}\r\n- {boolean};{Rn/start_time/end_time/duration}\r\n    - what Boolean expressions are acceptable? T, True, true, 1...?\r\n- {float} {unit};{Rn/start_time/end_time/duration}\r\n- {PMID}\\|{DOI}\\|{URL}\r\n- {PMID}\\|{DOI}\\|{URL}\\|{text}\r\n    - do we really wnat to define patterns for PMIDs, DOIs or URLs?\r\n- {term}: {term}, {text}\r\n    - what's the difference between a term, a term ID and a term label? \r\n- {termLabel} {[termID]}\\|{text}\r\n- {text};{float} {unit};{Rn/start_time/end_time/duration}\r\n- {text};{Rn/start_time/end_time/duration}\r\n\r\n\r\n",
"body": "Or is this more about _reporting_ the required formats than performing the validation?\r\n\r\nSme of the regular expression are quite long and it might not be appropriate to report them in the DH double-click description or guidance. \r\n\r\nIt probably is good to include \r\n- string serialization\r\n- min and max\r\n- required unique\r\n- examples\r\n\r\nThere are separate issues for several of those. I will try to reference those.\r\n",
"body": "In stand up today the idea was to hold off on the additional 9 until we get some feedback. Does that sound reasonable @pvangay and @emileyfadrosh?  I'll move to February for now. ",
"body": "@ssarrafan makes sense to wait til they get feedback on the above. A quick look - I think they warrant discussion at a metadata meeting.",
"body": "@turbomam reported this is done and issue can be closed during mid-sprint check-in today.",
"body": null,
"body": "See [#](https://github.com/microbiomedata/nmdc-metadata/issues/412#issuecomment-1026027716)",
"body": "@turbomam reported this is done and issue can be closed during mid-sprint check-in today.",
"body": null,
"body": "Note from Mark:  I think 410 is a union of 411 and 412. I would suggest closing 410 with a note to that effect.",
"body": null,
"body": "These are logged here: https://docs.google.com/spreadsheets/d/1pSmxX6XGOxmoA7S7rKyj5OaEl3PmAl4jAOlROuNHrU0/edit?usp=sharing\r\n\r\nTab \"Terms\" Column P\r\n\r\nShould I copy them into an individual file?",
"body": null,
"body": "Slots/columns from all of those authorities/user facilities are represented in [Soil-NMDC-Template_Compiled](docs.google.com/spreadsheets/d/1pSmxX6XGOxmoA7S7rKyj5OaEl3PmAl4jAOlROuNHrU0) now and appear in the [NMDC DH prototype](https://microbiomedata.github.io/DataHarmonizer/main.html?template=dev)",
"body": null,
"body": "David signed off on the terms!",
"body": null,
"body": "See https://docs.google.com/spreadsheets/d/1pSmxX6XGOxmoA7S7rKyj5OaEl3PmAl4jAOlROuNHrU0/edit?usp=sharing\r\n\r\nNeed to add JGI. MIxS GitHub ticks associated with non-MIxS terms / changes made to MIxS terms\r\nOrigin in column N.\r\n\r\nJGI terms to be added",
"body": "Don't need MIxS GitHub tickets for JGI terms\r\n\r\nMake MIxS terms we've revised MIxS-Modified\r\n\r\n",
"body": "Looks like this one is done per Montana so closing",
"body": null,
"body": "Thank you @dehays for creating this issue. Should I add it to the December sprint?",
"body": "Ongoing -- some of these changes have been addressed.  Adding type and part_of values.  There is some data_object_set curation that needs to happen still.",
"body": "@dehays let me know if you'd like me to move this to the February sprint or if you plan to close it by Monday.  Thank you!",
"body": "Moving to February sprint but let me know if it should go to backlog instead @dehays ",
"body": "@dehays any update on this issue?  ",
"body": "Moving to March but please let me know if this is done or not being actively worked on @dehays ",
"body": "Moved to April - good to have - but has medium priority.  Imagine this starts as a Jupyter notebook.",
"body": "Discussed with David and he'll close or move to May.",
"body": "@dehays said he will close or work on in May so I'm moving to May sprint.",
"body": "@emileyfadrosh moving this to the backlog. Let me know if it should be assigned to someone else. \r\nFYI @dehays ",
"body": "Closing this issue from 2021. @dwinston @emileyfadrosh FYI\r\nBacklog cleanup 12-2023",
"body": "We should have referential integrity and type (constrained vocabulary) checking at document creation/insertion time.\r\n\r\nThe latter could be handled by JSON Schema from the NMDC Schema (only permit type values from a defined enumeration).\r\n\r\nThe portal ingest is mapping from Mongo document collections to Postgres relational tables - and is therefore more aware of missing and extra record references.  These could be handled with FK constraints, but then many document inserts as Postgres records would fail.  So in lieu of FK constraints, the ingest logs the missing and unreferenced documents.  Mostly these are missing and extra data objects - but there is a biosample in there too.\r\n\r\nTask here is to consider how to handle the following:\r\n\r\n```\r\nLoading omics processing...\r\nUnknown biosample gold:Gb0119280\r\nUnknown data object nmdc:8d16af5ca7671f7dc42de14deb8b0dd5\r\nUnknown data object nmdc:2a3baceee6e3dd4c4fc13567c2fd5df3\r\nUnknown data object nmdc:52c9e32cf184310313c50a4b0f98f87f\r\nUnknown data object nmdc:8f80860812e425dd92344f1f056d3d7e\r\nUnknown data object nmdc:91ab0ce1ea61b477a64e57a872624cb4\r\nUnknown data object nmdc:74621bf24161e2e072c651c0c489b521\r\nUnknown data object nmdc:57bd602fa807024237878435a358d136\r\nUnknown data object nmdc:754dde7a211a1cd9ecfb990d799c86fc\r\nUnknown data object nmdc:c139345a1c2ba3d6883a53a85463e8e4\r\nUnknown data object nmdc:dd43946edb26961e1913c8830f54e5cf\r\nUnknown data object nmdc:72779f8c6bba0a95693c89a92f4f6be3\r\nUnknown data object nmdc:38116da337f1e868ba6fec5a184ba2fc\r\nUnknown data object nmdc:796233a318facd24d5c14f44f479dc43\r\nUnknown data object nmdc:0f65059f9df59fe318f2780fc2e0605d\r\nUnknown data object nmdc:65b806917315e7518fdd36887bca0190\r\nUnknown data object nmdc:a198c6e6ba43f210857ca41f25e0ed10\r\nUnknown data object nmdc:f31a2a473fa6cc081ff6c136d79c454a\r\nUnknown data object nmdc:f098da7fe12707ec59757cd2dfb94d26\r\nUnknown data object nmdc:300109666a890c83f10c431a6245561a\r\nUnknown data object nmdc:19edfbb924938737398f443c7342d913\r\nUnknown data object nmdc:6f503435c01cf49ed7805ce4c2d26d46\r\nUnknown data object nmdc:2ab91c737308518038e6e4c0925bd12f\r\nUnknown data object nmdc:b6d907e2b41d013afcb2b6aa81c1be87\r\nUnknown data object nmdc:b0638ba985a67df56f072b7544e46317\r\nUnknown data object nmdc:20f714c290eeba8f76fe33ea21bf2291\r\nUnknown data object nmdc:2112eaa62884c29f33a47669bf01bb53\r\nUnknown data object nmdc:c52cdaa42622674591c66ceeb0c33758\r\nUnknown data object nmdc:86cb807a667b81fabb252a75eb79022c\r\nUnknown data object nmdc:087821706edc18d844ab743ec8865569\r\nUnknown data object nmdc:0afe727fea9effca194d4b1f607984ff\r\nUnknown data object nmdc:5333beedf0b1a6aeac85fd52e0c954a6\r\nUnknown data object nmdc:60ee79e73d43651cee0e89de0c346a20\r\nUnknown data object nmdc:f5b5e247913c5cdb5511dff98d349ce2\r\nUnknown data object nmdc:9a18a44f56928a2d4cb4e1541e182799\r\nUnknown data object nmdc:a1852a6601023d802e67f41aef7dfcde\r\nUnknown data object nmdc:9676ebc038756ae55077770846391495\r\nUnknown data object nmdc:492b743dc4a3ab1c730dd0e12912d8d1\r\nUnknown data object nmdc:259a1435146041ed02aa079a007fb06c\r\nUnknown data object nmdc:0df5ac2c9052a2b45cfd9578aaa562f7\r\nUnknown data object nmdc:94f5b389c2d9f7f5bc92e9fddedfc775\r\nUnknown data object nmdc:dac54b23fce5a5c56c11311c77b74294\r\nUnknown data object nmdc:426202d9528d4af01aa6aeeb6ebb5aac\r\nUnknown data object nmdc:ef11b09bff6940ee45f3c05842b16931\r\nUnknown data object nmdc:d18ad58ac8a0a7e9748c518081f9059d\r\nUnknown data object nmdc:104c9da6da3a685e5b1b8a3b2652bdd7\r\nUnknown data object nmdc:fee26dc0a11fb4a39c28d7130c2358f6\r\nUnknown data object nmdc:bef74063c8db88eca336299184d80942\r\nUnknown data object nmdc:8656757191fe5a86d3a4d524d5f513e2\r\nUnknown data object nmdc:65b3ee1c8092cfe1b7fef18cbca970d9\r\nUnknown data object nmdc:d38a56c9121372e8eb41f4f8f139481c\r\nUnknown data object nmdc:acee10e153052c8b7bc98c2fe462fdd9\r\nUnknown data object nmdc:00a2071567e1e8e58bef5263fbdf7905\r\nUnknown data object nmdc:3896cc46b145ba465c67a164e7446400\r\nUnknown data object nmdc:62915d08fc404130f4abe2c947a4e13e\r\nUnknown data object nmdc:091325e3152cae4d694e2bbf5b7093db\r\nUnknown data object nmdc:fe61b5e7c3aff7b27e5be1f97f55efda\r\nUnknown data object nmdc:e444ada18237f6db32de92516773b0d5\r\nUnknown data object nmdc:1d2ea6cc3c176479f6355a6716bf0279\r\nUnknown data object nmdc:59532226ec5755915a032e602dc04a03\r\nUnknown data object nmdc:d08893db578667fdc61428fde84f8279\r\nUnknown data object nmdc:7b093e525bf7741654105516790060a0\r\nUnknown data object nmdc:4779dacd0e7071f528be8c03fac547e7\r\nUnknown data object nmdc:da44ab401932bc11c5c7e2ec4f50d945\r\nUnknown data object nmdc:fb1897fb6c87bcf5b25c76e0ac149b67\r\nUnknown data object nmdc:908fe1703358c811ae7bf408886a6e87\r\nUnknown data object nmdc:12b43da62aae4332869c589de5853062\r\nUnknown data object nmdc:625075a39014d701fda177605f8f8858\r\nUnknown data object nmdc:8d9b361423c5819782294a8789859b9b\r\nUnknown data object nmdc:6e84b6d72daf43591617f4c278a8540f\r\nUnknown data object nmdc:722f2dbb28d08d2f65cacea4c5435da2\r\nUnknown data object nmdc:4fa30e2045705f394631c65180c5199a\r\nUnknown data object nmdc:61a97e80cb6d26e90f140f38b008abab\r\nUnknown data object nmdc:8a573eec92876f6621ae5305d9ed3bd2\r\nUnknown data object nmdc:5e84dfde0d632897ed93abf84fd75dbd\r\nUnknown data object nmdc:2f05dd5770ff3ebe3b56f008854bac78\r\nUnknown data object nmdc:4b5fb58671da52ebbff9fc85324638ac\r\nUnknown data object nmdc:7f0c6c7be34ce22ab91df9a75f3e4379\r\nUnknown data object nmdc:f9f1ddf2e1eca8e9c8a18b5096433c54\r\nUnknown data object nmdc:076ff634d28625c03f79842a9b3bb354\r\nUnknown data object nmdc:f4ddf238d2d7dec9c86b93713d0ff075\r\nUnknown data object nmdc:fc02b18994a1ea74808d16d18735a04a\r\nUnknown data object nmdc:4acac4ba90588c9923ed2d02d3f516b7\r\nUnknown data object nmdc:a6596e0c6c077b864048f00a68ab6c78\r\nUnknown data object nmdc:3900b15ebaa5ecba247164c7165d2f38\r\nUnknown data object nmdc:f2b267f00e22a74e94e6dd75fe0531f0\r\nUnknown data object nmdc:a68418156612ccea5ffa4c2d9b6a6114\r\nUnknown data object nmdc:9a37ea20e51282596cf799605d6e912c\r\nUnknown data object nmdc:cb53962aabcda827b19e270a805dc0e1\r\nUnknown data object nmdc:f408775f43e5a6041ade55edecaaeb1a\r\nUnknown data object nmdc:dbfdeaccbb5b01e4b567e04c1ec60b95\r\nUnknown data object nmdc:989711381573525c3c32f77fb8b4bcf7\r\nUnknown data object nmdc:8139981465fa40b6488805919efdbcd6\r\nUnknown data object nmdc:8224d0f7d3ceb191111f6d49e415afc8\r\nUnknown data object nmdc:cf4c63cdb2f8d4b17dc591ac83c042e0\r\nUnknown data object nmdc:e0e0b9582935ccbf60eab11942ee902b\r\nUnknown data object nmdc:82254db0eab492d5074a5d36b96e491a\r\nUnknown data object nmdc:44cd635395e777cfab314dcf1789b6d2\r\nUnknown data object nmdc:967517f83a03de07d4c0eb53f7c83f05\r\nUnknown data object nmdc:c4df425ae66b46dcf353097aa64c8935\r\nUnknown data object nmdc:2437e48c81f26729595351c727f94b0b\r\nUnknown data object nmdc:7f57dcee7abd6613a46bed9e6d3bc61b\r\nUnknown data object nmdc:22afa3d49b73eaec2e9787a6b88fbdc3\r\nUnknown data object nmdc:995c8b403d4ae43206bcd9cb0168d7a7\r\nUnknown data object nmdc:49b6ab7f5a43b171f4b6de616624fe02\r\nUnknown data object nmdc:340ba2dc2e14b38bf653cbc8dcedaf9b\r\nUnknown data object nmdc:452104acaf8a6d065f9a8fdbd64ee882\r\nLoading metabolomics analysis...\r\nLoading read based analysis...\r\nUnexpected type nmdc:ReadBasedAnalysisActivity\r\nUnexpected type nmdc:ReadBasedAnalysisActivity\r\nUnexpected type nmdc:ReadBasedAnalysisActivity\r\nUnexpected type nmdc:ReadBasedAnalysisActivity\r\nUnexpected type nmdc:ReadBasedAnalysisActivity\r\nUnexpected type nmdc:ReadBasedAnalysisActivity\r\nUnexpected type nmdc:ReadBasedAnalysisActivity\r\nUnexpected type nmdc:ReadBasedAnalysisActivity\r\nUnexpected type nmdc:ReadBasedAnalysisActivity\r\nUnexpected type nmdc:ReadBasedAnalysisActivity\r\nUnexpected type nmdc:ReadBasedAnalysisActivity\r\nUnexpected type nmdc:ReadBasedAnalysisActivity\r\nUnexpected type nmdc:ReadBasedAnalysisActivity\r\nUnexpected type nmdc:ReadBasedAnalysisActivity\r\nUnexpected type nmdc:ReadBasedAnalysisActivity\r\nUnexpected type nmdc:ReadBasedAnalysisActivity\r\nUnexpected type nmdc:ReadBasedAnalysisActivity\r\nUnexpected type nmdc:ReadBasedAnalysisActivity\r\nUnexpected type nmdc:ReadBasedAnalysisActivity\r\nUnexpected type nmdc:ReadBasedAnalysisActivity\r\nUnexpected type nmdc:ReadBasedAnalysisActivity\r\nUnexpected type nmdc:ReadBasedAnalysisActivity\r\nUnexpected type nmdc:ReadBasedAnalysisActivity\r\nUnexpected type nmdc:ReadBasedAnalysisActivity\r\nUnexpected type nmdc:ReadBasedAnalysisActivity\r\nUnexpected type nmdc:ReadBasedAnalysisActivity\r\nUnexpected type nmdc:ReadBasedAnalysisActivity\r\nUnexpected type nmdc:ReadBasedAnalysisActivity\r\nUnexpected type nmdc:ReadBasedAnalysisActivity\r\nUnexpected type nmdc:ReadBasedAnalysisActivity\r\nUnexpected type nmdc:ReadBasedAnalysisActivity\r\nUnexpected type nmdc:ReadBasedAnalysisActivity\r\nUnexpected type nmdc:ReadBasedAnalysisActivity\r\nUnexpected type nmdc:ReadBasedAnalysisActivity\r\nUnexpected type nmdc:ReadBasedAnalysisActivity\r\nUnexpected type nmdc:ReadBasedAnalysisActivity\r\nUnexpected type nmdc:ReadBasedAnalysisActivity\r\nUnexpected type nmdc:ReadBasedAnalysisActivity\r\nUnexpected type nmdc:ReadBasedAnalysisActivity\r\nUnexpected type nmdc:ReadBasedAnalysisActivity\r\nUnexpected type nmdc:ReadBasedAnalysisActivity\r\nUnexpected type nmdc:ReadBasedAnalysisActivity\r\nUnexpected type nmdc:ReadBasedAnalysisActivity\r\nUnexpected type nmdc:ReadBasedAnalysisActivity\r\nUnexpected type nmdc:ReadBasedAnalysisActivity\r\nUnexpected type nmdc:ReadBasedAnalysisActivity\r\nUnexpected type nmdc:ReadBasedAnalysisActivity\r\nUnexpected type nmdc:ReadBasedAnalysisActivity\r\nUnexpected type nmdc:ReadBasedAnalysisActivity\r\nUnexpected type nmdc:ReadBasedAnalysisActivity\r\nUnexpected type nmdc:ReadBasedAnalysisActivity\r\nUnexpected type nmdc:ReadBasedAnalysisActivity\r\nUnexpected type nmdc:ReadBasedAnalysisActivity\r\nUnexpected type nmdc:ReadBasedAnalysisActivity\r\nUnexpected type nmdc:ReadBasedAnalysisActivity\r\nUnexpected type nmdc:ReadBasedAnalysisActivity\r\nUnexpected type nmdc:ReadBasedAnalysisActivity\r\nUnexpected type nmdc:ReadBasedAnalysisActivity\r\nUnexpected type nmdc:ReadBasedAnalysisActivity\r\nUnexpected type nmdc:ReadBasedAnalysisActivity\r\nUnexpected type nmdc:ReadBasedAnalysisActivity\r\nUnexpected type nmdc:ReadBasedAnalysisActivity\r\nUnexpected type nmdc:ReadBasedAnalysisActivity\r\nUnexpected type nmdc:ReadBasedAnalysisActivity\r\nUnexpected type nmdc:ReadBasedAnalysisActivity\r\nUnexpected type nmdc:ReadBasedAnalysisActivity\r\nUnexpected type nmdc:ReadBasedAnalysisActivity\r\nUnexpected type nmdc:ReadBasedAnalysisActivity\r\nUnexpected type nmdc:ReadBasedAnalysisActivity\r\nUnexpected type nmdc:ReadBasedAnalysisActivity\r\nUnexpected type nmdc:ReadBasedAnalysisActivity\r\nUnexpected type nmdc:ReadBasedAnalysisActivity\r\nUnexpected type nmdc:ReadBasedAnalysisActivity\r\nUnexpected type nmdc:ReadBasedAnalysisActivity\r\nUnexpected type nmdc:ReadBasedAnalysisActivity\r\nUnexpected type nmdc:ReadBasedAnalysisActivity\r\nUnexpected type nmdc:ReadBasedAnalysisActivity\r\nUnexpected type nmdc:ReadBasedAnalysisActivity\r\nUnexpected type nmdc:ReadBasedAnalysisActivity\r\nUnexpected type nmdc:ReadBasedAnalysisActivity\r\nUnexpected type nmdc:ReadBasedAnalysisActivity\r\nUnexpected type nmdc:ReadBasedAnalysisActivity\r\nUnexpected type nmdc:ReadBasedAnalysisActivity\r\nUnexpected type nmdc:ReadBasedAnalysisActivity\r\nUnexpected type nmdc:ReadBasedAnalysisActivity\r\nUnexpected type nmdc:ReadBasedAnalysisActivity\r\nUnexpected type nmdc:ReadBasedAnalysisActivity\r\nUnexpected type nmdc:ReadBasedAnalysisActivity\r\nUnexpected type nmdc:ReadBasedAnalysisActivity\r\nUnexpected type nmdc:ReadBasedAnalysisActivity\r\nUnexpected type nmdc:ReadBasedAnalysisActivity\r\nUnexpected type nmdc:ReadBasedAnalysisActivity\r\nUnexpected type nmdc:ReadBasedAnalysisActivity\r\nUnexpected type nmdc:ReadBasedAnalysisActivity\r\nUnexpected type nmdc:ReadBasedAnalysisActivity\r\nUnexpected type nmdc:ReadBasedAnalysisActivity\r\nUnexpected type nmdc:ReadBasedAnalysisActivity\r\nUnexpected type nmdc:ReadBasedAnalysisActivity\r\nUnexpected type nmdc:ReadBasedAnalysisActivity\r\nUnexpected type nmdc:ReadBasedAnalysisActivity\r\nUnexpected type nmdc:ReadBasedAnalysisActivity\r\nUnexpected type nmdc:ReadBasedAnalysisActivity\r\nUnexpected type nmdc:ReadBasedAnalysisActivity\r\nUnexpected type nmdc:ReadBasedAnalysisActivity\r\nUnexpected type nmdc:ReadBasedAnalysisActivity\r\nUnexpected type nmdc:ReadBasedAnalysisActivity\r\nUnexpected type nmdc:ReadBasedAnalysisActivity\r\nUnexpected type nmdc:ReadBasedAnalysisActivity\r\nLoading metatranscriptome activities...\r\nUnknown data object nmdc:3d2cc3c5ba651c5f92302ee5c1c0d36b\r\nUnknown data object nmdc:369be15c709557b137c6ad6994ced3e4\r\nUnknown data object nmdc:8ef63c54cbfef72c19733e48ad0d1961\r\nUnknown data object nmdc:8ec141e339b4bedc49fbef7236422bec\r\nUnknown data object nmdc:35280ee871ca08e52849a30f18c497b0\r\nUnknown data object nmdc:8f6ed75bd49fa03502adbd7ec7c55a09\r\nUnknown data object nmdc:af403f9e2180b4ee5f0d536f6130a50d\r\nUnknown data object nmdc:957a5665e44143eea0c3a99b5665a51d\r\nUnknown data object nmdc:fcc5bd82615fab43bb54006632862521\r\nUnknown data object nmdc:c8d6693287398701b91c4d194856d0f3\r\nUnknown data object nmdc:7455b386b754925ce055f8f585f6242c\r\nUnknown data object nmdc:5e220105f8713dbb00a38eb3013b0f93\r\n\r\nUnknown data object nmdc:5e81b6549123027d1b7b9f439bbd1cd0\r\nUnknown data object nmdc:18b8afd638a9bb80a633f138150b7edd\r\nUnknown data object nmdc:88c54f9cd321218cfecdd844c999f402\r\nUnknown data object nmdc:61f06a2309788ded26b1fdec53ca3791\r\nUnknown data object nmdc:6a455b07be6e9c6b3f0631858a8ade17\r\nUnknown data object nmdc:b8f11f271313ebce716edfe8a9650118\r\nUnknown data object nmdc:957600e89955173435e9b35666e3f1d5\r\nUnknown data object nmdc:8c96c0ddd734b2d7c3355a85fb478727\r\nUnknown data object nmdc:fd4e4871caef5352801a0d58b2fc5727\r\nUnknown data object nmdc:ee594da0ca22271208e72ed9480b9878\r\nUnknown data object nmdc:03c49b063726126a4526bc96c3f03078\r\nUnknown data object nmdc:753162645bb37b64f3ef9c0b2ca8a935\r\nUnknown data object nmdc:1f02bef68a0a71ecbb325dfdbff6ae85\r\nUnknown data object nmdc:157f619acb8d1af497dbd311bb0129e0\r\nUnknown data object nmdc:44c38f11b62931b22a3e38e44e12a99b\r\nUnknown data object nmdc:eb216db5f15b5982f60cb2c5f0f82b97\r\nUnknown data object nmdc:690271181735467ff2f978d804ce4fee\r\nUnknown data object nmdc:0114daea61986c6cf6290657d1fa8ee0\r\nUnknown data object nmdc:376cc399590f368eaf5a486087750077\r\nUnknown data object nmdc:565eb354afc5db4ed502bb6dece91d03\r\nUnknown data object nmdc:4b9b0f82bf50950ecf8b77d24a141565\r\nUnknown data object nmdc:e4cf91ffe121a58186e6f123f117e0c2\r\nUnknown data object nmdc:18589f426c24e06ff58610dcd48f3bd9\r\nUnknown data object nmdc:e7e7582466f2c7d419e1d03f0b529879\r\nUnknown data object nmdc:bb14b03eb4a4e30fcea4b9faa98c08e0\r\nUnknown data object nmdc:59e944a5bd686bb1d85d9ad06356854a\r\nUnknown data object nmdc:d16c1df1b6eca2a3997c93250673c58d\r\nUnknown data object nmdc:80e2cf75fff69f6111ea7a738fe68eac\r\nLoading NOM analysis...\r\nLoading MAGs...\r\nSkipping annotation ingest\r\nLoading read qc...\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object jgi:5bd6893146d1e604fecfb2fd\r\nUnknown data object nmdc:61a97e80cb6d26e90f140f38b008abab\r\nUnknown data object nmdc:fee26dc0a11fb4a39c28d7130c2358f6\r\nUnknown data object nmdc:91ab0ce1ea61b477a64e57a872624cb4\r\nUnknown data object nmdc:340ba2dc2e14b38bf653cbc8dcedaf9b\r\nUnknown data object nmdc:5333beedf0b1a6aeac85fd52e0c954a6\r\nUnknown data object nmdc:5e84dfde0d632897ed93abf84fd75dbd\r\nUnknown data object nmdc:2ab91c737308518038e6e4c0925bd12f\r\nUnknown data object nmdc:7b093e525bf7741654105516790060a0\r\nUnknown data object nmdc:9a37ea20e51282596cf799605d6e912c\r\nUnknown data object nmdc:a198c6e6ba43f210857ca41f25e0ed10\r\nUnknown data object nmdc:f5b5e247913c5cdb5511dff98d349ce2\r\nUnknown data object nmdc:f408775f43e5a6041ade55edecaaeb1a\r\nUnknown data object nmdc:967517f83a03de07d4c0eb53f7c83f05\r\nUnknown data object nmdc:3900b15ebaa5ecba247164c7165d2f38\r\nUnknown data object nmdc:fc02b18994a1ea74808d16d18735a04a\r\nUnknown data object nmdc:2f05dd5770ff3ebe3b56f008854bac78\r\nUnknown data object nmdc:091325e3152cae4d694e2bbf5b7093db\r\nUnknown data object nmdc:8224d0f7d3ceb191111f6d49e415afc8\r\nUnknown data object nmdc:6f503435c01cf49ed7805ce4c2d26d46\r\nUnknown data object nmdc:995c8b403d4ae43206bcd9cb0168d7a7\r\nUnknown data object nmdc:8f80860812e425dd92344f1f056d3d7e\r\nUnknown data object nmdc:8d16af5ca7671f7dc42de14deb8b0dd5\r\nUnknown data object nmdc:e0e0b9582935ccbf60eab11942ee902b\r\nUnknown data object nmdc:300109666a890c83f10c431a6245561a\r\nUnknown data object nmdc:da44ab401932bc11c5c7e2ec4f50d945\r\nUnknown data object nmdc:076ff634d28625c03f79842a9b3bb354\r\nUnknown data object nmdc:f2b267f00e22a74e94e6dd75fe0531f0\r\nUnknown data object nmdc:a6596e0c6c077b864048f00a68ab6c78\r\nUnknown data object nmdc:dac54b23fce5a5c56c11311c77b74294\r\nUnknown data object nmdc:dd43946edb26961e1913c8830f54e5cf\r\nUnknown data object nmdc:6e84b6d72daf43591617f4c278a8540f\r\nUnknown data object nmdc:452104acaf8a6d065f9a8fdbd64ee882\r\nUnknown data object nmdc:f9f1ddf2e1eca8e9c8a18b5096433c54\r\nUnknown data object nmdc:94f5b389c2d9f7f5bc92e9fddedfc775\r\nUnknown data object nmdc:0df5ac2c9052a2b45cfd9578aaa562f7\r\nUnknown data object nmdc:65b3ee1c8092cfe1b7fef18cbca970d9\r\nUnknown data object nmdc:38116da337f1e868ba6fec5a184ba2fc\r\nUnknown data object nmdc:4acac4ba90588c9923ed2d02d3f516b7\r\nUnknown data object nmdc:20f714c290eeba8f76fe33ea21bf2291\r\nUnknown data object nmdc:c4df425ae66b46dcf353097aa64c8935\r\nUnknown data object nmdc:0afe727fea9effca194d4b1f607984ff\r\nUnknown data object nmdc:2112eaa62884c29f33a47669bf01bb53\r\nUnknown data object nmdc:cb53962aabcda827b19e270a805dc0e1\r\nUnknown data object nmdc:f098da7fe12707ec59757cd2dfb94d26\r\nUnknown data object nmdc:acee10e153052c8b7bc98c2fe462fdd9\r\nUnknown data object nmdc:c139345a1c2ba3d6883a53a85463e8e4\r\nUnknown data object nmdc:8d9b361423c5819782294a8789859b9b\r\nUnknown data object nmdc:9a18a44f56928a2d4cb4e1541e182799\r\nUnknown data object nmdc:d38a56c9121372e8eb41f4f8f139481c\r\nUnknown data object nmdc:4fa30e2045705f394631c65180c5199a\r\nUnknown data object nmdc:e444ada18237f6db32de92516773b0d5\r\nUnknown data object nmdc:f31a2a473fa6cc081ff6c136d79c454a\r\nUnknown data object nmdc:722f2dbb28d08d2f65cacea4c5435da2\r\nUnknown data object nmdc:259a1435146041ed02aa079a007fb06c\r\nUnknown data object nmdc:c52cdaa42622674591c66ceeb0c33758\r\nUnknown data object nmdc:59532226ec5755915a032e602dc04a03\r\nUnknown data object nmdc:62915d08fc404130f4abe2c947a4e13e\r\nUnknown data object nmdc:49b6ab7f5a43b171f4b6de616624fe02\r\nUnknown data object nmdc:8656757191fe5a86d3a4d524d5f513e2\r\nUnknown data object nmdc:74621bf24161e2e072c651c0c489b521\r\nUnknown data object nmdc:3896cc46b145ba465c67a164e7446400\r\nUnknown data object nmdc:19edfbb924938737398f443c7342d913\r\nUnknown data object nmdc:1d2ea6cc3c176479f6355a6716bf0279\r\nUnknown data object nmdc:44cd635395e777cfab314dcf1789b6d2\r\nUnknown data object nmdc:bef74063c8db88eca336299184d80942\r\nUnknown data object nmdc:65b806917315e7518fdd36887bca0190\r\nUnknown data object nmdc:f4ddf238d2d7dec9c86b93713d0ff075\r\nUnknown data object nmdc:796233a318facd24d5c14f44f479dc43\r\nUnknown data object nmdc:b6d907e2b41d013afcb2b6aa81c1be87\r\nUnknown data object nmdc:00a2071567e1e8e58bef5263fbdf7905\r\nUnknown data object nmdc:82254db0eab492d5074a5d36b96e491a\r\nUnknown data object nmdc:dbfdeaccbb5b01e4b567e04c1ec60b95\r\nUnknown data object nmdc:22afa3d49b73eaec2e9787a6b88fbdc3\r\nUnknown data object nmdc:625075a39014d701fda177605f8f8858\r\nUnknown data object nmdc:908fe1703358c811ae7bf408886a6e87\r\nUnknown data object nmdc:86cb807a667b81fabb252a75eb79022c\r\nUnknown data object nmdc:754dde7a211a1cd9ecfb990d799c86fc\r\nUnknown data object nmdc:104c9da6da3a685e5b1b8a3b2652bdd7\r\nUnknown data object nmdc:57bd602fa807024237878435a358d136\r\nUnknown data object nmdc:4b5fb58671da52ebbff9fc85324638ac\r\nUnknown data object nmdc:2a3baceee6e3dd4c4fc13567c2fd5df3\r\nUnknown data object nmdc:fb1897fb6c87bcf5b25c76e0ac149b67\r\nUnknown data object nmdc:52c9e32cf184310313c50a4b0f98f87f\r\nUnknown data object nmdc:d08893db578667fdc61428fde84f8279\r\nUnknown data object nmdc:492b743dc4a3ab1c730dd0e12912d8d1\r\nUnknown data object nmdc:fe61b5e7c3aff7b27e5be1f97f55efda\r\nUnknown data object nmdc:ef11b09bff6940ee45f3c05842b16931\r\nUnknown data object nmdc:7f57dcee7abd6613a46bed9e6d3bc61b\r\nUnknown data object nmdc:9676ebc038756ae55077770846391495\r\nUnknown data object nmdc:4779dacd0e7071f528be8c03fac547e7\r\nUnknown data object nmdc:72779f8c6bba0a95693c89a92f4f6be3\r\nUnknown data object nmdc:8a573eec92876f6621ae5305d9ed3bd2\r\nUnknown data object nmdc:d18ad58ac8a0a7e9748c518081f9059d\r\nUnknown data object nmdc:2437e48c81f26729595351c727f94b0b\r\nUnknown data object nmdc:12b43da62aae4332869c589de5853062\r\nUnknown data object nmdc:087821706edc18d844ab743ec8865569\r\nUnknown data object nmdc:a1852a6601023d802e67f41aef7dfcde\r\nUnknown data object nmdc:a68418156612ccea5ffa4c2d9b6a6114\r\nUnknown data object nmdc:60ee79e73d43651cee0e89de0c346a20\r\nUnknown data object nmdc:426202d9528d4af01aa6aeeb6ebb5aac\r\nUnknown data object nmdc:989711381573525c3c32f77fb8b4bcf7\r\nUnknown data object nmdc:cf4c63cdb2f8d4b17dc591ac83c042e0\r\nUnknown data object nmdc:0f65059f9df59fe318f2780fc2e0605d\r\nUnknown data object nmdc:7f0c6c7be34ce22ab91df9a75f3e4379\r\nUnknown data object nmdc:b0638ba985a67df56f072b7544e46317\r\nUnknown data object nmdc:8139981465fa40b6488805919efdbcd6\r\nLoading metaproteomic analysis...\r\nUnknown data object nmdc:7bfe2f3c086105ffe665317a21af38d3\r\nUnknown data object nmdc:ff5f339ebacb8f723d133f3c2daff1bf\r\nUnknown data object nmdc:7bfe2f3c086105ffe665317a21af38d3\r\nUnknown data object nmdc:7bfe2f3c086105ffe665317a21af38d3\r\nUnknown data object nmdc:7bfe2f3c086105ffe665317a21af38d3\r\nUnknown data object nmdc:7bfe2f3c086105ffe665317a21af38d3\r\nUnknown data object nmdc:7bfe2f3c086105ffe665317a21af38d3\r\nUnknown data object nmdc:7bfe2f3c086105ffe665317a21af38d3\r\nUnknown data object nmdc:7bfe2f3c086105ffe665317a21af38d3\r\nUnknown data object nmdc:7bfe2f3c086105ffe665317a21af38d3\r\nUnknown data object nmdc:7bfe2f3c086105ffe665317a21af38d3\r\nUnknown data object nmdc:7bfe2f3c086105ffe665317a21af38d3\r\nUnknown data object nmdc:7bfe2f3c086105ffe665317a21af38d3\r\nUnknown data object nmdc:7bfe2f3c086105ffe665317a21af38d3\r\nUnknown data object nmdc:7bfe2f3c086105ffe665317a21af38d3\r\nUnknown data object nmdc:7bfe2f3c086105ffe665317a21af38d3\r\nUnknown data object nmdc:7bfe2f3c086105ffe665317a21af38d3\r\nUnknown data object nmdc:7bfe2f3c086105ffe665317a21af38d3\r\nUnknown data object nmdc:7bfe2f3c086105ffe665317a21af38d3\r\nUnknown data object nmdc:7bfe2f3c086105ffe665317a21af38d3\r\nUnknown data object nmdc:7bfe2f3c086105ffe665317a21af38d3\r\nUnknown data object nmdc:7bfe2f3c086105ffe665317a21af38d3\r\nUnknown data object nmdc:7bfe2f3c086105ffe665317a21af38d3\r\nUnknown data object nmdc:7bfe2f3c086105ffe665317a21af38d3\r\nUnknown data object nmdc:7bfe2f3c086105ffe665317a21af38d3\r\nUnknown data object nmdc:7bfe2f3c086105ffe665317a21af38d3\r\nUnknown data object nmdc:7bfe2f3c086105ffe665317a21af38d3\r\nUnknown data object nmdc:7bfe2f3c086105ffe665317a21af38d3\r\nUnknown data object nmdc:7bfe2f3c086105ffe665317a21af38d3\r\nUnknown data object nmdc:7bfe2f3c086105ffe665317a21af38d3\r\nUnknown data object nmdc:7bfe2f3c086105ffe665317a21af38d3\r\nUnknown data object nmdc:7bfe2f3c086105ffe665317a21af38d3\r\nUnknown data object nmdc:7bfe2f3c086105ffe665317a21af38d3\r\nUnknown data object nmdc:7bfe2f3c086105ffe665317a21af38d3\r\nLoading metagenome assembly...\r\nPopulating mga_gene_functions...\r\nPopulating metap_gene_functions...\r\nPopulating multiomics...\r\nPreprocessing envo term data\r\nLoading search indices\r\nIngest finished successfully\r\nmissing biosample:\r\ngold:Gb0119280\r\nmissing data_object:\r\nnmdc:6a455b07be6e9c6b3f0631858a8ade17\r\nnmdc:57bd602fa807024237878435a358d136\r\nnmdc:1d2ea6cc3c176479f6355a6716bf0279\r\nnmdc:86cb807a667b81fabb252a75eb79022c\r\nnmdc:60ee79e73d43651cee0e89de0c346a20\r\nnmdc:2437e48c81f26729595351c727f94b0b\r\nnmdc:19edfbb924938737398f443c7342d913\r\nnmdc:74621bf24161e2e072c651c0c489b521\r\nnmdc:65b3ee1c8092cfe1b7fef18cbca970d9\r\nnmdc:f9f1ddf2e1eca8e9c8a18b5096433c54\r\nnmdc:bb14b03eb4a4e30fcea4b9faa98c08e0\r\nnmdc:cf4c63cdb2f8d4b17dc591ac83c042e0\r\nnmdc:4fa30e2045705f394631c65180c5199a\r\nnmdc:9676ebc038756ae55077770846391495\r\nnmdc:61a97e80cb6d26e90f140f38b008abab\r\nnmdc:091325e3152cae4d694e2bbf5b7093db\r\nnmdc:492b743dc4a3ab1c730dd0e12912d8d1\r\nnmdc:03c49b063726126a4526bc96c3f03078\r\nnmdc:c139345a1c2ba3d6883a53a85463e8e4\r\nnmdc:f408775f43e5a6041ade55edecaaeb1a\r\nnmdc:2a3baceee6e3dd4c4fc13567c2fd5df3\r\nnmdc:8139981465fa40b6488805919efdbcd6\r\nnmdc:3900b15ebaa5ecba247164c7165d2f38\r\nnmdc:da44ab401932bc11c5c7e2ec4f50d945\r\nnmdc:49b6ab7f5a43b171f4b6de616624fe02\r\nnmdc:ee594da0ca22271208e72ed9480b9878\r\nnmdc:426202d9528d4af01aa6aeeb6ebb5aac\r\nnmdc:087821706edc18d844ab743ec8865569\r\nnmdc:7b093e525bf7741654105516790060a0\r\nnmdc:2112eaa62884c29f33a47669bf01bb53\r\nnmdc:076ff634d28625c03f79842a9b3bb354\r\nnmdc:e7e7582466f2c7d419e1d03f0b529879\r\nnmdc:94f5b389c2d9f7f5bc92e9fddedfc775\r\nnmdc:00a2071567e1e8e58bef5263fbdf7905\r\nnmdc:989711381573525c3c32f77fb8b4bcf7\r\nnmdc:e4cf91ffe121a58186e6f123f117e0c2\r\nnmdc:59532226ec5755915a032e602dc04a03\r\nnmdc:157f619acb8d1af497dbd311bb0129e0\r\nnmdc:61f06a2309788ded26b1fdec53ca3791\r\nnmdc:59e944a5bd686bb1d85d9ad06356854a\r\nnmdc:f31a2a473fa6cc081ff6c136d79c454a\r\nnmdc:5333beedf0b1a6aeac85fd52e0c954a6\r\nnmdc:fee26dc0a11fb4a39c28d7130c2358f6\r\nnmdc:e0e0b9582935ccbf60eab11942ee902b\r\nnmdc:fd4e4871caef5352801a0d58b2fc5727\r\nnmdc:a68418156612ccea5ffa4c2d9b6a6114\r\nnmdc:dac54b23fce5a5c56c11311c77b74294\r\nnmdc:565eb354afc5db4ed502bb6dece91d03\r\nnmdc:35280ee871ca08e52849a30f18c497b0\r\nnmdc:c8d6693287398701b91c4d194856d0f3\r\nnmdc:7f57dcee7abd6613a46bed9e6d3bc61b\r\nnmdc:af403f9e2180b4ee5f0d536f6130a50d\r\nnmdc:88c54f9cd321218cfecdd844c999f402\r\nnmdc:7455b386b754925ce055f8f585f6242c\r\nnmdc:a1852a6601023d802e67f41aef7dfcde\r\nnmdc:8656757191fe5a86d3a4d524d5f513e2\r\nnmdc:8ec141e339b4bedc49fbef7236422bec\r\nnmdc:625075a39014d701fda177605f8f8858\r\nnmdc:12b43da62aae4332869c589de5853062\r\nnmdc:0afe727fea9effca194d4b1f607984ff\r\nnmdc:ff5f339ebacb8f723d133f3c2daff1bf\r\nnmdc:6f503435c01cf49ed7805ce4c2d26d46\r\nnmdc:38116da337f1e868ba6fec5a184ba2fc\r\nnmdc:fc02b18994a1ea74808d16d18735a04a\r\nnmdc:369be15c709557b137c6ad6994ced3e4\r\nnmdc:d08893db578667fdc61428fde84f8279\r\nnmdc:0114daea61986c6cf6290657d1fa8ee0\r\nnmdc:44cd635395e777cfab314dcf1789b6d2\r\nnmdc:acee10e153052c8b7bc98c2fe462fdd9\r\nnmdc:722f2dbb28d08d2f65cacea4c5435da2\r\nnmdc:995c8b403d4ae43206bcd9cb0168d7a7\r\nnmdc:9a18a44f56928a2d4cb4e1541e182799\r\nnmdc:8224d0f7d3ceb191111f6d49e415afc8\r\nnmdc:690271181735467ff2f978d804ce4fee\r\nnmdc:eb216db5f15b5982f60cb2c5f0f82b97\r\nnmdc:4779dacd0e7071f528be8c03fac547e7\r\nnmdc:f098da7fe12707ec59757cd2dfb94d26\r\nnmdc:3896cc46b145ba465c67a164e7446400\r\nnmdc:8d9b361423c5819782294a8789859b9b\r\nnmdc:d18ad58ac8a0a7e9748c518081f9059d\r\nnmdc:3d2cc3c5ba651c5f92302ee5c1c0d36b\r\nnmdc:5e84dfde0d632897ed93abf84fd75dbd\r\nnmdc:a198c6e6ba43f210857ca41f25e0ed10\r\nnmdc:7f0c6c7be34ce22ab91df9a75f3e4379\r\nnmdc:754dde7a211a1cd9ecfb990d799c86fc\r\nnmdc:8f80860812e425dd92344f1f056d3d7e\r\nnmdc:259a1435146041ed02aa079a007fb06c\r\nnmdc:0f65059f9df59fe318f2780fc2e0605d\r\nnmdc:0df5ac2c9052a2b45cfd9578aaa562f7\r\nnmdc:c4df425ae66b46dcf353097aa64c8935\r\nnmdc:fcc5bd82615fab43bb54006632862521\r\nnmdc:376cc399590f368eaf5a486087750077\r\nnmdc:b6d907e2b41d013afcb2b6aa81c1be87\r\nnmdc:22afa3d49b73eaec2e9787a6b88fbdc3\r\nnmdc:62915d08fc404130f4abe2c947a4e13e\r\nnmdc:52c9e32cf184310313c50a4b0f98f87f\r\nnmdc:f4ddf238d2d7dec9c86b93713d0ff075\r\nnmdc:dbfdeaccbb5b01e4b567e04c1ec60b95\r\nnmdc:4b5fb58671da52ebbff9fc85324638ac\r\nnmdc:5e81b6549123027d1b7b9f439bbd1cd0\r\nnmdc:957a5665e44143eea0c3a99b5665a51d\r\nnmdc:5e220105f8713dbb00a38eb3013b0f93\r\n\r\nnmdc:18589f426c24e06ff58610dcd48f3bd9\r\nnmdc:9a37ea20e51282596cf799605d6e912c\r\nnmdc:452104acaf8a6d065f9a8fdbd64ee882\r\nnmdc:f2b267f00e22a74e94e6dd75fe0531f0\r\nnmdc:44c38f11b62931b22a3e38e44e12a99b\r\nnmdc:967517f83a03de07d4c0eb53f7c83f05\r\nnmdc:6e84b6d72daf43591617f4c278a8540f\r\nnmdc:82254db0eab492d5074a5d36b96e491a\r\nnmdc:bef74063c8db88eca336299184d80942\r\nnmdc:b8f11f271313ebce716edfe8a9650118\r\nnmdc:4acac4ba90588c9923ed2d02d3f516b7\r\nnmdc:dd43946edb26961e1913c8830f54e5cf\r\nnmdc:1f02bef68a0a71ecbb325dfdbff6ae85\r\nnmdc:91ab0ce1ea61b477a64e57a872624cb4\r\nnmdc:8c96c0ddd734b2d7c3355a85fb478727\r\nnmdc:4b9b0f82bf50950ecf8b77d24a141565\r\nnmdc:753162645bb37b64f3ef9c0b2ca8a935\r\nnmdc:8f6ed75bd49fa03502adbd7ec7c55a09\r\nnmdc:e444ada18237f6db32de92516773b0d5\r\nnmdc:7bfe2f3c086105ffe665317a21af38d3\r\nnmdc:2ab91c737308518038e6e4c0925bd12f\r\nnmdc:8d16af5ca7671f7dc42de14deb8b0dd5\r\nnmdc:f5b5e247913c5cdb5511dff98d349ce2\r\nnmdc:cb53962aabcda827b19e270a805dc0e1\r\nnmdc:80e2cf75fff69f6111ea7a738fe68eac\r\nnmdc:72779f8c6bba0a95693c89a92f4f6be3\r\nnmdc:908fe1703358c811ae7bf408886a6e87\r\nnmdc:2f05dd5770ff3ebe3b56f008854bac78\r\nnmdc:8ef63c54cbfef72c19733e48ad0d1961\r\nnmdc:340ba2dc2e14b38bf653cbc8dcedaf9b\r\nnmdc:d16c1df1b6eca2a3997c93250673c58d\r\nnmdc:c52cdaa42622674591c66ceeb0c33758\r\nnmdc:d38a56c9121372e8eb41f4f8f139481c\r\nnmdc:b0638ba985a67df56f072b7544e46317\r\nnmdc:8a573eec92876f6621ae5305d9ed3bd2\r\nnmdc:18b8afd638a9bb80a633f138150b7edd\r\nnmdc:300109666a890c83f10c431a6245561a\r\nnmdc:796233a318facd24d5c14f44f479dc43\r\njgi:5bd6893146d1e604fecfb2fd\r\nnmdc:ef11b09bff6940ee45f3c05842b16931\r\nnmdc:a6596e0c6c077b864048f00a68ab6c78\r\nnmdc:20f714c290eeba8f76fe33ea21bf2291\r\nnmdc:104c9da6da3a685e5b1b8a3b2652bdd7\r\nnmdc:fb1897fb6c87bcf5b25c76e0ac149b67\r\nnmdc:fe61b5e7c3aff7b27e5be1f97f55efda\r\nnmdc:957600e89955173435e9b35666e3f1d5\r\nnmdc:65b806917315e7518fdd36887bca0190\r\n\r\n```",
"body": "When DataHarmonizer templates are generated from LinkML by [linkml_to_dh_no_annotations.py](https://github.com/turbomam/linkml-round-trips/blob/main/linkml_round_trips/linkml_to_dh_no_annotations.py), the sections are arranged alphabetically, as are the columns within each section.\r\n\r\nThe identifiers section should probably always come first, because the first column is frozen from scrolling. The appropriate column can be determined if it has the `identifier` attribute set.\r\n",
"body": "I believe this is the ticket for \"verify definition of INSDC slots\".\r\nINSDC has \"- insdc_biosample_identifiers\" & \"insdc_secondary_sample_identifiers\"\r\nBEFORE we assign these slots to Biosample class we need to verify that the INSDC definition of a biosamples matches that of NMDC.\r\n\r\nChris thinks the INSDC biosample IS NOT the biosample, but rather the data product or analytical sample. (Biosample = environmental material, soil, source material, starting material).",
"body": "@mslarae13 will indicate which fields and packages she wants to include",
"body": "@dehays is following up with team on a few issues. Should be closed soon but will move to December sprint per David.",
"body": "Per email exchange with @cmungall @pvangay @mslarae13 , all Brodie samples should be updated to be consistent with the following: \r\n\r\n biome: meadow ecosystem\r\n feature: watershed\r\n material: bulk soil\r\n\r\nyay change sheets! @wdduncan @dehays ",
"body": "For all biosamples part_of \"gold:Gs0135149\"\r\n\r\n`{part_of: [\"gold:Gs0135149\"]}`\r\n\r\n53 total samples\r\n\r\nenv_broad_scale.has_raw_value --> \"ENVO:00000108\"\r\nenv_local_scale.has_raw_value --> \"ENVO:00000292\"\r\nenv_medium.has_raw_value --> \"ENVO:00005802\"\r\n",
"body": "All Brodie study samples have been updated by change sheet per EnvO terms above",
"body": "Figure out environment for Brodie\u2019s 5 samples (captured[ here](https://github.com/microbiomedata/nmdc-server/issues/537#issuecomment-941632979))",
"body": "@emileyfadrosh and @dehays I know we are still trying to get in touch with NEON so I will move this to the November sprint. If it should be in the backlog instead please let me know.  ",
"body": "Let's move this to the backlog. It's not clear the timing on re-engagement with a relevant NEON POC. Thanks. ",
"body": "I do not know what the current status of NEON data is.  NEON is not among the data sources I've heard discussed recently.\r\n\r\nAssigning to Emiley so she can assign when NEON data work is needed",
"body": "Deprecating this ticket in favor of the squad work happening in 2023. We will be using NEON directly which has more comprehensive data compared to the subset of records in NCBI.",
"body": "Process NEON data into portal\t\r\n\r\nAll data in NCBI: https://trace.ncbi.nlm.nih.gov/Traces/sra/?study=ERP024395 \r\n\r\nDavid to use this GOLD study https://gold.jgi.doe.gov/study?id=Gs0144570 -  was curated with EnvO terms by Jagadish.\r\n\r\nReassign to Bin/Shane/Kitware as needed. \r\n",
"body": "Assigned to Mark to start.  Can re-assign to Shane/Bin/Kitware or we can create new issues for them as needed.",
"body": "Calrifying: there is no requirement to get metadata from EBI\r\n\r\nThis is the corresponding record in qiita: https://qiita.ucsd.edu/public/?study_id=13114\r\n\r\nThis has metagenome and 16S - no metabolomics\r\n\r\nEach of the qiita records unfolds to something like (for a 16s):\r\n\r\n```\r\nartifact_88547_102721-133454\r\nartifact_88547_102721-133454/.DS_Store\r\nartifact_88547_102721-133454/Demultiplexed\r\nartifact_88547_102721-133454/Demultiplexed/88547\r\nartifact_88547_102721-133454/Demultiplexed/88547/seqs.demux\r\nartifact_88547_102721-133454/Demultiplexed/88547/seqs.fastq.gz\r\nartifact_88547_102721-133454/Demultiplexed/88547/seqs.fasta.gz\r\nartifact_88547_102721-133454/mapping_files\r\nartifact_88547_102721-133454/mapping_files/88547_mapping_file.txt\r\n```\r\n\r\nThe mapping file has the metadata:\r\n\r\n|sample_name|aliquot|barcode|center_name|experiment_design_description|extraction_robot|extractionkit_lot|instrument_model|library_construction_protocol|linker|mastermix_lot|pcr_primers|platform|plating|primer|primer_date|primer_plate|processing_robot|qiita_prep_id|run_center|run_date|run_prefix|runid|sample_plate|sequencing_meth|target_gene|target_subfragment|tm1000_8_tool|tm300_8_tool|tm50_8_tool|water_lot|well_description|well_id|\r\n|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\r\n|13114.BLANK5.5A|Not applicable|GATCCGGCAGGA|UCSDMI|samples from EMP 500|Carmen_HOWE_KF1|157025216|Illumina MiSeq|Illumina EMP protocol 515fbc, 806r amplification of 16S rRNA V4|GT|594370_584456|FWD:GTGYCAGCMGCCGCGGTAA; REV:GGACTACNVGGGTWTCTAAT|Illumina|NA|GTGTGYCAGCMGCCGCGGTAA|31218|5|NA|8755|UCSDMI|8/15/18|EMP500_MiniPCR_16S_5-8_S1_L001|180815_M05314_0114_000000000-BYGF5|EMP_500_MiniPCR_16S_Plate_5|Sequencing by synthesis|16S rRNA|V4|108379Z|NA|NA|9217050|EMP_500_MiniPCR_16S_Plate_5_BLANK5.5A_A5|A5|\r\n|13114.BLANK5.5B|Not applicable|CTTCCAACTCAT|UCSDMI|samples from EMP 500|Carmen_HOWE_KF1|157025216|Illumina MiSeq|Illumina EMP protocol 515fbc, 806r amplification of 16S rRNA V4|GT|594370_584456|FWD:GTGYCAGCMGCCGCGGTAA; REV:GGACTACNVGGGTWTCTAAT|Illumina|NA|GTGTGYCAGCMGCCGCGGTAA|31218|5|NA|8755|UCSDMI|8/15/18|EMP500_MiniPCR_16S_5-8_S1_L001|180815_M05314_0114_000000000-BYGF5|EMP_500_MiniPCR_16S_Plate_5|Sequencing by synthesis|16S rRNA|V4|108379Z|NA|NA|9217050|EMP_500_MiniPCR_16S_Plate_5_BLANK5.5B_B5|B5|\r\n|13114.BLANK5.5C|Not applicable|CGACCTCGCATA|UCSDMI|samples from EMP 500|Carmen_HOWE_KF1|157025216|Illumina MiSeq|Illumina EMP protocol 515fbc, 806r amplification of 16S rRNA V4|GT|594370_584456|FWD:GTGYCAGCMGCCGCGGTAA; REV:GGACTACNVGGGTWTCTAAT|Illumina|NA|GTGTGYCAGCMGCCGCGGTAA|31218|5|NA|8755|UCSDMI|8/15/18|EMP500_MiniPCR_16S_5-8_S1_L001|180815_M05314_0114_000000000-BYGF5|EMP_500_MiniPCR_16S_Plate_5|Sequencing by synthesis|16S rRNA|V4|108379Z|NA|NA|9217050|EMP_500_MiniPCR_16S_Plate_5_BLANK5.5C_C5|C5|\r\n|13114.BLANK5.5D|Not applicable|GTCAGAGTATTG|UCSDMI|samples from EMP 500|Carmen_HOWE_KF1|157025216|Illumina MiSeq|Illumina EMP protocol 515fbc, 806r amplification of 16S rRNA V4|GT|594370_584456|FWD:GTGYCAGCMGCCGCGGTAA; REV:GGACTACNVGGGTWTCTAAT|Illumina|NA|GTGTGYCAGCMGCCGCGGTAA|31218|5|NA|8755|UCSDMI|8/15/18|EMP500_MiniPCR_16S_5-8_S1_L001|180815_M05314_0114_000000000-BYGF5|EMP_500_MiniPCR_16S_Plate_5|Sequencing by synthesis|16S rRNA|V4|108379Z|NA|NA|9217050|EMP_500_MiniPCR_16S_Plate_5_BLANK5.5D_D5|D5|\r\n|13114.BLANK6.10C|Not applicable|TCCTAGGTCCGA|UCSDMI|samples from EMP 500|Carmen_HOWE_KF2|157025216|Illumina MiSeq|Illumina EMP protocol 515fbc, 806r amplification of 16S rRNA V4|GT|594370_584456|FWD:GTGYCAGCMGCCGCGGTAA; REV:GGACTACNVGGGTWTCTAAT|Illumina|NA|GTGTGYCAGCMGCCGCGGTAA|31218|6|NA|8755|UCSDMI|8/15/18|EMP500_MiniPCR_16S_5-8_S1_L001|180815_M05314_0114_000000000-BYGF5|EMP_500_MiniPCR_16S_Plate_6|Sequencing by synthesis|16S rRNA|V4|108379Z|NA|NA|9217050|EMP_500_MiniPCR_16S_Plate_6_BLANK6.10C_C10|C10|\r\n\r\nfor a metagenome:\r\n\r\n```\r\nartifact_125499_102721-144437\r\nartifact_125499_102721-144437/BIOM\r\nartifact_125499_102721-144437/BIOM/125499\r\nartifact_125499_102721-144437/BIOM/125499/feature-table.qza\r\nartifact_125499_102721-144437/BIOM/125499/support_files\r\nartifact_125499_102721-144437/BIOM/125499/support_files/sample-frequency-detail.html\r\nartifact_125499_102721-144437/BIOM/125499/support_files/index.html\r\nartifact_125499_102721-144437/BIOM/125499/support_files/licenses\r\nartifact_125499_102721-144437/BIOM/125499/support_files/licenses/vega.txt\r\nartifact_125499_102721-144437/BIOM/125499/support_files/licenses/vega-embed.txt\r\nartifact_125499_102721-144437/BIOM/125499/support_files/css\r\nartifact_125499_102721-144437/BIOM/125499/support_files/css/spinkit.css\r\nartifact_125499_102721-144437/BIOM/125499/support_files/sample-frequencies.png\r\nartifact_125499_102721-144437/BIOM/125499/support_files/js\r\nartifact_125499_102721-144437/BIOM/125499/support_files/js/vega.min.js\r\nartifact_125499_102721-144437/BIOM/125499/support_files/js/vega-embed.min.js\r\nartifact_125499_102721-144437/BIOM/125499/support_files/feature-frequency-detail.csv\r\nartifact_125499_102721-144437/BIOM/125499/support_files/sample-frequencies.pdf\r\nartifact_125499_102721-144437/BIOM/125499/support_files/feature-frequency-detail.html\r\nartifact_125499_102721-144437/BIOM/125499/support_files/sample-frequency-detail.csv\r\nartifact_125499_102721-144437/BIOM/125499/support_files/feature-frequencies.pdf\r\nartifact_125499_102721-144437/BIOM/125499/support_files/feature-frequencies.png\r\nartifact_125499_102721-144437/BIOM/125499/support_files/q2templateassets\r\nartifact_125499_102721-144437/BIOM/125499/support_files/q2templateassets/css\r\nartifact_125499_102721-144437/BIOM/125499/support_files/q2templateassets/css/bootstrap.min.css\r\nartifact_125499_102721-144437/BIOM/125499/support_files/q2templateassets/css/base-template.css\r\nartifact_125499_102721-144437/BIOM/125499/support_files/q2templateassets/css/tab-parent.css\r\nartifact_125499_102721-144437/BIOM/125499/support_files/q2templateassets/css/normalize.css\r\nartifact_125499_102721-144437/BIOM/125499/support_files/q2templateassets/js\r\nartifact_125499_102721-144437/BIOM/125499/support_files/q2templateassets/js/parent.js\r\nartifact_125499_102721-144437/BIOM/125499/support_files/q2templateassets/js/bootstrap.min.js\r\nartifact_125499_102721-144437/BIOM/125499/support_files/q2templateassets/js/jquery-3.2.0.min.js\r\nartifact_125499_102721-144437/BIOM/125499/support_files/q2templateassets/js/child.js\r\nartifact_125499_102721-144437/BIOM/125499/support_files/q2templateassets/img\r\nartifact_125499_102721-144437/BIOM/125499/support_files/q2templateassets/img/qiime2-rect-200.png\r\nartifact_125499_102721-144437/BIOM/125499/support_files/q2templateassets/fonts\r\nartifact_125499_102721-144437/BIOM/125499/support_files/q2templateassets/fonts/glyphicons-halflings-regular.woff\r\nartifact_125499_102721-144437/BIOM/125499/support_files/q2templateassets/fonts/glyphicons-halflings-regular.eot\r\nartifact_125499_102721-144437/BIOM/125499/support_files/q2templateassets/fonts/glyphicons-halflings-regular.woff2\r\nartifact_125499_102721-144437/BIOM/125499/support_files/q2templateassets/fonts/glyphicons-halflings-regular.ttf\r\nartifact_125499_102721-144437/BIOM/125499/support_files/q2templateassets/fonts/glyphicons-halflings-regular.svg\r\nartifact_125499_102721-144437/BIOM/125499/index.html\r\nartifact_125499_102721-144437/BIOM/125499/alignment.tar\r\nartifact_125499_102721-144437/BIOM/125499/free.biom\r\nartifact_125499_102721-144437/mapping_files\r\nartifact_125499_102721-144437/mapping_files/125499_mapping_file.txt\r\n\u279c  D\r\n```\r\n\r\n|sample_name|aliquot|center_name|center_project_name|experiment_design_description|forward_read|i5_index_id|i7_index_id|index|index2|instrument_model|lane|library_construction_protocol|platform|qiita_prep_id|reverse_read|run_center|run_date|run_prefix|runid|sample_name_old|sample_plate|sample_project|sample_well|sequencing_meth|\r\n|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\r\n|13114.angenent.65.s001|a00|UCSDMI|EMP500|EMP500 metagenomics|Angenent65_misc_104_S2_L002_R1_001_trimmed_paired.fastq.gz|iTru5_01_G|iTru7_107_10|AACTTGCC|GTTCCATG|Illumina NovaSeq 6000|2|Knight Lab Kapa HP|Illumina|8765|Angenent65_misc_104_S2_L002_R2_001_trimmed_paired.fastq.gz|UCSDMI|7/13/18|Angenent65_misc_104_S2_L002|180713_A00169_0105_AH5CCJDSXX|Angenent65_misc_104|EMP500_2_remake|Angenent65|I5|sequencing by synthesis|\r\n|13114.angenent.65.s002|a00|UCSDMI|EMP500|EMP500 metagenomics|Angenent65_misc_519_S8_L002_R1_001_trimmed_paired.fastq.gz|iTru5_18_A|iTru7_110_02|AACCGTTC|ACGCTTCT|Illumina NovaSeq 6000|2|Knight Lab Kapa HP|Illumina|8765|Angenent65_misc_519_S8_L002_R2_001_trimmed_paired.fastq.gz|UCSDMI|7/13/18|Angenent65_misc_519_S8_L002|180713_A00169_0105_AH5CCJDSXX|Angenent65_misc_519|EMP500_2_5-8_P8-9soil|Angenent65|C4|sequencing by synthesis|\r\n|13114.angenent.65.s003|a00|UCSDMI|EMP500|EMP500 metagenomics|Angenent65_misc_946_S9_L002_R1_001_trimmed_paired.fastq.gz|iTru5_05_G|iTru7_110_09|GGCGTTAT|ACATGCCA|Illumina NovaSeq 6000|2|Knight Lab Kapa HP|Illumina|8765|Angenent65_misc_946_S9_L002_R2_001_trimmed_paired.fastq.gz|UCSDMI|7/13/18|Angenent65_misc_946_S9_L002|180713_A00169_0105_AH5CCJDSXX|Angenent65_misc_946|KHP_2017_P6-9|Angenent65|I21|sequencing by synthesis|\r\n|13114.angenent.65.s004|a00|UCSDMI|EMP500|EMP500 metagenomics|Angenent65_misc_1022_S1_L002_R1_001_trimmed_paired.fastq.gz|iTru5_03_F|iTru7_109_03|CATTCGGT|CCTAGAGA|Illumina NovaSeq 6000|2|Knight Lab Kapa HP|Illumina|8765|Angenent65_misc_1022_S1_L002_R2_001_trimmed_paired.fastq.gz|UCSDMI|7/13/18|Angenent65_misc_1022_S1_L002|180713_A00169_0105_AH5CCJDSXX|Angenent65_misc_1022|KHP_2017_P6-9|Angenent65|E6|sequencing by synthesis|\r\n|13114.angenent.65.s005|a00|UCSDMI|EMP500|EMP500 metagenomics|Angenent65_misc_1538_S3_L002_R1_001_trimmed_paired.fastq.gz|iTru5_14_E|iTru7_113_09|TCAAGGAC|AATCGCTG|Illumina NovaSeq 6000|2|Knight Lab Kapa HP|Illumina|8765|Angenent65_misc_1538_S3_L002_R2_001_trimmed_paired.fastq.gz|UCSDMI|7/13/18|Angenent65_misc_1538_S3_L002|180713_A00169_0105_AH5CCJDSXX|Angenent65_misc_1538|EMP500_2_1-4|Angenent65|C14|sequencing by synthesis|\r\n|13114.angenent.65.s006|a00|UCSDMI|EMP500|EMP500 metagenomics|Angenent65_misc_1622_S4_L002_R1_001_trimmed_paired.fastq.gz|iTru5_117_D|iTru7_304_12|GAATCGTG|GTATCGAG|Illumina NovaSeq 6000|2|Knight Lab Kapa HP|Illumina|8765|Angenent65_misc_1622_S4_L002_R2_001_trimmed_paired.fastq.gz|UCSDMI|7/13/18|Angenent65_misc_1622_S4_L002|180713_A00169_0105_AH5CCJDSXX|Angenent65_misc_1622|EMP500_2_1-4|Angenent65|B12|sequencing by synthesis|\r\n|13114.angenent.65.s007|a00|UCSDMI|EMP500|EMP500 metagenomics|Angenent65_misc_1722_S5_L002_R1_001_trimmed_paired.fastq.gz|iTru5_121_H|iTru7_101_04|GATCCATG|GATGCTAC|Illumina NovaSeq 6000|2|Knight Lab Kapa HP|Illumina|8765|Angenent65_misc_1722_S5_L002_R2_001_trimmed_paired.fastq.gz|UCSDMI|7/13/18|Angenent65_misc_1722_S5_L002|180713_A00169_0105_AH5CCJDSXX|Angenent65_misc_1722|EMP500_2_1-4|Angenent65|J24|sequencing by synthesis|\r\n|13114.angenent.65.s008|a00|UCSDMI|EMP500|EMP500 metagenomics|Angenent65_misc_1818_S6_L002_R1_001_trimmed_paired.fastq.gz|iTru5_04_F|iTru7_109_11|GGTTGTCA|TTCCAGGT|Illumina NovaSeq 6000|2|Knight Lab Kapa HP|Illumina|8765|Angenent65_misc_1818_S6_L002_R2_001_trimmed_paired.fastq.gz|UCSDMI|7/13/18|Angenent65_misc_1818_S6_L002|180713_A00169_0105_AH5CCJDSXX|Angenent65_misc_1818|KHP_2017_P6-9|Angenent65|E8|sequencing by synthesis|\r\n",
"body": "Data have been downloaded to project scratch space in NERSC. New metaG workflow are being tested to support single end fastqs. We'll also need to import MGnify workflows since a lot of the data are 16S and 18S amplicon sequencing data. Will need to move to next sprint for processing.",
"body": "Moving to the November sprint to be included in release to portal.",
"body": "Not sure if this is the right metaB data, but this is what I found for EMP500 on GNPS - https://gnps.ucsd.edu/ProteoSAFe/result.jsp?task=3de2b5de5c274ca6b689977d08d84195&view=advanced_view\r\n\r\nMaybe this helps? @corilo @turbomam ",
"body": "Paul pointed me to this:\n\nhttps://massive.ucsd.edu/ProteoSAFe/dataset.jsp?task=3de2b5de5c274ca6b689977d08d84195\n\nSo looks like it is LC-MS acquired on a QExactive Orbitrap what we are\nunsure about is:\n\nWhat was the strategy used for data acquisition. DDA, DIA?\nBesides the mzML, is there the original raw data available?\nWhat was the sample preparation protocol?\nWhat was the separation protocol? Column used, solvent and gradient\nprogram?\n\n\nEm qua., 3 de nov. de 2021 \u00e0s 14:22, Kjiersten ***@***.***>\nescreveu:\n\n> Not sure if this is the right metaB data, but this is what I found for\n> EMP500 on GNPS -\n> https://gnps.ucsd.edu/ProteoSAFe/result.jsp?task=3de2b5de5c274ca6b689977d08d84195&view=advanced_view\n>\n> Maybe this helps? @corilo <https://github.com/corilo> @turbomam\n> <https://github.com/turbomam>\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/microbiomedata/nmdc-metadata/issues/400#issuecomment-960088646>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AEFQWITC7SONSD4AZXT4X6DUKGY3HANCNFSM5FUQATLQ>\n> .\n> Triage notifications on the go with GitHub Mobile for iOS\n> <https://apps.apple.com/app/apple-store/id1477376905?ct=notification-email&mt=8&pt=524675>\n> or Android\n> <https://play.google.com/store/apps/details?id=com.github.android&referrer=utm_campaign%3Dnotification-email%26utm_medium%3Demail%26utm_source%3Dgithub>.\n>\n>\n",
"body": "Awesome, thanks for listing out the questions.\n\nI think Emiley knows these folks and we can try to get those questions\naddressed directly.\n\nOn Wed, Nov 3, 2021 at 2:45 PM Yuri Corilo ***@***.***> wrote:\n\n> Paul pointed me to this:\n>\n>\n> https://massive.ucsd.edu/ProteoSAFe/dataset.jsp?task=3de2b5de5c274ca6b689977d08d84195\n>\n> So looks like it is LC-MS acquired on a QExactive Orbitrap what we are\n> unsure about is:\n>\n> What was the strategy used for data acquisition. DDA, DIA?\n> Besides the mzML, is there the original raw data available?\n> What was the sample preparation protocol?\n> What was the separation protocol? Column used, solvent and gradient\n> program?\n>\n>\n> Em qua., 3 de nov. de 2021 \u00e0s 14:22, Kjiersten ***@***.***>\n> escreveu:\n>\n> > Not sure if this is the right metaB data, but this is what I found for\n> > EMP500 on GNPS -\n> >\n> https://gnps.ucsd.edu/ProteoSAFe/result.jsp?task=3de2b5de5c274ca6b689977d08d84195&view=advanced_view\n> >\n> > Maybe this helps? @corilo <https://github.com/corilo> @turbomam\n> > <https://github.com/turbomam>\n> >\n> > \u2014\n> > You are receiving this because you were mentioned.\n> > Reply to this email directly, view it on GitHub\n> > <\n> https://github.com/microbiomedata/nmdc-metadata/issues/400#issuecomment-960088646\n> >,\n> > or unsubscribe\n> > <\n> https://github.com/notifications/unsubscribe-auth/AEFQWITC7SONSD4AZXT4X6DUKGY3HANCNFSM5FUQATLQ\n> >\n> > .\n> > Triage notifications on the go with GitHub Mobile for iOS\n> > <\n> https://apps.apple.com/app/apple-store/id1477376905?ct=notification-email&mt=8&pt=524675\n> >\n> > or Android\n> > <\n> https://play.google.com/store/apps/details?id=com.github.android&referrer=utm_campaign%3Dnotification-email%26utm_medium%3Demail%26utm_source%3Dgithub\n> >.\n> >\n> >\n>\n> \u2014\n> You are receiving this because you commented.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/microbiomedata/nmdc-metadata/issues/400#issuecomment-960147770>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AALPGDYR5GONC74WTRK4TTTUKGUPXANCNFSM5FUQATLQ>\n> .\n> Triage notifications on the go with GitHub Mobile for iOS\n> <https://apps.apple.com/app/apple-store/id1477376905?ct=notification-email&mt=8&pt=524675>\n> or Android\n> <https://play.google.com/store/apps/details?id=com.github.android&referrer=utm_campaign%3Dnotification-email%26utm_medium%3Demail%26utm_source%3Dgithub>.\n>\n>\n",
"body": "I have Google Sheets with\r\n- EMP500 SRA run IDs, with an indication of whether they are from WGS or amplicon experiments\r\n    - [EMP500 SRA runs amplicon vs WGS aka PRJEB42019_SRRs](https://docs.google.com/spreadsheets/d/1p5Me9fjBr7oADORleM7uGAnDZwV1vDWhM2bmSPVMnkQ/edit#gid=576786620)\r\n    - @hubin-keio also wants to know the endedness\r\n    - This was created with manual mouse clicking at the NCBI web interface. Code could be written to replicate it with efetch in BioPython.\r\n- EMP500 BioSample metadata\r\n    - [emp500_study_id_biosample_attributes_wide](https://docs.google.com/spreadsheets/d/1vk2S63uczLdkL5zHJ_JX_J9bAhbQ9G3JHrKkWfEIuMc/edit#gid=1621069737)\r\n    - There are two header rows. The second one includes harmonized attribute names for the attributes submitted by the EMP500 people, if a harmonized name is available\r\n    - This was extracted from the BioSample XML file with an XQuery. I'll post that soon.",
"body": "@emileyfadrosh regarding questions for the EMP500 people: I see there have been a few mentions of metabolomics samples in this issue, but I haven't really looked into them yet.\r\n\r\nWould you please ask for a list of EMP500 sample identifiers for samples that underwent metabolomics data? I don't think I need to get the metabolomics data files, but maybe other people in NMDC need to, so you could ask for tem too.",
"body": "Moving this to the December sprint per @turbomam via Slack",
"body": "> @emileyfadrosh regarding questions for the EMP500 people: I see there have been a few mentions of metabolomics samples in this issue, but I haven't really looked into them yet.\r\n> \r\n> Would you please ask for a list of EMP500 sample identifiers for samples that underwent metabolomics data? I don't think I need to get the metabolomics data files, but maybe other people in NMDC need to, so you could ask for tem too.\r\n\r\n@turbomam Did you get a response on this?  Should I keep this GH issue open till February?  ",
"body": "I haven't done anything EMP500 related in a while. My work so far is ensuring that BioSamples belonging to the EMP500 project are clearly identified in our [NCBI BioSample SQLite database](https://portal.nersc.gov/project/m3513/biosample/biosample_basex.db.gz)\r\n\r\nI created some reports base on that SQLite database:\r\n- [emp500_study_id_biosample_attributes_wide](https://docs.google.com/spreadsheets/d/1vk2S63uczLdkL5zHJ_JX_J9bAhbQ9G3JHrKkWfEIuMc/edit#gid=1621069737) from a previous, custom version of the BioSample SQLite database. The latest version of the SQLite database parses BioProject IDs and accessions out of the BioSample records, but it doesn't appear that the EMP500 BioSamples are annotated with BioProject information. We may be able to add those more direct links back in from the BIoProject XML. In the meantime, a less direct query retrieves the links between EMP500 BioSample IDs and SRA IDs. This query is very slow unless extra indices are added. See below.\r\n- [EMP500 SRA runs amplicon vs WGS aka PRJEB42019_SRRs](https://docs.google.com/spreadsheets/d/1p5Me9fjBr7oADORleM7uGAnDZwV1vDWhM2bmSPVMnkQ/edit#gid=576786620). That links the BioSample IDs for EMP500 samples along with their SRA **run** identifiers, and an indicator of whether those were WGS or amplicon runs. I created this mostly manually, by pointing and clicking at the NCBI web interface. See efetch query below, starting with BioProject accession\r\n\r\nI believe all EMP500 samples are included in BioProject [`PRJEB42019`](https://www.ncbi.nlm.nih.gov/bioproject/PRJEB42019). I don't know whether that BioProject may include some non-EMP500 samples.\r\n\r\nThere's also a [NMDC EMP500 Google Drive folder](https://drive.google.com/drive/folders/14Nwh8TxCu8SoGm74RTWxoWKU23HlAN7p?ths=true). I don't recognize those files.\r\n\r\nI haven't done anything else to process the data or make it available in the portal. \r\n\r\n\r\n```sql\r\nselect\r\n\tdistinct\r\n\tnam.id,\r\n\tnam.sra_id,\r\n\tnam.bp_id,\r\n\tbia.bp_acc\r\nfrom\r\n\tall_attribs aa\r\nleft join non_attribute_metadata nam on\r\n\tnam.raw_id = aa.raw_id\r\nleft join bp_id_accession bia on\r\n\tnam.bp_id = bia.bp_id\r\nwhere\r\n\taa.attribute_name in ('emp500_principal_investigator', 'emp500_study_id', 'emp500_title' ) ;\r\n```\r\n\r\nDDL with indices. I'm not clear on whether the performance improvement is from the single-column or multi-column indices.:\r\n\r\n```sql\r\n-- all_attribs definition\r\n\r\nCREATE TABLE all_attribs(\r\n  \"raw_id\" INTEGER,\r\n  \"attribute_name\" TEXT,\r\n  \"harmonized_name\" TEXT,\r\n  \"value\" TEXT\r\n);\r\n\r\nCREATE INDEX all_attribs_idx on all_attribs(\"harmonized_name\", \"raw_id\", \"attribute_name\");\r\nCREATE INDEX all_attribs_raw_id_IDX ON all_attribs (raw_id);\r\nCREATE INDEX all_attribs_attribute_name_IDX ON all_attribs (attribute_name);\r\n```\r\n\r\nEMP500 BioProject Id -> SRA run IDs (SRRs)\r\n```shell\r\nesearch -db sra -query PRJEB42019 | efetch -format runinfo > PRJEB42019_runinfo.csv\r\n```",
"body": "@hubin-keio do you need anything else from @turbomam to continue the EMP500 data processing?  \r\n\r\nFYI @emileyfadrosh ",
"body": "Per Slack discussion, we'll need the list of identifiers for the ~160 metagenome samples from soil.",
"body": "[EMP500-soil-SRA-IDs.txt](https://github.com/microbiomedata/nmdc-metadata/files/7989254/EMP500-soil-SRA-IDs.txt)\r\n@hubin-keio @Michal-Babins @scanon \r\n\r\nHere is the list of the run IDs for the set of 168 soil biosamples. This includes both WGS (top) and amplicon (bottom), but we will only need to process the WGS through the end-to-end metaG workflow. \r\n\r\nLet me know what you think. We should ideally maintain the sample_names so that the various omic types can be linked through that identifier. Hope that makes sense. Thanks!",
"body": "Thanks, Emiley. This list shall work and we can map the biosample and run id back to EMP sample names.",
"body": "@turbomam reported this his part for the EMP500 is done and issue can be closed during mid-sprint check-in today.",
"body": "Process EMP500 data into portal\r\n\r\nAll data is in EBI (https://www.ebi.ac.uk/ena/browser/view/PRJEB42019?show=reads) \r\n\r\nMark M - pull metadata from EBI -- Need to check to see if GOLD has pulled it in yet. \r\n\r\nShane, Bin - Move raw data to NERSC, set up processing\r\n\r\nKitware - ingest new data into portal\r\n",
"body": "@wdduncan  The slot you are thinking of on metaG activities is 'was_informed_by'\r\n\r\n@wdduncan @dwinston  Linking the sequencing projects that Bill has included could be done by iterating through the list of SP IDs to get instances of documents in the read_QC_analysis_activity_set.  For example, query for the nmdc:ReadQCAnalysisActivity where was_informed_by is \"gold:Gp0208361\", etc.\r\n\r\n`{\r\n   \r\n    \"has_input\": [\"nmdc:dac54b23fce5a5c56c11311c77b74294\"],\r\n    \r\n    \"git_url\": \"https://github.com/microbiomedata/mg_annotation/releases/tag/0.1\",\r\n    \r\n    \"has_output\": [\"nmdc:457cded9b27ef66bb7a306dd61639774\", \"nmdc:2d6aaadb2e2d175ab3c39df88cabfa09\"],\r\n    \r\n    \"was_informed_by\": \"gold:Gp0208361\",\r\n    \r\n    \"input_read_count\": 86662544,\r\n    \r\n    \"output_read_bases\": {\r\n        \"$numberLong\": \"12902064623\"\r\n    },\r\n    \r\n    \"id\": \"nmdc:f1d1a3d044767ded5828bf67415a41be\",\r\n    \r\n    \"execution_resource\": \"NERSC-Cori\",\r\n    \r\n    \"input_read_bases\": {\r\n        \"$numberLong\": \"13086044144\"\r\n    },\r\n    \r\n    \"name\": \"Read QC Activity for nmdc:mga07w21\",\r\n    \r\n    \"output_read_count\": 86035480,\r\n    \r\n    \"started_at_time\": \"2021-08-11T00:35:01+00:00\",\r\n    \r\n    \"type\": \"nmdc:ReadQCAnalysisActivity\",\r\n    \r\n    \"ended_at_time\": \"2021-09-15T00:02:20+00:00\"\r\n}`\r\n\r\nThen use the value you see in the has_input list to set a value in the has_output of the nmdc:OmicsProcessing document with ID \"gold:Gp0208361\".\r\n\r\nRepeat for the next project ID, etc.",
"body": "oops ... I used the wrong predicate, should have been `was _informed_by`.\r\n\r\nSo, in the example above, the `has_output` property for `gold:Gp0208361` should be set to `[\"nmdc:dac54b23fce5a5c56c11311c77b74294\"]`.\r\n\r\nRight?",
"body": "I'm using the same ID type that I used for the original FICUS data sets.  How was the linkage happening before?  I had assumed that there was an omic_process_activity record that had the \"gold:GpXXXX\" id and some other linkages.\r\n",
"body": "@scanon in the previous iteration, @dehays provided me with a file that contained the outputs of the gold projects.",
"body": "I was able to add `data_object_set` IDs to `has_output` for 106 of the 123 `omics_processing_set` documents that are `part_of` the SPRUCE study (`gold:Gs0110138`), by finding these `data_object_set` IDs as the `has_input` of `read_QC_analysis_activity_set` documents that are `was_informed_by` any of those 123 `omics_processing_set` IDs (in this case, GOLD project IDs).\r\n\r\nThe following 17 `omics_processing_set` IDs were not found to inform (via `was_informed_by`) any `read_QC_analysis_activity_set` documents: \r\n\r\n```\r\ngold:Gp0208358\r\ngold:Gp0208345\r\ngold:Gp0208347\r\ngold:Gp0208357\r\ngold:Gp0208346\r\ngold:Gp0208344\r\ngold:Gp0208348\r\ngold:Gp0208356\r\ngold:Gp0208355\r\ngold:Gp0208351\r\ngold:Gp0208343\r\ngold:Gp0208380\r\ngold:Gp0208350\r\ngold:Gp0208349\r\ngold:Gp0208352\r\ngold:Gp0208353\r\ngold:Gp0208354\r\n```",
"body": "@dwinston Speaking with Shane earlier - he said analysis was done for 107 metagenomes but that there may have been one that had issues.  The remaining 16 are metatranscriptomes.  So I think you have all 106 projects for which there is analysis.\r\n\r\nThinking beyond the current metadata release, Shane suggested that analysis metadata automation might be better suited to take on responsibility for creating the omics_processing (sequencing project) creation - because it is at that point that there is enough information to know if a sequencing project should be included; unlike the GOLD ETL, which does not know what is going to happen later with analysis.  From the initial query to JAMO to get the raw fastq, the GOLD project ID is also available.  It is possible that the GOLD biosample and GOLD study are NOT always available from JAMO metadata records, but the GOLD API could provide a source for these.",
"body": "Thanks. It seems that `gold:Gp0208380` is the one with an issue.\r\n\r\nAlso, the following is true, as you requested:\r\n```\r\n(mdb.omics_processing_set.count_documents({\"has_output.0\": {\"$exists\": True}})\r\n ==\r\n mdb.omics_processing_set.count_documents({})\r\n)\r\n```",
"body": "Can we close this issue?",
"body": "@scanon @dwinston @dehays   We to be able to link gold projects to the data objects you have for the SPRUCE project. I thought you were going to put the gold id of project in the `was generated by` slot. But I may be misremembering. \r\n\r\nHere is a list of the gold project ids (123 of them).\r\n\r\n```\r\nGp0208361\r\nGp0208364\r\nGp0213354\r\nGp0213365\r\nGp0138734\r\nGp0138735\r\nGp0138741\r\nGp0138753\r\nGp0213340\r\nGp0213342\r\nGp0213348\r\nGp0213349\r\nGp0213367\r\nGp0213375\r\nGp0208363\r\nGp0213334\r\nGp0213360\r\nGp0213361\r\nGp0138756\r\nGp0138760\r\nGp0138727\r\nGp0138742\r\nGp0138749\r\nGp0213336\r\nGp0213346\r\nGp0213359\r\nGp0213369\r\nGp0213371\r\nGp0208349\r\nGp0208350\r\nGp0208353\r\nGp0208377\r\nGp0208378\r\nGp0208380\r\nGp0208381\r\nGp0208362\r\nGp0213366\r\nGp0138759\r\nGp0138736\r\nGp0138752\r\nGp0138762\r\nGp0213357\r\nGp0208366\r\nGp0208370\r\nGp0208374\r\nGp0208375\r\nGp0213345\r\nGp0213355\r\nGp0213372\r\nGp0138740\r\nGp0138743\r\nGp0138758\r\nGp0138733\r\nGp0138744\r\nGp0213363\r\nGp0213373\r\nGp0213374\r\nGp0208358\r\nGp0208367\r\nGp0208371\r\nGp0208346\r\nGp0213332\r\nGp0213333\r\nGp0213335\r\nGp0213343\r\nGp0138746\r\nGp0138739\r\nGp0213347\r\nGp0213352\r\nGp0208343\r\nGp0208355\r\nGp0208356\r\nGp0208379\r\nGp0208344\r\nGp0208351\r\nGp0208360\r\nGp0213331\r\nGp0213362\r\nGp0138731\r\nGp0138738\r\nGp0138745\r\nGp0138750\r\nGp0138754\r\nGp0138761\r\nGp0138764\r\nGp0138732\r\nGp0138755\r\nGp0213353\r\nGp0213368\r\nGp0213370\r\nGp0208365\r\nGp0208376\r\nGp0208347\r\nGp0213337\r\nGp0213350\r\nGp0213364\r\nGp0138748\r\nGp0138747\r\nGp0213339\r\nGp0213356\r\nGp0213344\r\nGp0208352\r\nGp0208359\r\nGp0208372\r\nGp0208382\r\nGp0208348\r\nGp0208369\r\nGp0213338\r\nGp0213341\r\nGp0138728\r\nGp0138729\r\nGp0138730\r\nGp0138737\r\nGp0138757\r\nGp0138763\r\nGp0138751\r\nGp0213358\r\nGp0213351\r\nGp0208354\r\nGp0208357\r\nGp0208373\r\nGp0208345\r\nGp0208368\r\n```",
"body": "## MIxS soil vs Montana's Example Soil Google Sheet\r\n\r\nI did an accounting of the differences between Montana's Example Soil Google Sheet and my (MIxS-based) DataHarmonizer Soil template. It started out as a Python script but became pretty manual\r\n- Determining which columns are \"associated\" with soil samples in Montana's sheet. I don't have a definition for associated. It could mean required, recommended, optional. I would say that agrochem_addition is associated with soil samples in cells A292:B292 of the MenuTerms tab. I made the associations with manual inspection of the MenuTerms tab. I have some preliminary code to do that with searching the sheet for keywords clustering the locations to find dense mentions of agrochem_addition or soil . I think the associations could also be determined  by analyzing the formulae in tabs like Metadata and EnvironmentalMetadata but I don't know how to do that.\r\n- Looking for patterns that explain the mismatches between Montana's soil-associated columns and MIxS' soil slots.\r\nSince it started out programmatically, the output is JSON. I added structure and notes to explain the mismatches. (edited) \r\n\r\ncode: https://github.com/microbiomedata/nmdc-metadata/blob/issue-398/notebooks/soil_slot_column_analysis.ipynb\r\n\r\ncomputed output: https://github.com/microbiomedata/nmdc-metadata/blob/issue-398/notebooks/soil_slot_column_analysis.json\r\n\r\n**curated output**: https://github.com/microbiomedata/nmdc-metadata/blob/issue-398/notebooks/soil_slot_column_analysis_curated.json",
"body": "## Per-package slot usage within INSDC Biosamples vs MIxS guidance\r\n\r\ncode: https://github.com/microbiomedata/nmdc-metadata/blob/issue-398/notebooks/insdc_per_package_column_usage.ipynb\r\n\r\nThree sub-steps are included in the notebook\r\n1. Determine what kind of annotations are applied to the INSDC Biosamples on a package-by-package basis. These are called \"columns\" in the code, but that isn't quite right. Technically, they start out as attributes in `biosample_set.xml.gz`. Only those attributes that have a harmonized name are included. This is then merged with a table of which MIxS slots (which largely overlap with the attributes) are associated with each package. With that, you can query for the slots that MIxS associates with packages but are least frequently used in INSDC Biosamples, or for the attributes that are most frequently used for samples from some package in INSDC, even though MIxS doesn't associate that slot with that package.\r\n    - Output\r\n        - https://github.com/microbiomedata/nmdc-metadata/blob/issue-398/notebooks/insdc_per_package_column_usage.tsv\r\n2. PCA plot of the per-package Biosample attribute usage. Intended as a conversation starter: there are 20M biosamples but only 251k are annotated with an `env_package`. Could we use the attribute usage alone to predict the packages for all of those other samples?\r\n    - Output (raw and curated)\r\n        - https://github.com/microbiomedata/nmdc-metadata/blob/issue-398/notebooks/insdc_per_package_column_usage.pdf\r\n        - https://github.com/microbiomedata/nmdc-metadata/blob/issue-398/notebooks/insdc_per_package_column_usage_untangled.pdf\r\n3. What are the common values for all of those attributes? Determined with [Pandas Profiling](https://github.com/pandas-profiling/pandas-profiling)\r\n    - Output below. You'll have to download the HTML report or clone the repo, as opposed to viewing it in the GitHub web interface.\r\n        - https://github.com/microbiomedata/nmdc-metadata/blob/issue-398/notebooks/insdc_per_package_column_usage_profile.html\r\n        - https://github.com/microbiomedata/nmdc-metadata/blob/issue-398/notebooks/insdc_per_package_column_usage_profile.json\r\n",
"body": "Gather input, code and output for\r\n- [x] MIxS soil vs Montana's Example Soil Google Sheet\r\n- [x] Per-package slot usage within INSDC Biosamples vs MIxS guidance\r\n- [ ] review of @mslarae13's Index of Terms for a potiential EMSL DataHarmonizer template\r\n",
"body": "@scanon is generating hopefully-NMDC-compliant metadata (including data object documents) as part of the workflow and submitting that metadata to the automation API. The nmdc-runtime daemon will sense this and launch a validation-and-ingest job to be performed automatically, which can trigger subsequent ETL jobs.\r\n\r\nThis is in contrast to the prior practice of @scanon et al. generating the NMDC metadata JSON and placing those files in a well-known directory on NERSC, and then me manually fetching them to validate and ingest for ETL. ",
"body": "There is no prior practice of analysis providing the JSON for the raw fastq file DataObject.  What is there now were created by part of @wdduncan 's processing of tsv generated by manual JAMO query.  The SPRUCE study to be included this month is the first time some other process creates that DataObject that connects what GOLD provides for the sequencing project (as output )with what analysis provides (as input).\r\n\r\nIf automation is providing that DataObject - does automation somehow update the omics_processing documents to set their has_output lists?\r\n\r\nAnd without automation in September, who is providing those specific  DataObjects for the SPRUCE study  and how?",
"body": "Is the analysis automation process microbiomedata/nmdc-runtime#1 responsible for the creation of the new DataObject for the raw fastq file; i.e. the output of the sequencing project instrument process and the input of Metagenome / Metatranscriptome Analysis QC activities?\r\n\r\nIn the absence of workflow automation metadata generation - who is responsible for creating this file data object? @scanon is retrieving these files from JAMO via script.  Can your script generate the DataObject metadata for the raw fastq file?\r\n\r\nCurrently, the GOLD ETL process chooses to include or not include the sequencing project based on the presence or absence of the raw fastq DataObject (because it references the DO in its output).   The Metagenome and Metatranscriptome analysis would also reference the raw fastq DO in input to the qc activities.",
"body": "Marking this as done as we're moving to data harmonizer",
"body": "- [ ] Add notes & comments on recommended changes for the next version of the metadata template (All interested)\r\n- [ ] Verify & approve comments / change requests from NMDC staff (Montana)\r\n- [ ] Generate V5 template. (October)\r\n\r\nSee below spreadsheet to review.\r\nDO NOT MAKE CHANGES TO THE CELLS IN THIS SPREADSHEET! **Please just add comments** where you feel a field should be updated. If your request / updated cannot be well detailed in a comment field, let Montana know and we can discuss.\r\n\r\nhttps://docs.google.com/spreadsheets/d/1INlBo5eoqn2efn4H2P2i8rwRBtnbDVTqXrochJEAPko/edit?usp=sharing\r\n\r\n\r\n",
"body": "Special characters? Anything I can advise or help with @turbomam ",
"body": "Thanks @mslarae13. I think the best example is a mu character for some chemical addition. I'll pull up the specifics today. If you can envision a requirement to only use ASCII characters, that would solve the problem. But maybe I can handle this on my own.",
"body": "One component of #375\r\n\r\n",
"body": "One component of #375 \r\n\r\n\"documents\" with `NaN` values that appear at the root level of a `biosample` are removed, but `depth`s, `elev`s etc that have `NaN` values in a nested slot are **not scrubbed yet**\r\n",
"body": "Would it be helpful if I filled out a plant example for you as well?",
"body": "> Would it be helpful if I filled out a plant example for you as well?\r\n\r\nYes, that would be very helpful. How much of a drag is that for you? I have also been thinking of looking through the BioSample databases that the BBOP team maintains. Maybe I can some plant associated samples that would be especially useful for testing out other features of the template parsing.\r\n\r\nI'll write more later today.",
"body": "This is one component of #375 \r\n\r\nI haven't tested the NMDC Sample Metadata Template parser on these `plant` associated slots yet\r\n\r\n- host_common_name\r\n- host_taxid\r\n- plant_struc\r\n",
"body": "Added!\r\n",
"body": "Awesome!",
"body": "We had talked about doing something plant associated, hadn't we? Somebody (maybe @cmungall ?) suggested that I not invest myself too much into plant-associated, but I would like to see some example data for parsing the  plant-associated-unique columns (plant_struc, host_common_name, host_taxid)\r\n\r\n",
"body": "Yeah. I remembered when I saw the other github ticket for plant specifically. Sorry!",
"body": "This is one component of #375",
"body": "Note added to corret size_fract to frac\r\n\r\nDefinition for MIxS is \"filtering pore size used in sample preparation\" so it's more preparation metadata. I'm open to suggestions on what this should be. But, MIxS is more analyte preparation metadata & defines sample more as the analysis subsample than the biological sample itself. In my attempt to not diverge from MIxS, this is the field I felt best fit the information I was gathering.",
"body": "OK, I appreciate the effort to use MIxS terms. I may not really get the distinction you're making between MIxS's sample prep orientation and the orientation you're trying to emphasize.\r\n\r\nI'm going to continue working through your recent posts and responses. I'll probably want a one-on-one live meeting soon.",
"body": "frac vs fract taken care of\n\nsub property is irrelevant now. \n\nIF size_frac is brought up again we can refer back.",
"body": "This is one component of #375\r\n\r\nFirst, MIxS says `size_frac` not `size_fract`\r\n\r\nNext, the NMDC Sample Metadata Template seems to imply that \r\n\r\n- `filter_type`\r\n- `sieving`\r\n\r\nAre sub-properties of the `size_frac` property. MIxS does not make those assertions.\r\n\r\nThe NMDC Sample Metadata Template also uses an undefined `filter_size`\r\n\r\nIt doesn't seem like the `size_frac` slot is ever used directly\r\n",
"body": "samp_collec_device is used in V6\r\n",
"body": "This is one component of issue #375\r\n\r\nFrom `mixs.yaml`:\r\n\r\n```YAML\r\nname: samp_collec_device\r\ndefinition_uri: https://w3id.org/mixs/vocab/samp_collec_device\r\naliases:\r\n- sample collection device\r\nmappings:\r\n- MIXS:0000002\r\ndescription: The device used to collect an environmental sample. This field accepts\r\n  terms listed under environmental sampling device (http://purl.obolibrary.org/obo/ENVO).\r\n  This field also accepts terms listed under specimen collection device (http://purl.obolibrary.org/obo/GENEPIO_0002094).\r\ncomments:\r\n- 'Expected value: device name'\r\n- 'Position: 31.0'\r\nexamples:\r\n- value: swab, biopsy, niskin bottle, push core, drag swab [GENEPIO:0002713]\r\nfrom_schema: http://w3id.org/mixs/terms\r\nexact_mappings:\r\n- 'MIGS:'\r\nis_a: nucleic acid sequence source field\r\nrange: string\r\nslot_uri: MIXS:0000002\r\nowner: core\r\ndomain_of:\r\n- MIGS eukaryote\r\n- MIGS bacteria\r\n- MIGS plant\r\n- MIGS virus\r\n- MIGS org\r\n- ME\r\n- MIMARKS specimen\r\n- MIMARKS survey\r\n- MISAG\r\n- MIMAG\r\n- MIUVIG\r\n- core\r\npattern: '{termLabel} {[termID]}|{text}'\r\n ```\r\n\r\nI think the MenuTerms tab in the NMDC Sample Metadata Template is implying the following as descendants of the `samp_collect_device` slot:\r\n- shovel\r\n- slide_hammer_core\r\n- deep_corer\r\n- russian_corer\r\n- sipper\r\n- other-samp_collect_device\r\n\r\nAll of which would take a string range\r\n\r\nAlso, double check `samp_collect_device` vs `samp_collec_device`\r\n",
"body": "Did you also post an issue on the MIxS tracker? If so, can you link to it here?",
"body": "This is because MIxS is focuing on the details on how the sequence data is done. THe information i'm gathering here is similar in definition, but we need more fields. \r\n\r\nOpen to changing this term if it needs to be unique from investigation_type (maybe analyses_performed, which is what I had suggested but I was limited to MIxS terms). ",
"body": "This is one component of issue #375\r\n\r\n## MIxS\r\n\r\n```\r\nbacteria_archaea\r\neukaryote\r\nmetagenome\r\nmetatranscriptome\r\nmimag\r\nmimarks-specimen\r\nmimarks-survey\r\nmisag\r\nmiuvig\r\norganelle\r\nplasmid\r\nvirus\r\n```\r\n\r\n## NMDC Sample Metadata Template\r\n\r\n```\r\ngenome\r\ntranscriptome\r\n16S-Amplicon\r\nITS-Amplicon\r\n18S-Amplicon\r\nproteome\r\nmetabolome\r\nlipidome\r\norganic matter\r\nimaging- light\r\nimaging- electron\r\nimaging- ion\r\nchemical speciation/mapping\r\nmolecular structure\r\n```\r\n",
"body": "Correct, I added this one. I keep forgetting to put in a request to GSC to add it. It could be included in the chem_administration (1880\u00b5g of 13C- carbon as glucose added) but that seems like a lot and would be harder to parse, so I separated them 1880\u00b5g of 13C for isotope and 4.5mg of glucose for chemical administration.\r\n\r\nMake sense? Open to suggestions on what to do in V5 & how to handle this.",
"body": "This is one component of issue #375\r\n\r\nUnlike `isotope_exposure`, these template-allowed treatments are all defined in mixs\r\n\r\ntreatment\r\n----------\r\nchem_administration\r\nwatering_regm\r\nair_temp_regm\r\ngaseous_environment\r\nisotope_exposure\r\nclimate_environment\r\nhumidity_regm\r\nlight_regm\r\nbiotic_regm\r\n\r\n",
"body": "@mslarae13 I would especially like to improve the alignment between this template tab and the NMDC schema as @cmungall and others have recently added terms in support of it. I'll probably want to have a meeting with you soon.\r\n\r\nhttps://microbiomedata.github.io/nmdc-schema/Study/#class-study",
"body": "This is one component of issue #375\r\n\r\n- Type of samples\r\n    - helper for constraining columns on other tabs like `metadata`?  \r\n- Umbrella Bio Project Name\r\n    - should this be appended to the list of `alternative names`? The fact that it is specifically a \"Umbrella Bio Project Name\" would probably be lost.\r\n- Principal Investigator Email\r\n    - specifically, no slot for the `principal investigator` associated with the study\r\n",
"body": "See also ambiguous ID situation at #384 ",
"body": "There are several other `study` slots in the NMDC schema that don't seem to have fields in the Sample Metadata template's ProjectInformation tab, but none of those have been filled in the small number of studies currently in mongodb.\r\n\r\n- abstract\r\n- alternate identifiers\r\n- alternative descriptions\r\n- alternative titles\r\n- objective\r\n",
"body": "This is one component of issue #375\r\n\r\nThere is no field  that explicitly matches the `title` slot in the NMDC schema. That slot is optional, but half of the studies currently in mongodb do have a title.",
"body": "I suggest using the gold as primary\r\n\r\nThe other should go into alternate_identifiers, and we also have specific fields for different databases:\r\n\r\nhttps://github.com/microbiomedata/nmdc-metadata/issues/384\r\n\r\nWe don't have a field for emsl or jgi yet, but can add these.\r\n\r\n",
"body": "Looking at spreadsheet\r\n\r\nRemember *all* identifiers used in NMDC must conform to\r\n\r\nhttps://microbiomedata.github.io/nmdc-schema/identifiers\r\n\r\nUmbrella Bio Project Name | NCBI Accession: PRJNA594403 | \u00a0 | \u00a0 | \u00a0 | \u00a0 | \u00a0 | \u00a0 | \u00a0 | \u00a0 | \u00a0 | \u00a0 | \u00a0 | \u00a0 | \u00a0 | \u00a0 | \u00a0 | \u00a0 | \u00a0 | \u00a0 | \u00a0 | \u00a0 | \u00a0 | \u00a0 | \u00a0 | \u00a0\r\n-- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | --\r\n\r\nThis isn't a name. This is the INSDC bioproject identifier. The correct prefix for this is `bioproject`\r\n\r\nE.g.\r\nhttps://identifiers.org/bioproject:PRJNA594403\r\n\r\nUmbrella Bio Project ID | NCBI ID: 594403 | \u00a0 | \u00a0 | \u00a0 | \u00a0 | \u00a0 | \u00a0 | \u00a0 | \u00a0 | \u00a0 | \u00a0 | \u00a0 | \u00a0 | \u00a0 | \u00a0 | \u00a0 | \u00a0 | \u00a0 | \u00a0 | \u00a0 | \u00a0 | \u00a0 | \u00a0 | \u00a0 | \u00a0\r\n-- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | --\r\n\r\nI don't think we should include this\r\n\r\nJGI Proposal ID | JGI:1781 | \u00a0 | \u00a0 | \u00a0 | \u00a0 | \u00a0 | \u00a0 | \u00a0 | \u00a0 | \u00a0 | \u00a0 | \u00a0 | \u00a0 | \u00a0 | \u00a0 | \u00a0 | \u00a0 | \u00a0 | \u00a0 | \u00a0 | \u00a0 | \u00a0 | \u00a0 | \u00a0 | \u00a0\r\n-- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | --\r\n\r\nI don't believe this is registered in any prefix registry. If we want to include this, we should registed. I suspect there needs additional disambiguation in the ID, either in the prefix (e.g. jgi.proposal:1781) or the local part (e.g. JGI:proposal1781)\r\n\r\n",
"body": "Further comment on conforming identifiers:\r\n\r\n'jgi' and 'jgi.proposal' are NOT registered CURIE prefixes.  I would question whether NMDC needs to have any knowledge of JGI proposals.  The supported identifiers would be GOLD study identifiers. (Which although not guaranteed to be 1:1 with JGI proposals, are usually 1:1.  I believe GOLD studies can potentially span multiple JGI proposals - as proposals represent a funded unit of work.)\r\n\r\nSimilarly 'emsl' and 'uuid' are not registered CURIE prefixes so including those prefixes currently doesn't add any value.  It would be good if 'emsl' was registered and that emsl prefixed identifiers were resolvable.  'uuid' describes an algorithm and not an identifier domain so it would not be registered.   That doesn't mean that EMSL couldn't use one of the UUID algorithms to generate the local portion of the ID that is used within a valid FAIR identifier; i.e. emsl:<UUID identifier> where https://identifiers.org/emsl:<UUID> resolved to the desired record.\r\n\r\n_______\r\n\r\n@cmungall recommends using the GOLD identifier as the primary identifier for NMDC sample, study and instrument process IDs.\r\n\r\nHowever - these will not always exist.  We already have samples that do not exist in GOLD.  These currently have emsl: or igsn: identifiers as their primary ID.  And of course, for new samples, there will be no GOLD, EMSL or IGSN identifer at all.  So new NMDC identifiers would need to be created.\r\n\r\nAlso, in considering of the proposal that NMDC sample identifiers be embedded in analysis identifiers, all samples in NMDC would need NMDC identifiers.  These would be the primary ID within NMDC.\r\n",
"body": "This is one component of issue #375 \r\n\r\nThe Sample Metadata Template has several columns that look like IDs to me, but I assume that only one or two will be filled for most rows\r\n\r\nHow do we decide which should fill the NMDC shema `id` slot?\r\n\r\n- EMSL Proposal/Study Number\r\n- GOLD Study ID\r\n- JGI Proposal ID\r\n- Umbrella Bio Project ID\r\n\r\nSee also\r\nhttps://microbiomedata.github.io/nmdc-schema/Study.html#class-study\r\nhttps://microbiomedata.github.io/nmdc-schema/id.html\r\n\r\nInput from @wdduncan @dwinston  or other welcome too!\r\n",
"body": "@dwinston These are soil chemistry samples which share common source material samples with the DNA samples we have in GOLD.  Might need to discuss how to best handle this.  It'd be good to get the additional soil chemistry attributes - but the mapping is a little convoluted.  The ID and location on the bioscale: samples indicate a tree ID - the ID has a suffix of '_sc' indicating soil chemistry.  But Stan has indicated these these and the DNA all came from the same bucket per tree (the actual source environmental material).  The tree ID appears at the end of the GOLD sample names after the hyphen.",
"body": "I don't know what the current status is of including metadata for processed (soil chemistry in this case) BioScales samples.  This requires mapping from the soil chemistry samples to common biosamples from which DNA was isolated for sequencing.  This may also involve further support for processed samples; i.e. sample graphs rooted in an environmental biosample.\r\n\r\nAssigning to Emiley to reasign according to BioSample / processed sample plans are.",
"body": "Closing as this is very old and no longer relevant given the BioScales squad activities referenced here: https://github.com/orgs/microbiomedata/projects/49",
"body": "@StantonMartin provided [39 biosample metadata records](https://fair.ornl.gov/NMDC/NMDC.json) with `id` values that have a \"bioscales:\" (case insensitive) prefix. However, I get zero results for\r\n```\r\n# mongodb console\r\ndb.biosample_set.find({\"id\": {$regex: \"^bioscales\", $options: 'i'}})\r\n```\r\n. I would not expect the biosamples to be ingested as-is, because the metadata records do not include the required ENVO-term fields `env_broad_scale`, `env_local_scale`, and `env_medium`.\r\n\r\nI am wondering if these records are present in the database, perhaps using an \"ISGN:\" id, if they need to be annotated with ENVO terms, if they need to include a `part_of` value for their study, etc.\r\n\r\ncc @wdduncan ",
"body": "On a biosample - I think we should consider making part_of required and not permit an empty list value.  @wdduncan \r\n\r\nThe reason that these samples have no study association is because that association was set in the GOLD ETL and that process knows nothing about these samples that were never in GOLD.  These samples were added post GOLD ETL based on Stegen and Brodie data provided by Montana / EMSL.  Each should be the input of metaP, metaB or NOM processing - so we should be able to set the study in the biosample part_of by looking at the omics_processing part_of.",
"body": "okay, looking into using `omics_processing.part_of` as fallback to set `biosample.part_of` for these.",
"body": "@dwinston I can take care of the 5 EMSL only samples.  In addition to the part_of value there are issues with the sample names and possibly the dates.  I'll have a PR for you in a few minutes.",
"body": "okay. FYI I found `db.omics_processing.count_documents({\"has_input\": {\"$in\": ids_biosamples__no_part_of}})` to be zero (as well as `db.omics_processing.count_documents({\"part_of\": {\"$in\": ids_biosamples__no_part_of}})`, but this latter query should match studies and not biosamples, so I expect a count of zero).",
"body": "> Each should be the input of metaP, metaB or NOM processing\r\n\r\nAlso got zero results for\r\n```\r\ndb.metabolomics_analysis_activity_set.count_documents({\"has_input\": {\"$in\": ids_biosamples__no_part_of}})\r\ndb.metaproteomics_analysis_activity_set.count_documents({\"has_input\": {\"$in\": ids_biosamples__no_part_of}})\r\ndb.nom_analysis_activity_set.count_documents({\"has_input\": {\"$in\": ids_biosamples__no_part_of}})\r\n```",
"body": "Ugh. I needed to be searching `db.omics_processing_set.count_documents({\"has_input\": {\"$in\": ids_biosamples__no_part_of}})` (notice the **_set**), which returns nonzero.",
"body": "There are 40 documents in `biosample_set` that have no `part_of` field (shown below. This is allowed schema-wise, as `part_of` is not a required field. I want to verify that this is okay, or if this is an issue.\r\n\r\n```\r\n# db.biosample_set.distinct('id', {part_of: {$exists: false}})\r\n[\r\n    \"emsl:63ca2c7e-6647-11eb-ae93-0242ac130002\",\r\n    \"emsl:63ca2eae-6647-11eb-ae93-0242ac130002\",\r\n    \"emsl:63ca2f94-6647-11eb-ae93-0242ac130002\",\r\n    \"emsl:63ca3070-6647-11eb-ae93-0242ac130002\",\r\n    \"emsl:63ca3340-6647-11eb-ae93-0242ac130002\",\r\n    \"emsl:63ca341c-6647-11eb-ae93-0242ac130002\",\r\n    \"emsl:63ca34da-6647-11eb-ae93-0242ac130002\",\r\n    \"emsl:63ca358e-6647-11eb-ae93-0242ac130002\",\r\n    \"emsl:63ca3642-6647-11eb-ae93-0242ac130002\",\r\n    \"emsl:63ca3700-6647-11eb-ae93-0242ac130002\",\r\n    \"emsl:63ca37b4-6647-11eb-ae93-0242ac130002\",\r\n    \"emsl:63ca3868-6647-11eb-ae93-0242ac130002\",\r\n    \"emsl:63ca3b1a-6647-11eb-ae93-0242ac130002\",\r\n    \"emsl:63ca3d04-6647-11eb-ae93-0242ac130002\",\r\n    \"emsl:63ca3dc2-6647-11eb-ae93-0242ac130002\",\r\n    \"emsl:63ca3e76-6647-11eb-ae93-0242ac130002\",\r\n    \"emsl:63ca3f2a-6647-11eb-ae93-0242ac130002\",\r\n    \"emsl:63ca3fd4-6647-11eb-ae93-0242ac130002\",\r\n    \"emsl:63ca4088-6647-11eb-ae93-0242ac130002\",\r\n    \"emsl:63ca4146-6647-11eb-ae93-0242ac130002\",\r\n    \"emsl:63ca443e-6647-11eb-ae93-0242ac130002\",\r\n    \"emsl:63ca459c-6647-11eb-ae93-0242ac130002\",\r\n    \"emsl:63ca46fa-6647-11eb-ae93-0242ac130002\",\r\n    \"emsl:63ca47e0-6647-11eb-ae93-0242ac130002\",\r\n    \"emsl:63ca489e-6647-11eb-ae93-0242ac130002\",\r\n    \"emsl:63ca4952-6647-11eb-ae93-0242ac130002\",\r\n    \"emsl:63ca4a38-6647-11eb-ae93-0242ac130002\",\r\n    \"emsl:63ca4aec-6647-11eb-ae93-0242ac130002\",\r\n    \"emsl:63ca4d4e-6647-11eb-ae93-0242ac130002\",\r\n    \"emsl:63ca4e02-6647-11eb-ae93-0242ac130002\",\r\n    \"emsl:63ca4eb6-6647-11eb-ae93-0242ac130002\",\r\n    \"emsl:63ca4f6a-6647-11eb-ae93-0242ac130002\",\r\n    \"emsl:63ca5014-6647-11eb-ae93-0242ac130002\",\r\n    \"emsl:63ca50c8-6647-11eb-ae93-0242ac130002\",\r\n    \"emsl:63ca517c-6647-11eb-ae93-0242ac130002\",\r\n    \"igsn:IEWFS000A\",\r\n    \"igsn:IEWFS000B\",\r\n    \"igsn:IEWFS000I\",\r\n    \"igsn:IEWFS000J\",\r\n    \"igsn:IEWFS000K\"\r\n]\r\n```",
"body": "@jagadishcs please let @emileyfadrosh know if you have any questions about this request.  Would it be possible to get this done by early next week?  ",
"body": "@jagadishcs @emileyfadrosh \r\n\r\nWe had our mid-sprint review today so I'm checking in with folks who have issues for this sprint to see if you need help with anything, are blocked by anything or have any concerns about completing your issue by the end of July.  Let me know if there are any concerns.  \r\n",
"body": "The BioSample metadata from BioProjects PRJEB39495, PRJEB39496 and PRJEB39497 are made available [here](https://drive.google.com/drive/folders/1KBflo3OmH-Sm3YWJp8OK3rWKyOGr1D8o) using the latest NMDC metadata template. \r\nThe data available as it is in NCBI has been included in a separate tab for each project. ",
"body": "@jagadishcs and @emileyfadrosh can we close this GitHub issue? ",
"body": "Hi @pvangay, do you want to communicate Ricardo the [metadata](https://drive.google.com/drive/folders/1KBflo3OmH-Sm3YWJp8OK3rWKyOGr1D8o) shared and suggest closing this GitHub issue?",
"body": "@ssarrafan I think we can close this, and @pvangay can contact Ricardo when she is back in the office. Thanks, @jagadishcs!",
"body": "Shared with Ricardo today. Thanks all!",
"body": "TES SFA team asked for help pulling down the metadata from NCBI: PRJEB39497 (metaG), PRJEB39495 (16S rRNA), PRJEB39496 (fungal ITS). Ricardo will review it in detail, and follow up with the appropriate people to fill in any gaps. He says that he does not have access to all of the original metadata that was submitted to NCBI - so asked for our help in pulling it down so that he can review it with the other metadata that he does have in the SFA. Hope this makes sense. Please let me know if you have any questions.",
"body": "Thanks @johanneswerner . There has some reorganization of content between the https://github.com/microbiomedata/nmdc-metadata and https://github.com/microbiomedata/nmdc-schema repositories.\r\n\r\n@wdduncan and I are working through it. \r\n\r\nWhile the nmdc-schema README doesn't have links to artifacts like the nmdc-metadata README did, some of the artifacts do appear in subdirectories of the repo, like https://github.com/microbiomedata/nmdc-schema/tree/main/jsonschema",
"body": "@turbomam this seems related to microbiomedata/nmdc-schema#84. Perhaps combine them? Alternative, versioned schema representations are also \"data objects\".",
"body": "The links in the README file (see below) are all leading to 404 errors. \r\n\r\n```\r\nThe schema is also available as:\r\n\r\n- JSON Schema\r\n- Protobuf\r\n- GraphQL\r\n- OWL\r\n- ShEx\r\n```",
"body": "Done!",
"body": "@ssarrafan \r\n@emileyfadrosh \r\n@cmungall \r\n@TBKReddy\r\nEnvO term curation for 14K environmental biosamples that became available recently in the GOLD",
"body": "@faiza-a this issue is the pre-requisite to your assigned issue.  Once this is completed we'll set up a time to discuss the design with you for the submission portal.  ",
"body": "@emileyfadrosh @dehays wanted to make sure you coordinate. This issue is currently assigned to Emiley. @dehays if you're working on the requirements please let me know and let me know if this issue should be re-assigned to David or anyone else. ",
"body": "Will get to this after the NAR paper is submitted on Sunday. Unless I am mistaken, no action is needed from @dehays.",
"body": "Compiled the three separate requirements docs, and put together a straw man outline for input from the team: \r\nhttps://docs.google.com/document/d/1w-1ObkcIJUZ-iUB0RqB_wsM5TzOMfTa2Sta1MF2A07I/edit?usp=sharing\r\n\r\n Would appreciate input from @kfagnan @pvangay @mslarae13 @cmungall @turbomam @wdduncan @dehays @ssarrafan ",
"body": "Shared above document and discussed with team, further implementation details will be worked out for September sprint. ",
"body": "This is step 7 of Goal 2 for the July sprint.\r\n\r\nDefine the scope of the submission site (Emiley, Pajau, Montana)\r\n- Is this just submission of the spreadsheet or can PIs upload files?\r\n- If we don\u2019t want to handle file uploads, how do PIs provide us URLs or identifiers to let us locate the files programmatically?\r\n- Select URL\r\n",
"body": "Moved to August since the preceding steps are not done and have been moved to August. ",
"body": "@ssarrafan can you note here the nature of the \"new unvalidated metadata\" and/or link this issue to any upstream issue that identifies/tracks this \"new metadata\"? I'm not sure what specifically this issue is supposed to be tracking.",
"body": "Is this done (I think the capabilities are there) or does this task refer to doing this for SPRUCE study related metadata?  And I am assuming that [Ingest new data into portal](https://github.com/microbiomedata/nmdc-runtime/issues/22) is about inclusion of SPRUCE study metadata - so is this issue dependent on that issue? @ssarrafan ",
"body": "![Goal2Sprint4](https://user-images.githubusercontent.com/79225425/131187963-6f157ac0-b230-4109-83bc-05cdb80560c9.png)\r\nThe attached file shows the list of related issues.  This one is step 6 so dependent on the first 5 steps being completed. This was in an email sent July 16.  Currently blocked by not getting metadata back from researchers. ",
"body": "@dehays yes this issue needs to be done before Kitware can do the[ final step of ingesting it into the portal](https://github.com/microbiomedata/nmdc-runtime/issues/22) which is the goal for this sprint.  @dwinston any updates on this?  \r\n",
"body": "I'm closing this one since I'm pretty sure it's done.  @dwinston @dehays let me know if it should be re-opened.",
"body": "This is step 6 of Goal 2 for the July sprint.\r\n\r\nNew unvalidated metadata available\r\n- Validation against the schema (Donny) \r\n- Ingest into Mongo (Donny) \r\n- Update NMDC runtime with new valid data available (Donny)\r\n\r\nIf Validation succeeds proceed to get data ingested to portal",
"body": "Pasting link to goals document: https://docs.google.com/document/d/1iBNXkBn24ZkmJkeptoqpyjcz5PAQU59ZjMOzDObnx4E/edit?ts=60d55721\r\n\r\nHere is goal 2 step 5 from the document:\r\n```\r\nNew unvalidated workflow metadata is available\r\n- Validation against the schema (Donny) \r\n- Ingest into Mongo (Donny)\r\n-  Update NMDC runtime with new valid data available (Donny) \r\n```",
"body": "Moving to August sprint since step 4 that precedes this is not done and has been moved to August sprint.  ",
"body": "I believe this issue relates to including metadata for the SPRUCE SFA study / biosamples / sequencing projects from GOLD and the biosamples and instrument processes from EMSL.\r\n\r\n1.  The study and biosamples have already been included from GOLD.  Need to include the sequencing projects (either from GOLD API or from GOLD DB Dump).  \r\n2. Need to determine who is responsible for creating the data object for the raw data file  output from the instrument process. \r\n3. For EMSL samples and instrument runs - need to track down information that Sam compiled.  Montana may be able to help with EMSL sample matching (to GOLD biosamples) and identifying EMSL only samples and their metadata.",
"body": "@wdduncan @dehays can this issue be closed?  ",
"body": "Closing per slack message from David. ",
"body": "This is step 5 of Goal 2 for the July sprint.  ",
"body": "I think this may be simpler\r\n\r\n - The task is to map from the spreadsheet to NMDC schema compliant JSON\r\n - We already have validators for this",
"body": "@cmungall If I understand you correctly, that's exacting what I'm working towards. At least the conversion part. Not the validation part yet. That's what motivated my questions about determining the classes in a linkml model, including all imports.",
"body": "See https://github.com/microbiomedata/nmdc-metadata/blob/issue-375/notebooks/nmdc_metadata_issue_375_prototype.ipynb",
"body": "Despite these issues\r\n\r\n- #384 \r\n- #385 \r\n- #386\r\n- microbiomedata/nmdc-schema#94\r\n\r\nThe study data from the example NMDC Sample Metadata Template is in this state now. No encoding or validation has been performed yet.\r\n\r\n```YAML\r\n{'doi': {'has raw value': 'https://doi.org/10.25585/1487765'},\r\n 'id': 'b808403a208c4a39b291107ebef4873e',\r\n 'name': '\"Soil microbial response to elevated temperatures and increased '\r\n         'carbon availability\"',\r\n 'principal_investigator': {'has raw value': 'Montana Smith',\r\n                            'orcid': '0000-0002-8683-0050'},\r\n 'publications': ['https://doi.org/10.1016/j.soilbio.2019.107561',\r\n                  'Keiser, Ashley D., et al. \"Peatland microbial community '\r\n                  'response to altered climate tempered by nutrient '\r\n                  'availability.\" Soil Biology and Biochemistry 137 (2019): '\r\n                  '107561.'],\r\n 'type': 'Study',\r\n 'websites': ['https://microbiomedata.org/',\r\n              'https://github.com/microbiomedata']}\r\n```",
"body": "Despite issues\r\n\r\n- #388 \r\n- #389\r\n- #390\r\n- #391\r\n- #392\r\n- #393\r\n- #394\r\n\r\nThe biosample set from the example NMDC Sample Metadata Template is in this state now. No encoding or validation has been performed yet.\r\n\r\n```YAML\r\n[\r\n    {\r\n        \"id\": \"UUID:472894-473947-642384\",\r\n        \"name\": \"P4_-0-10_4C\",\r\n        \"env_package\": \"plant_associated\",\r\n        \"investigation_type\": \"genome|metabolome\",\r\n        \"type\": \"Biosample\",\r\n        \"part_of\": \"b808403a208c4a39b291107ebef4873e\",\r\n        \"growth_facil\": \"field\",\r\n        \"geo_loc_name\": \"USA; Prosser, Washington; Washington State University-Irrigated Agriculture Research and Extension Center\",\r\n        \"samp_mat_process\": \"snap freeze in liquid N\",\r\n        \"store_cond\": \"fresh\",\r\n        \"samp_store_temp\": \"4 degree Celsius\",\r\n        \"env_broad_scale\": \"arid biome\",\r\n        \"env_local_scale\": \"agricultural field\",\r\n        \"env_medium\": \"agricultural soil\",\r\n        \"lat_lon\": \"46.251709, -119.728663\",\r\n        \"gold_path_field\": \"5424:Environmental:Terrestrial:Soil:Bulk soil:Agricultural land\",\r\n        \"collection_date\": \"2020-05-21T12:00:00\",\r\n        \"ncbi_taxonomy_name\": \"soil metagenome\",\r\n        \"ID\": \"UUID:472894-473947-847398\",\r\n        \"depth\": {\r\n            \"has_raw_value\": \"0-1\",\r\n            \"has_unit\": \"cm\"\r\n        },\r\n        \"elev\": {\r\n            \"has_raw_value\": 500,\r\n            \"has_unit\": \"m\"\r\n        },\r\n        \"samp_collect_device\": \"UUID:472894-473947-642384\",\r\n        \"sieving\": \"1-.05mm\"\r\n    },\r\n    {\r\n        \"id\": \"UUID:472894-473947-847396\",\r\n        \"name\": \"L10_-20-30_13C-Gluc\",\r\n        \"env_package\": \"soil\",\r\n        \"source_mat_id\": \"UUID:472894-473947-847398\",\r\n        \"investigation_type\": \"transcriptome|metabolome\",\r\n        \"type\": \"Biosample\",\r\n        \"part_of\": \"b808403a208c4a39b291107ebef4873e\",\r\n        \"growth_facil\": \"field_incubation\",\r\n        \"geo_loc_name\": \"USA; Prosser, Washington; Washington State University-Irrigated Agriculture Research and Extension Center\",\r\n        \"samp_mat_process\": \"2micron sieve, wet to 25% gravimetric water capacity\",\r\n        \"store_cond\": \"frozen\",\r\n        \"samp_store_temp\": \"-80 degree Celsius\",\r\n        \"env_broad_scale\": \"arid biome\",\r\n        \"env_local_scale\": \"agricultural field\",\r\n        \"env_medium\": \"agricultural soil\",\r\n        \"lat_lon\": \"46.251709, -119.728663\",\r\n        \"gold_path_field\": \"5424:Environmental:Terrestrial:Soil:Bulk soil:Agricultural land\",\r\n        \"collection_date\": \"2020-05-21T13:30:00\",\r\n        \"ncbi_taxonomy_name\": \"soil metagenome\",\r\n        \"ID\": \"UUID:684267-410686-971057\",\r\n        \"depth\": {\r\n            \"has_raw_value\": \"0-1\",\r\n            \"has_unit\": \"cm\"\r\n        },\r\n        \"elev\": {\r\n            \"has_raw_value\": 500,\r\n            \"has_unit\": \"m\"\r\n        },\r\n        \"isotope_exposure\": \"13C Glucose\",\r\n        \"chem_administration\": \"1000\\u00b5g of C (glucose)/g soil\",\r\n        \"samp_collect_device\": \"UUID:472894-473947-847396\",\r\n        \"sieving\": \"2mm\"\r\n    },\r\n    {\r\n        \"id\": \"UUID:472894-473947-847398\",\r\n        \"name\": \"6_J2_75-WHC\",\r\n        \"env_package\": \"soil\",\r\n        \"source_mat_id\": \"UUID:472894-473947-847398\",\r\n        \"investigation_type\": \"organic matter\",\r\n        \"type\": \"Biosample\",\r\n        \"part_of\": \"b808403a208c4a39b291107ebef4873e\",\r\n        \"growth_facil\": \"field\",\r\n        \"geo_loc_name\": \"USA; Prosser, Washington; Washington State University-Irrigated Agriculture Research and Extension Center\",\r\n        \"samp_mat_process\": \"aggregate separation at optimal moisture, dried at 100C\",\r\n        \"store_cond\": \"other\",\r\n        \"samp_store_temp\": \"room temperature\",\r\n        \"env_broad_scale\": \"arid biome\",\r\n        \"env_local_scale\": \"agricultural field\",\r\n        \"env_medium\": \"agricultural soil\",\r\n        \"lat_lon\": \"46.251709, -119.728663\",\r\n        \"gold_path_field\": \"5424:Environmental:Terrestrial:Soil:Bulk soil:Agricultural land\",\r\n        \"collection_date\": \"2020-05-21 00:00:00\",\r\n        \"ncbi_taxonomy_name\": \"soil metagenome\",\r\n        \"ID\": \"UUID:472894-473947-847396\",\r\n        \"depth\": {\r\n            \"has_raw_value\": \"0-1\",\r\n            \"has_unit\": \"cm\"\r\n        },\r\n        \"elev\": {\r\n            \"has_raw_value\": 500,\r\n            \"has_unit\": \"m\"\r\n        },\r\n        \"chem_administration\": \"1000\\u00b5g of C (glucose)/g soil\",\r\n        \"watering_regm\": \"75% water holding capacity; moisture maintained every 3 days\",\r\n        \"samp_collect_device\": \"UUID:472894-473947-847398\",\r\n        \"sieving\": \"4mm\"\r\n    },\r\n    {\r\n        \"id\": \"UUID:516394-970067-847398\",\r\n        \"name\": \"T4-35\",\r\n        \"env_package\": \"soil\",\r\n        \"investigation_type\": \"lipidome|16S-Amplicon|ITS-Amplicon\",\r\n        \"type\": \"Biosample\",\r\n        \"part_of\": \"b808403a208c4a39b291107ebef4873e\",\r\n        \"growth_facil\": \"field\",\r\n        \"geo_loc_name\": \"USA; Prosser, Washington; Washington State University-Irrigated Agriculture Research and Extension Center\",\r\n        \"samp_mat_process\": \"crushed via morter and pestle, temperature acclimation to 35C\",\r\n        \"store_cond\": \"lyophilized\",\r\n        \"samp_store_temp\": \"-80 degree Celsius\",\r\n        \"env_broad_scale\": \"arid biome\",\r\n        \"env_local_scale\": \"agricultural field\",\r\n        \"env_medium\": \"agricultural soil\",\r\n        \"lat_lon\": \"46.251500, -119.728483\",\r\n        \"gold_path_field\": \"5424:Environmental:Terrestrial:Soil:Bulk soil:Agricultural land\",\r\n        \"collection_date\": \"2021-01-05T15:05:00\",\r\n        \"ncbi_taxonomy_name\": \"soil metagenome\",\r\n        \"ID\": \"UUID:516394-970067-847398\",\r\n        \"depth\": {\r\n            \"has_raw_value\": NaN,\r\n            \"has_unit\": \"cm\"\r\n        },\r\n        \"elev\": {\r\n            \"has_raw_value\": 1000,\r\n            \"has_unit\": \"m\"\r\n        },\r\n        \"air_temp_regm\": \"35C\",\r\n        \"samp_collect_device\": \"UUID:516394-970067-847398\",\r\n        \"sieving\": \"0.5-.25mm\"\r\n    },\r\n    {\r\n        \"id\": \"UUID:684267-410686-971057\",\r\n        \"name\": \"2020-05-21_S19\",\r\n        \"env_package\": \"soil\",\r\n        \"source_mat_id\": \"UUID:516394-970067-847398\",\r\n        \"investigation_type\": \"proteome|genome\",\r\n        \"type\": \"Biosample\",\r\n        \"part_of\": \"b808403a208c4a39b291107ebef4873e\",\r\n        \"growth_facil\": \"field\",\r\n        \"geo_loc_name\": \"USA; Prosser, Washington; Washington State University-Irrigated Agriculture Research and Extension Center\",\r\n        \"samp_mat_process\": \"ground via omni bead beater\",\r\n        \"store_cond\": \"frozen\",\r\n        \"samp_store_temp\": \"-20 degree Celsius\",\r\n        \"env_broad_scale\": \"arid biome\",\r\n        \"env_local_scale\": \"agricultural field\",\r\n        \"env_medium\": \"agricultural soil\",\r\n        \"lat_lon\": \"46.251500, -119.728483\",\r\n        \"gold_path_field\": \"5424:Environmental:Terrestrial:Soil:Bulk soil:Agricultural land\",\r\n        \"collection_date\": \"2021-03-11T09:25:00\",\r\n        \"ncbi_taxonomy_name\": \"soil metagenome\",\r\n        \"ID\": \"UUID:472894-473947-642384\",\r\n        \"depth\": {\r\n            \"has_raw_value\": NaN,\r\n            \"has_unit\": \"cm\"\r\n        },\r\n        \"elev\": {\r\n            \"has_raw_value\": 1000,\r\n            \"has_unit\": \"m\"\r\n        },\r\n        \"samp_collect_device\": \"UUID:684267-410686-971057\",\r\n        \"sieving\": \"2mm\"\r\n    }\r\n]\r\n```\r\n\r\n",
"body": "@turbomam \r\n\r\nSee my comments on each ticket and let me know what else you need from me / how else I can enable you.\r\n\r\nAlso, I've started this document: \r\nhttps://docs.google.com/spreadsheets/d/1INlBo5eoqn2efn4H2P2i8rwRBtnbDVTqXrochJEAPko/edit?usp=sharing\r\n\r\nWhere I'm commenting change suggestions we've received from the SFAs and where I need to make corrections. This may be helpful in thinking about how V5 of the metadata template will be parsed & where we can add comments & suggestions from others for changes.",
"body": "@turbomam should this ticket be moved to August or closed and new tickets created for the next steps? ",
"body": "Please keep it active for next month. Sorry I didn't respond to your previous messages. ",
"body": "Here's the latest parse. Includes everything from the various sample tabs. (The parsed study data goes into a different file). The code that produced this doesn't have explicit plant-associated parsers yet, but doing those parses should be possible with generic parsers I have written.\r\n\r\nhttps://github.com/microbiomedata/nmdc-metadata/blob/issue-375/notebooks/sample_medata_template_parse_20210804.json\r\n\r\n",
"body": "This is step 4 of Goal 2 for the July sprint.  See issues #374 #373 and #372 for more. \r\n\r\nExtraction of metadata from the spreadsheets when completed (Bill/Mark/Chris)\r\n- Develop a script to extract the metadata from the spreadsheet\r\n- Transform the metadata into JSON\r\n- Develop a script to validate the extracted metadata against the schema\r\n",
"body": "I've started a document to add comments to on recommendations & changes for V5 of the NMDC sample metadata template. \r\nHere: https://docs.google.com/spreadsheets/d/1INlBo5eoqn2efn4H2P2i8rwRBtnbDVTqXrochJEAPko/edit?usp=sharing\r\n\r\nClosing this ticket as I've added some refining components to add. And making a new ticket for V5.",
"body": "V5 ticket: https://github.com/microbiomedata/nmdc-metadata/issues/396\r\n",
"body": "This is step 3 of Goal 2 for the July sprint.  \r\n\r\nMake updates and refinements to the spreadsheet after testing it out with users/sites/studies.",
"body": "Question, what do you mean establish a protocol? Just the best way to fill out the metadata?",
"body": "@ssarrafan & @emileyfadrosh & @kfagnan \r\n\r\nPlease clarify what you mean by establish a protocol?\r\n\r\nWe've recorded sessions for Microbes Persist (Pett-Ridge), SPRUCE (Schadt), TES & Watershed (Brodie) .. SFAs we have not heard back from are the Plant-Microbe Interfaces (Schadt) & Soils SFA (McDermott)",
"body": "Moving to sprint 5. Hopefully we hear from Soils & PMI to close soon!",
"body": "@mslarae13 for a \"protocol\" I might suggest just having a checklist for items you ask about for user feedback. I think similar to what was developed for the usability testing interviews that Pajau has been doing. Does that make sense? ",
"body": "@mslarae13 I checked with @emileyfadrosh per your Slack update and she is ok with closing this so I'll go ahead and close this.  ",
"body": "This is step two of Goal 2 for July sprint.  Getting feedback from users on the spreadsheet designed to collect data.  \r\n\r\n- Establish a protocol\r\n- Record work session (for feedback)\r\n",
"body": "Link to sprint planning document\r\nhttps://docs.google.com/document/d/1iBNXkBn24ZkmJkeptoqpyjcz5PAQU59ZjMOzDObnx4E/edit?ts=60d55721",
"body": "Move to August sprint? We've requested metadata but have not received anything \r\n@ssarrafan ",
"body": "Metadata still has not been received. I think we either close this issue and make an issue for tasks AFTER metadata is received. But any progress here is blocked until the PIs send me metadata. IDK what the best way for us to track this in issues.",
"body": "@mslarae13 I will remove it from this sprint and add the backlog label effectively putting this goal on hold till we can get metadata from the researchers.  \r\n\r\n@dehays @emileyfadrosh ",
"body": "Assuming if we haven't heard from researchers by now we probably wont. Closing issue. @mslarae13 @emileyfadrosh let me know if this should be re-opened. \r\n\r\nBacklog cleanup 12-2023",
"body": "This is the first step for Goal 2 of the July sprint.  ",
"body": "https://docs.google.com/spreadsheets/d/1IXFhklF1PyF6mqXuJo9mu6QrTvnEvWI1JV52TOHJphc/edit?usp=sharing\r\n\r\nThe above linked file contains the column headers and descriptions for the NMDC metadata template.\r\nNeed confirmation of components & discussion for getting them into the schema and how we will ingest/handle this template.",
"body": "## Posting this same comment across multiple GitHub tickets encompassing corrects to be made in GOLD, correct spreadsheets, and issues to still be sorted.\r\n@pvangay @dehays @jagadishcs \r\n\r\nBrodie\r\n- Correct sheet: https://drive.google.com/file/d/1aRJhuTX7bxf1LRH8F7qK5jYpoca7-kdQ/view?usp=sharing\r\n- Fields to correct/add\r\n- -- Depth units should be cm, not m.\r\n- -- Depth range, not single digit (https://github.com/microbiomedata/nmdc-metadata/issues/355)\r\n- -- Latitude & Longitude updated to match IGSNs\r\n- -- IGSN was added, can this be included?\r\n- -- Ecosystem subtype (Column N), Specific ecosystem (Column O), Habitat (Column P) were updated.\r\n- -- PI added Elevation\r\n- Note: Matching IGSNs or ParentSample IDs indicates the same JGI and EMSL sample. Metadata is the same across these matching samples, even though it's not repeated in the \"EMSL\" row\r\n- I don't believe there are any additional questions about the SAMPLE METADATA. @jagadishcs  can you confirm?\r\n- There's some sorting to be done with the FTICR / Organic Matter data files. @corilo and I are working on that.\r\n\r\n\r\nWrighton\r\n- Correct sheet: https://drive.google.com/file/d/1YiDWPxAEhpctuxuzsqBrWu2MmV_gyt83/view?usp=sharing\r\n- Fields to correct/add\r\n- --sample_collection_site (column J), not all samples are HRC-FS. How should we handle these? Exclude until we have clarification? Update relevant/correct samples?\r\n- Updated columns: N, P, U-Y, AB-AJ, AK, AL, AR, AT, BI, \r\n- Note: No JGI -> EMSL sample mapping has been accomplished. Waiting to hear back from Reb.\r\n- Note: Many of the fields listed in updated columns are updated for some samples but list NA/ not measured for other samples. Need to determine how to update this.\r\n- -- See https://docs.google.com/document/d/1B1YZK2-0mBbTuRwTEJH9qkWvNerGeHvH3gbmgQML13E/edit?usp=sharing\r\n- -- Waiting for Reb to respond with EMSL project #, associated sample analyses, and a sample list/map. Once we receive that, we can follow up on the questions in this document.\r\n\r\n\r\nStegen\r\n- Correct: https://drive.google.com/file/d/1NrTWTWV39nqvy4ftq3LLQu9rF0dHBsZ-/view?usp=sharing\r\n- Updated columns: J, P, T, U\r\n- --Depth, column T, is in meters. centimeters would be better, and needs a range value like Brodie.\r\n- See https://docs.google.com/document/d/1in7uAM9CjCu-5vr572hr-MoIyjDwOaP-4yry72V1MFU/edit?usp=sharing\r\n- -- There are a few follow up questions\r\n- -- Most important, relates to the sand mesocosms. I'm not sure if there were treatments applied to these that wasn't captured.\r\n",
"body": "Above was curated in GOLD and provided to NMDC as source for ETL: [https://drive.google.com/drive/folders/1TXEkgfp276Ivd77i4sq35tZppAcNCiT7](https://drive.google.com/drive/folders/1TXEkgfp276Ivd77i4sq35tZppAcNCiT7)",
"body": "Prior to GSP, the FICUS PIs had sent updated spreadsheets with metadata for us to include but we were not able to incorporate their updates. We will need to make sure that the metadata in these spreadsheets are incorporated when we do updates (these updates will address _some_ existing GH issues)\r\n\r\n[Brodie](https://drive.google.com/file/d/19PH8F-YqTZ3oUoWg1vKtPKHZT9YznXoA/view?usp=sharing)\r\n[Wrighton](https://drive.google.com/file/d/1YiDWPxAEhpctuxuzsqBrWu2MmV_gyt83/view)\r\n[Stegen](https://docs.google.com/spreadsheets/d/1NrTWTWV39nqvy4ftq3LLQu9rF0dHBsZ-/edit#gid=1030830903)\r\n\r\nAdding for FYI: @mslarae13 @kfagnan @dwinston ",
"body": "Further investigation / trial after June sprint / quarterly release",
"body": "As @dehays notes in #343, we don't have a curation process / UI whereby folks such as @pvangay, who are in contact with study PIs, can add/update metadata without being required to update a source database such as GOLD. Curation events should be possible, and recorded as part of the provenance of metadata, because updating primary source databases is sometimes intractable.\r\n\r\nSeveral metadata errors have been [tagged as issues](https://github.com/microbiomedata/nmdc-metadata/labels/metadata-update), and developing a workable curation process for use ASAP (this month) has been requested by @kfagnan et al.\r\n\r\nI was recently introduced to [Corda](https://www.cordra.org/documentation/design/schemas.html), which is a system with a built-in web UI for managing collections of JSON-Schema-conformant documents, and for editing (based on the schema) and saving versions of documents.\r\n\r\nI don't think the Cordra UI is suitable for metadata submission (#332), but I do think it could be a good fit for metadata curation by NMDC staff, where the curation events recorded by Cordra could feed into the broader NMDC ETL process.",
"body": "Done! Emiley sent me information & I'm updating it!",
"body": "NCBI require organism or taxonomy for samples as they match to -> https://www.ncbi.nlm.nih.gov/Taxonomy/Browser/wwwtax.cgi?id=408169\r\n\r\n@SamuelPurvine has mentioned that DMS at EMSL can link this as well and is useful for proteomics. I need some information & a decision on how to identify / describe this component and what we want to call it.\r\n\r\nSee column S in Metadata Tab or row 68 in the ReadMe tab\r\nhttps://docs.google.com/spreadsheets/d/10TU3E-TAbtzeo-_S8rYfSq8Xvp6wm1RMpo0LYtR4t9w/edit?usp=sharing\r\n ",
"body": "I made comments, but unfortunately. I am not familiar with things like NCBI Umbrella Projects.",
"body": "There are a few terms we might need to talk thru. Made some comments. \r\ne.g., investigation_type - that was a term in v5, which was deprecated in v6. I don't think we should try to include it with new CV, as it will make back-compatibility really confusing. Also, if pink is mandatory, I think there are a few fields (growth_facil) that shouldn't be mandatory.",
"body": "I commented back with any questions I had, and made indicated changes where I could.\r\nIf responses to these comments aren't addressed, could we spend some time this Wednesday at the Aim 1 meeting to discuss?\r\n\r\n @wdduncan\r\n @turbomam\r\n @emileyfadrosh\r\n @elishawc\r\n @pvangay\r\n @dehays",
"body": "Updated and corrected based on discussion & comments from Wednesday's meeting. \r\n\r\nSee: https://docs.google.com/spreadsheets/d/10TU3E-TAbtzeo-_S8rYfSq8Xvp6wm1RMpo0LYtR4t9w/edit?usp=sharing\r\n\r\n",
"body": "See - https://docs.google.com/spreadsheets/d/10TU3E-TAbtzeo-_S8rYfSq8Xvp6wm1RMpo0LYtR4t9w/edit?usp=sharing \r\n\r\nReadMe -> Project Information section (details from GOLD or added per meeting conversation)\r\n\r\nEveryone, could you please information what components here are not necessary, what needs added, and add definitions to components with ??, as I am not familiar with how to identify these.\r\n\r\n@wdduncan & @turbomam - Using the information in the row ID and definition, are these matching to what's in the schema now, if not can we add them, and if they're in the schema but with a different name can you provide me with this names?\r\n\r\nPlease Comment with suggestions, changes, or questions. Reminder, you need to do this in G-SHEET. \r\nPlease check you box when you've complete your review of ProjectInformation\r\n\r\n- [x] @wdduncan \r\n- [x] @turbomam \r\n- [x] @emileyfadrosh \r\n- [x] @elishawc \r\n- [x] @pvangay \r\n- [x] @dehays \r\n",
"body": "@emileyfadrosh I assigned this to you but let me know if it should be assigned to someone else. The other person listed in my notes to work on this is @dehays ",
"body": "As the metadata records have already been created in GOLD (https://gold.jgi.doe.gov/study?id=Gs0154044), the following process will apply: \r\n- [x] @jagadishcs to review records for the 217 metagenome biosamples and curate with EnvO terms\r\n- [ ] @dehays will coordinate with @StantonMartin for additional fields for soil chemistry, ect to be included \r\n- [ ] @dehays @elishawc add topic for discussion about study page for BioScales at Tech Sync\r\n\r\nMetagenome data will likely take ~3-4 months to generate; will coordinate with JGI staff for workflow processing and data exchange. ",
"body": "@emileyfadrosh \r\nReviewed the biosamples of a BioScales project (GOLD study ID Gs0154044) and shared for update in GOLD.",
"body": "Additional metadata values that are not available from GOLD but are used by the UI will need to be added to post ETL ( see microbiomedata/nmdc-schema#51 )",
"body": "Study and samples are included in GOLD DB export.  Will need to set values for web sites, profile_image_url, title, scientific objective post-ETL.",
"body": "@dehays @emileyfadrosh I'm assuming this issue should move to July but please confirm. ",
"body": "Had a meeting with BioScales team earlier today and update from JGI is to expect ~200 metagenomes to be ready in the next couple weeks. Suggest adding new tickets to (1) schedule call and collect additional metadata from the BioScales team and (2) develop plan for pulling data from JGI production. ",
"body": null,
"body": "@elishawc I assigned this to you but let me know If it should be re-assigned.  The other person mentioned in the notes to work on this is @mslarae13 ",
"body": "This is fine. I'll see them thru the next round of polishing. @mslarae13 and I need to connect on the hand-off plan.",
"body": "Adding the \"online activity\" work to this ticket, so we can close out the next one. @ssarrafan - we'll likely need a ticket in Jul/Aug to test the metadata spreadsheet upload w/ NCBI. @mslarae13 would be the point there. ",
"body": "Per slack message from @elishawc moving to July.",
"body": "Since the metadata training happened this month I will assume the slides are finalized.  @elishawc if you can add a link to the final slides in this GitHub issue that would be great.  I'm going to close this issue.  ",
"body": null,
"body": "Sorting this metadata is complex. Requested a meeting with Nick to go over the samples & identify sample links between JGI and EMSL\r\n",
"body": "Moving to next sprint. Have not heard back from user :(\r\n",
"body": "Nick responded and clarified some sample information. I've transposed his metadata to the NMDC template and sent it to him. Waiting to hear back with updated sample metadata.",
"body": "Nick sent some metadata & confirmed sample linking. Will complete metadata (hopefully) soon.  ",
"body": "Moving to September Sprint. I am hopeful Nick will complete in September & we can complete the metadata!",
"body": "Metadata looks good. I obtained temperature, light, and plant metadata from the publication supplemental information. When we have a way to implement parent -> child relationships & can upload this metadata to NMDC portal, I will ask Rebecca and Nick to confirm it's correct & provide details for study landing page. Until parent -> child relationships can be made, I'm backlogging this.",
"body": "Moving to backlog per Slack note from Montana \"until we can support parent-child relationships\"",
"body": "@mslarae13 should this issue remain open in the backlog still?  \r\nFYI @aclum ",
"body": " we never ingested this study. we need to do this!",
"body": "PI sent metadata, working to finalize samples map\r\n\r\n- [x] Finish sorting metadata\r\n\r\n- [x] Send followup questions\r\n- [ ] Confirm metadata once received",
"body": "Added to August per Slack message with @mslarae13 ",
"body": "No longer pursuing. Unless PI reaches out we will not add. ",
"body": "Hess team will follow up mid June with metadata",
"body": "Continuation of work discussed (at least on GH) from the May sprint at #308",
"body": "@turbomam I've kept you as the one assignee on this issue.  Let me know if that's not ok.",
"body": "@ssarrafan This should be assigned to me.",
"body": "> @ssarrafan This should be assigned to me.\r\n\r\nok thanks for taking another one Bill!",
"body": "Adding backlog label to be reprioritized for another sprint.  ",
"body": "This is an old issue assigned to Bill in 2021. Closing it.  FYI @cmungall @turbomam \r\nBacklog clean up 12-2023",
"body": "This issue is to document, implement the third way to do integrity checks:\r\n\r\nIs the ID valid and appropriate?\r\n\r\n\r\nThe 3rd is more difficult, a few approaches:\r\n\r\nAdditional code outside the schema that does lookups with public APIs to check the ID is valid and not obsolete and yields a semantically appropriate entity\r\nWe enumerate all valid IDs and include as an enum in the schema. Note these could be quite large, but we would generate these programmatically and include as a separate import\r\nWe take advantage of the ability in linkml to identify a codeset, and create this separately\r\n",
"body": "As of 06/28 there's been no response. I will follow up, moving to July Sprint as no communication was completed for June.\r\n",
"body": "Added to August per Slack message with @mslarae13 ",
"body": "No longer actively pursuing this project. Unless PI reaches out, we will not add.",
"body": "05/27 Bowen group followed up that they're finishing the metadata. Once received, finalize the data for ingestion",
"body": "@turbomam @wdduncan \r\nDo you also need to know what sample types will have each component? Or does that matter?\r\nFor example, plant_struct is only in plant.",
"body": "https://docs.google.com/spreadsheets/d/1IXFhklF1PyF6mqXuJo9mu6QrTvnEvWI1JV52TOHJphc/edit?usp=sharing\r\n",
"body": "> @turbomam @wdduncan\r\n> Do you also need to know what sample types will have each component? Or does that matter?\r\n> For example, plant_struct is only in plant.\r\n\r\nGood question. Right now, I would say \"no\" for me, but I might be overlooking something.\r\n\r\n@wdduncan , would the ENVO term subsetting for MIxS triads apply to this potential sample type/component alignment.",
"body": "@turbomam  @wdduncan \r\n\r\nHave you had a chance to look these over? I am going to close this issue and make a follow up for you two to look it over & us meet and discuss next steps. Maybe this would be a good agenda item for out metadata related meetings on wednesdays? ",
"body": "Mark & Bill requested detailed information about the columns and components of the metadata to make a \"map\" or SSSOM.",
"body": "Packages added and complete. Waiting on completion of other issues for this to be 100 % complete\r\nhttps://github.com/microbiomedata/nmdc-metadata/issues/366\r\n&\r\nhttps://github.com/microbiomedata/nmdc-metadata/issues/367\r\n",
"body": "version complete. SFA roll out beginning soon.",
"body": "- [x] Soil\r\n- [x] Sediment\r\n- [x] Plant Assoc\r\n- [x] Water",
"body": "After the completion of microbiomedata/nmdc-schema#20 - there would be task for @corilo to provide descriptions for these data objects and a task nmdc-server to use the data object description (looks like the UI is already looking for it)",
"body": "This will be partly addressed by microbiomedata/nmdc-schema#78\r\n\r\nYuri would like to display the file name instead of the general description in the description column.  That's take some custom nmdc-server change.",
"body": "Discovered this when @mslarae13 and I sat down with Eoin and his team to review their data in the portal.\r\n\r\nEoin and his team did not know what any of these NOM files were based on the filenames. We either need to add descriptions to each of these files, rename them, or refine which files should be included here. They also pointed out that Brodie_w_rJanHESI_neg.csv sounds like it indicates that the sample was run by EMSL in January, but this is not useful and can be confusing in the context of the study.\r\n\r\n![image](https://user-images.githubusercontent.com/7374085/119737304-e89aca00-be33-11eb-9c07-b513c829e7c4.png)\r\n",
"body": "Note that these values are represented as ranges in GOLD, therefore this is not a GOLD issue. This may be related to the need to support ranges from #355 - and perhaps disappears altogether on the portal sample page because the value may be represented as 0.",
"body": "There are two parts to this - First, @turbomam did Bill's support for depth ranges ever get addeded to the schema?  If not, there is a schema change (merge of a branch Bill worked on) and then subsequent support for ranges in the data portal search.  Second, once the schema accepts ranges, properly set the range values in the biosample documents in Mongo.  Could use a changesheet for that.\r\n\r\nAssigning to Mark as he would be involved in the initial schema updates needed.",
"body": "_Soil microbial communities from the East River watershed near Crested Butte, Colorado, United States - ER_DNA_379_ does not have a depth parameter on its sample page: https://data.microbiomedata.org/details/sample/igsn:IEWFS001F - but it's reported as 0-5 in his [spreadsheet](https://drive.google.com/file/d/19PH8F-YqTZ3oUoWg1vKtPKHZT9YznXoA/view?usp=sharing).\r\n\r\nThere may be other samples that also have this problem.\r\n\r\n\r\n",
"body": "This is a larger problem because MIxS has only a single value for 'depth' and does not support ranges.  If NMDC tries to support a range than that would mean diverging from MIxS. (There is a reason that Darwin Core has two fields: minDepth and maxDepth.)",
"body": "Not sure if this is helpful, but MIxS's description for Depth:\r\n\r\n> Depth is defined as the vertical distance below local surface, e.g. For sediment or soil samples depth is measured from sediment or soil surface, respectively. **Depth can be reported as an interval for subsurface samples.**",
"body": "https://github.com/microbiomedata/nmdc-metadata/issues/327#issuecomment-857219621\r\n\r\ncomment from Reddy. range is ok for GOLD.",
"body": "Can we modify the schema to support ranges for Depth? We discussed this at yesterday's metadata sync and I believe the decision was to support it. Please confirm @dehays @cmungall @wdduncan ",
"body": "I have filed a ticket with GSC to assess needs for measurements:  \r\nhttps://github.com/GenomicsStandardsConsortium/mixs/issues/166",
"body": "Related to issue https://github.com/microbiomedata/nmdc-schema/issues/80",
"body": "Closing this issue since it's a duplicate of microbiomedata/nmdc-schema#80. Checked with @wdduncan.  ",
"body": "Discovered this when @mslarae13 and I sat down with Eoin and his team to review their data in the portal.\r\n\r\n_Soil microbial communities from the East River watershed near Crested Butte, Colorado, United States - ER_DNA_380_ has a depth of 5, when it should be 5-15 ([Brodie spreadsheet](https://drive.google.com/file/d/19PH8F-YqTZ3oUoWg1vKtPKHZT9YznXoA/view)). All of the depth values for the Brodie dataset were submitted as a range - it is common to report depth as a range for Soil and Sediment environments.\r\n\r\nUnclear if this requires a schema update, or if the metadata value was incorrectly stored, or simply not being displayed properly on the UI. Please relabel/reassign as needed @dehays ",
"body": "appears to have been fixed with latest changes",
"body": "For all studies, when you:\r\n\r\n1. Select 1 study\r\n2. Click on the point on the map (which is supposed to filter by the lat/lon of the study)\r\n\r\nThe number of omics data counts after Step 1 and Step 2 are different, when one would expect them to be the same. Perhaps some samples don't have lat/lon assigned? Or is this a breakdown in the links between samples/omics data? Or is this a UI issue? Please help @dehays \r\n\r\nDiscovered this when @mslarae13 and I sat down with Eoin and his team to review their data in the portal.",
"body": "Per Infrastructure Sync today:\r\n\r\nRemove:\r\n- Location\r\n- Community\r\n- Sample Collection Site\r\n- Habitat\r\n- NCBI Taxonomy name\r\n\r\nRename geo loc name --> Geographical Location Name\r\n\r\n",
"body": "This very old issue appears to have been resolved in a tech sync a year ago.",
"body": "@dehays and Aim 1, please make a decision on the following: \r\n\r\n1. Should these be in the left-panel search of the data portal? I think these are from GOLD and i dont see them in the NMDC spreadsheet. (these terms are a source of confusion for users, especially since we dont yet have descriptions)\r\n\r\n- Community\r\n- Location\r\n- Sample Collection Site\r\n- Habitat\r\n\r\n2. May want to consider adding elevation (mandatory for soil samples)\r\n\r\n3. Should we enable search by MIxS environmental package? (is the env package stored in the schema anywhere?)\r\n\r\nAdding as an FYI since we chatted about this @kfagnan ",
"body": "\r\n\r\nCorrect: https://drive.google.com/file/d/1NrTWTWV39nqvy4ftq3LLQu9rF0dHBsZ-/view?usp=sharing\r\nUpdated columns: J, P, T, U\r\n--Depth, column T, is in meters. centimeters would be better, and needs a range value like Brodie.\r\nSee https://docs.google.com/document/d/1in7uAM9CjCu-5vr572hr-MoIyjDwOaP-4yry72V1MFU/edit?usp=sharing\r\n-- There are a few follow up questions\r\n-- Most important, relates to the sand mesocosms. I'm not sure if there were treatments applied to these that wasn't captured.",
"body": "Email follow up sent 06/16 requesting more information & clarification.",
"body": "@mslarae13 and I met with James today to review his data in the portal.\r\n\r\n1. Sample names that are longer and contain a \"T\" such as: _Groundwater microbial communities from the Columbia River, Washington, USA, for microbe roles in carbon and contaminant biogeochemistry - GW-RW metaG **T**3_30-Apr-14_ are sand samples that have been sterilized in the lab per methods [here](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0228165#sec013) then incubated back in the ground as \"sand packs\" and collected at various time points. This is distinct from other samples in this dataset are \"native\" sediment samples.\r\n\r\n2. Sample names with \"N\" as in _Groundwater microbial communities from the Columbia River, Washington, USA - GW-RW **N**3_10_20_ did not come from areas with vegetation. Samples with \"S\" as in _Groundwater microbial communities from the Columbia River, Washington, USA - GW-RW **S**2_00_10_ had a lot of vegetation nearby. Can we modify the EnvO terms for these samples to more accurately reflect these features? @jagadishcs (these features are part of the science story)\r\n\r\n3. James also mentioned that all samples should have distinct lat/lon values as they were sampled across space and time.\r\n\r\nJames mentioned a [spreadsheet](https://drive.google.com/file/d/1IpP5FWsTpepphy0-ZkDJQIuvXeBZj3Q8/view?usp=sharing) that he shared before GSP that should already have all of these details in them. Please share the link here @mslarae13. Thanks!\r\n",
"body": "Using updated EMSL dataset lists (see #341) likely will reduce the number of NOM listed for Stegen.  The 121 count for metaP is also coming from the total number of instrument runs (EMSL datasets).  I know the number of metaP instrument datasets for which any analysis workflow was applied is much lower as the workflow requires matching to metaG annotation.  Meaning, if we should make a decision to only include metaP instrument runs for which there is NMDC analysis, that number comes way down too.",
"body": "# Posting this same comment across multiple GitHub tickets encompassing corrects to be made in GOLD, correct spreadsheets, and issues to still be sorted.\r\n@pvangay @dehays @jagadishcs\r\n\r\nBrodie\r\nCorrect sheet: https://drive.google.com/file/d/1aRJhuTX7bxf1LRH8F7qK5jYpoca7-kdQ/view?usp=sharing\r\nFields to correct/add\r\n-- Depth units should be cm, not m.\r\n-- Depth range, not single digit (#355)\r\n-- Latitude & Longitude updated to match IGSNs\r\n-- IGSN was added, can this be included?\r\n-- Ecosystem subtype (Column N), Specific ecosystem (Column O), Habitat (Column P) were updated.\r\n-- PI added Elevation\r\nNote: Matching IGSNs or ParentSample IDs indicates the same JGI and EMSL sample. Metadata is the same across these matching samples, even though it's not repeated in the \"EMSL\" row\r\nI don't believe there are any additional questions about the SAMPLE METADATA. @jagadishcs can you confirm?\r\nThere's some sorting to be done with the FTICR / Organic Matter data files. @corilo and I are working on that.\r\n\r\nWrighton\r\nCorrect sheet: https://drive.google.com/file/d/1YiDWPxAEhpctuxuzsqBrWu2MmV_gyt83/view?usp=sharing\r\nFields to correct/add\r\n--sample_collection_site (column J), not all samples are HRC-FS. How should we handle these? Exclude until we have clarification? Update relevant/correct samples?\r\nUpdated columns: N, P, U-Y, AB-AJ, AK, AL, AR, AT, BI,\r\nNote: No JGI -> EMSL sample mapping has been accomplished. Waiting to hear back from Reb.\r\nNote: Many of the fields listed in updated columns are updated for some samples but list NA/ not measured for other samples. Need to determine how to update this.\r\n-- See https://docs.google.com/document/d/1B1YZK2-0mBbTuRwTEJH9qkWvNerGeHvH3gbmgQML13E/edit?usp=sharing\r\n-- Waiting for Reb to respond with EMSL project #, associated sample analyses, and a sample list/map. Once we receive that, we can follow up on the questions in this document.\r\n\r\nStegen\r\nCorrect: https://drive.google.com/file/d/1NrTWTWV39nqvy4ftq3LLQu9rF0dHBsZ-/view?usp=sharing\r\nUpdated columns: J, P, T, U\r\n--Depth, column T, is in meters. centimeters would be better, and needs a range value like Brodie.\r\nSee https://docs.google.com/document/d/1in7uAM9CjCu-5vr572hr-MoIyjDwOaP-4yry72V1MFU/edit?usp=sharing\r\n-- There are a few follow up questions\r\n-- Most important, relates to the sand mesocosms. I'm not sure if there were treatments applied to these that wasn't captured.",
"body": "This may be related to https://github.com/microbiomedata/nmdc-metadata/issues/341\r\n\r\n@mslarae13 and I met with James today to review his data in the portal. He thinks that every sample that has NOM should also have metaG. The numbers for the omics types do not seem to match what he thinks they should be. 1111 for NOM and 121 for metaP seems especially high.\r\n\r\n\r\n\r\n",
"body": "via microbiomedata/nmdc-runtime@e206ff7f50f2300c5dbd6dfea520f221da73da3b",
"body": "https://journals.plos.org/plosone/article/authors?id=10.1371/journal.pone.0228165",
"body": "This issue might be better off in nmdc-server (where, non intuitively, the client code is) because this is about how best to display an NMDC biosample.  That display can only use the biosample attributes that are available.  So this is not a question of whether to display an IGSN or a UUID, biosample has an id attribute that can take several forms: gold:, igsn: or emsl:.  For gold: and igsn: sample ids the ID could be displayed to link back to the record indicated by the identifier.  sample_name is a field on the MIxS 6, which would likely map to the NMDC biosample name field.  The NMDC biosample name field is what is currently displayed in the UI.",
"body": "@dehays should this issue be added to the July sprint board?  ",
"body": "@ssarrafan Yes - and there could be two tasks here.  1) Given the attributes of a biosample in NMDC, how should that biosample be displayed in the UI; i.e. what field values should be displayed and how should they be displayed.  2) There is also discussion about whether the GOLD biosample name should be used as the NMDC biosample name.  GOLD biosample names default to a naming scheme that uses the sequencing project name combined with the researcher sample name.  If we pursue this modification for name from GOLD to NMDC then there needs to be a naming scheme defined.",
"body": "Samples are currently listed by study/proposal names, which can be misleading in some cases (as in #342), or too long to distinguish between samples (#340)\r\n\r\nIn 5/21/21 \"docuthon\" meeting, @mslarae13 @dehays @dwinston discussed options, which include one or more of:\r\n\r\n- sample_name (new datasets)\r\n- IGSN\r\n- UUID\r\n- local sample ID\r\n\r\n**Action items:** \r\n\r\n- [ ] identify who needs to be included in the discussion / decision making\r\n- [ ] schedule meeting to determine an alternative to what we're doing currently\r\n- [ ] implement new alternative\r\n\r\nAdding as listeners: @kfagnan @turbomam ",
"body": "@dwinston and @dehays can one of you own this issue (maybe do the first draft?) so we can try having GH issues assigned to one person at a time?  ",
"body": "For Sprint 3 - filter rules to be applied post ETL (against both GOLD and EMSL sourced metadata):\r\n\r\nbiosamples - must be part_of one of the included studies\r\n                      \r\nomics_processing - must be part_of one of the included studies\r\n                                   must have a non empty / non null has_input value (must be associated with input biosamples).  \r\n                                   (The above should be true already as the ETL will drop non conformant omics_processing and\r\n                                   has_input is now required.)\r\n                                   must be referenced by at least one was_informed_by analysis activity (must have associated analysis)",
"body": "> For Sprint 3 - filter rules to be applied post ETL (against both GOLD and EMSL sourced metadata):\r\n> \r\n> biosamples - must be part_of one of the included studies\r\n> \r\n> omics_processing - must be part_of one of the included studies\r\n> must have a non empty / non null has_input value (must be associated with input biosamples).\r\n> (The above should be true already as the ETL will drop non conformant omics_processing and\r\n> has_input is now required.)\r\n> must be referenced by at least one was_informed_by analysis activity (must have associated analysis)\r\n\r\nThanks for documenting this @dehays.  Can this issue be closed?  Or does it need to go to July or the backlog?  ",
"body": "Since this is the last open issue in sprint 3 and I haven't heard back on what to do with it I'm going to move it to the July sprint. But if this is not a priority for July please let me know so I can remove it from the sprint. \r\n@dehays @emileyfadrosh @kfagnan ",
"body": "I'm moving this to the 'backlog' and removing from active sprints",
"body": "Closing this old issue from 2021.  FYI @kfagnan @emileyfadrosh @lamccue \r\n\r\nBacklog cleanup 12-2023",
"body": "This issue is related to issues 312 and 309:\r\nhttps://github.com/microbiomedata/nmdc-metadata/issues/309\r\nhttps://github.com/microbiomedata/nmdc-metadata/issues/312\r\n\r\n@dehays and @dwinston  to implement business logic for JGI and EMSL to filter appropriate data into NMDC",
"body": "@ssarrafan this won't be in progress until some exemplary logic is in place for the release this month, and the final data to validate is not yet available. So, this will either be suddenly in progress and then done this month, or will be pushed to next month.",
"body": "@dwinston thanks for the update.  I'll keep it here till next week and tif it's not done by 6/30 I'll move it to July, assuming it's still a priority \r\n@emileyfadrosh \r\n@kfagnan ",
"body": "Haven't seen any updates on this so moving this to the backlog. @dwinston @kfagnan let me know if it should be in October's sprint.",
"body": "Closing this old issue from 2021.  @dwinston let me know if this is something that should still be on our radar. \r\nFYI @kfagnan @shreddd \r\n\r\nBacklog cleanup 12-2023",
"body": "This issue is related to issue 312: https://github.com/microbiomedata/nmdc-metadata/issues/312\r\n@dwinston offered to create documentation and templates so more people can help with code on the NMDC team.  \r\n\r\nDue to Donny's availability I am pushing this to the June sprint. \r\n\r\n",
"body": "From the email conversation with Patrick Chain, it seems that this requires identification of particular tasks and issues. I have made a [python](https://github.com/microbiomedata/nmdc-runtime/labels/python) tag in the nmdc-runtime repo for annotating these as they become apparent. Also, it seems that completing #347 would be a prerequisite for such help.",
"body": "Since completing #347 is a prerequisite and that can't be done till June I'm moving this to the June sprint.  Chris did offer some help from Mark too. ",
"body": "Discussed with @cmungall and will have additional support from his team. Will need issues clearly assigned. ",
"body": "This issue is related to issue [312](https://github.com/microbiomedata/nmdc-metadata/issues/312) and issue 309: https://github.com/microbiomedata/nmdc-metadata/issues/309\r\nThis issue is assigned to Emiley and Set to get some help for Python expertise.  ",
"body": "Shared \"final\" draft slides with broader training community representative for feedback and discussion around next steps. Slides here: https://docs.google.com/presentation/d/1hs9OROPTuB6ZUXTvmAj9hihGYlQ1XLkhNWF4rnBDSC8/edit?ts=60a34533#slide=id.p1",
"body": "Closing per @elishawc ",
"body": "Develop slides and activity for community training sessions related to sample metadata",
"body": "@cmungall I've removed many of the directories in the `nmdc-metadata` repo. The files have been moved to either the `nmdc-schema` or `nmdc-runtime` repos.\r\n\r\nCan you review the changes on branch `issue-288` and see what else you think be removed?",
"body": "Implementing isseu #288 \r\nReorganizing the nmdc-metadata repo.",
"body": "If your screen is wide enough the full name is shown.  Maybe we need to make the name multi-line rather than truncating (with an ellipsis) when it doesn't fit?",
"body": "Oh wait, I guess for the Brodie biosamples the name is like that in the database.  I assume this is coming from upstream in the pipeline because nothing in the ingest does any truncation.",
"body": "You're right @jbeezley - I see it in the Mongo documents:\r\n\r\n```\r\n{\"_id\":\r\n{\"$oid\":\"602551d125261d62add15a31\"},\r\n\"name\":\"Soil microbial communities from the East River watershed near Crested Butte, Colorado, United States - \",\r\n\r\n\"description\":\"Soil microbial communities from the East River watershed near Crested Butte, Colorado, United States\",\r\n\r\n\"lat_lon\":{\"has_raw_value\":\"38.9206 -106.9489\",\r\n    \"latitude\":38.9206,\r\n    \"longitude\":-106.9489},\r\n\r\n...\r\n```\r\nI  would agree making the display wrap to multi lines so long names display regardless of window width.\r\n\r\nI'll move this to the ETL issues as I think that is where the truncation must be happening.",
"body": "@wdduncan  It appears that this biosample name truncation is happening in the ETL.  The example above is truncated at 103 characters. (Maybe when you load from Oracle to your local DB?)",
"body": "The json that I output has more data than what is shown above. Here is the json for one Brodie's (`Gs0135149`) study biosamples (note the name has ** - ER_DNA_115**).\r\n```json\r\n{\r\n      \"id\": \"gold:Gb0191643\",\r\n      \"name\": \"Soil microbial communities from the East River watershed near Crested Butte, Colorado, United States - ER_DNA_115\",\r\n      \"description\": \"Soil microbial communities from the East River watershed near Crested Butte, Colorado, United States\",\r\n      \"type\": \"nmdc:Biosample\",\r\n      \"collection_date\": {\r\n        \"has_raw_value\": \"2017-03-07\"\r\n      },\r\n      \"lat_lon\": {\r\n        \"has_raw_value\": \"38.9206 -106.9489\",\r\n        \"latitude\": 38.9206,\r\n        \"longitude\": -106.9489\r\n  }\r\n}\r\n```\r\nThe name matches what is on the GOLD portal for biosample `Gb0191643` (see screenshot).\r\n![image](https://user-images.githubusercontent.com/3186638/117729203-85b0fe00-b1b8-11eb-907c-9520f0c0f407.png)\r\n",
"body": "This is kinda yuck.  @wdduncan - this is not truncation happening in the GOLD ETL as I had originally thought.  \r\n\r\nFor the Brodie study, there are 53 biosample metadata documents in Mongo and as expected 53 biosamples on the search portal. Bill, your ETL produces nearly twice that number.  This is because the RNA and DNA samples were merged into single source samples.  @dwinston - the naming from that merge appears to be the shared part of the name but doesn't include the different part of the name. (Makes sense, there'd need to be a special rule to do something useful with the different parts of the names.)  So two samples from GOLD, Gb0191643 and Gb0205601 with names  \"Soil microbial communities from the East River watershed near Crested Butte, Colorado, United States - ER_DNA_115\" and \"Soil microbial communities from the East River watershed near Crested Butte, Colorado, United States - ER_RNA_115\", get merged to one sample igsn:IEWFS0001 with name \"Soil microbial communities from the East River watershed near Crested Butte, Colorado, United States -\".\r\n\r\nThese look truncated but are really the result of that 2:1 biosample transformation.  And this happen for each sample that has both a DNA and an RNA biosample in GOLD.  (There are only three GOLD DNA biosamples for this study that had no corresponding RNA biosample and those appear correctly in the portal ...ER_DNA_379, ..._ER_DNA_380 and ...ER_DNA_381.\r\n\r\nSomething similar happens for the Organic Matter samples that have not corresponding GOLD biosample record; e.g. igsn:IEWFS000K which ends up with name: \"Soil microbial communities from the East River watershed near Crested Butte, Colorado, United States -\"\r\n\r\nYet again - in this case, we know what happened, but there is no general solution beyond these specific samples.  The local names for the samples were numbers 115 - 381.  The DNA and RNA isolations got \"ER_DNA_\" and \"ER_RNA_\" prefixes for the local names for samples provided to JGI.  EMSL got mostly the numbered samples - except for a set of samples used for metabolomics that had completely different naming.\r\n\r\nI don't see any way for a transform to set appropriate sample names except as a a one-off that has knowledge of the local naming schemes.  ",
"body": "Some do have that extra text, some don't.  These are the entities in question:\r\n```\r\nnmdc> select id, name from biosample where name like '%- '                                                                     \r\n+----------------+---------------------------------------------------------------------------------------------------------+\r\n| id             | name                                                                                                    |\r\n|----------------+---------------------------------------------------------------------------------------------------------|\r\n| igsn:IEWFS0001 | Soil microbial communities from the East River watershed near Crested Butte, Colorado, United States -  |\r\n| igsn:IEWFS0002 | Soil microbial communities from the East River watershed near Crested Butte, Colorado, United States -  |\r\n| igsn:IEWFS0003 | Soil microbial communities from the East River watershed near Crested Butte, Colorado, United States -  |\r\n| igsn:IEWFS0004 | Soil microbial communities from the East River watershed near Crested Butte, Colorado, United States -  |\r\n| igsn:IEWFS0005 | Soil microbial communities from the East River watershed near Crested Butte, Colorado, United States -  |\r\n| igsn:IEWFS0006 | Soil microbial communities from the East River watershed near Crested Butte, Colorado, United States -  |\r\n| igsn:IEWFS0007 | Soil microbial communities from the East River watershed near Crested Butte, Colorado, United States -  |\r\n| igsn:IEWFS0008 | Soil microbial communities from the East River watershed near Crested Butte, Colorado, United States -  |\r\n| igsn:IEWFS0009 | Soil microbial communities from the East River watershed near Crested Butte, Colorado, United States -  |\r\n| igsn:IEWFS000C | Soil microbial communities from the East River watershed near Crested Butte, Colorado, United States -  |\r\n| igsn:IEWFS000D | Soil microbial communities from the East River watershed near Crested Butte, Colorado, United States -  |\r\n| igsn:IEWFS000E | Soil microbial communities from the East River watershed near Crested Butte, Colorado, United States -  |\r\n| igsn:IEWFS000F | Soil microbial communities from the East River watershed near Crested Butte, Colorado, United States -  |\r\n| igsn:IEWFS000G | Soil microbial communities from the East River watershed near Crested Butte, Colorado, United States -  |\r\n| igsn:IEWFS000H | Soil microbial communities from the East River watershed near Crested Butte, Colorado, United States -  |\r\n| igsn:IEWFS000L | Soil microbial communities from the East River watershed near Crested Butte, Colorado, United States -  |\r\n| igsn:IEWFS000M | Soil microbial communities from the East River watershed near Crested Butte, Colorado, United States -  |\r\n| igsn:IEWFS000N | Soil microbial communities from the East River watershed near Crested Butte, Colorado, United States -  |\r\n| igsn:IEWFS000O | Soil microbial communities from the East River watershed near Crested Butte, Colorado, United States -  |\r\n| igsn:IEWFS000P | Soil microbial communities from the East River watershed near Crested Butte, Colorado, United States -  |\r\n| igsn:IEWFS000Q | Soil microbial communities from the East River watershed near Crested Butte, Colorado, United States -  |\r\n| igsn:IEWFS000R | Soil microbial communities from the East River watershed near Crested Butte, Colorado, United States -  |\r\n| igsn:IEWFS000S | Soil microbial communities from the East River watershed near Crested Butte, Colorado, United States -  |\r\n| igsn:IEWFS000T | Soil microbial communities from the East River watershed near Crested Butte, Colorado, United States -  |\r\n| igsn:IEWFS000U | Soil microbial communities from the East River watershed near Crested Butte, Colorado, United States -  |\r\n| igsn:IEWFS000V | Soil microbial communities from the East River watershed near Crested Butte, Colorado, United States -  |\r\n| igsn:IEWFS000W | Soil microbial communities from the East River watershed near Crested Butte, Colorado, United States -  |\r\n| igsn:IEWFS000X | Soil microbial communities from the East River watershed near Crested Butte, Colorado, United States -  |\r\n| igsn:IEWFS000Y | Soil microbial communities from the East River watershed near Crested Butte, Colorado, United States -  |\r\n| igsn:IEWFS000Z | Soil microbial communities from the East River watershed near Crested Butte, Colorado, United States -  |\r\n| igsn:IEWFS0010 | Soil microbial communities from the East River watershed near Crested Butte, Colorado, United States -  |\r\n| igsn:IEWFS0011 | Soil microbial communities from the East River watershed near Crested Butte, Colorado, United States -  |\r\n| igsn:IEWFS0012 | Soil microbial communities from the East River watershed near Crested Butte, Colorado, United States -  |\r\n| igsn:IEWFS0013 | Soil microbial communities from the East River watershed near Crested Butte, Colorado, United States -  |\r\n| igsn:IEWFS0014 | Soil microbial communities from the East River watershed near Crested Butte, Colorado, United States -  |\r\n| igsn:IEWFS0015 | Soil microbial communities from the East River watershed near Crested Butte, Colorado, United States -  |\r\n| igsn:IEWFS0016 | Soil microbial communities from the East River watershed near Crested Butte, Colorado, United States -  |\r\n| igsn:IEWFS0017 | Soil microbial communities from the East River watershed near Crested Butte, Colorado, United States -  |\r\n| igsn:IEWFS0018 | Soil microbial communities from the East River watershed near Crested Butte, Colorado, United States -  |\r\n| igsn:IEWFS0019 | Soil microbial communities from the East River watershed near Crested Butte, Colorado, United States -  |\r\n| igsn:IEWFS001A | Soil microbial communities from the East River watershed near Crested Butte, Colorado, United States -  |\r\n| igsn:IEWFS001B | Soil microbial communities from the East River watershed near Crested Butte, Colorado, United States -  |\r\n| igsn:IEWFS001C | Soil microbial communities from the East River watershed near Crested Butte, Colorado, United States -  |\r\n| igsn:IEWFS001D | Soil microbial communities from the East River watershed near Crested Butte, Colorado, United States -  |\r\n| igsn:IEWFS001E | Soil microbial communities from the East River watershed near Crested Butte, Colorado, United States -  |\r\n| igsn:IEWFS000I | Soil microbial communities from the East River watershed near Crested Butte, Colorado, United States -  |\r\n| igsn:IEWFS000K | Soil microbial communities from the East River watershed near Crested Butte, Colorado, United States -  |\r\n| igsn:IEWFS000B | Soil microbial communities from the East River watershed near Crested Butte, Colorado, United States -  |\r\n| igsn:IEWFS000A | Soil microbial communities from the East River watershed near Crested Butte, Colorado, United States -  |\r\n| igsn:IEWFS000J | Soil microbial communities from the East River watershed near Crested Butte, Colorado, United States -  |\r\n+----------------+---------------------------------------------------------------------------------------------------------+\r\n```",
"body": "@jbeezley See my explanation - each merged RNA and DNA GOLD biosample and each EMSL only sample ends up looking truncated.  ",
"body": "@dehays glad to know it is not a GOLD ETL issue. But, I'm not sure what the right approach to take is.",
"body": "@dwinston You addressed this in the changes you made while meeting with Bill and I last Thursday. Can you close this with the PR for those changes.",
"body": "documented in [microbiomedata/nmdc-runtime/metadata-translation/notebooks/202106_curation_updates.ipynb](https://github.com/microbiomedata/nmdc-runtime/blob/e206ff7f50f2300c5dbd6dfea520f221da73da3b/metadata-translation/notebooks/202106_curation_updates.ipynb)",
"body": "The primary issue here is that the biosample names (which originate from GOLD) are truncated in the search portal.\r\n\r\nEoin Brodie pointed out in a call yesterday that there was no way to differentiate between the different samples in the UI because the part of the biosample name that is different - has been truncated.\r\n\r\nFor example,  GOLD appears to build the biosample name by appending the local sample name to the end of the study name; i.e. \"Soil microbial communities from the East River watershed near Crested Butte, Colorado, United States - ER_DNA_115\"\r\n\r\nBut in most cases - all of the Brodie biosamples display \"Soil microbial communities from the East River watershed near Crested Butte, Colorado, United States -\" as the sample names.\r\n\r\nFirst and easier step to address this: display the entire biosample name\r\n\r\nIn future, consider adopting a different sample naming scheme than GOLD's.",
"body": "\r\n@pvangay and @emileyfadrosh thought you may want to see this issue so adding you here.  ",
"body": "This is what we have in the portal database for that study:\r\n```\r\n Metagenome                      |    48\r\n Lipidomics                      |    86\r\n Metatranscriptome               |    45\r\n Organic Matter Characterization |   652\r\n```",
"body": "> This is what we have in the portal database for that study:\r\n> \r\n> ```\r\n>  Metagenome                      |    48\r\n>  Lipidomics                      |    86\r\n>  Metatranscriptome               |    45\r\n>  Organic Matter Characterization |   652\r\n> ```\r\n\r\nThanks @jbeezley.  Can you help me figure out who would be the best person to assign this to?  @dwinston or @wdduncan? ",
"body": "In the past, I have relied on @dehays to track down missing data.  Most of the upstream process is a black box to me.",
"body": "@jbeezley Seems the portal database must also have 52 Metabolomics as that is what is being displayed.\r\n\r\nThe issue here, when I look into it, is that there are 52 omics_processing entities that are part of this study (gold:Gs0135149) but those study entities do no have sample input - so there are not samples to list.\r\n\r\nA couple larger issues here \r\n\r\n1) Triaging issues seen in the portal.  It is good that people report apparent issues when viewing the portal.  It is not the responsibility of the reporter to determine the cause of the problem.  But I think it will take some time from myself or others to determine where a problem is and who should be involved in addressing it.  @jbeezley can certainly contribute to that triage in that he can say ' Hey, this is in the metadata that was provided and is not actually something that can be fixed on the search portal server or client.'  The upstream stuff should be a black box from the perspective of Jon and Brandon- in my opinion, more of a black box than it is now.\r\n\r\n2) Schema changes for required fields.  There are other GH issues on this.  In this case, an instrument process (omics_process) without input samples shouldn't be valid.  That should be a change in the schema and Jon should not see omics_processing without samples.\r\n\r\nAt the moment there are both a number of schema changes and a number of metadata changes to be made.  We (Set, Bill, Kj, et al) can discuss whether this sprint or the next is the right place for a schema release and new metadata release.  ",
"body": "@dehays are you ok with taking the token on this one? I agree it may not be something to fully resolve this sprint.",
"body": "I'm happy to provide tier 1 support and fix the issue if it is bug in the portal code.  It would be nice to work out an official method of escalation that I could follow so that these issues don't get lost.  Perhaps I should open a new issue in https://github.com/microbiomedata/nmdc-metadata in the future?",
"body": "@jeffbaumes I'm good with being the assignee here.  As I'd mentioned, there are a number of metadata corrections and updates to make.  Some relate to changes in the schema for additional and required fields.  (Such as those on studies.)\r\n\r\n@jbeezley Agreed.  For the moment we can do something more with refining bug labels (metadata-bug, portal-bug, etc.) and moving issues between repo issue queues.\r\n\r\nAnd in some cases I think new issues would be appropriate - should I make one for that 'incompatible data table error - wrong number of cols' error that the map in the UI ?\r\n\r\nThe start of some sort of official process could be making it easier for me to find a list of bugs to investigate and assign.  Jon, you can help with that when you determine something is or is not a portal-bug -- comment and label.",
"body": "FYI this looks like a duplicate of https://github.com/microbiomedata/nmdc-server/issues/333\r\n\r\nAdding here in case previous comments are useful - @dehays should we close 333?",
"body": "> FYI this looks like a duplicate of [microbiomedata/nmdc-server#333](https://github.com/microbiomedata/nmdc-server/issues/333)\r\n> \r\n> Adding here in case previous comments are useful - @dehays should we close 333?\r\n\r\nIt is a duplicate! Sorry about that. David and I were on a call and noticed and I should have checked the other GH issues first.  Let me know if you'd like me to close this one or 333.  ",
"body": "The solution to this and other issues of omics_processing without has_input samples is to use an agreed upon (Yuri, Lee Ann) set of instrument process datasets from EMSL as the basis of inclusion in NMDC.\r\n\r\nWhat we currently have in NMDC is based on these files that Lee Ann provided:\r\n\r\n[EMSL_FICUS_project_process_data_export](https://docs.google.com/spreadsheets/d/1VMJ_Tvld3cZYh9NJHdItVWpV0DmOUYH4)\r\n[PNNL_LCMS_Process_Metadata_EMSL_49483_Blanchard_Export](https://docs.google.com/spreadsheets/d/1lWp_n8ZUKMjEk1wybs1xlXJj0nAGwxAj)\r\n\r\nYuri indicates that these include many datasets that should NOT have been included and that the datasets listed in these files are correct:\r\n\r\n[NOM Data to Process](https://docs.google.com/spreadsheets/d/1V2f8UYmAQk5UIGfgBxkCVpeNwL7dQSJV)\r\n[GC-MS Metabolomics Experiments to Process Final](https://docs.google.com/spreadsheets/d/1VUqe_DOCQT7ZPhU565Xf7MtvZbWsT_VD)\r\n\r\nAt least for Natural Organic Matter and Metabolomics omics types.  All Lipidomics omics type datasets and should be removed.\r\n\r\nGeneral validation at the schema level would be to make has_input on omics_processing entities require a non empty value (Cannot be null and cannot be [].)\r\n\r\n*Complicating case using the EMSL dataset lists above:  they all include blank and config datasets which should be removed now and then added later once the NMDC schema can represent additional omics_processing input relationships and possibly special sample types for blanks.",
"body": "appears to have been fixed with latest changes",
"body": "@dehays and I were looking at the portal and noticed that there is a problem with displaying metabolomics samples when searching on Eoin Brodie's study.  See attached screenshot.  \r\n\r\n<img width=\"1340\" alt=\"Screen Shot 2021-05-07 at 11 16 27 AM\" src=\"https://user-images.githubusercontent.com/79225425/117493435-d5c56180-af27-11eb-8ba7-1bc9304ae653.png\">\r\n",
"body": "See #338 ",
"body": "Done. See https://github.com/microbiomedata/nmdc-metadata/pull/339",
"body": "In the Pipefile, the biolink requirement needs to be changed to linkml.\r\n\r\nNote: also need to regenerate requirement.txt and requirement-dev.txt files.",
"body": "This is an upstream problem in GOLD, so it needs discussion to assign to the right person to fix GOLD and/or ingest from GOLD.",
"body": "@pvangay There are three different issues in the feedback from Reb on the Wrighton study.\r\n\r\n1) Sample naming - Currently the sample names in most cases are those from the GOLD biosample records.  Those are not 'proposal' names (which are less consistent and can be even longer) but follow GOLD's sample naming scheme - which is study name + local sample name (i.e. the name provided by the researcher.). For the Wrighton samples this results in names like: \"Deep subsurface shale carbon reservoir microbial communities from Ohio, USA - Utica-2 Time Series 2014_10_10\"\r\n\r\nThis issue is very similar to the one Eoin reported - that the differentiating part of the sample name coming at the end can cause the distinguishing part of the name hidden in the display.  microbiomedata/nmdc-metadata#340. I don't have a good suggestion for how to change the GOLD ETL , or in general, how to deal with problems with sample names in a sample metadata source.\r\n\r\n2) Correct environments for samples - both GOLD 5-tuple and MIxS/EnvO triad.  This is a curation issue.  But I don't know how GOLD could be responsible for knowing about semantic naming schemes used by researchers.  GOLD does have an SOP for updating metadata.  The NMDC question here is whether or not NMDC will directly curate records that originated in GOLD or depend on curation happening in GOLD and then being updated in NMDC with future GOLD ETL runs.\r\n\r\n3) Each of the samples for the Wrighton study that are visible on the portal - are inputs for metagenome sequencing projects.  We removed both the sequencing projects and samples for isolate genomes.  So what about the 6 here that Reb says are were used for isolate genome sequencing?  Looking at: 'Deep subsurface shale carbon reservoir microbial communities from Ohio, USA - Methanotroph_Enrichment_5' aka gold:Gb0119281 which is the input of https://gold.jgi.doe.gov/project?id=Gp0119871  . This is a metagenome sequencing project not an isolate genome.\r\n\r\nThere were 40 isolate samples - sequencing projects as part of this study, but we already removed them.  I believe the 6 samples above are metagenome samples.\r\n\r\n",
"body": "> 1. Sample naming\r\n\r\nI wonder if this could be resolved by using sample_name - which I believe is in MIxS v6 right?\r\n\r\n> 2. Editing metadata from GOLD\r\n\r\nI think it's important to percolate edits/corrections back to GOLD - but I also think it's important to develop our own process for updates to metadata as we will not be expecting all of our datasets to come through GOLD/IMG.\r\n\r\n> 3. 6 samples\r\n\r\nSo I think Reb's main concern was that these samples were labeled with the study name that indicates the samples were from the deep subsurface shale carbon reservoir -- when instead, these samples represent a variety of things. Reb used _isolates_ when referring to the viral samples - and based on my limited understanding of viral inductions (and a quick chat with @elishawc - thx!), they likely isolated bacteria first, then induced the viruses with a chemical, then sequenced the resulting sample. I can confirm this with Reb when she returns to the office in 2 weeks.\r\n\r\n**Additional context about the 6 samples from our meeting notes:**\r\nThey discovered that viruses were important in shale and wanted to do isolations - so they induced viruses because they also wanted to analyze the metabolites from the viral lysis. These samples are technically deep subsurface samples, but Reb said that they represent isolates from the well.\r\n- Deep subsurface shale carbon reservoir viral communities from Ohio, USA - WG14 viral induction ssDNA\r\n- Deep subsurface shale carbon reservoir microbial communities from Ohio, USA - WG8 viral induction\r\n- Deep subsurface shale carbon reservoir microbial communities from Ohio, USA - Halanaerobium induction\r\n\r\nThey enriched a soil sample from Old Woman Creek (wetland in Ohio) and added methylated compounds. It was added to the project because they were interested in comparing methanogens and methanotrophs from other environments with the carbon shale samples. Reb says these should be removed for now to avoid confusion because they are not samples from shale carbon.\r\n- Deep subsurface shale carbon reservoir microbial communities from Ohio, USA - Methanogen_OWC (+ methanogen enrichment)\r\n- Deep subsurface shale carbon reservoir microbial communities from Ohio, USA - Methanotroph_Enrichment_5\r\n\r\nThey found that fracking appeared to pump in cellulose so they collected a moose gut sample (with is expected to contain a lot of cellulose based on their diets) so that they could compare the ecosystems. Similar to the methano(gen/troph) samples, Reb suggested removing for now to avoid confusion because they are not samples from shale carbon.\r\n- Deep subsurface shale carbon reservoir microbial communities from Ohio, USA - LMS_cellobiose_enrichment\r\n\r\n**So in summary...**\r\nThese kinds of samples are important use cases for thinking through how to represent samples that have been manipulated in the lab. In addition, once we correct the metadata, these samples could be really valuable for showcasing the portal features (i.e. cellulose degradation across environments). So I think there just needs to be a decision on how to handle these types of samples - I would argue that we shouldn't just leave them in as-is.",
"body": "@dehays sorry for stating the 6 samples weren't microbiome samples - I think that probably caused a lot of confusion!",
"body": "@dehays I was discussing this with @pvangay  and we added it to the sprint to see if it can be worked on since it will help with some of the other portal related fixes.  Let us know if it shouldn't be in this sprint or if it should be assigned to someone else.  ",
"body": "The decision here is to either 1) make the changes in GOLD and then propagate to NMDC or 2) make the change in NMDC and alert GOLD to update biosample records there.",
"body": "@mslarae13 please add a link to wrighton's latest metadata spreadsheet as some of these details may already be captured there",
"body": "\r\nWrighton\r\nCorrect sheet: https://drive.google.com/file/d/1YiDWPxAEhpctuxuzsqBrWu2MmV_gyt83/view?usp=sharing\r\nFields to correct/add\r\n--sample_collection_site (column J), not all samples are HRC-FS. How should we handle these? Exclude until we have clarification? Update relevant/correct samples?\r\nUpdated columns: N, P, U-Y, AB-AJ, AK, AL, AR, AT, BI,\r\nNote: No JGI -> EMSL sample mapping has been accomplished. Waiting to hear back from Reb.\r\nNote: Many of the fields listed in updated columns are updated for some samples but list NA/ not measured for other samples. Need to determine how to update this.\r\n-- See https://docs.google.com/document/d/1B1YZK2-0mBbTuRwTEJH9qkWvNerGeHvH3gbmgQML13E/edit?usp=sharing\r\n-- Waiting for Reb to respond with EMSL project #, associated sample analyses, and a sample list/map. Once we receive that, we can follow up on the questions in this document.\r\n",
"body": "@pvangay said this should move to the July sprint so moving this one.",
"body": "Looks like almost everything was addressed, except the moose gut sample.",
"body": "Moose gut was updated post ETL for the July release (https://github.com/microbiomedata/nmdc-runtime/issues/11#issuecomment-876853472) and will get further corrected with more accurate values in GOLD. This will get updated in future data dumps.",
"body": "@mslarae13 and I met with Reb Daly from the Wrighton group today to review their data in the portal.\r\n\r\n### **Sample names need to be renamed to something that is not the Proposal name.** \r\nSuggest using IDs of some sort. This is misleading because not all samples are \"deep subsurface shale\", which just happens to be the name of the proposal.\r\n\r\n### Can we reclassify these samples into their correct environments (GOLD and EnvO)? \r\nProbably need to make sure these are corrected upstream as well (GOLD). Sample names with:\r\n- LW = Fresh Water (from a lake nearby)\r\n- HT = Holding Tank (Fresh water that's in a holding tank before being mixed with chemicals)\r\n- FC or FF = Fresh water mixed with fracking chemicals (this get pumped into the shale for fracking)\r\n- All other samples are time series samples of the fluid post-fracking\r\n\r\n### **Remove all of these samples, as they're isolates that were used in the study but not microbiome samples**\r\n- Deep subsurface shale carbon reservoir microbial communities from Ohio, USA - WG8 viral induction\r\n- Deep subsurface shale carbon reservoir microbial communities from Ohio, USA - Halanaerobium induction\r\n- Deep subsurface shale carbon reservoir microbial communities from Ohio, USA - Methanogen_OWC (+ methanogen enrichment)\r\n- Deep subsurface shale carbon reservoir microbial communities from Ohio, USA - Methanotroph_Enrichment_5\r\n- Deep subsurface shale carbon reservoir viral communities from Ohio, USA - WG14 viral induction ssDNA\r\n- Deep subsurface shale carbon reservoir microbial communities from Ohio, USA - LMS_cellobiose_enrichment\r\n\r\nTagging @dehays as this is related to finding a way to edit NMDC metadata - please reference the relevant issues this should be associated with. Should this issue also be assigned to you?\r\n\r\nAdding as listeners: @kfagnan @dwinston \r\n\r\n\r\n",
"body": "We do have that citation in the [supplementary file](https://github.com/microbiomedata/nmdc-server/blob/master/nmdc_server/ingest/study_additional.json#L120).  The primary DOI coming from the data pipeline is the one that is shown `10.25585/1488224`.\r\n\r\nThe supplementary DOI's are being returned by the API, and I thought at one point they were being displayed.  @subdavis Do you know if this was intentionally changed or is it a bug?\r\n\r\nIn any case, if we want the primary DOI changed, then that will need to happen upstream.  Otherwise, I think we just need to fix the issue on the web client.",
"body": "@pvangay  Yes, this sort of edit should happen upstream.  That topic of study attributes is related to the discussion in microbiomedata/nmdc-schema#41. I do not believe Jon / search application, should have responsibility to merge from multiple sources of study attributes.\r\n\r\nThe issue is then how to add/update these attributes.  They are not available from the original study source (GOLD) so the place to add/update would be in the metadata store from which Jon draws metadata for his relational tables behind search.  That'd mean editing in Mongo or TerminusDB - there is not currently any curation UI.",
"body": "via microbiomedata/nmdc-runtime@e206ff7f50f2300c5dbd6dfea520f221da73da3b",
"body": "Update the dataset citation on [Eoin's landing page](https://data.microbiomedata.org/details/study/gold:Gs0135149) to: \r\nSorensen, P., Brodie, E., Beller, H., Wang, S., Bill, M., & Bouskill, N. (2019). Sample Collection Metadata for Soil Cores from the East River Watershed, Colorado collected in 2017 [Data set]. ESS-DIVE. https://doi.org/10.21952/WTR/1573029\r\n\r\n@dehays should this edit be done further upstream as well? FYI, this was a request from Joan at ESS DIVE (since this is an ESS DIVE dataset citation)",
"body": "Note: \r\n- SFA and NCBI template being reconciled & combined\r\n- MIxS terms needed for soil packages that can be settled using plant_assoc terms\r\n-",
"body": "GSC ticket: https://github.com/GenomicsStandardsConsortium/mixs/issues/133\r\n",
"body": "Updated version of template : https://docs.google.com/spreadsheets/d/1iuCyMjef97wl_Lsu1B9R4zAqrR7gfwftNKvx8LZnbW4/edit?usp=sharing\r\n\r\n@jagadishcs : Do you have GOLD paths for sediment, plant, and water?\r\n\r\nNote: I'm still working on getting the other controlled terms Jagadish made implemented \r\n",
"body": "@mslarae13 \r\nPlease refer to the [mapping](https://docs.google.com/spreadsheets/d/1J7cwpwOgxCXD8F_rzbvVoETrNIoaHwvAZN-Ki8i3Ku8/edit#gid=1487521647) of GOLD ecosystem classification paths with MIxS environmental packages. This file contains all of the GOLD paths (as on March 18, 2021) mapped to MIxS packages. ",
"body": "Thanks @jagadishcs ! Next question, when you developed the drop down lists for the FICUS project metadata template for soil fao_class, tillage, horizon, ect... did you just use the MIxS terms  that were listed as options? Or did you curate anything yourself?\r\n\r\n",
"body": "@mslarae13 \r\nFor all of the MIxS CV fields, I just used the terms that are provided in the specific MIxS packages & specific fields. ",
"body": "Version update:\r\nNMDC: https://docs.google.com/spreadsheets/d/1Glb9pWmV5H9UrI_oeC-eMxvzzmZKGALjh2FL-uRWI_o/edit?usp=sharing\r\n\r\n\r\nNCBI-NMDC:  https://docs.google.com/spreadsheets/d/1EErq7CmBJ7779qAt8ysnN_zpOgxxvwPxEEsSXDXCuOw/edit?usp=sharing\r\n\r\n",
"body": "@mslarae13 thank you for putting in the links.  Can this issue be closed?  ",
"body": "Template layout confirmed. Soil complete.\r\nThe \"feed back\" part of this task will start soon. I am going to close this one and create 2 new tasks in the June sprint.",
"body": "This issue the the next step in the development of metadata templates for new sample environments.",
"body": "Moved to the June sprint per @mslarae13 on Slack.  Also removed assignees @corilo and @pdpiehowski.  Once Montana is ready for them she can assign the issue to them when she's done with her part.  ",
"body": "I am moving this out of June Sprint. We have to get the metadata and information first. Actually processing the other project data will be later. \r\n\r\nI will move the FICUS project metadata into this sprint.",
"body": "This issue is for processing the metadata for FICUS studies",
"body": "Update:\r\nColwell:  Responded with metadata, but no sample map\r\nHess: Will follow up early June\r\nNeumann: Sent response, on Montana's to do list to follow up\r\n\r\nNo one else has responded. June 17th I'll send a follow up email stating we're planning to complete these projects the end of June, and if they're interested in being part of the next set of data searchable via NMDC, we will need the metadata and sample mapping information before the end of the month.\r\n",
"body": "Update\r\n\r\n1. Bowen: 05/27: Followed up, still working\r\n\r\n2. Brodie: updates needed see: \r\n[https://github.com/microbiomedata/nmdc-metadata/issues/355](url)\r\n[https://github.com/microbiomedata/nmdc-metadata/issues/356](url)\r\n[https://github.com/microbiomedata/nmdc-metadata/issues/327](url)\r\n[https://github.com/microbiomedata/nmdc-metadata/issues/340](url)\r\n[https://github.com/microbiomedata/nmdc-metadata/issues/341](url)\r\n & notes from meeting [https://docs.google.com/document/d/1BNMvESw4Mm-09w_kKI6S28CnaIBrHgO52USne90bKDo/edit?usp=sharing](url)\r\n\r\n3. Stegen: updates needed see\r\n[https://github.com/microbiomedata/nmdc-metadata/issues/352](url)\r\n[https://github.com/microbiomedata/nmdc-metadata/issues/351](url)\r\n& notes from meeting: [https://docs.google.com/document/d/1RuUQJq0HRs_hbypcd-Su3v90wTevzrdcfi7xrQScdgM/edit?usp=sharing](url)\r\n\r\n4. Wrighton: Updates to moose sample needed\r\n\r\n5. Colwell: User sent back metadata, but no sample mapping. Did not respond to 05/18 follow up\r\n\r\n6. Hess: 04/23: Requested to send data early June, will follow up.\r\n\r\n7. Neumann: received metadata info, need to follow up with more information once samples are better sorted\r\n\r\n8. Crump: No response to any emails. (Drop)\r\n\r\n9. Blanchard: No response to any emails (Dropped)\r\n\r\n10. Rich & Firestone: Dropped per Emiley's request",
"body": "Communications & decisions complete closing this, Creating issues for Bowen, Hess, and Neumann",
"body": "Update:\r\n\r\n1. Bowen: 07/29- I sent a follow up asking for the metadata\r\n2. Colwell: Sent followup asking for sample ID map on 04/26, 05/10, and 05/18. No response to any messages. @emileyfadrosh  should I poke again? Or drop it?\r\n3. Hess: 07/01- Sent follow up asking for metadata. I sent another on 07/29\r\n4. Neumann: Transposed metadata to NMDC template, identified sample IDs and like samples between JGI and EMSL. Sent template on 07/29 asking for more detail.\r\n\r\nDropped\r\nCrump: No response to any emails.\r\nBlanchard: No response to any emails.\r\nRich & Firestone: Dropped per Emiley's request",
"body": "Collecting any additional metadata before wrapping this up.  ",
"body": "David mentioned he'd follow up with Stan on this at the implementation leads meeting so adding them to this issue.",
"body": "@dehays @mslarae13 @StantonMartin any updates on this issue?  Can this issue be closed? ",
"body": "This was blocked in May by changes to NMDC schema and availability of additional sample metadata. Moving to June.",
"body": "Bioscales study is in the data portal. Closing this old issue from 2021.\r\n\r\nBacklog cleanup 12-2023",
"body": "This issue is to track the additional samples for Bioscales and getting that metadata into the portal",
"body": "This was on the list from the June sprint planning meeting so I will move this to the June sprint.  @dehays I'll leave it assigned to you but let me know if it should be re-assigned.  The other person noted to work on this is @dwinston ",
"body": "@dehays @emileyfadrosh @kfagnan this is an issue that we have planned for July but let me know if it should be assigned to someone else.  ",
"body": "Moving to August sprint per @dehays ",
"body": "@emileyfadrosh @dehays can this be combined with #378 ? Just want to make sure you're not both working on the same thing. ",
"body": "Hm, yes, this looks like a duplicate. @dehays could you please clarify what work you are doing related to this and the other ticket? ",
"body": "@emileyfadrosh @ssarrafan Agreed that this is a duplicate of #373 \r\n\r\nEmiley - I would like to capture the requirements/features for the first iteration of a metadata submission application.  This was the gist of the discussion from Wednesday's metadata meeting - and that discussion did lead to defining some requirements.  (First iteration to include wizard to produce custom study specific Google sheets, etc.)  Agreeing on the first version features is needed for Faiza to begin UI design work.\r\n\r\nAlso want to identify dependencies related to metadata submission; i.e. need to have a persistent NMDC data store for study and biosample records that are created during metadata submission.",
"body": "Closing this as it's a duplicate of #378 ",
"body": "This issue is to track the requirements for metadata submission process and/or portal for NMDC.  \r\n\r\nThere are some requirements from 2020 to start, the goal is to revise and iterate on those and get sign-off from NMDC leads to move forward.  \r\n\r\nRelated to milestone 1.5",
"body": "works. thanks!",
"body": "@dwinston I added the `EMSL_Hess_Stegen_Blanchard_DatasetToMetagenomeMapping.tsv` data to the repo, and updated the `read_excel` method for pandas.\r\n\r\nI can run `make build-merged-db` on my machine. Need to try yours :)",
"body": "Breaking 1.3 down and providing a unifying framework for integrating the different pieces. These are not all interdependent but could be done sequentially, although the base framework should be in place first.\r\n\r\n - [x] Write enrichment framework python library. The core framework will not perform any enrichment, it will provide the backbone from which individual routines can be implemented. @wdduncan\r\n - [ ] add NER routine for suggesting biome terms based on package + sample description, limited to soil/sediment package for first pass @turbomam \r\n - [ ] ditto for material and feature\r\n - [ ] ditto for fao_soil_class or other mixs controlled field of relevance to NMDC\r\n - [ ] plug in @StantonMartin's code for ORNL Identify elevation layer (we can choose another quantitive layer, this seems easy one)\r\n - [ ] plug in @StantonMartin's code for ORNL soil type layer (we can choose another qualitative layer, this seems easy one)\r\n - [ ] Wrap python library in flask or fastapi, exposing an openAPI endpoint (do we have NMDC API standards?)\r\n - [ ] provide demonstrator of how this can be integrated e.g. with a google sheet or gold database\r\n\r\nDifferences from 1.3 workplan: the underlying lib we use for NER is no longer SciGraph, Mark is using a mixture of services and OGER\r\n\r\nDeferred from workplan/TBD: \"metabolite sample descriptions\" \r\n\r\nThe python framework will take as input a non-necessarily-structured NMDC sample object as a simple dict, e.g.\r\n\r\n```yaml\r\n      id: \"gold:Gb0108335\"\r\n      name: \"Thawing permafrost microbial communities from the Arctic, studying carbon transformations - Permafrost 712P3D\"\r\n      lat_lon: \r\n        has_raw_value: \"68.3534 19.0472\"\r\n        latitude: 68.3534\r\n        longitude: 19.0472\r\n        type: \"nmdc:GeolocationValue\"\r\n      collection_date: \r\n        has_raw_value: \"2012-07-20\"\r\n      ecosystem: \r\n        has_raw_value: \"Environmental\"\r\n      ecosystem_category: \r\n        has_raw_value: \"Terrestrial\"\r\n      ecosystem_type: \r\n        has_raw_value: \"Soil\"\r\n      ecosystem_subtype: \r\n        has_raw_value: \"Wetlands\"\r\n      specific_ecosystem: \r\n        has_raw_value: \"Permafrost\"\r\n      depth: \r\n        has_raw_value: \"0.0\"\r\n      ncbi_taxonomy_name: \r\n        has_raw_value: \"permafrost metagenome\"\r\n      sample_collection_site: \r\n        has_raw_value: \"Palsa\"\r\n```\r\n\r\nand then suggest missing values, enhancements, potential problems. We will have a simple QC schema for this. Payload could be something like:\r\n\r\n```yaml\r\nannotation_sufficiency: 0.43\r\ndescription: <narrative text summarizing sufficiency metrics>\r\nsuggestions:\r\n  - type: location_inference\r\n     sample_ids: [gold:Gb0108335]\r\n     field: geo_loc_name\r\n     value: Sweden: Kiruna\r\n     confidence: HIGH\r\n     was_generated_by:\r\n       <prov information about identify/wikidata API call to fetch location name from geolocation>\r\n  - type: envo_inference\r\n     sample_ids: [gold:Gb0108335]\r\n     field: env_broad_scale\r\n     value: \r\n       term:\r\n          id: ENVO:00000446\r\n          name: terrestrial biome\r\n     confidence: MEDIUM\r\n     was_generated_by:\r\n       <prov information about NER API call to infer ENVO biome from text>\r\n  - ...\r\nproblems:\r\n  - type: MISSING_UNIT\r\n     sample_ids: [gold:Gb0108335]\r\n     field: depth\r\n     value: \"0.0\"\r\n     inferred_value:\r\n        has_raw_value: \"0.0 m\"\r\n        unit: m\r\n        value: 0.0\r\n```\r\n\r\n",
"body": "> Wrap python library in flask or fastapi, exposing an openAPI endpoint (do we have NMDC API standards?)\r\n\r\n@cmungall what do you mean by \"NMDC API standards\"?\r\n\r\nI am developing (with Bin, Shane, and Yuri) an OpenAPI-compliant API (via FastAPI) for workflow automation / data management at [microbiomedata/nmdc-runtime](https://github.com/microbiomedata/nmdc-runtime/tree/03ab944e840acd19522218e5c6ee45b1ae6587be/nmdc_runtime/api). We can extend this API to include a metadata enrichment endpoint.",
"body": "Thanks @cmungall. I'l move this to June.  ",
"body": "Discussed with @emileyfadrosh and @turbomam and assigning to Mark to do some pieces of this. Will follow up with Chris on outstanding items that Mark won't be doing.  Adding this to the July sprint.",
"body": "I am **currently** contributing the following capabilities to the nmdc sape annotator, based on receiving a single request through the API (as opposed to operating in bulk over the INSDC BioSample database) Each receives a value from the named fields, expecting that they may be very messy, and returning the _de facto_ mixs format or `None` if normalization is not possible\r\n\r\n- `env_package`\r\n- `env_broad_scale`\r\n- `env_local_scale`\r\n- `env_medium`\r\n\r\nI haven't started parsing any other inputs, like full text descriptions or other optional metadata like FAO soil class.\r\n\r\nThe resource I am most actively using is local parsing of OBO foundry JSON files (like EnvO). I have code that could also use a local rdftab ontology database, the OLS lookup service, or the BioPOrtal lookup service. (I'm not currently using OGER, but have in the past and could return to that, although I really doing term mapping, not NER.)\r\n\r\n",
"body": "Moving this issue to September with lower priority based on sprint planning.  This is broken down into smaller issues noted above.  ",
"body": "@cmungall and @turbomam should this issue be closed, moved to the backlog or moved to the October sprint?",
"body": "The work for this issue is generally taking place in https://github.com/microbiomedata/sample-annotator. The progress has been slow, but several of us are still working on it. Move forward to October.",
"body": "> The work for this issue is generally taking place in https://github.com/microbiomedata/sample-annotator. The progress has been slow, but several of us are still working on it. Move forward to October.\r\n\r\nHi @turbomam \r\nShould I keep this issue open?  Move it to November?  Or close this as it's taking place in the sample annotator repo?",
"body": "- \"enrichment framework python library\" has been created in https://github.com/microbiomedata/sample-annotator\r\n-  lightwieght \"NER routine for suggesting the following: continue into November. I think those are inclusive of https://github.com/microbiomedata/nmdc-schema/issues/113 \r\n    - biome terms based on package + sample description, limited to soil/sediment package for first pass\r\n    - material and feature\r\n    - fao_soil_class or other mixs controlled field of relevance to NMDC\r\n- ORNL Identify elevation and soil type: I have been to one meeting in the past week that addressed that. The effort continues, but I'm not working on it.\r\n- API endpoint: I'm not working on this. I don't think there has been a lot of progress. It think it should be continued into November. \r\n- \"demonstrator of how this can be integrated e.g. with a google sheet or gold database\": I don't know what that is.\r\n",
"body": "> * \"enrichment framework python library\" has been created in https://github.com/microbiomedata/sample-annotator\r\n> * lightwieght \"NER routine for suggesting the following: continue into November. I think those are inclusive of [Add NER routine for suggesting biome terms based on package + sample description for fao_soil_class or other mixs controlled field of relevance to NMDC\u00a0nmdc-schema#113](https://github.com/microbiomedata/nmdc-schema/issues/113)\r\n>   \r\n>   * biome terms based on package + sample description, limited to soil/sediment package for first pass\r\n>   * material and feature\r\n>   * fao_soil_class or other mixs controlled field of relevance to NMDC\r\n> * ORNL Identify elevation and soil type: I have been to one meeting in the past week that addressed that. The effort continues, but I'm not working on it.\r\n> * API endpoint: I'm not working on this. I don't think there has been a lot of progress. It think it should be continued into November.\r\n> * \"demonstrator of how this can be integrated e.g. with a google sheet or gold database\": I don't know what that is.\r\n\r\nThank you @turbomam \r\nIf I should re-assign this to someone else let me know\r\nI have moved it to the November sprint as you suggested",
"body": "@cmungall I am assigning this issue back to you.  We discussed this at the mid-sprint check in and Mark felt like it should be assigned to someone else as he is not in charge of all the pieces. If you'd like me to break this up into multiple new issues and close it let me know.  ",
"body": "Checked with @cmungall and he said this issue will be broken down into multiple issues. Moving to December so we can work on breaking this down.  ",
"body": "Removing from sprint and adding backlog label.  ",
"body": "This is a milestone from the pilot so I am closing this issue from 2021. \r\n@cmungall let me know if we need to open this back up or create other issues to address metadata enrichment. \r\nFYI @emileyfadrosh \r\n\r\n\r\nBacklog cleanup 12-2023",
"body": "Chris and/or team to review milestone 1.4 and finalize the scope and strategy around metadata enrichment.  Additional tasks can be created based on the strategy and scope.  ",
"body": "@mslarae13 you mentioned you wanted this in the April sprint since you were working on it. Can this issue be closed?  Or would you like me to move it to the May sprint?  ",
"body": "It's still active. I think we should move it to May. And provided users are quick to respond it should be finished in May.",
"body": "Next steps and follow ups completed. Waiting on response from a few PIs. see: https://github.com/microbiomedata/nmdc-metadata/issues/334\r\n",
"body": "This issue is to document the work that Montana has been doing in April.  ",
"body": "I get a\r\n```python\r\nTypeError: read_excel() got an unexpected keyword argument 'ignore_index'\r\n```\r\nFrom [this call site](https://github.com/microbiomedata/nmdc-metadata/blob/60898d379ad60d3fd2a1fca374cf417cec48974f/metadata-translation/src/bin/lib/nmdc_dataframes.py#L111).\r\n\r\nIt looks like this `pandas` function accepted and ignored unknown keyword arguments until version `1.1.x`, which was released on 2020-07-28.\r\n\r\nI'm able to get past this error if I `pip install \"pandas<1.1\"`. However, I then hit a\r\n```python\r\nFileNotFoundError: [Errno 2] File ../data/EMSL_Hess_Stegen_Blanchard_DatasetToMetagenomeMapping.tsv does not exist: '../data/EMSL_Hess_Stegen_Blanchard_DatasetToMetagenomeMapping.tsv'\r\n```\r\n, which seems to be an independent error.\r\n\r\nThis impacts #316.\r\n",
"body": "Thanks for pointing this out @pvangay.  If the data makes its way into GOLD, I can easily rerun my ETL or perhaps @dwinston can do an update? I don't know how difficult it would be to update the GOLD data and produce a new GOLD dump. Perhaps @jagadishcs or  @TBKReddy can provide some insights here.",
"body": "@pvangay, there is no artifact or limitation as such in GOLD that limits lat/long to four places after decimal. This is how the data arrived/submitted to GOLD.  \r\n\r\nYes we can update these values in GOLD now. There is already a process under way by NMDC to reach out to the PIs to seek additional metadata and get existing metadata updated. These lat/long values can be updated as part of that and then the updated values can make into the NMDC either by a new dump or via targeted updates. @jagadishcs include these updates along with any other metadata updates you get from the PI and then we can update. ",
"body": "Thanks for clarifying @TBKReddy. \r\n\r\nDoes it make more sense to update those values in GOLD, then have NMDC pull from GOLD? Or just update in both locations? I don't know the answer to this and hope those watching this issue will decide. @mslarae13 will let Eoin and his group know about the updated values from ESS DIVE when ready. Thanks all.",
"body": "@wdduncan @TBKReddy are there any encoding issues we may need to be careful about in GOLD or in the NMDC ETL? \r\n\r\nI notice, for instance that the NMDC schema lat/lon numeric properties both have a range of \"decimal degree\", which is [rightly identified](https://github.com/microbiomedata/nmdc-schema/blob/5a5e52f9d7198fb10f1af77a2487d9d966cbd636/src/schema/core.yaml#L53) as the `xsd:decimal` type for an RDF interpretation, but worryingly identified as a `float` type for e.g. Python use. IEEE 754 floating-point arithmetic may not accurately preserve the nine significant figures that @pvangay has observed. So we need to ensure that these fields are encoded as native decimal types (e.g. `decimal.Decimal` in python), or as string literals and only coerced to numeric forms during processing steps.\r\n",
"body": "@pvangay we will update these values in GOLD and then NMDC will pull these updates during the next data dump. \r\n\r\n@jagadishcs will be checking with the PIs about some other metadata. I think they indicated updates to sample collection date. All these will be updated together in GOLD.  \r\n",
"body": "@TBKReddy @pvangay  \r\nI just want to confirm before I email Eoin. We are updateding the lat_long in GOLD, which will then by proxy update the information in the NMDC. And we're doing this to reflect the more accurate lat_long provided to ESS-Dive. \r\n\r\nCorrect? ",
"body": "We are holding off on sending an email. Elisha is coordinating with each of the 3 PIs from the GSP push to establish their data landing pages. At this meeting we will slate some time to confirm sample metadata for all 3 projects & inquire about Brodie depths & lat-long.",
"body": "Meeting update\r\n\r\n1. Eoin & team are good with us updating GOLD & NMDC with Lat_Lon to match their IGSNs with more decimal places.\r\n2. The correct depth is referring to the units. The header said meters. But their depth is in cm. .. this also needs to allow for a range value. (this is a larger issue to address)\r\n\r\nNot sure what the remaining blocker is but we have answers to move forward!\r\n ",
"body": "Send us the original excel with these updates, so that we can make these updates in GOLD. \r\n\r\nDepth range is not a problem in GOLD, because we already supporting range. For example, the biosample came up in your discussions with Eoin (https://github.com/microbiomedata/nmdc-metadata/issues/355) already in GOLD with a range. Ex: https://gold.jgi.doe.gov/biosample?id=Gb0191689",
"body": "\r\n@pvangay @dehays @jagadishcs \r\n\r\nBrodie\r\n- Correct sheet: https://drive.google.com/file/d/1aRJhuTX7bxf1LRH8F7qK5jYpoca7-kdQ/view?usp=sharing\r\n- Fields to correct/add\r\n- -- Depth units should be cm, not m.\r\n- -- Depth range, not single digit (https://github.com/microbiomedata/nmdc-metadata/issues/355)\r\n- -- Latitude & Longitude updated to match IGSNs\r\n- -- IGSN was added, can this be included?\r\n- -- Ecosystem subtype (Column N), Specific ecosystem (Column O), Habitat (Column P) were updated.\r\n- -- PI added Elevation\r\n- Note: Matching IGSNs or ParentSample IDs indicates the same JGI and EMSL sample. Metadata is the same across these matching samples, even though it's not repeated in the \"EMSL\" row\r\n- I don't believe there are any additional questions about the SAMPLE METADATA. @jagadishcs  can you confirm?\r\n- There's some sorting to be done with the FTICR / Organic Matter data files. @corilo and I are working on that.\r\n\r\n",
"body": "Updating lat/long from Brodie sample information has been applied in GOLD and reflected in GOLD DB export",
"body": "Latitude and longitude for the Brodie dataset in the NMDC has limited significant digits (4 places after the decimal). I found the metadata for these samples from ESS DIVE ([WatershedSFA_SoilCores_IGSN_Metadata.xls](https://github.com/microbiomedata/nmdc-metadata/files/6368141/WatershedSFA_SoilCores_IGSN_Metadata.xls)) which show the lat/lon with 9 places after the decimal. This is likely an artifact of GOLD - as the lat/lon values were prepopulated from GOLD (and not provided directly by Eoin's team). \r\n\r\n**Why does this matter?** Brodie's samples are collected from different sites, and while they may vary by only 10s of meters, it's important to capture so that we can properly showcase his data on the portal (i.e. map). Right now they show up as being collected from a single location.\r\n\r\nI don't know what the process is for getting these values updated, but will assign those that may need to be involved at some point. We may need to examine the lat/lon for the other 2 (and new) datasets as well to make sure lat/long values aren't rounded/truncated from recorded measurements.\r\n\r\n",
"body": "change biolinkml to linkml",
"body": "Hi @jagadishcs, \r\nI've added this issue to the April sprint and Sprint 1 milestone.  ",
"body": "@jagadishcs is there any update on this issue?  Can it be moved to \"in progress\"?  ",
"body": "This is in progress.  This week's A1 meeting slot was used to plan for addressing subsetting EnvO terms by MIxS package and next week's 4/28 meeting is dedicated to @jagadishcs @cmungall @wdduncan and @elishawc  doing this for the soil package.",
"body": "We need to close this issue, and break it up into separate issues for each mixs package.  \r\nEach package will be addressed in the May sprint.",
"body": "@elishawc @dehays @ssarrafan @TBKReddy\r\n\r\nMapping of EnvO terms with specific MIxS environmental packages, so that subset of EnvO terms can be used as CV terms for NMDC by MIxS environmental packages.",
"body": "Fixes #323 ",
"body": "",
"body": "The nmdc-schema is now a pip package. \r\n\r\nNeed to test/run the GOLD etl pipeline using the nmdc-schema package.\r\n",
"body": "Can you please file ticket on the MIxS tracker: https://github.com/GenomicsStandardsConsortium/mixs/issues",
"body": "Done.\r\n\r\nhttps://github.com/GenomicsStandardsConsortium/mixs/issues/122\r\n\r\nClosing",
"body": "The initial Bioscales FAIR data mapping included the parameter nitro as it's MixS term.  This would not validate against the schema because it is not included. Subsequently the Bio Scales team noted the\r\ntot_nitro_content parameter in the schema and changed its mapping.  So there is no  current issue.  Question for NMDC, should the schema include the term nitro as well as tot_nitro_content since they are both in MixS?  They are defined almost synonymously, but the tot_nitro_content term allows for more units:\r\n \r\ntot_nitro_content  units: microgram per liter, micromole per liter, milligram per liter\r\n\r\nnitro  units:  micromole per liter",
"body": "this is done",
"body": "`biolinkml` has moved to `linkml`. Need to change this dependency for generating artifacts.\r\n\r\ncc @cmungall ",
"body": "Apache-2.0 in general (for built-in contributor agreement), to cover software source and objects. CC0-1.0 available for schema content.\r\n\r\nAlso mentions existing policy that data contributions are licensed as CC-BY-4.0, and links to data contributor agreement.\r\n\r\nCloses #317 ",
"body": "Agreed - I think a CC license is more appropriate for the schema content - include both? I favor CC-0 for schema",
"body": "I thought @kfagnan was looking into licensing? We brought this up a while ago (sometime last year) on the weekly calls.",
"body": "Yep, thanks for surfacing this again. I actually asked Set to assign this to me as an action for this sprint. IPO has indicated we can use the Apache license. \r\n\r\nWe actually got a bit held up by one license for NMDC or different licenses for different facets of the project. We can proceed either way. However, there are some aspects of the workflows we should not distribute because the 3rd party software has restrictions. So we need to decide as a team what we want to do with that edge case (maybe just make the workflows executable in EDGE?). If we aren't redistributing the software, then we don't need to license it. ",
"body": "Whether BSD 3-clause (the standard when I was at LBL), Apache 2 (clear contributor agreement w/o additional text), etc., this repo should have a `LICENSE` to be clear about *how* it is open-source.",
"body": "I'm working on a prototype at <https://github.com/polyneme/nmdc-runtime>.\r\n\r\nIf it goes well, I can transfer repo to this org or merge functionality into nmdc-metadata repo.",
"body": "I'm setting up a demo deployment for @dehays et al. to play around with, with example dagster components (pipeline, solids, sensor) that set schema and instance data for a database. I plan for this to be live by this upcoming Wednesday 2021-04-14.",
"body": "I now have an initial demo deployed (URL in slack portal-etl channel), which is reproducible locally via docker-compose (see README of https://github.com/polyneme/nmdc-runtime).",
"body": "@jbeezley @dehays I'm drafting an API resource layout to provide indirection over dagster+terminus for data access, as we discussed. See <https://github.com/polyneme/nmdc-runtime/blob/main/docs/design/api-resource-layout.md> for the beginnings of an API surface for long-running (i.e. more than a few seconds) operations and for (JSON) document import/export on top of that. I anticipate this approach to ingress will be suitable not only for portal updates but also for workflow execution.",
"body": "update: repo has been migrated to this org, i.e. <https://github.com/microbiomedata/nmdc-runtime>.\r\n\r\nI have dagster successfully connecting to local (for development) and remote (for production) MongoDB and TerminusDB resources, so the groundwork is in place to wrap existing/modified/new data transformations in dagster decorators (python decorators, e.g. `@pipeline`) and run them with monitoring. I demoed this in brief for @dehays and @wdduncan. \r\n\r\n@wdduncan and I will work to port his GOLD ETL pipeline now that the nmdc-schema repo is stable and this repo can be reorganized/renamed (#288). @jbeezley We can also get started on an integrity-checks pipeline (#309) in this repo as well.",
"body": "update: @wdduncan's GOLD ETL pipeline is now [wrapped for dagster](https://github.com/microbiomedata/nmdc-runtime/blob/e21c011b64f946237b65b9dfa63204de5c2b025e/nmdc_runtime/solids/jgi.py#L19) in the nmdc-runtime repo.",
"body": "This issue is too large. I am closing it with the intention of creating new, more tightly scoped issues that address the subject.",
"body": "Set up a system where people other than the author of a data transformation step can execute the step.\r\n\r\ne.g. Wrap current predefined data transformations as steps in a Dagster workflow. Deploy the Dagster system, including web UI, to Spin, and give appropriate people permissions.\r\n\r\ndata setting/transformation currently done by\r\n- [x] @wdduncan \r\n- [ ] @dwinston \r\n- [ ] @jbeezley \r\n- [ ] @subdavis ",
"body": "This is a duplicate, closing.",
"body": "See this file for what should probably be standardized as part of the JSON schema:\r\n\r\nhttps://github.com/microbiomedata/nmdc-server/blob/master/nmdc_server/ingest/study_additional.json",
"body": "@dehays if we will be bringing lipidomics back online, we may not need to address this in the near term. We can wait for the data to be ready and just remove the special checks in the client at that point. Any insight here?",
"body": "@jeffbaumes AFAIK lipidomics will be back once there is a lipidomics analysis workflow.  But in general, I'd prefer the client ingest not need to do any special filtering.  The tagging discussion earlier was a bit rushed - I'd like to speak more with Donny about that with the goal being the ingest against each Mongo collection retrieve documents with a specified tag.  Seems cleaner than ' give me docs rooted in a set of studies except for omics_processing for which there are no analysis (lipidomics case)' That is too much logic in the ingest.",
"body": "Moving this to the May sprint.  Lipidomics is a specific case of a larger issue that has two parts.\r\n\r\n1) The one that I was suggesting a git tag sort of solution for is in defining sets of metadata.  So ingest could specify a tag and get a subset of metadata.  Those subsets could be defined in multiple ways a) related to some set of studies b) specific types of documents (i.e. exclude lipidomics omics_processing and analysis) and c) in the TerminusDB case a tag could indicate a time-point associated with different versions of schema compliance.\r\n\r\n2) Then the possibly trickier part is portal UI dependence - which arises in both the b and c subset types above.  Whether lipidomics omics_processing entities are ingested or not - there are UI changes associated with including / excluding a type of omics_processing like lipidomics.  Maybe discuss whether the UI can be flexible enough to deal with inclusion / exclusion of types; i.e. Lipidomics labels and counts don't display when counts == 0, etc. (Though in the case of schema change - the ingest itself would need to change.)\r\n\r\nFurther implementation and decisions in May.",
"body": "Moved this to scoping per discussion with @dehays ",
"body": "Based on the meeting today with @dehays, @emileyfadrosh, @dwinston, @wdduncan, and @jbeezley the remaining work for this sprint for this issue will be\r\n- [ ] EMSL team to draft/finalize business logic for metabolomics, metaproteomics data. Per @dehays, @corilo may have the appropriate filters already.  \r\n- [ ] JGI team to draft/finalize business logic for metagenome and metatranscriptome data. @emileyfadrosh, @dehays and @jagadishcs to work on this. \r\n- [ ] Generalized rule(s) from business logic above to be implemented by @dehays and @dwinston (might need to be pushed to the next sprint). ",
"body": "@dehays @corilo @emileyfadrosh @jagadishcs is there any update on the business logic based on the previous comment? Will this logic be done this week?  ",
"body": "Closing and removing Backlog.  @lamccue @emileyfadrosh FYI\r\nBacklog clean up 12/2023.",
"body": "Eventually this will be added back, but right now we are manually filtering. Should we filter upstream somewhere in the official metadata if it is not ready for production?",
"body": "@wdduncan Also assigning you and @jbeezley to this one. Similar question, but I don't believe we can do this check in the schema. Where should we put non-schema validation code?",
"body": "Thanks @jeffbaumes !\r\n\r\nAdding @dehays, @cmungall , and @dwinston to this tickets. This gets into larger issues ...",
"body": "> Thanks @jeffbaumes !\r\n> \r\n> Adding @dehays, @cmungall , and @dwinston to this tickets. This gets into larger issues ...\r\n\r\n@wdduncan Can the \"larger issues\" be broken down into smaller chunks?  Let me know if I should create additional GitHub issues related to this.  ",
"body": "I agree with two things @jeffbaumes is saying here:  1) Ingest into the search application should not have responsibility for dealing with referential integrity as it does now.  This should happen upstream. 2) I don't think this can be done in the schema.  The schema can require that the was_informed, has_input, had_output have values but I don't think the capability is there to guarantee the existence of the referenced entities.\r\n\r\nThat leaves this type of business logic to be applied in or around the metadata store.  If that is Mongo that means audit logic outside Mongo that checks for existence of referenced entities across the the Mongo document collections.  If that is TerminusDB then if I am understanding @dwinston correctly it is possible to apply referential integrity checking rules. ",
"body": "Moved to May sprint per Bill and added @dwinston as an assignee.  ",
"body": "Based on the meeting today with @dehays, @emileyfadrosh, @dwinston, @wdduncan, and @jbeezley I'm closing this issue.  We had the discussion to consider where to do referential integrity checks. The plan is to update the NMDC schema by adding required fields needed (will create a ticket for @wdduncan) and to apply a rule that uses the updated schema changes and applies I to the database (will create a ticket for @wdduncan and @dwinston) .  \r\n\r\nNote: Consider continuing to group schema changes into a version and update the changelog and version appropriately. May want to consider only doing this quarterly? \r\n\r\nNote: This work requires writing logic in Python. Additional help would be nice to get and a new issue will be created for @emileyfadrosh and Set to get some help for Bill and Donny.  \r\n\r\nNote: A new ticket will be created for @dwinston who said he will document and template this type of work to make it easier for others to help with these types of changes in the future.  ",
"body": "Not sure where this code should lie but it should happen before ingestion into the pilot system.",
"body": "@wdduncan I assigned you and @jbeezley to this one. When ingesting annotations, we need to make sure the schema validates only valid ids (e.g. ENVO, KEGG, etc.) and I believe some regexes on the schema would help here. Could you help us figure out where to add these?",
"body": "Thanks @jeffbaumes   \r\nCan you post some examples of the bad data? ",
"body": "I believe there was an issue where function IDs sometimes came through with prefix `KO:` and sometimes came through with prefix `KEGG_ORTHOLOGY:`. A regex in schema validation could catch things like this. Basically if any ID should match a regex we should put a regex in the schema. @jbeezley may have further thoughts here.",
"body": "Didn't see the KEGG case, but this is the same as the ENVO case in #294 - @wdduncan  The request here is to identify fields for which the raw value must conform to a regex and then do that validation.  Looks like JSON Schema can do that ( https://json-schema.org/understanding-json-schema/reference/regular_expressions.html ) but that doesn't mean that the JSON Schema that gets generated in NMDC can include that.  Ideas Bill?",
"body": "Moving to May sprint per Bill's request and adding Large size label.  \r\nComment from Bill:\r\n I need to investigate how to use regular expressions in jsonschema to validate data. So, I will give an estimate of one week, but the issue is quite open ended. The only use case of KEGG_ORTHOLOGY. I imagine there are other use cases.",
"body": "Sorry just saw this now.\r\n\r\nThere are different levels of checks\r\n\r\n 1. Is the ID prefix valid? (e.g. KEGG.KO vs KEGG.ORTHOLOG)\r\n 2. Is the local part of the ID syntactically conformant? (e.g. KEGG:K\\d+)\r\n 3. Is the ID valid and appropriate?\r\n\r\nThe first is very easy to do with using the existing `id_prefixes` annotated in the schema\r\n\r\nThe second we can do by adding additional regexes (slot_usage)\r\n\r\nThe 3rd is more difficult, a few approaches:\r\n\r\n 1. Additional code outside the schema that does lookups with public APIs to check the ID is valid and not obsolete and yields a semantically appropriate entity\r\n 2. We enumerate all valid IDs and include as an enum in the schema. Note these could be quite large, but we would generate these programmatically and include as a separate import\r\n 3. We take advantage of the ability in linkml to identify a codeset, and create this separately\r\n\r\nBut we can tackle this incrementally, start with 1 then 2",
"body": "@cmungall and @wdduncan what would you like to do with this issue?  Can we close it as the considering is done?  And open a new ticket for June to start implementing per Chris's comment?  ",
"body": "Let's make one ticket for 1+2, another for 3",
"body": "Created two GH issues for June, assigned to @cmungall @wdduncan and @turbomam.  Please remove wrong assignments if any or let me know.  \r\n\r\nhttps://github.com/microbiomedata/nmdc-metadata/issues/360\r\nhttps://github.com/microbiomedata/nmdc-metadata/issues/362\r\n\r\nClosing this issue.  \r\n",
"body": "Hello, all. You may have seen that this was moved to https://github.com/microbiomedata/nmdc-schema/issues/69\r\n\r\n@jeffbaumes , I don't think you and I have had much on-on-one conversation. I joined @cmungall's group mid March.\r\n\r\nCan someone share some JSON objects that contain some of the error patterns mentioned in this original issue post?\r\n\r\nI have reviewed the declared orthology prefixes, and I have added acceptable patterns for the local part of their IDs in \r\n- https://github.com/microbiomedata/nmdc-schema/blob/issue-62/src/schema/annotation.yaml\r\n\r\nwhich corresponds to \r\n- https://github.com/microbiomedata/nmdc-schema/pull/70\r\n\r\nI can continue to add local portion patterns for other classes in `annotation.yaml` (or even other files) based on those that have `id_prefixes` slots. See \r\n- https://github.com/microbiomedata/nmdc-schema/blob/issue-69/util/discover_local_pattern/Find%20opportunities%20for%20ID%20validation.ipynb \r\n\r\n",
"body": "There was an instance where two forms of KEGG id prefixes got into the pilot metadata so we want to guard against things like that in the future.",
"body": "In `nmdc_data_source.yaml`,  for the biosample specification change has_numeric_value to has_raw_value:\r\n```\r\ncollection_date:\r\n          has_raw_value: collection_date # mixs:collection_date\r\n```\r\nFixes #305 ",
"body": "In `nmdc_data_source.yaml`, the biosample `collection_date` is specified as:\r\n```\r\ncollection_date:\r\n          has_numeric_value: collection_date # mixs:collection_date\r\n```\r\nI should use `has_raw_value` like so:\r\n```\r\ncollection_date:\r\n          has_raw_value: collection_date # mixs:collection_date\r\n```\r\n",
"body": "I think that definition is from BBtools stats.  Brian believes the proper notation should be N50=number of contigs making 50% of the assembly and L50=length lower limit of contigs making up 50% of the assembly.  ",
"body": "@scanon @hubin-keio Do you have any comment?  We use bbtools to get the assembly stats. However, bbtools defines the N50 and L50 is opposite to what [Wikipedia](https://en.wikipedia.org/wiki/N50,_L50,_and_related_statistics) says. ",
"body": "just for reference this is what we have now. The body of the text for N50 references L50, and the body of the text for L50 references N50, so it looks like whatever the canonical answer we have an inversion on our part:\r\n\r\n```\r\n  scaf_N50:\r\n    is_a: metagenome assembly parameter\r\n    description: >-\r\n      Given a set of scaffolds, each with its own length, the L50 count is defined as the smallest number of scaffolds whose length sum makes up half of genome size.\r\n    range: float\r\n\r\n  scaf_L50:\r\n    is_a: metagenome assembly parameter\r\n    description: >-\r\n      Given a set of scaffolds, the N50 is defined as the sequence length of the shortest scaffold at 50% of the total genome length.\r\n    range: float\r\n```",
"body": "commit 6c4ed99 ",
"body": "all the definitions for slots `{ctg,scaf}_[N|L]\\d+` need checked. It looks like N50 and L50 need inverted, as does N90 and L90, etc",
"body": "",
"body": "done see https://github.com/microbiomedata/nmdc-metadata/pull/303",
"body": "The code base for ETL is a bit of mess ... need to clean up:\r\n- consolidate reused blocks of code into functions\r\n- add some minimal docstrings\r\n- remove unused blocks of code left over from previous iterations.\r\n\r\nThe goals is not add functionality or software engineering perfection. Rather, the goal is just to make the code somewhat more maintainable.",
"body": "To clarify - this issue is about the attributes getting added (PI web sites, publications, PI image) downstream in the portal UI.  Issue #150 is about adding a relationship between biosamples and studies",
"body": "connects to e.g. #314",
"body": "@jeffbaumes duplicated by #315?",
"body": "I believe a conversation about what is in this JSON between @jbeezley and @wdduncan could start to address this.",
"body": "@ssarrafan can you move this to the next sprint?",
"body": "> @ssarrafan can you move this to the next sprint?\r\n\r\nIt's been moved to the May sprint.  ",
"body": "Was the suggestion at today's TechSync to divide this ticket up?\r\n\r\nIt would be nice if there were default values or placeholders for fields that we know we want to show up on the portal - even if we don't have the data. The route in for the data definitely needs to be sorted out - as David pointed out. \r\n\r\nIt would also be nice to give the users a way to upload this content, but that can be down the road. ",
"body": "Removing Jon and Donny per discussion with Kjiersten.  @wdduncan let me know if this shouldn't be assigned to you or if you don't have time to work on it. ",
"body": "@wdduncan is this ticket a duplicate of #51 ? Can this one be closed?  ",
"body": "Hi @ssarrafan  This looks like a duplicate of https://github.com/microbiomedata/nmdc-schema/issues/51.\r\nSo, I'll close this ticket. Reopen if needed.",
"body": "https://github.com/microbiomedata/nmdc-server/blob/master/nmdc_server/ingest/study_additional.json\r\n\r\nA number of study related fields are displayed in the portal UI that are not currently in the schema.  In addition to deciding what must be added, we need to consider the process by which these values are included",
"body": "",
"body": "After trying to do a fresh run/install of data translation I found the following missing packages from the requirements:\r\n\r\ngit_root\r\npandas\r\njq\r\ndotted_dict",
"body": "",
"body": "@cmungall I've generated new data based on the updated schema. The database validates.",
"body": "as it should but let's keep closeMappings in when we don't have an exact\n\nOn Tue, Mar 16, 2021 at 5:54 PM Bill Duncan ***@***.***>\nwrote:\n\n> ***@***.**** commented on this pull request.\n> ------------------------------\n>\n> In schema/mappings/gold-to-mixs.sssom.tsv\n> <https://github.com/microbiomedata/nmdc-metadata/pull/297#discussion_r595638250>\n> :\n>\n> > @@ -40,8 +43,8 @@ gold.vocab:soil_store_condition\tsoil_store_condition\tskos:exactMatch\tmixs:store_\n>  gold.vocab:soil_link_climate_info\tsoil_link_climate_info\tskos:exactMatch\tmixs:link_climate_info\tlink_climate_info\tSSSOMC:HumanCurated\tgold.vocab\tmixs\t1\t.\n>  gold.vocab:soil_annual_season_temp\tsoil_annual_season_temp\tskos:closeMatch\tmixs:annual_temp\tannual_temp\tSSSOMC:HumanCurated\tgold.vocab\tmixs\t1\t.\n>  gold.vocab:soil_annual_season_temp\tsoil_annual_season_temp\tskos:closeMatch\tmixs:season_temp\tseason_temp\tSSSOMC:HumanCurated\tgold.vocab\tmixs\t1\t.\n> -gold.vocab:soil_annual_season_precpt\tsoil_annual_season_precpt \tskos:closeMatch\tmixs:season_precpt\tseason_precpt\tSSSOMC:HumanCurated\tgold.vocab\tmixs\t1\t.\n> -gold.vocab:soil_annual_season_precpt\tsoil_annual_season_precpt \tskos:closeMatch\tmixs:annual_precpt\tannual_precpt\tSSSOMC:HumanCurated\tgold.vocab\tmixs\t1\t.\n>\n> I don't remember dropping these, but I must have done it ... I will add\n> the mappings back. Right now the algorithm only looks exact matches (i.e.,\n> the gold fields are only mapped to exact matches).\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/microbiomedata/nmdc-metadata/pull/297#discussion_r595638250>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AAAMMONXX45NO2E5XRHVSCTTD74WHANCNFSM4YULNC7Q>\n> .\n>\n",
"body": "update branch issue-291",
"body": "",
"body": "",
"body": "` ENVO:00000446` is correct. I thought I was converting `ENVO_` to `ENV:` in ETL. But, I must have missed that. I'll need to fix.",
"body": "@dehays I've resolved this. env_broad/local/medium values now have an \":\" instead of \"_\". E.g., \"ENVO:1234\".\r\n\r\nSee https://github.com/microbiomedata/nmdc-metadata/pull/295\r\n\r\ncc @dwinston @jbeezley \r\n",
"body": "Currently - biosamples provided for use in the portal have two different forms ENVO_00000446 and ENVO:00000446\r\n\r\nPajau noticed that none of the Brodie or Wrighton (and as it turns out, many of the Stegen) biosamples participate in EnvO search filtering.  I checked and saw that we did seem to be including values for the MIxS/EnvO triad for all the biosamples.  Jon pointed out this morning that the format using the '_' was unexpected and that those values did not return values when looking up the string values from EnvO.\r\n\r\nCan we decide on which format is correct?  (I believe it is ENVO:00000446 ) and then consistently produce JSON that uses the correct format?",
"body": "note: this isn't in workplan but it should be straightforward\r\n\r\nminimal information about a biosynthetic cluster:\r\n\r\nhttps://gensc.org/projects/mibig/\r\nhttps://www.nature.com/articles/nchembio.1890\r\n\r\nexample of mibig\r\n\r\nhttps://mibig.secondarymetabolites.org/repository/BGC0001122/BGC0001122.json",
"body": "https://isa-specs.readthedocs.io/en/latest/isajson.html",
"body": "Schema changes done. See PRs: https://github.com/microbiomedata/nmdc-metadata/pull/298 and https://github.com/microbiomedata/nmdc-metadata/pull/297.\r\n\r\nClosing for now.",
"body": "The changes here were made due to the need for a qucik turnaround for GSP:\r\n\r\nhttps://github.com/microbiomedata/nmdc-metadata/commit/aec1e2b302305871b563504ffec9c17d6638500d\r\n\r\nbut we should revert the overrides of mixs ranges now. This is not a scalable solution long term, as many of these need to be modeled as complex objects not literals/strings. This is causing confusion: #290 ",
"body": "@johanneswerner I understand your confusion ... this is not clear from documentation. \r\n\r\nLinkML allows you to define slots \"on the fly\" (so to speak) by using `slot_usage`. Unlike slots that are defined independently, slots defined using `slot_usage` cannot be shared between classes; i.e., the slots are bound to the classes.\r\n\r\nDoes that make sense?\r\n\r\ncd @cmungall ",
"body": "Hi @johanneswerner \r\n\r\nYou can find out more about the schema language here: https://github.com/biolink/biolinkml\r\n\r\nEach of the constructs has its own URI with documentation, for example:\r\n\r\nhttps://w3id.org/biolink/biolinkml/meta/slot_usage\r\n_the redefinition of a slot in the context of the containing class definition._\r\n\r\nThis is quite minimal so let me try more of an elucidation! \r\n\r\nBut first, I think your intuitions are on the right track, indeed the idea is to be able to reuse a generic field/property/slot and to refine and even over-ride it in a particular context. \r\n\r\nWhat you are getting tripped up by is a bit of a short term fix we made to temporarily simplify our schema: https://github.com/microbiomedata/nmdc-metadata/commit/aec1e2b302305871b563504ffec9c17d6638500d\r\n\r\nThank you for your interest, I would love to discuss this more with you, I will post more info in this ticket later...\r\n\r\n\r\n",
"body": "Hi @johanneswerner. I've modified the schema to make it simpler (doesn't have a lot slot_usages). Does it make better sense to you now?",
"body": "Hello, \r\n\r\nwe are trying to figure out what the fields `slots` and `slot_usage` in the yaml files represent. \r\n\r\nElisha forwarded us this information\r\n\r\n> slot_usage allows for an override. For example, mixs.yaml - slot diss_oxygen is defined to have a range of quality value\r\n> \r\n> `range: quantity value  ## syntax: {float} {unit} `\r\n> \r\n> However, we have some examples at the moment using strings, so slot_usage becomes: \r\n> \r\n> ```\r\n> slot_usage:\r\n> ....\r\n>    diss_oxygen:\r\n>      range: string\r\n> ```\r\n> \r\n> \r\n\r\nWe are still struggling a bit to understand the concept. \r\n\r\nWe assume that slots are fields that are part of classes, where certain slots can be overridden by class definition in different source files (for instance `collection_date` is present in `mixs.yaml` and `nmdc.yaml`). \r\n\r\nIs this correct or is something different intended? \r\n\r\nWhat is also unclear to us is how certain items can appear in `slot_usage`, but not in `slots` (within the same class). \r\n\r\nCan you help us with our questions and in understanding the schema better? \r\n\r\nThank you very much!",
"body": " * versions/dates for all upstream sources (EMSL, GOLD)\r\n * data on which ETL was executed\r\n * etc\r\n\r\n",
"body": "Update:  \r\nCreate new repo to hold the nmdc schema: https://github.com/microbiomedata/nmdc-schema\r\n\r\ncc @cmungall @dwinston @dehays @kfagnan @jbeezley @ssarrafan @turbomam ",
"body": "Update:  You can now install the nmdc-schema using pip: `pip install nmdc-schema`.  \r\n\r\nThere is still a lot of documentation work to do.",
"body": "Outcomes from conversation with @dwinston:\r\n\r\n1. rename the repo `nmdc-metadata-pipelines`; used for orchestrating different pipelines such as GOLD\r\n2. tag versions with releases\r\n\r\nstructure:\r\nnmdc-pipelines\r\n  - target (used for outputs of pipelines) or should this be in data output\r\n  - resources (used for inputs into pipelines; e.g. GOLD database dump)\r\n       - data source\r\n       - data sync\r\n       - data output\r\n\r\nmore to come ...",
"body": "Please move this to May sprint.\r\n@dwinston and I are getting close to finishing this. Probably a `medium` sized issue.",
"body": "Update\r\n\r\nI have removed number of directories. See PR https://github.com/microbiomedata/nmdc-metadata/pull/344 for details (or view repo on branch `issue-288`).\r\n\r\nAwaiting feedback before merging.",
"body": "A number of directories have been deleted. See PR https://github.com/microbiomedata/nmdc-metadata/pull/344\r\n\r\nThe schema has been moved to [nmdc-schema](https://github.com/microbiomedata/nmdc-schema).  \r\nThe ETL now lives in [nmdc-runtime](https://github.com/microbiomedata/nmdc-runtime).  \r\nThe custom notebooks that were created in the early stages of `NMDC` have been archived to [archived-metadata-notebooks](https://github.com/microbiomedata/archived-metadata-notebooks). This notebooks include:\r\n- [GOLD-level-analysis](https://github.com/microbiomedata/archived-metadata-notebooks/tree/main/GOLD-level-analysis)\r\n- [GOLD-path-translation](https://github.com/microbiomedata/archived-metadata-notebooks/tree/main/GOLD-path-translation)\r\n- [MIxS-ontology-translation](https://github.com/microbiomedata/archived-metadata-notebooks/tree/main/MIxS-ontology-translation)\r\n\r\n",
"body": "You can use https://github.com/cmungall/ontology_associations as a template\r\n\r\n * requirements.txt etc\r\n * tests/\r\n     *  data/\r\n * nmdc_metadata/\r\n      * datamodel.  ## autogenerated from schema below here\r\n            * nmdc.py\r\n            * core.py\r\n            * associations.py\r\n            * prov.py\r\n * src\r\n     * schema/. ## hand edited\r\n        * nmdc.yaml\r\n        * ....ymp\r\n  * jsonschema  ## autogenerated\r\n       * nmdc.schema.json\r\n   * shex etc\r\n\r\nAnd setup github actions to deploy nmdc_metadata to pypi (we have many examples of how to do this..). Note this simultaneously versions the schema and the python keeping both in sync\r\n\r\nOnce this is done, we can move ETL out to separate repo, the ETL repo will use the py modules",
"body": "we currently allow for linking between two biosamples via BiosampleProcessing\r\n\r\nWe should document this with some examples, and also map to other standards. It seems mixs will not support this https://github.com/GenomicsStandardsConsortium/mixs/issues/36\r\n\r\nSome notes on how this is done in ebi/ncbi/dwc/ESSDIVE here:\r\n\r\nhttps://docs.google.com/document/d/1Twi23xy1tI1C3YFBxQUJ-sOLaXKsPrVXO6ezcMdFuZ0/edit",
"body": "",
"body": "",
"body": "",
"body": "",
"body": "All instances of Ohio and Ohio, USA have been now updated to USA: Ohio at the source in GOLD.  The same can be done in the NMDC.  The correct format we use for geographic location is USA: City, State. \r\n\r\n@jagadishcs check for other inconsistencies in the geographic location field. Get those fixed and communicate the update values  for NMDC JSON update. \r\n",
"body": "Believe this has now been addressed in GOLD so should be reflected once GOLD data is ETLed and loaded into search application.",
"body": "Yes, this was updated already. ",
"body": "Search results show Ohio and Ohio, USA separately.  See attached screenshot.  \r\n\r\nConferred with @dehays and he said that the \"Ohio\" strings are coming from GOLD biosample records geographic_location field.  These happen to all be for Kelly Wrighton. \r\n<img width=\"656\" alt=\"ohio\" src=\"https://user-images.githubusercontent.com/79225425/108574423-3d2a2880-72cc-11eb-9920-d2130c7522fd.png\">\r\n",
"body": "Put the attached metadata overview documentation on Mkdocs.\r\n\r\n[Metadata_Documentation.docx](https://github.com/microbiomedata/nmdc-metadata/files/6013713/Metadata_Documentation.docx)\r\n",
"body": "",
"body": "There are several `/Environmental / Aquatic / Marine / \\w+ / Sediment/` classification paths in  GOLD, including Coastal. When I enter \"deep marine sediment basin\" into [this path search tool](https://polyneme.xyz/gold-ecosystem-paths/) I built, I see a \"Marine basin floor\" ecosystem_subtype, which matches the sample_collection_si field above, so it seems that would be more suitable than Coastal in this case?",
"body": "Reported biosample now showing marine basin floor as the ecosystem subtype. \r\nAll other biosamples under this study have marine basin floor (or other relevant values) and none showing coastal for ecosystem subtype anymore. \r\nhttps://gold.jgi.doe.gov/biosamples?page=1&Study.GOLD+Study+ID=Gs0133461&Study.Relevance.ID_options=or&Biosample.Ecosystem+Type=Marine&count=500&desc=Biosample.Ecosystem+Subtype\r\n\r\n@Jagadish Chandrabose Sundaramurthi  check this out and close it. Looks like this has been taken care of on or around Feb 22nd. ",
"body": "```\r\n             lat_lon: 33.0 -118.0\r\n     env_broad_scale: ENVO:00002030\r\nenv_broad_scale_labe: aquatic biome\r\n     env_local_scale: ENVO:00002450\r\nenv_local_scale_labe: ocean basin\r\n          env_medium: ENVO:00002113\r\n    env_medium_label: deep marine sediment\r\n        geo_loc_name: USA: California\r\n     collection_date: 2015-06-19\r\n           ecosystem: Environmental\r\n  ecosystem_category: Aquatic\r\n      ecosystem_type: Marine\r\n   ecosystem_subtype: Coastal\r\n  specific_ecosystem: Sediment\r\n               depth: 860.0 m\r\n            add_date: 21-MAY-17 11.27.12.558000000 AM\r\n           community: enriched cells\r\n             habitat: marine sediment\r\n          identifier: Roland_Nextera1\r\n            location: Santa Monica Basin, California, USA\r\n            mod_date: 18-JUN-19 04.41.31.672000000 PM\r\n  ncbi_taxonomy_name: marine sediment metagenome\r\nsample_collection_si: marine basin floor\r\n```\r\n\r\nis ecosystem_subtype correct? Is there a definition for the gold term 'Coastal'?",
"body": "Do you want this in the `metadata/src/bin` directory?",
"body": "",
"body": "ah, samp_tvdss is only seawater... but either way, should map to mixs to we should request",
"body": "Isee this in the latest gold conversion\r\n\r\n```\r\n      id: \"gold:Gb0119259\"\r\n      name: \"Deep subsurface shale carbon reservoir microbial communities from Ohio, USA - Utica-2 Time Series 2014_10_10\"\r\n      lat_lon: \r\n        has_raw_value: \"40.178000000000004 -81.07300000000001\"\r\n        latitude: 40.178000000000004\r\n        longitude: -81.07300000000001\r\n        type: \"nmdc:GeolocationValue\"\r\n      env_broad_scale: \r\n        has_raw_value: \"ENVO:00000446\"\r\n        term: \r\n          id: \"ENVO:00000446\"\r\n      env_local_scale: \r\n        has_raw_value: \"ENVO:01000941\"\r\n        term: \r\n          id: \"ENVO:01000941\"\r\n      env_medium: \r\n        has_raw_value: \"ENVO:02000119\"\r\n        term: \r\n          id: \"ENVO:02000119\"\r\n      geo_loc_name: \r\n        has_raw_value: \"USA: Ohio\"\r\n      collection_date: \r\n        has_raw_value: \"2014-10-10\"\r\n      ecosystem: \r\n        has_raw_value: \"Environmental\"\r\n      ecosystem_category: \r\n        has_raw_value: \"Terrestrial\"\r\n      ecosystem_type: \r\n        has_raw_value: \"Deep subsurface\"\r\n      ecosystem_subtype: \r\n        has_raw_value: \"Unclassified\"\r\n      specific_ecosystem: \r\n        has_raw_value: \"Unclassified\"\r\n      type: \"nmdc:Biosample\"\r\n      add_date: \r\n        has_raw_value: \"15-AUG-15 12.00.00.000000000 AM\"\r\n      community: \r\n        has_raw_value: \"microbial communities\"\r\n      habitat: \r\n        has_raw_value: \"Deep subsurface\"\r\n      identifier: \r\n        has_raw_value: \"Utica-2 Time Series 2014_10_10\"\r\n      location: \r\n        has_raw_value: \"Ohio\"\r\n      mod_date: \r\n        has_raw_value: \"08-JAN-20 02.49.25.000000000 PM\"\r\n      ncbi_taxonomy_name: \r\n        has_raw_value: \"subsurface metagenome\"\r\n      sample_collection_site: \r\n        has_raw_value: \"Aqueous Sample\"\r\n      subsurface_depth: \r\n        has_raw_value: \"2000.0\"\r\n```\r\n\r\nmultiple issues here\r\n\r\n - does not conform to syntax. what is unit?\r\n - surely we should use samp_tvdss in mixs?\r\n - subsurface_depth is declared as a slot, but is not an allowable slot in biosample, so why doesn't this fail json schem avalidation?",
"body": "",
"body": "",
"body": "Home - Nmdc schema (capitalize NMDC)\r\nHome - update the language at the top to be more clear about modules\r\nHome - remove Mixins, if not using\r\n\r\nIdentifiers - broken links (link in bold)\r\nFor example the class **OrthologyGroup** \r\nThese always have the field name **id**\r\nAll instances of **OmicsProcessing**\r\n",
"body": "",
"body": "Looks like:\r\n\r\n```python\r\ndb.biosample_set.insert_many([\r\n   {\r\n      \"name\":\"Soil microbial communities from the East River watershed near Crested Butte, Colorado, United States - \",\r\n      \"description\":\"Soil microbial communities from the East River watershed near Crested Butte, Colorado, United States\",\r\n      \"lat_lon\":{\r\n         \"has_raw_value\":\"38.9206 -106.9489\",\r\n         \"latitude\":38.9206,\r\n         \"longitude\":-106.9489\r\n      },\r\n      \"geo_loc_name\":\"USA: Colorado\",\r\n      \"collection_date\":\"2017-05-09\",\r\n      \"env_broad_scale\":{\r\n         \"has_raw_value\":\"ENVO_00000446\",\r\n         \"type\":\"ControlledTermValue\"\r\n      },\r\n      \"env_local_scale\":{\r\n         \"has_raw_value\":\"ENVO_00000292\",\r\n         \"type\":\"ControlledTermValue\"\r\n      },\r\n      \"env_medium\":{\r\n         \"has_raw_value\":\"ENVO_00001998\",\r\n         \"type\":\"ControlledTermValue\"\r\n      },\r\n      \"ecosystem\":\"Environmental\",\r\n      \"ecosystem_category\":\"Terrestrial\",\r\n      \"ecosystem_type\":\"Soil\",\r\n      \"ecosystem_subtype\":\"Unclassified\",\r\n      \"specific_ecosystem\":\"Unclassified\",\r\n      \"depth\":15,\r\n      \"ncbi_taxonomy_name\":\"soil metagenome\",\r\n      \"community\":\"microbial communities\",\r\n      \"location\":\"The East River watershed near Crested Butte, Colorado, USA\",\r\n      \"habitat\":\"soil\",\r\n      \"sample_collection_site\":\"soil\",\r\n      \"add_date\":\"22-Jun-18 04.28.47.015000 PM\",\r\n      \"mod_date\":\"01-Oct-19 09.41.01.459000 AM\",\r\n      \"id\":\"igsn:IEWFS000I\",\r\n      \"identifier\":\"igsn:IEWFS000I\"\r\n   },\r\n   {\r\n      \"name\":\"Soil microbial communities from the East River watershed near Crested Butte, Colorado, United States - \",\r\n      \"description\":\"Soil microbial communities from the East River watershed near Crested Butte, Colorado, United States\",\r\n      \"lat_lon\":{\r\n         \"has_raw_value\":\"38.9206 -106.9489\",\r\n         \"latitude\":38.9206,\r\n         \"longitude\":-106.9489\r\n      },\r\n      \"geo_loc_name\":\"USA: Colorado\",\r\n      \"collection_date\":\"2017-05-09\",\r\n      \"env_broad_scale\":{\r\n         \"has_raw_value\":\"ENVO_00000446\",\r\n         \"type\":\"ControlledTermValue\"\r\n      },\r\n      \"env_local_scale\":{\r\n         \"has_raw_value\":\"ENVO_00000292\",\r\n         \"type\":\"ControlledTermValue\"\r\n      },\r\n      \"env_medium\":{\r\n         \"has_raw_value\":\"ENVO_00001998\",\r\n         \"type\":\"ControlledTermValue\"\r\n      },\r\n      \"ecosystem\":\"Environmental\",\r\n      \"ecosystem_category\":\"Terrestrial\",\r\n      \"ecosystem_type\":\"Soil\",\r\n      \"ecosystem_subtype\":\"Unclassified\",\r\n      \"specific_ecosystem\":\"Unclassified\",\r\n      \"depth\":15,\r\n      \"ncbi_taxonomy_name\":\"soil metagenome\",\r\n      \"community\":\"microbial communities\",\r\n      \"location\":\"The East River watershed near Crested Butte, Colorado, USA\",\r\n      \"habitat\":\"soil\",\r\n      \"sample_collection_site\":\"soil\",\r\n      \"add_date\":\"22-Jun-18 04.28.47.015000 PM\",\r\n      \"mod_date\":\"01-Oct-19 09.41.01.459000 AM\",\r\n      \"id\":\"igsn:IEWFS000K\",\r\n      \"identifier\":\"igsn:IEWFS000K\"\r\n   },\r\n   {\r\n      \"name\":\"Soil microbial communities from the East River watershed near Crested Butte, Colorado, United States - \",\r\n      \"description\":\"Soil microbial communities from the East River watershed near Crested Butte, Colorado, United States\",\r\n      \"lat_lon\":{\r\n         \"has_raw_value\":\"38.9206 -106.9489\",\r\n         \"latitude\":38.9206,\r\n         \"longitude\":-106.9489\r\n      },\r\n      \"geo_loc_name\":\"USA: Colorado\",\r\n      \"collection_date\":\"2017-05-09\",\r\n      \"env_broad_scale\":{\r\n         \"has_raw_value\":\"ENVO_00000446\",\r\n         \"type\":\"ControlledTermValue\"\r\n      },\r\n      \"env_local_scale\":{\r\n         \"has_raw_value\":\"ENVO_00000292\",\r\n         \"type\":\"ControlledTermValue\"\r\n      },\r\n      \"env_medium\":{\r\n         \"has_raw_value\":\"ENVO_00001998\",\r\n         \"type\":\"ControlledTermValue\"\r\n      },\r\n      \"ecosystem\":\"Environmental\",\r\n      \"ecosystem_category\":\"Terrestrial\",\r\n      \"ecosystem_type\":\"Soil\",\r\n      \"ecosystem_subtype\":\"Unclassified\",\r\n      \"specific_ecosystem\":\"Unclassified\",\r\n      \"depth\":15,\r\n      \"ncbi_taxonomy_name\":\"soil metagenome\",\r\n      \"community\":\"microbial communities\",\r\n      \"location\":\"The East River watershed near Crested Butte, Colorado, USA\",\r\n      \"habitat\":\"soil\",\r\n      \"sample_collection_site\":\"soil\",\r\n      \"add_date\":\"22-Jun-18 04.28.47.015000 PM\",\r\n      \"mod_date\":\"01-Oct-19 09.41.01.459000 AM\",\r\n      \"id\":\"igsn:IEWFS000B\",\r\n      \"identifier\":\"igsn:IEWFS000B\"\r\n   },\r\n   {\r\n      \"name\":\"Soil microbial communities from the East River watershed near Crested Butte, Colorado, United States - \",\r\n      \"description\":\"Soil microbial communities from the East River watershed near Crested Butte, Colorado, United States\",\r\n      \"lat_lon\":{\r\n         \"has_raw_value\":\"38.9206 -106.9489\",\r\n         \"latitude\":38.9206,\r\n         \"longitude\":-106.9489\r\n      },\r\n      \"geo_loc_name\":\"USA: Colorado\",\r\n      \"collection_date\":\"2017-05-09\",\r\n      \"env_broad_scale\":{\r\n         \"has_raw_value\":\"ENVO_00000446\",\r\n         \"type\":\"ControlledTermValue\"\r\n      },\r\n      \"env_local_scale\":{\r\n         \"has_raw_value\":\"ENVO_00000292\",\r\n         \"type\":\"ControlledTermValue\"\r\n      },\r\n      \"env_medium\":{\r\n         \"has_raw_value\":\"ENVO_00001998\",\r\n         \"type\":\"ControlledTermValue\"\r\n      },\r\n      \"ecosystem\":\"Environmental\",\r\n      \"ecosystem_category\":\"Terrestrial\",\r\n      \"ecosystem_type\":\"Soil\",\r\n      \"ecosystem_subtype\":\"Unclassified\",\r\n      \"specific_ecosystem\":\"Unclassified\",\r\n      \"depth\":15,\r\n      \"ncbi_taxonomy_name\":\"soil metagenome\",\r\n      \"community\":\"microbial communities\",\r\n      \"location\":\"The East River watershed near Crested Butte, Colorado, USA\",\r\n      \"habitat\":\"soil\",\r\n      \"sample_collection_site\":\"soil\",\r\n      \"add_date\":\"22-Jun-18 04.28.47.015000 PM\",\r\n      \"mod_date\":\"01-Oct-19 09.41.01.459000 AM\",\r\n      \"id\":\"igsn:IEWFS000A\",\r\n      \"identifier\":\"igsn:IEWFS000A\"\r\n   },\r\n   {\r\n      \"name\":\"Soil microbial communities from the East River watershed near Crested Butte, Colorado, United States - \",\r\n      \"description\":\"Soil microbial communities from the East River watershed near Crested Butte, Colorado, United States\",\r\n      \"lat_lon\":{\r\n         \"has_raw_value\":\"38.9206 -106.9489\",\r\n         \"latitude\":38.9206,\r\n         \"longitude\":-106.9489\r\n      },\r\n      \"geo_loc_name\":\"USA: Colorado\",\r\n      \"collection_date\":\"2017-05-09\",\r\n      \"env_broad_scale\":{\r\n         \"has_raw_value\":\"ENVO_00000446\",\r\n         \"type\":\"ControlledTermValue\"\r\n      },\r\n      \"env_local_scale\":{\r\n         \"has_raw_value\":\"ENVO_00000292\",\r\n         \"type\":\"ControlledTermValue\"\r\n      },\r\n      \"env_medium\":{\r\n         \"has_raw_value\":\"ENVO_00001998\",\r\n         \"type\":\"ControlledTermValue\"\r\n      },\r\n      \"ecosystem\":\"Environmental\",\r\n      \"ecosystem_category\":\"Terrestrial\",\r\n      \"ecosystem_type\":\"Soil\",\r\n      \"ecosystem_subtype\":\"Unclassified\",\r\n      \"specific_ecosystem\":\"Unclassified\",\r\n      \"depth\":15,\r\n      \"ncbi_taxonomy_name\":\"soil metagenome\",\r\n      \"community\":\"microbial communities\",\r\n      \"location\":\"The East River watershed near Crested Butte, Colorado, USA\",\r\n      \"habitat\":\"soil\",\r\n      \"sample_collection_site\":\"soil\",\r\n      \"add_date\":\"22-Jun-18 04.28.47.015000 PM\",\r\n      \"mod_date\":\"01-Oct-19 09.41.01.459000 AM\",\r\n      \"id\":\"igsn:IEWFS000J\",\r\n      \"identifier\":\"igsn:IEWFS000J\"\r\n   }\r\n])\r\n```",
"body": "done. See https://github.com/microbiomedata/nmdc-metadata/pull/280",
"body": "Currently, I run the ETL from command line but I comment out certain lines when I do not want a particular ETL step to run. This is too hacky. Better to set a CLI and call the ETL workflow from the makefile.",
"body": "",
"body": "",
"body": "- [ ] Remove unused files and folders\r\n- [ ] Replace schema diagram (it isn't useful ... replace with a manual)\r\n- [ ] Update the ETL description\r\n- [ ] Update the external sources description\r\n- [ ] Add targets to makefile to run GOLD ETL (add CLI to python call)\r\n\r\ncc @cmungall ",
"body": "@dwinston I think have a sequence diagram like the one you've have an example of could be really helpful. I haven't used Apache Airflow. I have use [Apache NiFi](https://nifi.apache.org/), though. My experience with it was okay. A bit of a learning curve.",
"body": "After trying Airflow, I think it's story is a little shaky at this point due to v2 being pretty new. Their docs for a dockerized setup had a few bugs that I needed to work around.\r\n\r\nI'm a bit more bullish at the moment about [Dagster](https://dagster.io/), which among other features has official support for [including Jupyter notebooks with data dependencies](https://docs.dagster.io/overview/packages/dagstermill) in ETL pipelines.\r\n\r\n@jbeezley tagging you on this thread to think about what an ETL pipeline running on Spin could look like, one that gets new data / data changes to show on the pilot site without much intervention from you or me or @wdduncan .",
"body": "The only technical constraint that I know of is that you can only (currently) expose http/https services externally.  So as long as Dagster communicates through http, it should be possible.",
"body": "Superseded by #316",
"body": "I am thinking it could be good to set up a NERSC Spin service to run metadata ETL with the help of Apache Airflow and the Python Great Expectations library. I don't have much operational experience with these tools, but they seem like a good fit for NMDC needs and for migrating notebook-based workflows to something that is a bit more systematic and also observable (i.e. browser-based monitoring and reports), while still being Python-based.\r\n\r\nThe below is my sketch for a Spin service. I asked for feedback on the nerscusers Slack spin channel. @wdduncan @cmungall @dehays let me know your thoughts.\r\n\r\n![spin-airflow-mongo-cfs-ge](https://user-images.githubusercontent.com/1497854/108269093-7f703000-713b-11eb-8f0a-7df8daa4189e.png)\r\n\r\nFYI I generated the above using the [Mermaid](https://mermaid-js.github.io/) tool:\r\n```mermaid\r\nsequenceDiagram\r\n    participant CFS as NERSC CFS\r\n    participant NFS as Spin NFS\r\n    participant Air as Airflow\r\n    participant Py as Worker<br/>(same container<br/>as Airflow?)\r\n    participant Mongo as MongoDB\r\n    participant GE as GreatExpectations\r\n    Air->>NFS: get scheduled workflow\r\n    NFS->>Air: flow.py from NFS volume\r\n    Note over Air: Serve monitoring UI\r\n    Air->>+Py: run flow.py\r\n    Py->>Mongo: connect to db\r\n    loop For each subtask\r\n      Py->>Mongo: get from db\r\n      Py->>CFS: get from CFS\r\n      Py->>Py: execute logic\r\n      Py->>GE: run validations\r\n      Note over GE: Serve HTML report\r\n      opt Save\r\n        Py->>Mongo: write to db\r\n      end\r\n    end\r\n    Py->>Mongo: write to db\r\n    Py->>-Air: done\r\n```",
"body": "For some reason GOLD geographic_location field not mapping to MIxS geo_loc_name.",
"body": "",
"body": "",
"body": "@kfagnan actually... NCBI's taxonomy includes a bunch of XYZ metagenomes! Going to close this issue for now. https://www.ncbi.nlm.nih.gov/Taxonomy/Browser/wwwtax.cgi?id=408169",
"body": "![image (1)](https://user-images.githubusercontent.com/1504015/107835048-004eb680-6d4d-11eb-8820-b12abd793eac.png)\r\n\r\nFeedback: \r\nnot the right database for taxonomy. these are habitat names not species names\r\n\r\n@subdavis adding you as this might be a UI issue - not sure where \"NCBI taxonomy name\" is coming from",
"body": "Thanks!  I'll incorporate this and hopefully provide some options.\n\nI don't know how easy it will be to match to individual data objects, but at a minimum we can have these in a table in a dialog callable from the data object list area.",
"body": "One more thing - see https://github.com/microbiomedata/nmdc-server/issues/274\r\n\r\nThis contains an image suggesting these descriptions be added to a column. ",
"body": "@jbeezley there is a new MongoDB collection `notes` with documents of the form\r\n```python\r\n{\r\n    \"_id\" : ObjectId(\"602d502525261d62addcd830\"),\r\n    \"sh:pattern\" : \"filterStats.txt\",\r\n    \"skos:note\" : \"Reads QC summary statistics\",\r\n    \"@context\" : {\r\n        \"skos\" : \"http://www.w3.org/2004/02/skos/core#\",\r\n        \"sh\" : \"http://www.w3.org/ns/shacl#\"\r\n    }\r\n}\r\n```\r\nthat is referenced by a new field `_note` in a `data_object_set` document, e.g.\r\n```python\r\n{\r\n    \"_id\" : ObjectId(\"602551d225261d62add17d66\"),\r\n    \"id\" : \"nmdc:ae40d7ae535c92b6d347915d8b1ac125\",\r\n    \"name\" : \"filterStats.txt\",\r\n    \"description\" : \"Filtered read data stats for gold:Gp0061273\",\r\n    \"file_size_bytes\" : 290,\r\n    \"url\" : \"https://data.microbiomedata.org/data/1472_51277/qa/filterStats.txt\",\r\n    \"type\" : \"nmdc:DataObject\",\r\n    \"_note\" : {\r\n        \"ref\" : \"notes\",\r\n        \"id\" : ObjectId(\"602d502525261d62addcd830\")\r\n    }\r\n}\r\n```\r\nThe `_note` field has this schema:\r\n```python\r\n{\r\n    \"type\": \"object\",\r\n    \"description\": \"https://docs.mongodb.com/manual/reference/database-references/#dbrefs\",\r\n    \"required\": [\"ref\", \"id\"],\r\n    \"properties\": {\r\n        # XXX $jsonSchema incompatible with $ref and $id convention\r\n        \"ref\": {\"type\": \"string\"},\r\n        \"id\": {\"bsonType\": \"objectId\"},\r\n    }\r\n}\r\n```\r\n\r\n@dehays @wdduncan The workflow, from pattern-note map definition to db update, is in [this notebook](https://github.com/microbiomedata/nmdc-metadata/blob/5f36685347d096918501c90478733db1284a2e44/metadata-translation/notebooks/data-object-notes.ipynb) (its commit references this issue). What is a more stable place in this repo for the pattern-note map (@kfagnan's tables above) to live, that the workflow can source?",
"body": "@kfagnan to accommodate the left-most sticky note on microbiomedata/nmdc-server#274, we would want an additional attribute, a preferred label, to associate with a data object name pattern, in addition to associating the note.",
"body": "@dwinston I'm not opposed to this approach, but perhaps instead of calling it \"note\" could call it \"tooltip\" instead?\r\n\r\nOr you can make use of annotations from the semantic web space for refining various kinds of notes. E.g.:\r\n- comment\r\n- definition\r\n- label (for human readable labels)\r\n",
"body": "@wdduncan yes, I love the move to generalized annotation for various UI contexts, so e.g. could rename to `_anno` in `data_object_set` and reference an `annotations` collection instead of `notes`? I'll leave as is for now, but can refactor once you, @cmungall, et al. decide on an approach.",
"body": "Let's discuss more post GSP. I've added this item to ticket #257   \r\nGiven the short time span we have until GSP, I suggest we go with the approach that Kitware thinks will work best.\r\n",
"body": "I feel we are considering 1) the short term - 'have the feature for GSP' and the 2) actual solution that will require discussing how to include display strings in the JSON documents.\r\n\r\nFor now (until GSP) - I don't want to derail Brandon's intended implementation plans.  ",
"body": "A version of a fix was deployed.\r\n\r\n![Screenshot from 2021-02-17 15-56-55](https://user-images.githubusercontent.com/4214172/108267051-dd4f4880-7138-11eb-9a0f-54af4bb6c221.png)\r\n",
"body": "@subdavis - here's the promised content! I hope this is the right place to put this. And sorry, as I was writing some of this out, I realized I might be asking for more features - let me know if they need to go into their own issues. Please correct the text if this is not indeed what it represents. \r\n\r\nVisualization | Help icon pop-up text | Notes for Kitware\r\n-- | -- | --\r\n![image](https://user-images.githubusercontent.com/7374085/116628704-8e761a00-a904-11eb-8103-54e72810dd80.png) | Displays the number of samples for each data type available. Click on a bar to filter by data type. |\r\n![image](https://user-images.githubusercontent.com/7374085/116628781-b796aa80-a904-11eb-8aa8-44cf9800b9bb.png) | Displays geographical location (latitude, longitude) and sample size (as indicated by the size of the point). Click on a point to filter by a group of samples. | Please add legend with values for color and point sizes. Are the colors supposed to represent different sample types? If Brodie\u2019s data had more resolution with their lat/long values, would you still show his samples as 1 large point (and then disaggregate the points when the user zooms in?)\r\n![image](https://user-images.githubusercontent.com/7374085/116628806-c4b39980-a904-11eb-95b3-3090bfeda759.png) | Scroll the slider to narrow in on a sample collection date range. | add x and y labels (x = sample collection date, y = number of samples) I was expecting the dates to match up with where the sliders were - but it seems as though they\u2019re matching up with the dates at the edges of the visualizations which felt a little non-intuitive.\r\n![image](https://user-images.githubusercontent.com/7374085/116628829-d137f200-a904-11eb-8ff0-5186e5db234f.png)| This upset plot shows the number of samples with corresponding omic data associated. For example: there are 43 samples from 1 study that have metagenomics, metatranscriptomics, and natural organic matter characterizations. | Can a legend be added? If not, you can probably lump this into the help text: MB = metabolomicsMG = metagenomicsMP = metaprotomicsMT = metatranscriptomicsNOM = natural organic matter characterizations\r\n\r\n",
"body": "Thanks, I'll get these updated soon.  I think many of the items from our meeting today will spin off other issues. We're planning to get those in order at our next internal planning meeting.",
"body": "@jbeezley @subdavis @jeffbaumes @wdduncan @dwinston @dehays \r\nTagging you all as I'm not sure how you all will want to implement this.\r\n\r\nI'm including tables that map some of the terms on the website to more human-readable descriptions that we're hoping to incorporate into \"tool tips\" or some kind of alternate text. \r\n\r\n**Metagenome Output**\r\nExisting entry | new text\r\n\r\nfilterStats.txt | Reads QC summary statistics\r\n1781_86101.filtered.fastq.gz | Reads QC result fastq (clean data)\r\nmapping_stats.txt | Assembled contigs coverage information\r\nassembly_contigs.fna | Final assembly contigs fasta\r\nassembly_scaffolds.fna | Final assembly scaffolds fasta\r\nassembly.agp | An AGP format file describes the assembly\r\npairedMapped_sorted.bam | Sorted bam file of reads mapping back to the final assembly\r\nKO TSV | Tab delimited file for KO annotation.\r\nEC TSV | Tab delimited file for EC annotation.\r\nProtein FAA | FASTA amino acid file for annotated proteins.\r\n\r\n**Metaproteome files**\r\nExisting entry | new text \r\n\r\nMSGFjobs_MASIC_resultant.tsv | Tab delimited file of unfiltered metaproteomics results, both identifications and abundances\r\n500088_1781_100336_Peptide_Report.tsv | Tab delimited file of peptide results filtered to ~5% FDR, including protein and abundance information\r\n500088_1781_100336_Protein_Report.tsv | Tab delimited file of protein results derived from ~5% FDR filtered peptide data, including aggregated abundance information\r\n500088_1781_100336_QC_metrics.tsv | Tab delimited file of aggregate statistics derived from workflow results\r\n\r\n",
"body": "",
"body": "`nmdc_merged_data.tsv.zip` is missing the `principal_investigator_name` fields.",
"body": "",
"body": "Being lazy and just pasting from:\r\n\r\nhttps://www.metabolomicsworkbench.org/data/datasharing.php\r\n\r\nWe recommend the guidelines of the Metabolomics Society as published below, but the data/metadata requirements may extend beyond what is proposed in these documents. The Metabolomics Society published a set of rules in Metabolomics (ISSN 1573-3890), Volume 3, Number 3, September 2007; http://www.springerlink.com/content/1573-3882/3/3/\r\n\r\nThe metabolomics standards initiative (MSI) http://dx.doi.org/10.1007/s11306-007-0070-6\r\nStandard reporting requirements for biological samples in metabolomics experiments: mammalian/in vivo experiments http://dx.doi.org/10.1007/s11306-007-0077-z\r\nStandard reporting requirements for biological samples in metabolomics experiments: microbial and in vitro biology experiments; http://dx.doi.org/10.1007/s11306-007-0080-4\r\nMinimum reporting standards for plant biology context information in metabolomic studies http://dx.doi.org/10.1007/s11306-007-0068-0\r\nStandard reporting requirements for biological samples in metabolomics experiments: environmental context http://dx.doi.org/10.1007/s11306-007-0067-1\r\nProposed minimum reporting standards for chemical analysis Chemical Analysis Working Group (CAWG) Metabolomics Standards Initiative (MSI) http://dx.doi.org/10.1007/s11306-007-0082-2\r\nProposed reporting requirements for the description of NMR-based metabolomics experiments http://dx.doi.org/10.1007/s11306-006-0040-4\r\nProposed minimum reporting standards for data analysis in metabolomics http://dx.doi.org/10.1007/s11306-007-0081-3\r\nMetabolomics standards initiative: ontology working group work in progress http://dx.doi.org/10.1007/s11306-007-0069-z",
"body": "This a list for priorities that need to be discussed after GSP 2021. Please add to the list as needed.\r\n\r\n- [ ] Formalize schema versioning in releases (we currently have a version field for the schema, but we need to use it for publishing data)\r\n- [ ] Standardize the pipeline used for getting data into MongoDB and providing the data to Kitware (.e.g., perhaps put Kitware queries in a yaml file)\r\n  - [ ] Discuss workflow management for tooltips. See #262 \r\n- [ ] Discuss potential of setting up an API for GOLD.\r\n- [ ] Version the SOP for metadata collection. Right now if seems like we are playing fast & loose.\r\n- [ ] Formalize the requirements of the data management system.\r\n- [ ] Alternative to storing data as nmdc_database.json.zip in this repo as part of overall ETL pipeline\r\n\r\ncc @dehays @cmungall @jagadishcs @dwinston ",
"body": "@pvangay I posted a preliminary of conversion of document:  \r\nhttps://github.com/microbiomedata/nmdc-metadata/blob/issue-256/docs/NMDC_MIxS_Soil_documentation.md\r\n\r\nI had to make a few changes:\r\n- I edited the wording at the top a little.\r\n- I had to use bullets instead of number. The conversion wasn't keeping the numbers in sequence.",
"body": "Documentation deployed on Mkdocs:\r\nhttps://microbiomedata.github.io/nmdc-metadata/NMDC_MIxS_Soil_documentation/\r\n\r\nI'll leave this ticket open for now, in case we need to add to it.",
"body": "@pvangay I think were covered on this. Going to close. Let me know if I need to reopen the ticket.",
"body": "For the upcoming GSP, convert the `NMDC_MIxS_Soil_documentation.docx` (and others as needed) to markdown and add to Mkdocs documentation. \r\n\r\nSee attached.\r\n\r\n[NMDC_MIxS_Soil_documentation.docx](https://github.com/microbiomedata/nmdc-metadata/files/5968078/NMDC_MIxS_Soil_documentation.docx)\r\n\r\ncc @pvangay ",
"body": "Updated filter to\r\n```\r\n{\r\n    \"part_of\": [\"gold:Gs0114675\"],\r\n    \"processing_institution\": \"Environmental Molecular Sciences Lab\"\r\n}\r\n```\r\nto reflect schema update",
"body": "These are the omics processing docs to remove -\r\n\r\n```\r\ndb.omics_processing_set.deleteMany(\r\n\r\n{\"part_of\":[\"gold:Gs0114675\"], \"processing_institution\":{\"has_raw_value\":\"Environmental Molecular Sciences Lab\"}}\r\n\r\n)\r\n```\r\n\r\nAlso need to remove the data objects that are referred to in the has_output of the 40 omics_processing above.  (Joins in Mongo? )",
"body": "",
"body": "The working notebook for this issue and for #252 is [here](https://github.com/microbiomedata/nmdc-metadata/blob/fa000e848ec4658b88aa564ac1804e896bd6d4de/metadata-translation/notebooks/ghissue_252_253_linked_samples.ipynb). #252 is done (pushed to dwinston_share db).\r\n\r\nThe notebook is a bit long because (1) I decided to use the Google Sheets/Drive APIs to source the spreadsheet and the json template, and (2) I needed to update the mongo collection $jsonSchema validator given recent updates to the NMDC JSON Schema to include previously missing fields for Biosample objects. I encountered no issues for #252 wrt unexpectedly present/missing documents or conflicting omics_type values.",
"body": "[Done](https://github.com/microbiomedata/nmdc-metadata/blob/fb4e35acf421e9dcd71664a5b172377231430203/metadata-translation/notebooks/ghissue_252_253_linked_samples.ipynb).",
"body": "Using [Brodie_biosample_linking_update](https://docs.google.com/spreadsheets/d/1Gj6jwU5d8kdYhq8zuvjTB3T4-nt3Ru7NhxYpTeR9eRw/edit?usp=sharing) as input.\r\n\r\nUpdate existing omics_processing documents. Iterate through the values in column A, using this dataset id as the reference to existing omics_processing objects (where \"id\" is \"emsl:\" + value in column A). Please take note of any case where no omics_processing object is found for a given EMSL dataset ID.\r\n\r\nVerify that the \"omics_type\" object's \"has_raw_value\" matches the value in column B (Omics Type) We expect all these to match, but update the \"omics_type\" to the value from column B and log if they do not.\r\n\r\nUpdate the value \"has_input\" to be an array of size == 1 where the one value is the IGSN biosample ID from column D in the form: \"igsn:\" + column D string",
"body": "Using [Stegen biosample linking update](https://docs.google.com/spreadsheets/d/1nZOJYiC2QN0hOn5nDj9y9mteWeGyzQQls17zH5mESww/edit?usp=sharing) as input.\r\n\r\n\r\n- [x] Begin by creating new biosample documents.  Start with the unique set of values in column D (biosample ID) for which column E value is TRUE.  (The new biosample objects use UUIDs as IDs rather than GOLD biosample IDs.).  The IDs used on the new biosample objects should be of the form \"emsl:\" + value from column D.  The template object to use in creating new biosample objects is: [stegen_biosample_template.json](https://drive.google.com/file/d/1XoSHcImd9LRlZb2nYNWucGtTzgqmdMd0/view?usp=sharing) The template object uses the value of biosample ID (\"emsl: + column D) in value for the \"id\" key and the value of the sample name (column C) in the values for the \"name\" and \"identifier\" keys\r\n\r\n- [x] Update existing omics_processing documents.  Iterate through the values in column A, using this dataset id as the reference to existing omics_processing objects (where \"id\" is \"emsl:\" + value in column A).  Please take note of any case where no omics_processing object is found for a given EMSL dataset ID.\r\n\r\n  \r\nVerify that the \"omics_type\" object's \"has_raw_value\" matches the value in column B (Omics Type) We expect all these to match, but update the \"omics_type\" to the value from column B and log if they do not.\r\n\r\nUpdate the value \"has_input\" to be an array of size == 1 where the one value is the biosample ID from column D in the form: \"emsl:\" + column D string\r\n  \r\n \r\n ",
"body": "The omics process has additional properties not allowed:\r\n\r\n'principal_investigator_name'\r\n'mod_date'\r\n'add_date'\r\n'processing_institution'\r\n'ncbi_project_name'\r\nAlso for study check:\r\n\r\n'principal_investigator_name'\r\n'type'",
"body": "@dwinston @jbeezley @dehays @cmungall \r\nI modify the schema and the nmdc_database.json so that study, omics processing, and biosample now validate.  \r\nThe activity sets **do not** validate. This will require more changes to the nmdc_database.json.",
"body": "The omics process has additional properties not allowed:\r\n- 'principal_investigator_name'\r\n- 'mod_date'\r\n- 'add_date'\r\n- 'processing_institution'\r\n- 'ncbi_project_name'\r\n\r\nAlso for study check:\r\n\r\n- 'principal_investigator_name'\r\n- 'type'\r\n",
"body": "@dwinston @dehays @jbeezley metagenome_assembly_set added",
"body": "",
"body": "@dwinston @dehays @jbeezley metagenome_annotation_activity_set added",
"body": "",
"body": "@dwinston @dehays @jbeezley read based analysis activity set  added",
"body": "",
"body": "",
"body": "@dwinston @dehays @jbeezley properties added.",
"body": null,
"body": "I would also very much like to make sure we address the peptide quantification versus/in addition to protein quantification, whether these can/should be separate JSON entities or collapsed/grouped as you were suggesting. Once we have actual results with which to play it ought be easier to suss out the best path.",
"body": "In the run up to GSP we rapidly added many classes and fields to be able to accomodate all omics workflows and outputs. Post GSP we should return to this and fully document these, and map to existing ontologies where possible.\r\n\r\nIn some cases we have good documentation, but we still need to map to existing standards/ontologies; e.g\r\n\r\n      min_q_value:\r\n        description: >-\r\n          smallest Q-Value associated with the peptide sequence as provided by MSGFPlus tool\r\n        range: float\r\n      peptide_spectral_count:\r\n        description: >-\r\n          sum of filter passing MS2 spectra associated with the peptide sequence within a given LC-MS/MS data file\r\n        range: integer\r\n      peptide_sum_masic_abundance:\r\n        description: >-\r\n          combined MS1 extracted ion chromatograms derived from MS2 spectra associated with the peptide sequence from a given LC-MS/MS data file using the MASIC tool\r\n        range: integer\r\n  \r\nthese terms could be mapped to metaP standards from PSI, or potentially OBI\r\n\r\nWe should create an enum for data object type and have the values mapped to the appropriate ontology. We need to determine if OBI, EDAM, or SWO is appropriate here.\r\n\r\nThere are a lot of unmapped fields for metagenome assembly and MAGs. \r\n\r\n```yaml\r\n  scaf_logsum:\r\n    is_a: metagenome assembly parameter\r\n    description: >-\r\n      The sum of the (length*log(length)) of all scaffolds, times some constant.  Increase the contiguity, the score will increase\r\n    range: float\r\n\r\n  scaf_powsum:\r\n    is_a: metagenome assembly parameter\r\n    description: >-\r\n      Powersum of all scaffolds is the same as logsum except that it uses the sum of (length*(length^P)) for some power P (default P=0.25).\r\n    range: float \r\n\r\n  scaf_max:\r\n    is_a: metagenome assembly parameter\r\n    description: >-\r\n      Maximum scaffold length.\r\n    range: float\r\n      \r\n  scaf_bp:\r\n    is_a: metagenome assembly parameter\r\n    description: >-\r\n      Total size in bp of all scaffolds.\r\n    range: float\r\n\r\n  scaf_N50:\r\n    is_a: metagenome assembly parameter\r\n    description: >-\r\n      Given a set of scaffolds, each with its own length, the L50 count is defined as the smallest number of scaffolds whose length sum makes up half of genome size.\r\n    range: float\r\n```\r\n\r\nto be determined if this is in scope for an existing ontology or if the nmdc schema fields can be a proposed new standard\r\n",
"body": "corrected once are at : `/global/project/projectdirs/m3408/www/meta`\r\n```\r\n-rwxrwxrwx 1 anubhav  m3408 316369 Jan 29 22:36 stegen_MetaProteomicAnalysis_activity.json\r\n-rwxrwxrwx 1 anubhav  m3408   1537 Jan 29 22:36 stegen_emsl_analysis_data_objects.json\r\n```\r\n**_update_**:\r\n\r\n```\r\n   \"has_peptide_quantifications\":[\r\n      {\r\n         \"peptide_sequence\":\"NFDEVLR\",\r\n         \"best_protein\":\"nmdc:Ga0482236_012549_487_783\",\r\n         \"all_proteins\":[\r\n            \"nmdc:Ga0482236_012549_487_783\",\r\n            \"nmdc:Ga0482236_017136_248_676\",\r\n            \"nmdc:Ga0482236_022210_28_537\",\r\n            \"nmdc:Ga0482236_026658_3_296\",\r\n            \"nmdc:Ga0482236_031150_3_518\",\r\n            \"nmdc:Ga0482236_044271_1_444\",\r\n            \"nmdc:Ga0482236_068256_3_359\",\r\n            \"nmdc:Ga0482236_069613_1_369\",\r\n            \"nmdc:Ga0482236_096147_2_262\",\r\n            \"nmdc:Ga0482236_130779_1_294\"\r\n         ],\r\n         \"min_q_value\":\"0.031991\",\r\n         \"peptide_spectral_count\":\"1\",\r\n         \"peptide_sum_masic_abundance\":\"400840000\"\r\n      }\r\n```",
"body": "So...  the metaP analysis activity didn't validate because of the names of the fields in the peptide quantification objects.  Here's what you produced:\r\n```\r\n{\r\n         \"PeptideSequence\":\"NFDEVLR\",\r\n         \"BestProtein\":\"nmdc:Ga0482236_012549_487_783\",\r\n         \"all_proteins\":[\r\n            \"nmdc:Ga0482236_012549_487_783\",\r\n            \"nmdc:Ga0482236_017136_248_676\",\r\n            \"nmdc:Ga0482236_022210_28_537\",\r\n            \"nmdc:Ga0482236_026658_3_296\",\r\n            \"nmdc:Ga0482236_031150_3_518\",\r\n            \"nmdc:Ga0482236_044271_1_444\",\r\n            \"nmdc:Ga0482236_068256_3_359\",\r\n            \"nmdc:Ga0482236_069613_1_369\",\r\n            \"nmdc:Ga0482236_096147_2_262\",\r\n            \"nmdc:Ga0482236_130779_1_294\"\r\n         ],\r\n         \"min(QValue)\":\"0.031991\",\r\n         \"SpectralCount\":\"1\",\r\n         \"sum(MASICAbundance)\":\"400840000\"\r\n      }\r\n```\r\nand here is what is in the schema (  https://github.com/microbiomedata/nmdc-metadata/blob/master/schema/nmdc.yaml ) :\r\n          \r\n```\r\n  peptide quantification:\r\n    description: >-\r\n      This is used to link a metaproteomics analysis workflow to a specific peptide sequence and related information\r\n    slot_usage:\r\n      peptide sequence:\r\n        range: string\r\n      best protein:\r\n        description: >-\r\n          the specific protein identifier most correctly associated with the peptide sequence\r\n        range: gene product\r\n      all proteins:\r\n        description: >-\r\n          the list of protein identifiers that are associated with the peptide sequence\r\n        range: gene product\r\n        multivalued: true\r\n      min_q_value:\r\n        description: >-\r\n          smallest Q-Value associated with the peptide sequence as provided by MSGFPlus tool\r\n        range: float\r\n      peptide_spectral_count:\r\n        description: >-\r\n          sum of filter passing MS2 spectra associated with the peptide sequence within a given LC-MS/MS data file\r\n        range: integer\r\n      peptide_sum_masic_abundance:\r\n        description: >-\r\n          combined MS1 extracted ion chromatograms derived from MS2 spectra associated with the peptide sequence from a given LC-MS/MS data file using the MASIC tool\r\n        range: integer\r\n```\r\n\r\nThe issue is that  \"min(QValue)\", \"SpectralCount\",  \"sum(MASICAbundance)\", \"PeptideSequence\",  and \"BestProtein\" are unrecognized because they are not \"peptide_sequence\", \"best_protein\", \"min_q_value\", \"peptide_spectral_count\", \"peptide_sum_masic_abundance\"",
"body": "",
"body": "",
"body": "",
"body": "",
"body": "Closing this PR. We don't want to override the \"id\" field.",
"body": "",
"body": "nmdc-01.json now validates\r\nSee #236 ",
"body": "Fix schema issues for Froze_Core_2015_S2_0_10_7_Metab.json, feature-set.json, and nmdc-01.json.",
"body": "Okay, we need a separate collection for `MetagenomeAssembly` documents, akin to e.g. \"metabolomics_analysis_activity_set\" for `MetabolomicsAnalysisActivity` docs in order to have those extra metaG assembly columns pass though json schema validation. @wdduncan ? ",
"body": "and another collection for `ReadQCAnalysisActivity` documents to get in your Read QC table columns.",
"body": "...and another for `MetaproteomicsAnalysisActivity` documents to support metadata for those activities.",
"body": "@dwinston There is now a metaproteomics analysis activity set.  \r\nSee PR https://github.com/microbiomedata/nmdc-metadata/pull/239",
"body": "@jbeezley @dwinston added read QC analysis activity set to database schema.  \r\nSee PR https://github.com/microbiomedata/nmdc-metadata/pull/242\r\n",
"body": "In previous versions of the source data, the workflow execution activities contained extra attributes that I had made required columns.  These extra columns are missing from the latest data for read qc and metagenome assembly.\r\n\r\nThis is currently breaking ETL on these tables.  I could remove these attributes from my tables or make them nullable.  It mostly depends on what we want to be searchable/viewable on the portal.\r\n\r\nFor reference, these are the current schemas, everything below `execution_resource` is missing in both:\r\n\r\nRead QC\r\n```\r\n+--------------------+-----------------------------+-------------+\r\n| Column             | Type                        | Modifiers   |\r\n|--------------------+-----------------------------+-------------|\r\n| id                 | character varying           |  not null   |\r\n| name               | character varying           |  not null   |\r\n| type               | character varying           |  not null   |\r\n| git_url            | character varying           |  not null   |\r\n| started_at_time    | timestamp without time zone |  not null   |\r\n| ended_at_time      | timestamp without time zone |  not null   |\r\n| execution_resource | character varying           |  not null   |\r\n| input_read_count   | bigint                      |  not null   |\r\n| input_read_bases   | bigint                      |  not null   |\r\n| output_read_count  | bigint                      |  not null   |\r\n| output_read_bases  | bigint                      |  not null   |\r\n+--------------------+-----------------------------+-------------+\r\n```\r\n\r\nMetagenome assembly\r\n```\r\n+--------------------+-----------------------------+-------------+\r\n| Column             | Type                        | Modifiers   |\r\n|--------------------+-----------------------------+-------------|\r\n| id                 | character varying           |  not null   |\r\n| name               | character varying           |  not null   |\r\n| type               | character varying           |  not null   |\r\n| git_url            | character varying           |  not null   |\r\n| started_at_time    | timestamp without time zone |  not null   |\r\n| ended_at_time      | timestamp without time zone |  not null   |\r\n| execution_resource | character varying           |  not null   |\r\n| scaffolds          | bigint                      |  not null   |\r\n| contigs            | bigint                      |  not null   |\r\n| scaf_bp            | bigint                      |  not null   |\r\n| contig_bp          | bigint                      |  not null   |\r\n| scaf_N50           | bigint                      |  not null   |\r\n| scaf_L50           | bigint                      |  not null   |\r\n| ctg_N50            | bigint                      |  not null   |\r\n| ctg_L50            | bigint                      |  not null   |\r\n| scaf_N90           | bigint                      |  not null   |\r\n| scaf_L90           | bigint                      |  not null   |\r\n| ctg_N90            | bigint                      |  not null   |\r\n| ctg_L90            | bigint                      |  not null   |\r\n| scaf_max           | bigint                      |  not null   |\r\n| ctg_max            | bigint                      |  not null   |\r\n| scaf_n_gt50K       | bigint                      |  not null   |\r\n| scaf_l_gt50k       | bigint                      |  not null   |\r\n| scaf_pct_gt50K     | bigint                      |  not null   |\r\n| num_input_reads    | bigint                      |  not null   |\r\n| num_aligned_reads  | bigint                      |  not null   |\r\n| scaf_logsum        | double precision            |  not null   |\r\n| scaf_powsum        | double precision            |  not null   |\r\n| ctg_logsum         | double precision            |  not null   |\r\n| ctg_powsum         | double precision            |  not null   |\r\n| asm_score          | double precision            |  not null   |\r\n| gap_pct            | double precision            |  not null   |\r\n| gc_avg             | double precision            |  not null   |\r\n| gc_std             | double precision            |  not null   |\r\n+--------------------+-----------------------------+-------------+\r\n```\r\n\r\n@dwinston ",
"body": "@jbeezley I was wanting to check on the status of this ticket. Can I close it?\r\n",
"body": "I don't see them in mongo yet.",
"body": "@jbeezley can you clarify the exact nature of the `omics_processing` issue? It seems that those ids are biosample ids rather than data object ids, and referenced from the has_input field, i.e.\r\n\r\n```python\r\nimport os\r\n\r\nfrom dotenv import load_dotenv\r\nload_dotenv(os.path.expanduser(\"~/.nmdc_mongo.env\"))\r\n\r\nfrom nmdc_mongo import get_db\r\n\r\ndb_share = get_db(\"dwinston_share\")\r\n\r\nids_ops = \"\"\"\r\nigsn:IEWFS000A\r\nigsn:IEWFS000B\r\nigsn:IEWFS000I\r\nigsn:IEWFS000J\r\nigsn:IEWFS000K\r\nigsn:IEWFS0019\r\nigsn:IEWFS001A\r\nigsn:IEWFS001B\r\nigsn:IEWFS0001\r\nigsn:IEWFS0003\r\nigsn:IEWFS0005\r\nigsn:IEWFS0006\r\nigsn:IEWFS0007\r\nigsn:IEWFS0009\r\nigsn:IEWFS000D\r\nigsn:IEWFS000E\r\nigsn:IEWFS000F\r\nigsn:IEWFS000G\r\nigsn:IEWFS000L\r\nigsn:IEWFS000N\r\nigsn:IEWFS000O\r\nigsn:IEWFS000P\r\nigsn:IEWFS000R\r\nigsn:IEWFS000S\r\nigsn:IEWFS000U\r\nigsn:IEWFS000V\r\nigsn:IEWFS000X\r\nigsn:IEWFS000Z\r\nigsn:IEWFS0012\r\nigsn:IEWFS0015\r\nigsn:IEWFS0016\r\nigsn:IEWFS0018\r\nigsn:IEWFS001C\r\nigsn:IEWFS001D\r\nigsn:IEWFS001E\r\nigsn:IEWFS001F\r\nigsn:IEWFS001G\r\nigsn:IEWFS001H\r\nigsn:IEWFS0002\r\nigsn:IEWFS0004\r\nigsn:IEWFS0008\r\nigsn:IEWFS000C\r\nigsn:IEWFS000H\r\nigsn:IEWFS000Q\r\nigsn:IEWFS000W\r\nigsn:IEWFS000Y\r\nigsn:IEWFS0010\r\nigsn:IEWFS0011\r\nigsn:IEWFS0014\r\nigsn:IEWFS0017\r\nigsn:IEWFS0013\r\n\"\"\".strip().splitlines()\r\n\r\nlen(ids_ops) # 51\r\ndb_share.biosample_set.count_documents({\"id\": {\"$in\": ids_ops}}) # 51\r\n```\r\n\r\nAs for the metagenome annotation activity set docs, it does seem that the has_input field references data objects, and the 42 you list are missing data objects:\r\n\r\n```python\r\nids_mga = \"\"\"\r\nnmdc:7e0bb15dc62ea4a5ae94f51af347129f\r\nnmdc:6a455b07be6e9c6b3f0631858a8ade17\r\nnmdc:376cc399590f368eaf5a486087750077\r\nnmdc:fddf8cd12a559ba5c1dc7749ea6ffadb\r\nnmdc:6f83c763978b8cfccd1dbc3c1fff4976\r\nnmdc:fcc5bd82615fab43bb54006632862521\r\nnmdc:4b9b0f82bf50950ecf8b77d24a141565\r\nnmdc:8c96c0ddd734b2d7c3355a85fb478727\r\nnmdc:369be15c709557b137c6ad6994ced3e4\r\nnmdc:1f02bef68a0a71ecbb325dfdbff6ae85\r\nnmdc:44c38f11b62931b22a3e38e44e12a99b\r\nnmdc:8f6ed75bd49fa03502adbd7ec7c55a09\r\nnmdc:fd4e4871caef5352801a0d58b2fc5727\r\nnmdc:eb216db5f15b5982f60cb2c5f0f82b97\r\nnmdc:b8f11f271313ebce716edfe8a9650118\r\nnmdc:8ef63c54cbfef72c19733e48ad0d1961\r\nnmdc:18b8afd638a9bb80a633f138150b7edd\r\nnmdc:753162645bb37b64f3ef9c0b2ca8a935\r\nnmdc:3d2cc3c5ba651c5f92302ee5c1c0d36b\r\nnmdc:35280ee871ca08e52849a30f18c497b0\r\nnmdc:c8d6693287398701b91c4d194856d0f3\r\nnmdc:03c49b063726126a4526bc96c3f03078\r\nnmdc:0114daea61986c6cf6290657d1fa8ee0\r\nnmdc:157f619acb8d1af497dbd311bb0129e0\r\nnmdc:7455b386b754925ce055f8f585f6242c\r\nnmdc:8ec141e339b4bedc49fbef7236422bec\r\nnmdc:565eb354afc5db4ed502bb6dece91d03\r\nnmdc:88c54f9cd321218cfecdd844c999f402\r\nnmdc:957600e89955173435e9b35666e3f1d5\r\nnmdc:957a5665e44143eea0c3a99b5665a51d\r\nnmdc:690271181735467ff2f978d804ce4fee\r\nnmdc:af403f9e2180b4ee5f0d536f6130a50d\r\nnmdc:61f06a2309788ded26b1fdec53ca3791\r\nnmdc:ee594da0ca22271208e72ed9480b9878\r\nnmdc:f0bcb32cfb78fa6abb5be2ac7bd48284\r\nnmdc:d16c1df1b6eca2a3997c93250673c58d\r\nnmdc:e4cf91ffe121a58186e6f123f117e0c2\r\nnmdc:e7e7582466f2c7d419e1d03f0b529879\r\nnmdc:80e2cf75fff69f6111ea7a738fe68eac\r\nnmdc:18589f426c24e06ff58610dcd48f3bd9\r\nnmdc:59e944a5bd686bb1d85d9ad06356854a\r\nnmdc:bb14b03eb4a4e30fcea4b9faa98c08e0\r\n\"\"\".strip().splitlines()\r\n\r\ndb_share.metagenome_annotation_activity_set.count_documents({\"has_input\": {\"$in\": ids_mga}}) # 42\r\n\r\nids_ds = set(db_share.data_object_set.distinct(\"id\"))\r\nids_mga_all = set(db_share.metagenome_annotation_activity_set.distinct(\"has_input\"))\r\nlen(ids_mga_all - ids_ds) # 42\r\n```\r\n\r\nI don't know why they are missing. @dehays any ideas here?",
"body": "Yes, it appears as if the `omics_proccessing` issue has been resolved.  Now that I run the script again, I see two more missing data objects in the metaP collection:\r\n```\r\nnmdc:7bfe2f3c086105ffe665317a21af38d3\r\nnmdc:ff5f339ebacb8f723d133f3c2daff1bf\r\n```",
"body": "@jbeezley @dwinston  If I understand - the omics_processing (projects in Jon's schema) - references to Brodie biosamples (igsn ID biosamples) is no longer an issue.  Meaning those biosample docs are now there.\r\n\r\nBut there are still 42 metaG annotation and 2 metaP analysis that have has_input references to data objects that are not present.  \r\n\r\nMy idea on why they are not present is that they were not included in the provided data object JSON.  Donny - can you grab the IDs for the metaG annotation and metaP that reference the data object IDs above.  I can then follow up with Shane and Sam.",
"body": "Here you go, @dehays . The 2 missing metaP data objects are referenced by 33 metaP analysis docs. I noted also that each metaP analysis doc has three entries in its \"has_input\" array.\r\n\r\n```python\r\ndocs_metaG = list(\r\n    db_share.metagenome_annotation_activity_set.find({\r\n        \"has_input\": {\"$in\": ids_mga}}, [\"has_input\", \"id\"]\r\n    ))\r\nprint(len(docs_metaG), \"affected docs\")\r\n\r\nfor doc in docs_metaG:\r\n    print(\"metaG ID\", doc[\"id\"])\r\n    print(\"missing data_object ID\", doc[\"has_input\"][0])\r\n```\r\n```\r\n42 affected docs\r\nmetaG ID nmdc:c7e6625c228fb16c512a0ceefd10fdcf\r\nmissing data_object ID nmdc:3d2cc3c5ba651c5f92302ee5c1c0d36b\r\nmetaG ID nmdc:6dfdf838817c96138022176ec33de297\r\nmissing data_object ID nmdc:369be15c709557b137c6ad6994ced3e4\r\nmetaG ID nmdc:11592ec20682d5bc349b293ff6d61f9e\r\nmissing data_object ID nmdc:8ef63c54cbfef72c19733e48ad0d1961\r\nmetaG ID nmdc:1993a481f92d491d0550ae7c97233164\r\nmissing data_object ID nmdc:8ec141e339b4bedc49fbef7236422bec\r\nmetaG ID nmdc:a2eaeceb2f0a6b07083bdffd24e5f713\r\nmissing data_object ID nmdc:35280ee871ca08e52849a30f18c497b0\r\nmetaG ID nmdc:07ee3c5a879a27d082ee3e6f3518ca1b\r\nmissing data_object ID nmdc:8f6ed75bd49fa03502adbd7ec7c55a09\r\nmetaG ID nmdc:8c59b25253e4a63f0731b74909855e43\r\nmissing data_object ID nmdc:af403f9e2180b4ee5f0d536f6130a50d\r\nmetaG ID nmdc:a96c1578090a15845e5920f52dc01a44\r\nmissing data_object ID nmdc:957a5665e44143eea0c3a99b5665a51d\r\nmetaG ID nmdc:34472e64c7f249a6e1f2b0f9445b89d6\r\nmissing data_object ID nmdc:fcc5bd82615fab43bb54006632862521\r\nmetaG ID nmdc:ff1fe327ab9d07ae8affd29e3dbef16c\r\nmissing data_object ID nmdc:c8d6693287398701b91c4d194856d0f3\r\nmetaG ID nmdc:567e35cfffbc1e0ebc1e2c781ce726e3\r\nmissing data_object ID nmdc:fddf8cd12a559ba5c1dc7749ea6ffadb\r\nmetaG ID nmdc:e1952aad2afebadbac8eb462b6a84d2b\r\nmissing data_object ID nmdc:7455b386b754925ce055f8f585f6242c\r\nmetaG ID nmdc:647b163bdcb9528b8dcc8ab9b506c957\r\nmissing data_object ID nmdc:7e0bb15dc62ea4a5ae94f51af347129f\r\nmetaG ID nmdc:5c7d758a1ae4be3debf95de04fc0e50b\r\nmissing data_object ID nmdc:18b8afd638a9bb80a633f138150b7edd\r\nmetaG ID nmdc:7a119c050961e0618c731187dba892a5\r\nmissing data_object ID nmdc:88c54f9cd321218cfecdd844c999f402\r\nmetaG ID nmdc:dbce99ec57e05f3ff39af0223e3dbfee\r\nmissing data_object ID nmdc:61f06a2309788ded26b1fdec53ca3791\r\nmetaG ID nmdc:0e9fb1e720caf88f61ab8bc4d866af7e\r\nmissing data_object ID nmdc:6a455b07be6e9c6b3f0631858a8ade17\r\nmetaG ID nmdc:a1447564a93994425b47569f4110dce3\r\nmissing data_object ID nmdc:b8f11f271313ebce716edfe8a9650118\r\nmetaG ID nmdc:f19f53cba21dcecfd7c8fc0feac2277c\r\nmissing data_object ID nmdc:957600e89955173435e9b35666e3f1d5\r\nmetaG ID nmdc:ce0717d5f24e153fe33a42fec43b026b\r\nmissing data_object ID nmdc:8c96c0ddd734b2d7c3355a85fb478727\r\nmetaG ID nmdc:63bb43ea7f71db994f4c21b5d2ca7c3e\r\nmissing data_object ID nmdc:fd4e4871caef5352801a0d58b2fc5727\r\nmetaG ID nmdc:6aa6cb8058330eddc3c4ffe2418f96e2\r\nmissing data_object ID nmdc:ee594da0ca22271208e72ed9480b9878\r\nmetaG ID nmdc:51880e32d7564747a46f00854e071d32\r\nmissing data_object ID nmdc:6f83c763978b8cfccd1dbc3c1fff4976\r\nmetaG ID nmdc:530593ca6433c5a14a82f66f99837e84\r\nmissing data_object ID nmdc:03c49b063726126a4526bc96c3f03078\r\nmetaG ID nmdc:cf6b096e809a5e4c4718da5553686651\r\nmissing data_object ID nmdc:753162645bb37b64f3ef9c0b2ca8a935\r\nmetaG ID nmdc:adef6b4b4874adb135620a21f27a53b6\r\nmissing data_object ID nmdc:1f02bef68a0a71ecbb325dfdbff6ae85\r\nmetaG ID nmdc:f863d392fcda8b1873b80168a1d672ba\r\nmissing data_object ID nmdc:157f619acb8d1af497dbd311bb0129e0\r\nmetaG ID nmdc:4113345e630c2a4c9a3d535982a3480b\r\nmissing data_object ID nmdc:44c38f11b62931b22a3e38e44e12a99b\r\nmetaG ID nmdc:c64ec801a3898b29fa68eb83a23f18c9\r\nmissing data_object ID nmdc:eb216db5f15b5982f60cb2c5f0f82b97\r\nmetaG ID nmdc:b8f5351b114af34d5357646dbef04478\r\nmissing data_object ID nmdc:690271181735467ff2f978d804ce4fee\r\nmetaG ID nmdc:7ef7c51072a8fa8151571ab602d54277\r\nmissing data_object ID nmdc:0114daea61986c6cf6290657d1fa8ee0\r\nmetaG ID nmdc:200022c0672deff53cda040fee54b9e6\r\nmissing data_object ID nmdc:376cc399590f368eaf5a486087750077\r\nmetaG ID nmdc:c53e4c651cfd13ad8183925a92d7023a\r\nmissing data_object ID nmdc:565eb354afc5db4ed502bb6dece91d03\r\nmetaG ID nmdc:da77b0888e64217118bddd9ca88a5797\r\nmissing data_object ID nmdc:4b9b0f82bf50950ecf8b77d24a141565\r\nmetaG ID nmdc:994588e22bb440eefab12f51e8db6544\r\nmissing data_object ID nmdc:e4cf91ffe121a58186e6f123f117e0c2\r\nmetaG ID nmdc:18261bfa0823d43b13f74b931c13a1df\r\nmissing data_object ID nmdc:18589f426c24e06ff58610dcd48f3bd9\r\nmetaG ID nmdc:8cd14e5ca612bfe923e2d8f54da25fec\r\nmissing data_object ID nmdc:f0bcb32cfb78fa6abb5be2ac7bd48284\r\nmetaG ID nmdc:5b0dba88801b500203d5b763984251b7\r\nmissing data_object ID nmdc:e7e7582466f2c7d419e1d03f0b529879\r\nmetaG ID nmdc:3937b209cad2769633a309e8bd646a09\r\nmissing data_object ID nmdc:bb14b03eb4a4e30fcea4b9faa98c08e0\r\nmetaG ID nmdc:6ace961767fd864cda21d485bf5711a8\r\nmissing data_object ID nmdc:59e944a5bd686bb1d85d9ad06356854a\r\nmetaG ID nmdc:65ff4bf5e258bcbf8d9e0d956a32988a\r\nmissing data_object ID nmdc:d16c1df1b6eca2a3997c93250673c58d\r\nmetaG ID nmdc:50e40947cb4664d4b4163ab37f3d4103\r\nmissing data_object ID nmdc:80e2cf75fff69f6111ea7a738fe68eac\r\n```\r\n\r\nand \r\n\r\n```python\r\nids_metaP = \"\"\"\r\nnmdc:7bfe2f3c086105ffe665317a21af38d3\r\nnmdc:ff5f339ebacb8f723d133f3c2daff1bf\r\n\"\"\".strip().splitlines()\r\n\r\ndocs_metaP = list(\r\n    db_share.metaproteomics_analysis_activity_set.find({\r\n        \"has_input\": {\"$in\": ids_metaP}}, [\"has_input\", \"id\"]\r\n    ))\r\nprint(len(docs_metaP), \"affected docs\")\r\n\r\nfor doc in docs_metaP:\r\n    print(\"metaP ID\", doc[\"id\"])\r\n    print(\"missing data_object ID\", next(inp for inp in doc[\"has_input\"] if inp in ids_metaP))\r\n```\r\n```\r\n33 affected docs\r\nmetaP ID nmdc:e642e3d734849753562e09e7ec3c9caa\r\nmissing data_object ID nmdc:ff5f339ebacb8f723d133f3c2daff1bf\r\nmetaP ID nmdc:1bfd6e40ac02f766c6c45581e696ddf1\r\nmissing data_object ID nmdc:7bfe2f3c086105ffe665317a21af38d3\r\nmetaP ID nmdc:5041575072fa5dc7b7e4f42f95584968\r\nmissing data_object ID nmdc:7bfe2f3c086105ffe665317a21af38d3\r\nmetaP ID nmdc:8aa240e26ad9c9bc7fc77bb48d2fb0da\r\nmissing data_object ID nmdc:7bfe2f3c086105ffe665317a21af38d3\r\nmetaP ID nmdc:e7164af2295a144b0855d02643fb0cd9\r\nmissing data_object ID nmdc:7bfe2f3c086105ffe665317a21af38d3\r\nmetaP ID nmdc:81d5da75e9a8e8637f7aab3e4ff70f24\r\nmissing data_object ID nmdc:7bfe2f3c086105ffe665317a21af38d3\r\nmetaP ID nmdc:77e34889d1be229f3aff74d0b449d4e1\r\nmissing data_object ID nmdc:7bfe2f3c086105ffe665317a21af38d3\r\nmetaP ID nmdc:c254a4df8d62db7d128bb96a02011381\r\nmissing data_object ID nmdc:7bfe2f3c086105ffe665317a21af38d3\r\nmetaP ID nmdc:54c3eb3d3cec3f142f39bd5efff05c2f\r\nmissing data_object ID nmdc:7bfe2f3c086105ffe665317a21af38d3\r\nmetaP ID nmdc:9ce22398cc92e5c969769afaf611b137\r\nmissing data_object ID nmdc:7bfe2f3c086105ffe665317a21af38d3\r\nmetaP ID nmdc:1ec84045ca630dc2a5695a9a8e92f985\r\nmissing data_object ID nmdc:7bfe2f3c086105ffe665317a21af38d3\r\nmetaP ID nmdc:98ad100ae227a58340b72d74adacaea0\r\nmissing data_object ID nmdc:7bfe2f3c086105ffe665317a21af38d3\r\nmetaP ID nmdc:8ad20466b614a1c2fdfa8d66dcf86e38\r\nmissing data_object ID nmdc:7bfe2f3c086105ffe665317a21af38d3\r\nmetaP ID nmdc:b1ab4b501e9c5c70e593b384283f2270\r\nmissing data_object ID nmdc:7bfe2f3c086105ffe665317a21af38d3\r\nmetaP ID nmdc:e094cf2a26b4f2a95d27c480abe81717\r\nmissing data_object ID nmdc:7bfe2f3c086105ffe665317a21af38d3\r\nmetaP ID nmdc:ccba2d4d4c04fab0a8424de4c35f1645\r\nmissing data_object ID nmdc:7bfe2f3c086105ffe665317a21af38d3\r\nmetaP ID nmdc:174d4e2e75f34a25bc02b6bf02ddd01c\r\nmissing data_object ID nmdc:7bfe2f3c086105ffe665317a21af38d3\r\nmetaP ID nmdc:e2bf7a7250f26990dbda7c648d7a8cab\r\nmissing data_object ID nmdc:7bfe2f3c086105ffe665317a21af38d3\r\nmetaP ID nmdc:cb00d652d71e9a926acaaad2e70f0cfe\r\nmissing data_object ID nmdc:7bfe2f3c086105ffe665317a21af38d3\r\nmetaP ID nmdc:da3b4b60eabac7f3788e734bebae7f50\r\nmissing data_object ID nmdc:7bfe2f3c086105ffe665317a21af38d3\r\nmetaP ID nmdc:f60f4a40e7cb8fe91c6462c56b3ad0f7\r\nmissing data_object ID nmdc:7bfe2f3c086105ffe665317a21af38d3\r\nmetaP ID nmdc:a2daaa3a2fe532754062f275d0ddcf7c\r\nmissing data_object ID nmdc:7bfe2f3c086105ffe665317a21af38d3\r\nmetaP ID nmdc:777c6c3a1770492f0c7094ee813be6ab\r\nmissing data_object ID nmdc:7bfe2f3c086105ffe665317a21af38d3\r\nmetaP ID nmdc:b232dc4ec98e8304ed77e59dadbacab6\r\nmissing data_object ID nmdc:7bfe2f3c086105ffe665317a21af38d3\r\nmetaP ID nmdc:b68c2721cdae7f00fe6c3e4400fb0fbc\r\nmissing data_object ID nmdc:7bfe2f3c086105ffe665317a21af38d3\r\nmetaP ID nmdc:4a8df3938084893addbaf51464148c78\r\nmissing data_object ID nmdc:7bfe2f3c086105ffe665317a21af38d3\r\nmetaP ID nmdc:5032ce3634219b35e2c6d0a3ce84c0da\r\nmissing data_object ID nmdc:7bfe2f3c086105ffe665317a21af38d3\r\nmetaP ID nmdc:82ab2b5905d172a7afb023997258daf7\r\nmissing data_object ID nmdc:7bfe2f3c086105ffe665317a21af38d3\r\nmetaP ID nmdc:9fe6ce2a57be10eb6dcaa1cba462d905\r\nmissing data_object ID nmdc:7bfe2f3c086105ffe665317a21af38d3\r\nmetaP ID nmdc:4ca1a1f561f0eaeb1cb40a54eee6be9c\r\nmissing data_object ID nmdc:7bfe2f3c086105ffe665317a21af38d3\r\nmetaP ID nmdc:9ccef749be4e638942d0931511bdced8\r\nmissing data_object ID nmdc:7bfe2f3c086105ffe665317a21af38d3\r\nmetaP ID nmdc:018bc0905284928015d7ff11b4d073d1\r\nmissing data_object ID nmdc:7bfe2f3c086105ffe665317a21af38d3\r\nmetaP ID nmdc:ab0ad22df5f89ae652174f5d189305d5\r\nmissing data_object ID nmdc:7bfe2f3c086105ffe665317a21af38d3\r\n```\r\n",
"body": "There are several data objects missing from the mongo instance that are referenced by other objects.  None of these will break anything on the portal, but they will be missing from search results.\r\n\r\nThe following data_objects are referenced by omics_processing:\r\n```\r\nigsn:IEWFS000A\r\nigsn:IEWFS000B\r\nigsn:IEWFS000I\r\nigsn:IEWFS000J\r\nigsn:IEWFS000K\r\nigsn:IEWFS0019\r\nigsn:IEWFS001A\r\nigsn:IEWFS001B\r\nigsn:IEWFS0001\r\nigsn:IEWFS0003\r\nigsn:IEWFS0005\r\nigsn:IEWFS0006\r\nigsn:IEWFS0007\r\nigsn:IEWFS0009\r\nigsn:IEWFS000D\r\nigsn:IEWFS000E\r\nigsn:IEWFS000F\r\nigsn:IEWFS000G\r\nigsn:IEWFS000L\r\nigsn:IEWFS000N\r\nigsn:IEWFS000O\r\nigsn:IEWFS000P\r\nigsn:IEWFS000R\r\nigsn:IEWFS000S\r\nigsn:IEWFS000U\r\nigsn:IEWFS000V\r\nigsn:IEWFS000X\r\nigsn:IEWFS000Z\r\nigsn:IEWFS0012\r\nigsn:IEWFS0015\r\nigsn:IEWFS0016\r\nigsn:IEWFS0018\r\nigsn:IEWFS001C\r\nigsn:IEWFS001D\r\nigsn:IEWFS001E\r\nigsn:IEWFS001F\r\nigsn:IEWFS001G\r\nigsn:IEWFS001H\r\nigsn:IEWFS0002\r\nigsn:IEWFS0004\r\nigsn:IEWFS0008\r\nigsn:IEWFS000C\r\nigsn:IEWFS000H\r\nigsn:IEWFS000Q\r\nigsn:IEWFS000W\r\nigsn:IEWFS000Y\r\nigsn:IEWFS0010\r\nigsn:IEWFS0011\r\nigsn:IEWFS0014\r\nigsn:IEWFS0017\r\nigsn:IEWFS0013\r\n```\r\n\r\nAnd these are referenced by metagenome annotation:\r\n```\r\nnmdc:7e0bb15dc62ea4a5ae94f51af347129f\r\nnmdc:6a455b07be6e9c6b3f0631858a8ade17\r\nnmdc:376cc399590f368eaf5a486087750077\r\nnmdc:fddf8cd12a559ba5c1dc7749ea6ffadb\r\nnmdc:6f83c763978b8cfccd1dbc3c1fff4976\r\nnmdc:fcc5bd82615fab43bb54006632862521\r\nnmdc:4b9b0f82bf50950ecf8b77d24a141565\r\nnmdc:8c96c0ddd734b2d7c3355a85fb478727\r\nnmdc:369be15c709557b137c6ad6994ced3e4\r\nnmdc:1f02bef68a0a71ecbb325dfdbff6ae85\r\nnmdc:44c38f11b62931b22a3e38e44e12a99b\r\nnmdc:8f6ed75bd49fa03502adbd7ec7c55a09\r\nnmdc:fd4e4871caef5352801a0d58b2fc5727\r\nnmdc:eb216db5f15b5982f60cb2c5f0f82b97\r\nnmdc:b8f11f271313ebce716edfe8a9650118\r\nnmdc:8ef63c54cbfef72c19733e48ad0d1961\r\nnmdc:18b8afd638a9bb80a633f138150b7edd\r\nnmdc:753162645bb37b64f3ef9c0b2ca8a935\r\nnmdc:3d2cc3c5ba651c5f92302ee5c1c0d36b\r\nnmdc:35280ee871ca08e52849a30f18c497b0\r\nnmdc:c8d6693287398701b91c4d194856d0f3\r\nnmdc:03c49b063726126a4526bc96c3f03078\r\nnmdc:0114daea61986c6cf6290657d1fa8ee0\r\nnmdc:157f619acb8d1af497dbd311bb0129e0\r\nnmdc:7455b386b754925ce055f8f585f6242c\r\nnmdc:8ec141e339b4bedc49fbef7236422bec\r\nnmdc:565eb354afc5db4ed502bb6dece91d03\r\nnmdc:88c54f9cd321218cfecdd844c999f402\r\nnmdc:957600e89955173435e9b35666e3f1d5\r\nnmdc:957a5665e44143eea0c3a99b5665a51d\r\nnmdc:690271181735467ff2f978d804ce4fee\r\nnmdc:af403f9e2180b4ee5f0d536f6130a50d\r\nnmdc:61f06a2309788ded26b1fdec53ca3791\r\nnmdc:ee594da0ca22271208e72ed9480b9878\r\nnmdc:f0bcb32cfb78fa6abb5be2ac7bd48284\r\nnmdc:d16c1df1b6eca2a3997c93250673c58d\r\nnmdc:e4cf91ffe121a58186e6f123f117e0c2\r\nnmdc:e7e7582466f2c7d419e1d03f0b529879\r\nnmdc:80e2cf75fff69f6111ea7a738fe68eac\r\nnmdc:18589f426c24e06ff58610dcd48f3bd9\r\nnmdc:59e944a5bd686bb1d85d9ad06356854a\r\nnmdc:bb14b03eb4a4e30fcea4b9faa98c08e0\r\n```\r\n\r\n@dwinston ",
"body": "@dwinston @jbeezley   \r\nI change the name of the property in the schema to `principal investigator name`. See PR https://github.com/microbiomedata/nmdc-metadata/pull/240\r\n\r\nLet me know if this works.",
"body": "The principle investigator in not being included in the study data. Will debug as part of new GOLD ETL dump (see #189).\r\n\r\ncc @cmungall @dehays @dwinston ",
"body": "",
"body": "Fixes #230 ",
"body": "see #230 ",
"body": "sets to add:\r\n- [x] nom workflow execution activity set\r\n- [x] metabolomics analysis activity set\r\n- [x] read based analysis activity set",
"body": "In the `nmdc.yaml` add new `sets` to include more sets. I.e., expand the `slots` in the `database` class:\r\n```json\r\ndatabase:\r\n    aliases:\r\n      - \"NMDC metadata object\"\r\n    description: >-\r\n      An abstract holder for any set of metadata and data. It does not need to correspond to an actual managed databse\r\n      top level holder class. When translated to JSON-Schema this is the 'root' object.\r\n      It should contain pointers to other objects of interest\r\n    slots:\r\n      - biosample set\r\n      - study set\r\n      - data object set\r\n      - activity set\r\n      - mags activity set\r\n      - omics processing set\r\n      - functional annotation set\r\n      - genome feature set\r\n```\r\nAlso add new test files to the `examples` folder as needed.\r\n\r\n@dwinston @dehays @jbeezley @corilo @cmungall \r\nI'm going to add the examples posted in Slack, but if you could update this tickets with sets that I miss it would helpful for keeping information consolidated.",
"body": "",
"body": "Why is mongo utils in the `schema` directory?",
"body": "I was originally thinking of putting the helper utils in a python file, but I think it's fine for them to live in the notebook for now.",
"body": "You can put the helper functions in a`notebooks/lib` directory too. ",
"body": "",
"body": "@dwinston Do you have link to file I should look at to test with?",
"body": "Sure, https://nmdcdemo.emsl.pnnl.gov/metabolomics/metadata/Froze_Core_2015_S2_0_10_7_Metab.json",
"body": "'has_calibration' therein is not currently part of the schema but should be there as a string-typed id reference. @corilo array-typed, i.e. can the calibration be relative to multiple entities?",
"body": "@wdduncan changing the subject of this issue to accommodate a solution where another database \"set\" is introduced, e.g. MAGsAnalysisActivity has mags_activity_set",
"body": "No, it's always only relative to one entity\n\nEm sex., 22 de jan. de 2021 \u00e0s 12:56, Donny Winston <\nnotifications@github.com> escreveu:\n\n> 'has_calibration' therein is not currently part of the schema but should\n> be there as a string-typed id reference. @corilo\n> <https://github.com/corilo> array-typed, i.e. can the calibration be\n> relative to multiple entities?\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/microbiomedata/nmdc-metadata/issues/227#issuecomment-765679793>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AEFQWIS7KBA4IKL6MMEH3LTS3HRBVANCNFSM4WO67MYQ>\n> .\n>\n",
"body": "see also #230 ",
"body": "@dwinston I'm going to close this b/c our creation of different activity sets addresses this. Please re-open if you think this is still an issue.",
"body": "I think it's still an issue until e.g. #231 is merged. I won't re-open because I expect #231 to merge soon.\r\n\r\nEdit: ...and it's merged. :) Thanks.",
"body": "In the json schema, [activity_set](https://github.com/microbiomedata/nmdc-metadata/blob/6e0c5d1a2534eca59226b0a491cb25ee33d6676b/schema/nmdc.schema.json#L2018) is a list of references to `WorkflowExecutionActivity` objects. However, when a conceptual subclass such as `MetabolomicsAnalysisActivity` is checked for conformance, it is considered invalid by `jsonschema` if for example it has a [has_metabolite_quantifications](https://github.com/microbiomedata/nmdc-metadata/blob/6e0c5d1a2534eca59226b0a491cb25ee33d6676b/schema/nmdc.schema.json#L1002) field because `WorkflowExecutionActivity` specifies that `\"additionalProperties\": false`. Thus, `WorkflowExecutionActivity` should include a union of the properties of its subclasses.\r\n\r\nThis is an issue with conformance for the data of @corilo \r\n\r\n@wdduncan @cmungall what do you think?",
"body": "Enhance the MIxS documentation so that terms can be petitioned by package.\r\n\r\ncc @cmungall ",
"body": "Fixes #215 ",
"body": "@wdduncan the transformed nmdc database is accessible as the ['activity_set', 'biosample_set', 'data_object_set', 'foo', 'omics_processing_set', 'study_set'] collections of the 'dwinston_share' mongo db.",
"body": "Is Kitware grabbing the data from `dwinston_share`? ",
"body": "For #210 \r\n\r\n- [x] update the biosample objects to merge the GOLD RNA and DNA biosample objects into single objects. The new object will use the IGSN id provided.\r\n- [x] The omics_processing entities that previously referred to the pre-merge biosample objects would need to be updated to refer to the new post merge object, i.e. the one with the igsn id.\r\n- [x] the spreadsheet (referenced in #210) contains EMSL dataset IDs in column H that correspond to omics_processing entities (The omics_processing objects use the EMSL dataset ID as ID.). These need to reference the new (igsn-id'ed) biosample objects",
"body": "See #189",
"body": "This will take a bit of discussion. I dont think that are properties like id and name belong in prov. ",
"body": "Sure. You recently [added id and name to prov](https://github.com/microbiomedata/nmdc-metadata/commit/c760c6ff4c5e5d676ce0f4234238298e1ade3c6d), but I guess this was intended as temporary? I'm fine with id and name not being in prov -- it makes sense for prov to merely subset terms of <http://www.w3.org/ns/prov#> and not add anything else.",
"body": "so what I did was add these as class slots to the classes in prov, the\nfields are still defined in core\n\nthis is suboptimal for a modularization point of view as we have a\nreciprical dependency between prov and core. this is harmless so long as\nyou are using the root of the import chain (nmdc), which is what we care\nabout... but if you want to work with prov as a separate unit then you\ndon't have the fields declared and you get errors as you discovered\n\ntl;dr - not a big issue for now but we can fix later with better\nmodulatization!\n\nOn Sun, Jan 17, 2021 at 1:32 PM Donny Winston <notifications@github.com>\nwrote:\n\n> Sure. You recently added id and name to prov\n> <https://github.com/microbiomedata/nmdc-metadata/commit/c760c6ff4c5e5d676ce0f4234238298e1ade3c6d>,\n> but I guess this was intended as temporary? I'm fine with id and name not\n> being in prov -- it makes sense for prov to merely subset terms of\n> http://www.w3.org/ns/prov# and not add anything else.\n>\n> \u2014\n> You are receiving this because your review was requested.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/microbiomedata/nmdc-metadata/pull/222#issuecomment-761883707>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AAAMMOLYOMQPVTMVR3HFYTDS2NJOHANCNFSM4WGFPAUA>\n> .\n>\n",
"body": "Ah, now I understand the adding/definition distinction and how that relates to the dependency resolution. Agreed that nmdc.yml is the principal concern. Thanks for clarifying.",
"body": "not a priority. can revisit.",
"body": "To close biolink/biolinkml#333.\r\n\r\ngen-owl schema/{prov,core,nmdc}.yaml all work after this change (using `biolinkml==1.7.0`).",
"body": "todo for @wdduncan \r\n\r\n - [x] get test working on master again\r\n - [x] add remaining fields for MAGs activities and MAGs bins\r\n - [x] add examples/MAGs_activity.json to test suite\r\n\r\n",
"body": null,
"body": "add `mkdocs.yml` to files monitored by workflow.",
"body": "",
"body": "Fixes #217 ",
"body": "Modify the `mkdocs.yml` to include the identifier and validation docs.",
"body": "",
"body": "We may need to add an empty `ReadbasedAnalysis` analysis class. All the fields are the parent class.",
"body": "First we need a ReadBased Analysis Activity in the NMDC Schema (class and appropriate slots) to nmdc.yaml, and Second check that the following are valid and adequate\r\n\r\nhttps://portal.nersc.gov/cfs/m3408/meta/ReadbasedAnalysis_activity.json\r\nhttps://portal.nersc.gov/cfs/m3408/meta/ReadbasedAnalysis_activity_data_objects.json",
"body": "I believe this also needs a workflow execution activity added to the NMDC Schema",
"body": "@dehays The schema now has a `nom analysis activity set`. Can we close this ticket?",
"body": "yes",
"body": "Very similar to the metabolomics work that @corilo already did",
"body": "I believe this also needs a workflow execution activity added to the NMDC Schema",
"body": "I would imagine this to be similar to what @scanon did for the IMG metaG analysis activity and the annotation work #184 but the only related JSON I have seen is pynmdc/blob/main/src/nmdc/test_data/MetaT/metaT.json which is not NMDC Schema compliant (Not sure it is even meant to be.)",
"body": "None of the JSON for DataObjects in nmdc-metadata/blob/master/metadata-translation/src/data/nmdc_database.json.zip include the URL property necessary for downloading.  All fastq, raw EMSL, qc, assembly files that are intended for download need to be wrapped in DataObjects that include the URL property",
"body": "url is already present in DataObject https://microbiomedata.github.io/nmdc-metadata/DataObject/ - can we close this?",
"body": "@cmungall This issue is about instances of DataObject that have already been created and need to be updated based on information regarding file location.  As you say, URL is present in the schema - added this when I closed #173",
"body": "@scanon You are the person with the information necessary to do this update as you are the person who is setting the locations of files on CFS.  Is it on your radar to do this for the existing files - raw read fastq on down?  If needed, we can deal with the JSON object updates if you can provide the file/DataObject ID --> URL information.",
"body": "include URL values for all files supporting downloadability",
"body": "",
"body": "for omics_processing entities, only to-IGSN has_input IDs\r\n",
"body": "done via #224 ",
"body": "Currently - nmdc-metadata/blob/master/metadata-translation/src/data/nmdc_database.json.zip contains biosamples representing both RNA and DNA samples.  Sequencing omics_processing objects refer to these biosample objects.\r\n\r\nFor Brodie - we need to update the biosample objects to merge the GOLD RNA and DNA biosample objects into single objects.  The new object will use the IGSN id provided.\r\n\r\nhttps://docs.google.com/spreadsheets/d/19PH8F-YqTZ3oUoWg1vKtPKHZT9YznXoA\r\n\r\nThe omics_processing entities that previously referred to the pre merge biosample objects would need to be updated to refer to the new post merge object, i.e. the one with the igsn: ID\r\n\r\nAlso - the spreadsheet above contains EMSL dataset IDs in column H that correspond to omics_processing entitiies (The omics_processing objects use the EMSL dataset ID as ID.). These need to reference the new biosamples.\r\n\r\nThat is, all metaG, metaT and EMSL (In this case NOM) omics_processing entities need to reference the new IGSN ID'd samples according to the spreadsheet above",
"body": "",
"body": "Worked with @wdduncan on getting @scanon's examples in to the repo\r\n\r\n - copied the examples (an activity set and a data object set) from slack\r\n - added relevant \"holders\" (the top level object should be a dict with various lists; need to document this a bit better)\r\n - added these to the test suite\r\n - made changes to the schema in order for this to validate\r\n     - we mistakenly had the 'id' for 'activity' be 'activity_id'. Now fixed to 'id'\r\n     - workflow activities were being validated as activities, and so use of fields specific to workflow activities were not counted as valid. we made the activity list be a workflow activity list\r\n  ",
"body": "In the data object generated by NMDC the slot `url` conflicts with `mixs:url`.   \r\nThe range of `nmdc:url` is a string, whereas the range of `mixs:url` is an object.  \r\n\r\ncc @cmungall ",
"body": "",
"body": "Would a \"common list of reasons validation fails\" be helpful?  Sometimes the validation errors are non intuitive (the ones where a certain JSON object is referenced in another object show up as \"not found\" errors sometimes instead of a incorrect syntax for referencing the embedded object).   ",
"body": "",
"body": "After submitting the issue to GH, I was informed that deploying to gh-pages will timeout if the process takes longer that 10 min. Pasting in GH's suggestion about how to address our issue.\r\n\r\ncc @cmungall @deepakunni3 \r\n\r\nPasted content follows.\r\n---------------\r\n\r\nUnfortunately, it looks like your builds are timing out. I triggered a build myself and it, too, timed out. Pages builds have a strict 10 minute time limit, and the size or structure of a repository can cause build timeout problems.\r\n\r\nOur build process creates a fresh clone of your repository each time it is run, so it's likely that this is taking too long and is what's causing your build to fail. Your builds may be timing out due to the large number of files Jekyll is trying to parse. We recommend reducing the size of your repository and number of files, if at all possible. We would also recommend storing any permanent static assets on an external static file host or CDN.\r\n\r\nAlternatively, you can sometimes mitigate the impact of this timeout by disabling our Jekyll build process and pushing pre-built HTML files (i.e. what Jekyll creates locally in the _site directory). Ordinarily users take this approach when pushing files from other static site builders like Hugo, but you can pre-build your Jekyll files as well. To disable the Jekyll portion of the process, create an empty file named .nojekyll in the root of your publishing source. The idea is to do as much of the work outside of the GitHub page build process as possible, so that the page build process takes less time.\r\n\r\nThe Jekyll team has also published a tutorial for how you can pre-build and deploy using Actions:\r\n\r\nhttps://jekyllrb.com/docs/continuous-integration/github-actions/\r\n\r\nThe tutorial recommends an Action, but if you do a search there are actually several you could try.\r\n\r\nI do see that you were possibly already using Actions to deploy to the gh-pages branch, but I'm not familiar with the JamesIves/github-pages-deploy-action Action and how it works. You would need to make sure to use an Action that goes through the Jekyll build process and then pushes the built files to the gh-pages branch (or whichever branch you want to serve the site from) with a .nojekyll file. It doesn't look like that Action was doing so, but you may be able to configure it.\r\n\r\nSorry this is not a simple fix, but I hope this helps! Please let us know if you have further questions and we will be happy to assist.\r\n",
"body": "We have switched to using Mkdocs and this has fixed the issue. We can close.",
"body": "The GH actions for creating the documentation is timing out.",
"body": "Add comments to make use the workflow executes for the pull request.",
"body": "In the Makefile, change the extension of the owl products to have `owl.ttl` extenesion.\r\nE.g.:\r\n```\r\n# OWL\r\nschema/%.owl.ttl: schema/%.yaml env.lock\r\n        pipenv run gen-owl $< > $@.tmp && mv $@.tmp $@ && perl -pi -ne 's@prefix meta: <https://w3id.org/biolink/biolinkml/meta/>@prefix meta: <https://w3id.org/$*/>@' $@\r\n```\r\ncc @cmungall ",
"body": "",
"body": "",
"body": "Working on this. See #203 for details.",
"body": "fixed",
"body": "I tried a several links in the documentation and they all seemed broken. For example the following one from https://github.com/microbiomedata/nmdc-metadata/issues/184:\r\nhttps://microbiomedata.github.io/nmdc-metadata/docs/GeneProduct\r\n\r\nAnd this one from README.md:\r\nhttps://microbiomedata.github.io/nmdc-metadata\r\n\r\n",
"body": "uncomment secrets in deploy-documentation.yml",
"body": "change deploy-documentation.yml not use secrets",
"body": "As of Fall 2022 we have identifier rules for workflow outputs and those are documented [here](https://microbiomedata.github.io/nmdc-schema/identifiers/ )\r\nPlease reopen/open a new ticket if other work is needed. ",
"body": "see also #2 for the general issue\r\n\r\ncc @scanon to fill in details\r\n\r\nI would like to see documentation on IDs we use for\r\n\r\n - omics processing objects\r\n - data objects\r\n - objects created as part of workflows\r\n     - sequences/contigs/transcripts\r\n     - individual gene products and sequence feature elements\r\n - objects referenced as part of workflows\r\n     - KO terms, taxa etc",
"body": "@wdduncan do we have an easy way to tell which subset of MIxS is in the MIMAG subset\r\n\r\nMIMAG described here, with a link to S1 which has MIMAG terms - I believe these are all now in MIxS\r\nhttps://www.nature.com/articles/nbt.3893#MOESM9\r\n\r\n\r\n\r\n",
"body": "I don't think so. We have a mixs-rdf call on Jan. 11. Perhaps we should bring this up?",
"body": "@cmungall It looks like there is column named \"mimag\" under the checklists that can identify such terms.",
"body": "Need to represent MAG results. Here is an example.\r\n\r\n```json\r\n{\r\n        \"id\": \"nmdc:187e749319929d47e762542bec8d9f08\",\r\n        \"name\": \"MAGs activiity 1777_95818\",\r\n        \"was_informed_by\": \"gold:Gp0119849\",\r\n        \"started_at_time\": \"2021-01-06\",\r\n        \"ended_at_time\": \"2021-01-06\",\r\n        \"type\": \"nmdc:MAGsAnalysisActivity\",\r\n        \"execution_resource\": \"NERSC - Cori\",\r\n        \"git_url\": \"https://github.com/microbiomedata/metaMAGs/releases/tag/1.0.0\",\r\n        \"has_input\": [\r\n            \"nmdc:70fba0e579271c70e65c7ef5909958ed\",\r\n            \"nmdc:52e139e6493a510831aff8a1e9ad3fbb\",\r\n            \"nmdc:abab6020b6823a014799efa5a2833194\"\r\n        ],\r\n        \"has_output\": [\r\n            \"nmdc:52d0bc80f4af44b60382600f8d1df96a\",\r\n            \"nmdc:58e118423d401e4ed6fe77f2acbd249c\",\r\n            \"nmdc:3b786f91556086d5b2cbb5d997c2cb6a\",\r\n            \"nmdc:ba5e90fbe9ca46912d7137089bedd7c5\",\r\n            \"nmdc:d10adaba5c6bb1276638e9f75a3c7c57\",\r\n            \"nmdc:9bb237915d704f853ac0d8c078e35c16\",\r\n            \"nmdc:cf6b6a3b00114077bbc7946e35e2bc3f\"\r\n        ],\r\n        \"input_contig_num\": 12279,\r\n        \"too_short_contig_num\": 9846,\r\n        \"lowDepth_contig_num\": 0,\r\n        \"unbineed_contig_num\": 2030,\r\n        \"binned_contig_num\": 403,\r\n        \"mags_list\": [\r\n            {\r\n                \"bin_name\": \"bins.1\",\r\n                \"number_of_contig\": 92,\r\n                \"completeness\": 90.1,\r\n                \"contamination\": 0.0,\r\n                \"gene_count\": 1837,\r\n                \"bin_quality\": \"MQ\",\r\n                \"num_16s\": 0,\r\n                \"num_5s\": 2,\r\n                \"num_23s\": 0,\r\n                \"num_tRNA\": 0,\r\n                \"gtdbtk_domain\": \"Archaea\",\r\n                \"gtdbtk_phylum\": \"Euryarchaeota\",\r\n                \"gtdbtk_class\": \"Thermococci\",\r\n                \"gtdbtk_order\": \"Thermococcales\",\r\n                \"gtdbtk_family\": \"Thermococcaceae\",\r\n                \"gtdbtk_genus\": \"Thermococcus_A\",\r\n                \"gtdbtk_species\": \"Thermococcus_A sp000430485\"\r\n            },\r\n            {\r\n                \"bin_name\": \"bins.2\",\r\n                \"number_of_contig\": 7,\r\n                \"completeness\": 98.21,\r\n                \"contamination\": 1.79,\r\n                \"gene_count\": 1962,\r\n                \"bin_quality\": \"MQ\",\r\n                \"num_16s\": 1,\r\n                \"num_5s\": 1,\r\n                \"num_23s\": 1,\r\n                \"num_tRNA\": 0,\r\n                \"gtdbtk_domain\": \"Bacteria\",\r\n                \"gtdbtk_phylum\": \"Thermotogota\",\r\n                \"gtdbtk_class\": \"Thermotogae\",\r\n                \"gtdbtk_order\": \"Thermotogales\",\r\n                \"gtdbtk_family\": \"Thermotogaceae\",\r\n                \"gtdbtk_genus\": \"Thermotoga\",\r\n                \"gtdbtk_species\": \"Thermotoga petrophila\"\r\n            },\r\n            {\r\n                \"bin_name\": \"bins.3\",\r\n                \"number_of_contig\": 112,\r\n                \"completeness\": 19.3,\r\n                \"contamination\": 0.0,\r\n                \"gene_count\": 963,\r\n                \"bin_quality\": \"LQ\",\r\n                \"num_16s\": 1,\r\n                \"num_5s\": 0,\r\n                \"num_23s\": 0,\r\n                \"num_tRNA\": 0,\r\n                \"gtdbtk_domain\": null,\r\n                \"gtdbtk_phylum\": null,\r\n                \"gtdbtk_class\": null,\r\n                \"gtdbtk_order\": null,\r\n                \"gtdbtk_family\": null,\r\n                \"gtdbtk_genus\": null,\r\n                \"gtdbtk_species\": null\r\n            },\r\n            {\r\n                \"bin_name\": \"bins.4\",\r\n                \"number_of_contig\": 192,\r\n                \"completeness\": 47.54,\r\n                \"contamination\": 7.02,\r\n                \"gene_count\": 1571,\r\n                \"bin_quality\": \"LQ\",\r\n                \"num_16s\": 2,\r\n                \"num_5s\": 0,\r\n                \"num_23s\": 0,\r\n                \"num_tRNA\": 0,\r\n                \"gtdbtk_domain\": null,\r\n                \"gtdbtk_phylum\": null,\r\n                \"gtdbtk_class\": null,\r\n                \"gtdbtk_order\": null,\r\n                \"gtdbtk_family\": null,\r\n                \"gtdbtk_genus\": null,\r\n                \"gtdbtk_species\": null\r\n            }\r\n        ]\r\n}\r\n```\r\ncc @cmungall @chienchi @dehays ",
"body": "@wdduncan  As far as I can tell - this is a duplicate of #194 - consider closing this one and keeping #194 as it has comments",
"body": "nice catch @dehays !\r\nNot sure how this happened. Going to close issue.",
"body": "Need to represent MAG results. Here is an example.\r\n\r\n```json\r\n{\r\n        \"id\": \"nmdc:187e749319929d47e762542bec8d9f08\",\r\n        \"name\": \"MAGs activiity 1777_95818\",\r\n        \"was_informed_by\": \"gold:Gp0119849\",\r\n        \"started_at_time\": \"2021-01-06\",\r\n        \"ended_at_time\": \"2021-01-06\",\r\n        \"type\": \"nmdc:MAGsAnalysisActivity\",\r\n        \"execution_resource\": \"NERSC - Cori\",\r\n        \"git_url\": \"https://github.com/microbiomedata/metaMAGs/releases/tag/1.0.0\",\r\n        \"has_input\": [\r\n            \"nmdc:70fba0e579271c70e65c7ef5909958ed\",\r\n            \"nmdc:52e139e6493a510831aff8a1e9ad3fbb\",\r\n            \"nmdc:abab6020b6823a014799efa5a2833194\"\r\n        ],\r\n        \"has_output\": [\r\n            \"nmdc:52d0bc80f4af44b60382600f8d1df96a\",\r\n            \"nmdc:58e118423d401e4ed6fe77f2acbd249c\",\r\n            \"nmdc:3b786f91556086d5b2cbb5d997c2cb6a\",\r\n            \"nmdc:ba5e90fbe9ca46912d7137089bedd7c5\",\r\n            \"nmdc:d10adaba5c6bb1276638e9f75a3c7c57\",\r\n            \"nmdc:9bb237915d704f853ac0d8c078e35c16\",\r\n            \"nmdc:cf6b6a3b00114077bbc7946e35e2bc3f\"\r\n        ],\r\n        \"input_contig_num\": 12279,\r\n        \"too_short_contig_num\": 9846,\r\n        \"lowDepth_contig_num\": 0,\r\n        \"unbineed_contig_num\": 2030,\r\n        \"binned_contig_num\": 403,\r\n        \"mags_list\": [\r\n            {\r\n                \"bin_name\": \"bins.1\",\r\n                \"number_of_contig\": 92,\r\n                \"completeness\": 90.1,\r\n                \"contamination\": 0.0,\r\n                \"gene_count\": 1837,\r\n                \"bin_quality\": \"MQ\",\r\n                \"num_16s\": 0,\r\n                \"num_5s\": 2,\r\n                \"num_23s\": 0,\r\n                \"num_tRNA\": 0,\r\n                \"gtdbtk_domain\": \"Archaea\",\r\n                \"gtdbtk_phylum\": \"Euryarchaeota\",\r\n                \"gtdbtk_class\": \"Thermococci\",\r\n                \"gtdbtk_order\": \"Thermococcales\",\r\n                \"gtdbtk_family\": \"Thermococcaceae\",\r\n                \"gtdbtk_genus\": \"Thermococcus_A\",\r\n                \"gtdbtk_species\": \"Thermococcus_A sp000430485\"\r\n            },\r\n            {\r\n                \"bin_name\": \"bins.2\",\r\n                \"number_of_contig\": 7,\r\n                \"completeness\": 98.21,\r\n                \"contamination\": 1.79,\r\n                \"gene_count\": 1962,\r\n                \"bin_quality\": \"MQ\",\r\n                \"num_16s\": 1,\r\n                \"num_5s\": 1,\r\n                \"num_23s\": 1,\r\n                \"num_tRNA\": 0,\r\n                \"gtdbtk_domain\": \"Bacteria\",\r\n                \"gtdbtk_phylum\": \"Thermotogota\",\r\n                \"gtdbtk_class\": \"Thermotogae\",\r\n                \"gtdbtk_order\": \"Thermotogales\",\r\n                \"gtdbtk_family\": \"Thermotogaceae\",\r\n                \"gtdbtk_genus\": \"Thermotoga\",\r\n                \"gtdbtk_species\": \"Thermotoga petrophila\"\r\n            },\r\n            {\r\n                \"bin_name\": \"bins.3\",\r\n                \"number_of_contig\": 112,\r\n                \"completeness\": 19.3,\r\n                \"contamination\": 0.0,\r\n                \"gene_count\": 963,\r\n                \"bin_quality\": \"LQ\",\r\n                \"num_16s\": 1,\r\n                \"num_5s\": 0,\r\n                \"num_23s\": 0,\r\n                \"num_tRNA\": 0,\r\n                \"gtdbtk_domain\": null,\r\n                \"gtdbtk_phylum\": null,\r\n                \"gtdbtk_class\": null,\r\n                \"gtdbtk_order\": null,\r\n                \"gtdbtk_family\": null,\r\n                \"gtdbtk_genus\": null,\r\n                \"gtdbtk_species\": null\r\n            },\r\n            {\r\n                \"bin_name\": \"bins.4\",\r\n                \"number_of_contig\": 192,\r\n                \"completeness\": 47.54,\r\n                \"contamination\": 7.02,\r\n                \"gene_count\": 1571,\r\n                \"bin_quality\": \"LQ\",\r\n                \"num_16s\": 2,\r\n                \"num_5s\": 0,\r\n                \"num_23s\": 0,\r\n                \"num_tRNA\": 0,\r\n                \"gtdbtk_domain\": null,\r\n                \"gtdbtk_phylum\": null,\r\n                \"gtdbtk_class\": null,\r\n                \"gtdbtk_order\": null,\r\n                \"gtdbtk_family\": null,\r\n                \"gtdbtk_genus\": null,\r\n                \"gtdbtk_species\": null\r\n            }\r\n        ]\r\n}\r\n```\r\ncc @cmungall @chienchi @dehays ",
"body": "this is great, thanks!\r\n\r\nI suggest as a follow up\r\n\r\n 1. add a superclass that groups the pep/pro quantification\r\n 2. we declare the slots as standalone entities to avoid repetion (don't worry about this!)\r\n\r\nIt seems I need to articulate why I want to do 1, based on convo with Sam in slack..",
"body": "Adding protein quantification section",
"body": "Updating peptide quantification entries",
"body": "adds url slot to data object class",
"body": "The schema for the GOLD data dump `GOLD_NMDC_DUMP_10162020.zip` has changed.  Need to modify ETL scripts.\r\n",
"body": "@cmungall \r\nI have forked the repo and I am testing GH actions here:\r\nhttps://github.com/wdduncan/nmdc-metadata",
"body": "GH actions have implemented for pull requests.",
"body": "Migrate to Github Actions from Travis for CI/CD.",
"body": "incremental change #169",
"body": "This PR adds a GFF3 to NMDC JSON converter.\r\n\r\nCC'ing @cmungall ",
"body": "",
"body": "Thanks so much, @cmungall . This is really helpful. Yes, col 9 is the annotation column. I have looked into the Python source code that is generated from the schema file and created a separate repository  (microbiomedata/pynmdc) so that people can try out the code easily. You, @wdduncan @scanon have been added to this repo, among a few others. \r\n\r\n**What I need help with is how to:**\r\n\r\n1. Translate 'CDS' to 'SO:0000316,' which is a ControlledTermValue?\r\n2. Transliate other features in annotation to ControlledTermValue?\r\n3. Define \"encodes\" in \"GeneProduct\"\r\n\r\nThanks!",
"body": "I was able to get the string \"SO:0000316\" from the [SO-Ontologies](https://github.com/The-Sequence-Ontology/SO-Ontologies/tree/master/Ontology_Files) but I still need to see an example of how to parse the correct mapping object to \"type.\" Thanks, @cmungall @wdduncan. ",
"body": "@hubin-keio - all you need to do is fill in the SO ID for the type. Let me know if you want help mapping other types (will we have other types than CDS?)\r\n\r\nFor 3, 'encodes' is the relationship between a feature like a CDS and the protein",
"body": "Thanks, @cmungall.  I tried it using the schema (nmdc.py). Below is the code and error message:\r\n\r\n nmdc_gf = schema.GenomeFeature(\r\n                        seqid=f'NMDC:{rec.id}',  # record id\r\n                        start=feature_start,\r\n                        end=feature_end,\r\n                        strand=feature_strand,\r\n                        type='SO:0000316',\r\n                        encodes=f'NMDC:{feature_id}'  # feature id # FIXME\r\n                    )\r\n\r\nERROR: test_GenomeFeature (__main__.testMetadata)\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"/home/hu/Projects/NMDC/pynmdc/src/nmdc/tests/test_testadata.py\", line 55, in test_GenomeFeature\r\n    encodes=f'NMDC:{feature_id}'  # feature id # FIXME\r\n  File \"<string>\", line 10, in __init__\r\n  File \"/home/hu/Projects/NMDC/pynmdc/src/nmdc/metadata/schema.py\", line 1561, in __post_init__\r\n    self.type = ControlledTermValue(**self.type)\r\nTypeError: type object argument after ** must be a mapping, not str\r\n",
"body": "Ah good catch, it looks like the schema was using a [ControlledTermValue](https://microbiomedata.github.io/nmdc-metadata/docs/ControlledTermValue) class which is a container for a [OntologyClass](https://microbiomedata.github.io/nmdc-metadata/docs/OntologyClass.html). I'm fixing to just use OntologyClass directly. With my PR your code should work\r\n\r\n(the point of the container class is for biosample attributes, where every attribute assignment has specific provenance attached, and also allows storage of unnormalized string forms of structured values)\r\n\r\nAside: I didn't know you were using the python object model - great! But if you like you can just create json objects directly with Python dicts, the choice is yours.",
"body": "Thanks. I just checked out branch issue-184-cv and it solved the problem of assigning string value to \"type.\" For the other properties, how do I assign other features/properties to GenomeFeature objects, @cmungall ? Using the example you provided above, these features are pasted below. I was thinking using the Python Object Model generated from the schema may provide better data consistency. I can add separate functions to translate GenomeFeature objects to JSON.\r\n\r\n        ID => ['Ga0185794_41_48_1037']\r\n\ttranslation_table => ['11']\r\n\tstart_type => ['ATG']\r\n\tproduct => ['5-methylthioadenosine/S-adenosylhomocysteine deaminase']\r\n\tproduct_source => ['KO:K12960']\r\n\tcath_funfam => ['3.20.20.140']\r\n\tcog => ['COG0402']\r\n\tko => ['KO:K12960']\r\n\tec_number => ['EC:3.5.4.28', 'EC:3.5.4.31']\r\n\tpfam => ['PF01979']\r\n\tsuperfamily => ['51338', '51556']\r\n\tsource => ['GeneMark.hmm-2 v1.05']\r\n\tscore => ['56.13']\r\n\tphase => ['0']\r\n",
"body": "Currently the schema doesn't support translation table, start_type. I don't see a use case for these in the immediate future so I just we proceed incrementally - don't include in the json for now, and return to this later.\r\n\r\nFor the source field, we have a provenance model (prov). If it's OK I'll return to describing how to fit in the program used for prediction into this. We'll also want to record provenance on each individual functional annotation (whether it comes from prokka, an hmm, ...) but again I suggest returning to this.\r\n\r\nFor all of the functional annotations, I suggest we use IDs using standardized identifiers.org / n2t.net prefixes. These are included in the yaml and also visible on the html docs.\r\n\r\nE.g.\r\n\r\nhttps://microbiomedata.github.io/nmdc-metadata/docs/OrthologyGroup\r\n\r\n```\r\nIdentifier prefixes\r\nKEGG.ORTHOLOGY\r\nEGGNOG\r\nPFAM\r\nTIGRFAM\r\nSUPFAM\r\nPANTHER.FAMILY\r\n```\r\n\r\nso rather than KO:K12960 we would use the more standard KEGG.ORTHOLOGY:K12960\r\n\r\nTip for aim3: all identifiers in NMDC should be resolvable via identifiers.org or n2t.net\r\n\r\nE.g. http://identifiers.org/KEGG.ORTHOLOGY:K12960\r\n\r\n http://identifiers.org/CATH:3.20.20.140",
"body": "`superfamily => ['51338', '51556']`\r\n\r\nis this correct?\r\n\r\nhttp://supfam.org/SUPERFAMILY/51338\r\n\r\ngives 404\r\n\r\nis it this?\r\nhttps://registry.identifiers.org/registry/supfam\r\n\r\nor this?\r\nhttps://registry.identifiers.org/registry/cath.superfamily",
"body": "on the call I volunteered me/@deepakunni3 to help @hubin-keio with the gff->json transform\r\n\r\nto help we would need some sample gff3 files. This is what I have from a random img analysis, is this representative?\r\n\r\n```\r\nGa0185794_01    GeneMark.hmm-2 v1.05    CDS     2       217     9.84    -       0       ID=Ga0185794_01_2_217;translation_table=11;partial=3';start_type=ATG;product=isoaspartyl peptidase/L-asparaginase-like protein (Ntn-hydrolase superfamily);product_source=COG1446;cog=COG1446;pfam=PF01112;superfamily=56235\r\nGa0185794_01    GeneMark.hmm-2 v1.05    CDS     249     1208    52.49   +       0       ID=Ga0185794_01_249_1208;translation_table=11;start_type=TTG;product=hypothetical protein;product_source=Hypo-rule applied;superfamily=56784\r\nGa0185794_01    GeneMark.hmm-2 v1.05    CDS     1388    2383    46.14   +       0       ID=Ga0185794_01_1388_2383;translation_table=11;start_type=ATG;product=large subunit ribosomal protein L3;product_source=KO:K02906;cath_funfam=4.10.960.10;cog=COG0087;ko=KO:K02906;pfam=PF00297;superfamily=50447;tigrfam=TIGR03626\r\nGa0185794_01    GeneMark.hmm-2 v1.05    CDS     2399    3199    47.65   +       0       ID=Ga0185794_01_2399_3199;translation_table=11;start_type=TTG;product=large subunit ribosomal protein L4e;product_source=KO:K02930;cath_funfam=3.40.1370.10;cog=COG0088;ko=KO:K02930;pfam=PF00573;superfamily=52166;tigrfam=TIGR03672\r\nGa0185794_01    GeneMark.hmm-2 v1.05    CDS     3271    3498    11.41   +       0       ID=Ga0185794_01_3271_3498;translation_table=11;start_type=ATG;product=large subunit ribosomal protein L23;product_source=KO:K02892;cath_funfam=3.30.70.330;cog=COG0089;ko=KO:K02892;pfam=PF00276;superfamily=54189;tigrfam=TIGR03636\r\nGa0185794_01    GeneMark.hmm-2 v1.05    CDS     3511    4266    32.58   +       0       ID=Ga0185794_01_3511_4266;translation_table=11;start_type=ATG;product=large subunit ribosomal protein L2;product_source=KO:K02886;cath_funfam=2.30.30.30,2.40.50.140,4.10.950.10;cog=COG0090;ko=KO:K02886;pfam=PF00181,PF03947;smart=SM01382,SM01383;superfamily=50104,50249\r\nGa0185794_01    GeneMark.hmm-2 v1.05    CDS     4402    4995    48.79   -       0       ID=Ga0185794_01_4402_4995;translation_table=11;start_type=GTG;product=hypothetical protein;product_source=Hypo-rule applied;pfam=PF07691;superfamily=49785\r\nGa0185794_01    GeneMark.hmm-2 v1.05    CDS     5123    5308    3.46    -       0       ID=Ga0185794_01_5123_5308;translation_table=11;start_type=ATG;product=hypothetical protein;product_source=Hypo-rule applied;cath_funfam=3.30.565.10;superfamily=53335\r\nGa0185794_01    Prodigal v2.6.3 CDS     5378    5494    2.3     -       0       ID=Ga0185794_01_5378_5494;translation_table=11;start_type=ATG;product=2-polyprenyl-6-methoxyphenol hydroxylase-like FAD-dependent oxidoreductase;product_source=COG0654;cath_funfam=3.50.50.60;cog=COG0654;superfamily=51905\r\nGa0185794_01    GeneMark.hmm-2 v1.05    CDS     6206    7969    83.73   +       0       ID=Ga0185794_01_6206_7969;translation_table=11;start_type=ATG;product=hypothetical protein;product_source=Hypo-rule applied;smart=SM00933\r\nGa0185794_01    GeneMark.hmm-2 v1.05    CDS     8028    9782    88.16   +       0       ID=Ga0185794_01_8028_9782;translation_table=11;start_type=TTG;product=DNA helicase HerA-like ATPase;product_source=COG0433;cath_funfam=3.40.50.300;cog=COG0433;ko=KO:K06915;pfam=PF01935;superfamily=52540\r\nGa0185794_01    GeneMark.hmm-2 v1.05    CDS     9902    10324   15.37   +       0       ID=Ga0185794_01_9902_10324;translation_table=11;start_type=TTG;product=small subunit ribosomal protein S19;product_source=KO:K02965;cath_funfam=3.30.860.10;cog=COG0185;ko=KO:K02965;pfam=PF00203;superfamily=54570;tigrfam=TIGR01025\r\nGa0185794_01    GeneMark.hmm-2 v1.05    CDS     10406   10894   28.90   +       0       ID=Ga0185794_01_10406_10894;translation_table=11;start_type=TTG;product=nicotinamide-nucleotide adenylyltransferase;product_source=KO:K00952;cath_funfam=3.40.50.620;cog=COG1056;ko=KO:K00952;ec_number=EC:2.7.7.1;pfam=PF01467;superfamily=52374;tigrfam=TIGR01527\r\nGa0185794_01    GeneMark.hmm-2 v1.05    CDS     10910   11443   29.86   -       0       ID=Ga0185794_01_10910_11443;translation_table=11;start_type=ATG;product=O-acetyl-ADP-ribose deacetylase (regulator of RNase III);product_source=COG2110;cath_funfam=3.40.220.10;cog=COG2110;pfam=PF01661;smart=SM00506;superfamily=52949\r\nGa0185794_01    GeneMark.hmm-2 v1.05    CDS     11479   11637   1.91    -       0       ID=Ga0185794_01_11479_11637;translation_table=11;start_type=ATG;product=hypothetical protein;product_source=Hypo-rule applied\r\nGa0185794_01    GeneMark.hmm-2 v1.05    CDS     11886   14015   139.12  +       0       ID=Ga0185794_01_11886_14015;translation_table=11;start_type=ATG;product=ATP-binding cassette subfamily C protein;product_source=KO:K06148;cath_funfam=1.20.1560.10,2.30.29.50,3.40.50.300;cog=COG1132;ko=KO:K06148;pfam=PF00005,PF00664,PF14470;smart=SM00382;superfamily=50729,52540\r\nGa0185794_01    GeneMark.hmm-2 v1.05    CDS     14021   14530   15.91   +       0       ID=Ga0185794_01_14021_14530;translation_table=11;start_type=ATG;product=hypothetical protein;product_source=Hypo-rule applied;pfam=PF08909\r\nGa0185794_01    GeneMark.hmm-2 v1.05    CDS     14729   15001   1.01    -       0       ID=Ga0185794_01_14729_15001;translation_table=11;start_type=ATG;product=hypothetical protein;product_source=Hypo-rule applied\r\nGa0185794_01    GeneMark.hmm-2 v1.05    CDS     14998   15921   65.79   -       0       ID=Ga0185794_01_14998_15921;translation_table=11;start_type=TTG;product=aspartate carbamoyltransferase catalytic subunit;product_source=KO:K00609;cath_funfam=3.40.50.1370;cog=COG0540;ko=KO:K00609;ec_number=EC:2.1.3.2;pfam=PF00185,PF02729;superfamily=53671;tigrfam=TIGR00670\r\nGa0185794_01    GeneMark.hmm-2 v1.05    CDS     16069   16869   43.95   -       0       ID=Ga0185794_01_16069_16869;translation_table=11;start_type=ATG;product=D-amino peptidase;product_source=KO:K16203;cath_funfam=3.30.1360.130,3.40.50.10780;cog=COG2362;ko=KO:K16203;ec_number=EC:3.4.11.-;pfam=PF04951;superfamily=63992\r\nGa0185794_01    GeneMark.hmm-2 v1.05    CDS     17103   18191   67.60   +       0       ID=Ga0185794_01_17103_18191;translation_table=11;start_type=TTG;product=tryptophanyl-tRNA synthetase;product_source=KO:K01867;cath_funfam=1.10.240.10,3.40.50.620;cog=COG0180;ko=KO:K01867;ec_number=EC:6.1.1.2;pfam=PF00579;superfamily=52374;tigrfam=TIGR00233\r\nGa0185794_01    GeneMark.hmm-2 v1.05    CDS     18195   19700   119.58  +       0       ID=Ga0185794_01_18195_19700;translation_table=11;start_type=TTG;product=phenylalanyl-tRNA synthetase alpha chain;product_source=KO:K01889;cath_funfam=3.30.930.10;cog=COG0016;ko=KO:K01889;ec_number=EC:6.1.1.20;pfam=PF01409;superfamily=46785,55681;tigrfam=TIGR00468\r\nGa0185794_01    GeneMark.hmm-2 v1.05    CDS     19706   21400   105.79  +       0       ID=Ga0185794_01_19706_21400;translation_table=11;start_type=ATG;product=phenylalanyl-tRNA synthetase beta chain;product_source=KO:K01890;cath_funfam=3.30.56.10,3.30.930.10,3.50.40.10;cog=COG0072;ko=KO:K01890;ec_number=EC:6.1.1.20;pfam=PF03483,PF03484;smart=SM00873;superfamily=55681,56037;tigrfam=TIGR00471\r\n```",
"body": "@cmungall  Here are a a few of the 138661 lines of 1781_1000325_functional_annotation.gff (from /global/project/projectdirs/m3408/ficus/pipeline_products/1781_100325/annotation/ ).  This for one of the current Stegen metaG annotation workflow outputs.\r\n\r\n```\r\n1781_100325_scf_1000_c1 GeneMark.hmm-2 v1.05    CDS     3       1700    192.32  +       0       ID=1781_100325_scf_1000_c1_3_1700;translation_table=11;partial=5',3';product=PAS domain S-box-containing protein;product_source=TIGR00229;cath_funfam=3.30.450.20;cog=COG2202;pfam=GA,PA,PAS_;smart=55781,55785;superfamily=SM00086,SM00091;tigrfam=TIGR00229\r\n1781_100325_scf_1001_c1 GeneMark.hmm-2 v1.05    CDS     82      573     13.74   +       0       ID=1781_100325_scf_1001_c1_82_573;translation_table=11;product=uncharacterized membrane protein;product_source=COG2237;cog=COG2237\r\n1781_100325_scf_1001_c1 GeneMark.hmm-2 v1.05    CDS     859     1671    32.29   -       0       ID=1781_100325_scf_1001_c1_859_1671;translation_table=11;product=hypothetical protein;product_source=Hypo-rule applied\r\n1781_100325_scf_1002_c1 GeneMark.hmm-2 v1.05    CDS     1       99      0.46    +       0       ID=1781_100325_scf_1002_c1_1_99;translation_table=11;partial=5';product=large subunit ribosomal protein L18;product_source=KO:K02881;ko=KO:K02881\r\n1781_100325_scf_1002_c1 GeneMark.hmm-2 v1.05    CDS     96      731     37.60   +       0       ID=1781_100325_scf_1002_c1_96_731;translation_table=11;product=small subunit ribosomal protein S5;product_source=KO:K02988;cath_funfam=3.30.160.20,3.30.230.10;cog=COG0098;ko=KO:K02988;pfam=Ribosomal_S,Ribosomal_S5_;smart=54211,54768;tigrfam=TIGR01020\r\n1781_100325_scf_1002_c1 GeneMark.hmm-2 v1.05    CDS     765     1205    25.99   +       0       ID=1781_100325_scf_1002_c1_765_1205;translation_table=11;product=large subunit ribosomal protein L30;product_source=KO:K02907;cath_funfam=3.30.1390.20;cog=COG1841;ko=KO:K02907;pfam=Ribosomal_L3;smart=55129;tigrfam=TIGR01309\r\n1781_100325_scf_1002_c1 GeneMark.hmm-2 v1.05    CDS     1207    1629    20.09   +       0       ID=1781_100325_scf_1002_c1_1207_1629;translation_table=11;product=large subunit ribosomal protein L15;product_source=KO:K02876;cath_funfam=3.100.10.10,4.10.990.10;cog=COG0200;ko=KO:K02876;pfam=Ribosomal_L27;smart=52080\r\n1781_100325_scf_1002_c1 Prodigal v2.6.3 CDS     1626    1700    -4.7    +       0       ID=1781_100325_scf_1002_c1_1626_1700;translation_table=11;partial=3';product=hypothetical protein;product_source=Hypo-rule applied\r\n1781_100325_scf_1003_c1 GeneMark.hmm-2 v1.05    CDS     1       543     44.68   -       0       ID=1781_100325_scf_1003_c1_1_543;translation_table=11;partial=3';product=drug/metabolite transporter (DMT)-like permease;product_source=COG0697;cog=COG0697;pfam=Eam;smart=103481\r\n1781_100325_scf_1003_c1 GeneMark.hmm-2 v1.05    CDS     597     1697    97.45   +       0       ID=1781_100325_scf_1003_c1_597_1697;translation_table=11;partial=3';product=phosphoribosylformylglycinamidine synthase;product_source=KO:K01952;cath_funfam=3.30.1330.10,3.90.650.10;cog=COG0046;ko=KO:K01952;ec_number=EC:6.3.5.3;pfam=AIR,AIRS_;smart=55326,56042;tigrfam=TIGR01736\r\n1781_100325_scf_1004_c1 GeneMark.hmm-2 v1.05    CDS     1       255     8.85    -       0       ID=1781_100325_scf_1004_c1_1_255;translation_table=11;partial=3';product=predicted RNA-binding protein with TRAM domain;product_source=COG3269;cath_funfam=2.40.50.140;cog=COG3269;pfam=TRA;smart=50249\r\n1781_100325_scf_1004_c1 GeneMark.hmm-2 v1.05    CDS     313     1146    46.17   -       0       ID=1781_100325_scf_1004_c1_313_1146;translation_table=11;product=aspartate dehydrogenase;product_source=KO:K06989;cath_funfam=3.30.360.10,3.40.50.720;cog=COG1712;ko=KO:K06989;ec_number=EC:1.4.1.21;pfam=DUF10,DapB_,NAD_binding_;smart=51735,55347;tigrfam=TIGR03855\r\n1781_100325_scf_1004_c1 GeneMark.hmm-2 v1.05    CDS     1251    1433    2.26    -       0       ID=1781_100325_scf_1004_c1_1251_1433;translation_table=11;product=small subunit ribosomal protein S30e;product_source=KO:K02983;cog=COG4919;ko=KO:K02983;pfam=Ribosomal_S3\r\n1781_100325_scf_1005_c1 GeneMark.hmm-2 v1.05    CDS     2       829     71.94   -       0       ID=1781_100325_scf_1005_c1_2_829;translation_table=11;partial=3';product=DNA polymerase-4;product_source=KO:K02346;cath_funfam=1.10.150.20,3.30.70.270;cog=COG0389;ko=KO:K02346;ec_number=EC:2.7.7.7;pfam=IM;smart=56672;superfamily=SM00278\r\n1781_100325_scf_1005_c1 GeneMark.hmm-2 v1.05    CDS     877     1473    59.07   -       0       ID=1781_100325_scf_1005_c1_877_1473;translation_table=11;product=hypothetical protein;product_source=Hypo-rule applied;cath_funfam=1.20.5.100;smart=51735\r\n1781_100325_scf_1006_c1 GeneMark.hmm-2 v1.05    CDS     2       730     86.59   -       0       ID=1781_100325_scf_1006_c1_2_730;translation_table=11;partial=3';product=cysteinyl-tRNA synthetase;product_source=KO:K01883;cath_funfam=3.40.50.620;cog=COG0215;ko=KO:K01883;ec_number=EC:6.1.1.16;pfam=tRNA-synt_1;smart=52374\r\n1781_100325_scf_1006_c1 GeneMark.hmm-2 v1.05    CDS     761     1696    110.06  -       0       ID=1781_100325_scf_1006_c1_761_1696;translation_table=11;partial=5';product=ATP-dependent Zn protease;product_source=COG0465;cath_funfam=1.10.8.60;cog=COG0465;pfam=Peptidase_M4;smart=140990\r\n1781_100325_scf_1007_c1 GeneMark.hmm-2 v1.05    CDS     264     1550    115.96  -       0       ID=1781_100325_scf_1007_c1_264_1550;translation_table=11;product=hypothetical protein;product_source=Hypo-rule applied;pfam=DDE_Tnp_,DDE_Tnp_1_;smart=53098\r\n1781_100325_scf_1008_c1 GeneMark.hmm-2 v1.05    CDS     9       113     5.74    +       0       ID=1781_100325_scf_1008_c1_9_113;translation_table=11;product=elongation factor P;product_source=KO:K02356;cath_funfam=2.40.50.140;ko=KO:K02356;pfam=Elong-fact-P_;smart=50249;superfamily=SM00841\r\n1781_100325_scf_1008_c1 GeneMark.hmm-2 v1.05    CDS     118     546     41.51   +       0       ID=1781_100325_scf_1008_c1_118_546;translation_table=11;product=N utilization substance protein B;product_source=KO:K03625;cath_funfam=1.10.940.10;cog=COG0781;ko=KO:K03625;pfam=Nus;smart=48013;tigrfam=TIGR01951\r\n1781_100325_scf_1008_c1 GeneMark.hmm-2 v1.05    CDS     554     760     24.98   -       0       ID=1781_100325_scf_1008_c1_554_760;translation_table=11;product=sec-independent protein translocase protein TatA;product_source=KO:K03116;cog=COG1826;ko=KO:K03116;pfam=MttA_Hcf10;tigrfam=TIGR01411\r\n1781_100325_scf_1008_c1 GeneMark.hmm-2 v1.05    CDS     996     1562    81.24   +       0       ID=1781_100325_scf_1008_c1_996_1562;translation_table=11;product=pyrimidine operon attenuation protein/uracil phosphoribosyltransferase;product_source=KO:K02825;cath_funfam=3.40.50.2020;cog=COG2065;ko=KO:K02825;ec_number=EC:2.4.2.9;pfam=Pribosyltra;smart=53271\r\n1781_100325_scf_1008_c1 GeneMark.hmm-2 v1.05    CDS     1559    1696    8.04    +       0       ID=1781_100325_scf_1008_c1_1559_1696;translation_table=11;partial=3';product=aspartate carbamoyltransferase catalytic subunit;product_source=KO:K00609;cath_funfam=3.40.50.1370;cog=COG0540;ko=KO:K00609;ec_number=EC:2.1.3.2;smart=53671\r\n1781_100325_scf_1009_c1 GeneMark.hmm-2 v1.05    CDS     97      582     43.72   +       0       ID=1781_100325_scf_1009_c1_97_582;translation_table=11;product=HEAT repeat protein;product_source=COG1413;cath_funfam=1.25.10.20;cog=COG1413;pfam=HEAT_;smart=48371\r\n1781_100325_scf_1009_c1 Prodigal v2.6.3 CDS     579     749     8.4     -       0       ID=1781_100325_scf_1009_c1_579_749;translation_table=11;product=hypothetical protein;product_source=Hypo-rule applied;smart=57802\r\n1781_100325_scf_1009_c1 GeneMark.hmm-2 v1.05    CDS     746     1693    36.99   -       0       ID=1781_100325_scf_1009_c1_746_1693;translation_table=11;product=integrase/recombinase XerD;product_source=KO:K04763;cath_funfam=1.10.150.130,1.10.443.10;cog=COG4974;ko=KO:K04763;pfam=Phage_int_SAM_,Phage_integras;smart=56349\r\n1781_100325_scf_100_c1  GeneMark.hmm-2 v1.05    CDS     2       397     16.15   +       0       ID=1781_100325_scf_100_c1_2_397;translation_table=11;partial=5';product=two-component system nitrogen regulation response regulator GlnG;product_source=KO:K07712;cath_funfam=3.40.50.2300;cog=COG3437;ko=KO:K07712;pfam=Response_re;smart=52172\r\n1781_100325_scf_100_c1  GeneMark.hmm-2 v1.05    CDS     670     2514    85.48   +       0       ID=1781_100325_scf_100_c1_670_2514;translation_table=11;product=signal transduction histidine kinase;product_source=COG0642;cath_funfam=1.10.287.130,2.60.15.10,3.30.565.10;cog=COG0642;pfam=HATPase_,HisK,dCache_;smart=103190,55021,55874;superfamily=SM00387,SM00388\r\n1781_100325_scf_100_c1  GeneMark.hmm-2 v1.05    CDS     2522    3418    30.63   +       0       ID=1781_100325_scf_100_c1_2522_3418;translation_table=11;product=hypothetical protein;product_source=Hypo-rule applied;smart=81342\r\n1781_100325_scf_100_c1  GeneMark.hmm-2 v1.05    CDS     3598    3972    11.31   -       0       ID=1781_100325_scf_100_c1_3598_3972;translation_table=11;partial=5';product=DNA-binding beta-propeller fold protein YncE;product_source=COG3391;cath_funfam=2.120.10.30;cog=COG3391;pfam=DUF512,NH;smart=101898\r\n1781_100325_scf_1010_c1 GeneMark.hmm-2 v1.05    CDS     3       815     59.75   -       0       ID=1781_100325_scf_1010_c1_3_815;translation_table=11;partial=3';product=spermidine/putrescine transport system permease protein;product_source=KO:K11070;cath_funfam=1.10.3720.10;cog=COG1177;ko=KO:K11070;pfam=BPD_transp_;smart=161098\r\n1781_100325_scf_1010_c1 GeneMark.hmm-2 v1.05    CDS     812     1696    92.29   -       0       ID=1781_100325_scf_1010_c1_812_1696;translation_table=11;partial=5';product=spermidine/putrescine transport system permease protein;product_source=KO:K11071;cath_funfam=1.10.3720.10;cog=COG1176;ko=KO:K11071;pfam=BPD_transp_;smart=161098\r\n```\r\n",
"body": "@hubin-keio has provided examples here: https://github.com/microbiomedata/pynmdc/tree/main/src/nmdc/test_data",
"body": "Can you (@cmungall) provide a complete JSON version of the original example (Ga0185794_41)? I have pulled 1000 lines of a gff file from an early run of the annotation workflow and it is available here: https://github.com/microbiomedata/pynmdc/tree/main/src/nmdc/test_data/MetaG_annotation\r\n\r\nI am still working on the converter. The unfinished version is here: \r\nhttps://github.com/microbiomedata/pynmdc\r\n\r\nI would like to see a standard JSON output example before finalize the converter. Thanks.",
"body": "@hubin-keio Quick observations:\r\n\r\n- The objects in `test_data/MetaG_annotation/1781_100325_fa.json` should be separated by a comma. See https://github.com/microbiomedata/pynmdc/blob/main/src/nmdc/test_data/MetaG_annotation/1781_100325_fa.json#L37\r\n- Also, all the objects in a file should be arranged and grouped by a database/type holder.\r\n\r\nFor some examples of the JSON, see here:\r\n- https://gist.github.com/deepakunni3/ec286e533b788ea6e58e52674995990d\r\n- https://gist.github.com/deepakunni3/552eb3db0e43ec2c5690f47e572fe031\r\n\r\n ",
"body": "I added Deepak's examples to the repo in the examples folder: https://github.com/microbiomedata/nmdc-metadata/tree/master/examples\r\n\r\n(not we also validate against all examples in this folder as unit tests and within github/travis CI)",
"body": "Thanks for the comments. @deepakunni3, is your parser working? I have committed the last planned update before GSP this morning.",
"body": "The \"was_generated_by\": \"N/A\"\" field is still there in your examples. Maybe you want to remove it in your code?",
"body": "Yes, the \"N/A\" was a placeholder to remind us that this information is missing and needs to be incorporated. Will remove from the script.\r\n\r\n",
"body": "In the discussions in Aim1_standards channel it was mentioned on 1/9 \"yes, never use values like \"N/A\", always make it an explicit json null, or simply omit the key altoogether.\" But I am fine with your parser solution as long as it is okay among Aim 1 and 3. Please put in Aim 2 channel the location of your parser once it is done so that we can process the GFFs. Aim 3 needs the JSONs ready by this Friday (1/15).\r\n",
"body": "I am not sure what the expectation here is between your pynmdc converter vs my GFF3 converter.\r\n\r\nPerhaps we can talk more on the technical call today.\r\n\r\nRegarding the \"N/A\", thanks for clarifying. That makes sense. I can replace that with `null`",
"body": "the `was generated by` field should link to the MetagenomeAnnotation activity\r\n\r\nwe will better document this in the schema\r\n\r\n(this answers @scanon's Q on the tech sync call)",
"body": "The schema has inline docs detailing the mapping but we should provide a higher level guide. I will sketch out in this ticket and then this can be turned into docs on the site. I'm doing quickly so if anything is confusing, it's likely I made a mistake. I will also give examples in yaml but the json cognate should be obvious\r\n\r\nExample\r\n\r\n```\r\nGa0185794_41    GeneMark.hmm-2 v1.05    CDS     48      1037    56.13   +       0       ID=Ga0185794_41_48_1037;translation_table=11;start_type=ATG;product=5-methylthioadenosine/S-adenosylhomocysteine deaminase;product_source=KO:K12960;cath_funfam=3.20.20.140;cog=COG0402;ko=KO:K12960;ec_number=EC:3.5.4.28,EC:3.5.4.31;pfam=PF01979;superfamily=51338,51556\r\n```\r\n\r\nThis GFF line represents the output of structural annotation (the prediction of a CDS on sequence Ga0185794_41). This is given a protein ID (skolemized from reference + coordinates). `Ga0185794_41_48_1037`. Col9 represents the outputs of functional annotation. @scanon @hubin-keio do I have this right?\r\n\r\nThe core feature would be represented as an instance of\r\nhttps://microbiomedata.github.io/nmdc-metadata/docs/GenomeFeature\r\n\r\n![image](https://user-images.githubusercontent.com/50745/102566326-29780100-4094-11eb-8e12-120b99bae3c3.png)\r\n\r\nso our initial object would look like:\r\n\r\n```yaml\r\nseqid: NMDC:Ga0185794_41 \r\nstart: 48\r\nend: 1037\r\nstrand: \"+\"\r\ntype: SO:0000316 ## note we use a key to the SO object which is itself an instance of ControlledTerm\r\nencodes: NMDC:Ga0185794_41_48_1037\r\n```\r\n\r\nNote all IDs are prefixed to conform to the NMDC identifiers standards doc\r\n\r\nNote the 'encodes' field, to link to a GeneProduct (this will always be a Protein for the current pipeline, but in future we may have ncRNA annotations)\r\n\r\nhttps://microbiomedata.github.io/nmdc-metadata/docs/GeneProduct\r\n\r\nCurrently the GeneProduct field is fairly bare, but in future additional fields could be added - e.g. AA seq. The GeneProduct is what functional annotations are attached to\r\n\r\nhttps://microbiomedata.github.io/nmdc-metadata/docs/FunctionalAnnotation\r\n\r\nEach ';` separated section in col9 of the GFF would correspond to a separate annotation. The annotation links the gene product to the [controlled term](https://microbiomedata.github.io/nmdc-metadata/docs/FunctionalAnnotationTerm)\r\n\r\nMinimally this looks like:\r\n\r\n```yaml\r\nsubject: NMDC:Ga0185794_41_48_1037.  ## this is the protein ID\r\nhas_function: KO:K12960\r\nwas_informed_by: <...provenance here>\r\n```\r\n\r\nFor people familiar with the GO annotation system, each entry here represents a line in GAF or GPAD format files.\r\n\r\nThere would be one entry for each annotation. Above I am only showing the KO annotation\r\n\r\nNote the string KO:K12960 is a key to a [controlled term](https://microbiomedata.github.io/nmdc-metadata/docs/FunctionalAnnotationTerm) object. An example would be:\r\n\r\n```yaml\r\nid: KEGG.KO:K12960.  ## note we follow identifiers.org standards here for unique IDs\r\nname: mtaD\r\ndescription: 5-methylthioadenosine/S-adenosylhomocysteine deaminase\r\n```\r\n\r\nThis is a minimal representation of the KEGG KO object. It can be linked to other controlled term objects. For example, it can include mappings to other systems (EC), parent/child hierarchies, links to pathways, etc, and these can all be traced to compounds chemical entities. However, we will only support simple KO search for GSP, so I will not detail that here. Please refer to #176 for using pathway knowledge to implement more advanced search.\r\n\r\nAnnotations to other systems (e.g. Pfam) are handled analogously. Please see the `id_prefixes` field in the schema to see the canonical ID prefix for each system.\r\n\r\nTODO: document how the feature connects to the metaG/T output\r\n\r\n## to be discussed\r\n\r\n * we opted to have separate objects for GeneProduct and GenomeFeature. We can revisit this. We need to be careful that we don't reuse the same ID for two 'aspects' of the same thing\r\n * there is some concern about size of files in json vs gff3. We should do experiments to determine the difference. I suspect that compressed there will not be much difference",
"body": "Add IUPAC, COMMON, and TRADITIONAL names to the  ChemicalEntity obj",
"body": "> \"metabolite_quantified\": {\r\n> \"description\": \"the specific metabolite identifier\",\r\n> \"type\": \"string\"\r\n\r\n\"metabolite_quantified\" references the primary identifier for the chemical entity\r\n\r\n![image](https://user-images.githubusercontent.com/3186638/102825706-4b7fc500-43ad-11eb-9587-6686b379227e.png)\r\n",
"body": "@cmungall and @wdduncan @dehays \r\nWill this example work for populate the ChemicalEntity entries? If not what do you need changed?\r\n\r\n```json\r\n{\r\n  \"alternate_identifiers\": [\r\n   \"kegg:C00041\",\r\n   \"cas:56-41-7\"\r\n  ],\r\n  \"alternate_names\": [\r\n   \"iupac:(2S)-2-aminopropanoic acid\",\r\n   \"traditional:L-alanine\",\r\n   \"common:L-Alanine\"\r\n  ],\r\n  \"chemical_formula\": \"C3H7NO2\",\r\n  \"id\": \"chebi:16977\",\r\n  \"inchi\": \"InChI=1S/C3H7NO2/c1-2(4)3(5)6/h2H,4H2,1H3,(H,5,6)/t2-/m0/s1\",\r\n  \"inchikey\": \"QNAYBMKLOCPYGJ-REOHCLBHSA-N\",\r\n  \"name\": \"L-alanine\",\r\n  \"smiles\": [\r\n   \"C[C@H](N)C(O)=O\"\r\n  ]\r\n },\r\n {\r\n  \"alternate_identifiers\": [\r\n   \"kegg:C00152\",\r\n   \"cas:70-47-3\"\r\n  ],\r\n  \"alternate_names\": [\r\n   \"iupac:(2S)-2-amino-3-carbamoylpropanoic acid\",\r\n   \"traditional:L-asparagine\",\r\n   \"common:L-Asparagine\"\r\n  ],\r\n  \"chemical_formula\": \"C4H8N2O3\",\r\n  \"id\": \"chebi:17196\",\r\n  \"inchi\": \"InChI=1S/C4H8N2O3/c5-2(4(8)9)1-3(6)7/h2H,1,5H2,(H2,6,7)(H,8,9)/t2-/m0/s1\",\r\n  \"inchikey\": \"DCXYFEDJOCDNAF-REOHCLBHSA-N\",\r\n  \"name\": \"L-asparagine-15N2,d8\",\r\n  \"smiles\": [\r\n   \"N[C@@H](CC(N)=O)C(O)=O\"\r\n  ]\r\n },\r\n {\r\n  \"alternate_identifiers\": [\r\n   \"kegg:C00049\",\r\n   \"cas:56-84-8\"\r\n  ],\r\n  \"alternate_names\": [\r\n   \"iupac:(2S)-2-aminobutanedioic acid\",\r\n   \"traditional:L-aspartic acid\",\r\n   \"common:L-Aspartic acid\"\r\n  ],\r\n  \"chemical_formula\": \"C4H7NO4\",\r\n  \"id\": \"chebi:17053\",\r\n  \"inchi\": \"InChI=1S/C4H7NO4/c5-2(4(8)9)1-3(6)7/h2H,1,5H2,(H,6,7)(H,8,9)/t2-/m0/s1\",\r\n  \"inchikey\": \"CKLJMWTZIZZHCS-REOHCLBHSA-N\",\r\n  \"name\": \"L-aspartic acid\",\r\n  \"smiles\": [\r\n   \"N[C@@H](CC(O)=O)C(O)=O\"\r\n  ]\r\n },\r\n {\r\n  \"alternate_identifiers\": [\r\n   \"kegg:C00183\",\r\n   \"cas:72-18-4\"\r\n  ],\r\n  \"alternate_names\": [\r\n   \"iupac:(2S)-2-amino-3-methylbutanoic acid\",\r\n   \"traditional:L-valine\",\r\n   \"common:L-Valine\"\r\n  ],\r\n  \"chemical_formula\": \"C5H11NO2\",\r\n  \"id\": \"chebi:16414\",\r\n  \"inchi\": \"InChI=1S/C5H11NO2/c1-3(2)4(6)5(7)8/h3-4H,6H2,1-2H3,(H,7,8)/t4-/m0/s1\",\r\n  \"inchikey\": \"KZSNJWFQEVHDMF-BYPYZUCNSA-N\",\r\n  \"name\": \"L-valine\",\r\n  \"smiles\": [\r\n   \"CC(C)[C@H](N)C(O)=O\"\r\n  ]\r\n },\r\n {\r\n  \"alternate_identifiers\": [\r\n   \"kegg:C05422\",\r\n   \"cas:490-83-5\"\r\n  ],\r\n  \"alternate_names\": [\r\n   \"iupac:(5R)-5-[(1S)-1,2-dihydroxyethyl]oxolane-2,3,4-trione\",\r\n   \"traditional:DHAA\",\r\n   \"common:Dehydroascorbic acid\"\r\n  ],\r\n  \"chemical_formula\": \"C6H6O6\",\r\n  \"id\": \"chebi:27956\",\r\n  \"inchi\": \"InChI=1S/C6H6O6/c7-1-2(8)5-3(9)4(10)6(11)12-5/h2,5,7-8H,1H2/t2-,5+/m0/s1\",\r\n  \"inchikey\": \"SBJKKFFYIZUCET-JLAZNSOCSA-N\",\r\n  \"name\": \"dehydroascorbic acid\",\r\n  \"smiles\": [\r\n   \"[H][C@@]1(OC(=O)C(=O)C1=O)[C@@H](O)CO\"\r\n  ]\r\n },\r\n {\r\n  \"alternate_identifiers\": [\r\n   \"kegg:C00037\",\r\n   \"cas:56-40-6\"\r\n  ],\r\n  \"alternate_names\": [\r\n   \"iupac:2-aminoacetic acid\",\r\n   \"traditional:glycine\",\r\n   \"common:Glycine\"\r\n  ],\r\n  \"chemical_formula\": \"C2H5NO2\",\r\n  \"id\": \"chebi:15428\",\r\n  \"inchi\": \"InChI=1S/C2H5NO2/c3-1-2(4)5/h1,3H2,(H,4,5)\",\r\n  \"inchikey\": \"DHMQDGOQFOQNFH-UHFFFAOYSA-N\",\r\n  \"name\": \"glycine\",\r\n  \"smiles\": [\r\n   \"NCC(O)=O\"\r\n  ]\r\n },\r\n {\r\n  \"alternate_identifiers\": [\r\n   \"kegg:C00097\",\r\n   \"cas:52-90-4\"\r\n  ],\r\n  \"alternate_names\": [\r\n   \"iupac:(2R)-2-amino-3-sulfanylpropanoic acid\",\r\n   \"traditional:L-cysteine\",\r\n   \"common:L-Cysteine\"\r\n  ],\r\n  \"chemical_formula\": \"C3H7NO2S\",\r\n  \"id\": \"chebi:17561\",\r\n  \"inchi\": \"InChI=1S/C3H7NO2S/c4-2(1-7)3(5)6/h2,7H,1,4H2,(H,5,6)/t2-/m0/s1\",\r\n  \"inchikey\": \"XUJNEKJLAYXESH-REOHCLBHSA-N\",\r\n  \"name\": \"L-cysteine\",\r\n  \"smiles\": [\r\n   \"N[C@@H](CS)C(O)=O\"\r\n  ]\r\n }\r\n]\r\n \r\n```",
"body": "\"metabolite_quantified\": should be the ChemicalEntity object\r\n \"$ref\": \"#/definitions/ChemicalEntity\",\r\n\r\n\"MetaboliteQuantification\": {: \r\n         \"additionalProperties\": false,\r\n         \"description\": \"This is used to link a metabolomics analysis workflow to a specific metabolite\",\r\n         \"properties\": {\r\n            \"highest_similarity_score\": {\r\n               \"description\": \"TODO: Yuri to fill in\",\r\n               \"type\": \"number\"\r\n            },\r\n            \"metabolite_quantified\": {\r\n               \"description\": \"the specific metabolite identifier\",\r\n               \"type\": \"string\"\r\n            }\r\n         },",
"body": "> Dependent on #169\r\n> \r\n> The JSON should validate against nmdc.json\r\n> \r\n> (trying to assign @anubhav0fnu but am unable to)\r\n\r\n@cmungall , now you can assign, I wasn't part of repo",
"body": "The initial issue #169 has been closed, and to the best of my knowledge the json is validating against nmdc.json. closing the issue.",
"body": "Dependent on #169 \r\n\r\nThe JSON should validate against nmdc.json\r\n\r\n(trying to assign @anubhav0fnu but am unable to)",
"body": "@cmungall @dehays @wdduncan \r\n\r\nHere is the metadata example based on the MetabolomicsAnalysisActivity schema, please let me know if any modification are needed: \r\n\r\n```json\r\n{\r\n \"activity_id\": \"nmdc:b00cbf1a0506499f873cd795543f8a7a\",\r\n \"ended_at_time\": \"2021-01-05 11:30:30\",\r\n \"execution_resource\": \"EMSL-RZR\",\r\n \"git_url\": \"https://github.com/microbiomedata/metaMS\",\r\n \"has_input\": \"emsl:output_501139\",\r\n \"has_output\": \"nmdc:91545873ce109f9b81e21368dfb7ae65\",\r\n \"started_at_time\": \"2021-01-05 11:30:30\",\r\n \"used\": \"Agilent_GC_MS\",\r\n \"was_informed_by\": \"emsl:501139\",\r\n \"has_metabolite_quantifications\": [\r\n  {\r\n   \"highest_similarity_score\": 0.4452153683457105,\r\n   \"metabolite_quantified\": \"chebi:17724\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C01026\",\r\n    \"cas:1118-68-9\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.4872927888320037,\r\n   \"metabolite_quantified\": \"chebi:32816\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C00022\",\r\n    \"cas:127-17-3\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.472894997403009,\r\n   \"metabolite_quantified\": \"chebi:422\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C00186\",\r\n    \"cas:79-33-4\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.8933444893542664,\r\n   \"metabolite_quantified\": \"chebi:17497\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C03547\",\r\n    \"cas:79-14-1\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.6484406280773884,\r\n   \"metabolite_quantified\": \"chebi:30831\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C00109\",\r\n    \"cas:600-18-0\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.7705704183153843,\r\n   \"metabolite_quantified\": \"chebi:16530\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C00141\",\r\n    \"cas:759-05-7\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.6868741440029694,\r\n   \"metabolite_quantified\": \"chebi:50613\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C05984\",\r\n    \"cas:3347-90-8\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.7168707400721402,\r\n   \"metabolite_quantified\": \"chebi:16995\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C00209\",\r\n    \"cas:144-62-7\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.9876426239539051,\r\n   \"metabolite_quantified\": \"chebi:28976\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C01353\",\r\n    \"cas:463-79-6\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.7747768962088075,\r\n   \"metabolite_quantified\": \"chebi:16995\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C00209\",\r\n    \"cas:144-62-7\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.7584047279897679,\r\n   \"metabolite_quantified\": \"chebi:75144\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:None\",\r\n    \"cas:2043-43-8\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.8140858448623509,\r\n   \"metabolite_quantified\": \"chebi:48430\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C00233\",\r\n    \"cas:816-66-0\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.3939086317220801,\r\n   \"metabolite_quantified\": \"chebi:33033\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C06255\",\r\n    \"cas:1821-02-9\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.7451962145743798,\r\n   \"metabolite_quantified\": \"chebi:18053\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C01234\",\r\n    \"cas:22059-21-8\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.5445312010413639,\r\n   \"metabolite_quantified\": \"chebi:37051\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:None\",\r\n    \"cas:473-86-9\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.8381129782621634,\r\n   \"metabolite_quantified\": \"chebi:5445\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C02154\",\r\n    \"cas:56-82-6\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.5359508634091753,\r\n   \"metabolite_quantified\": \"chebi:30860\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C02170\",\r\n    \"cas:516-05-2\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.9551416662474789,\r\n   \"metabolite_quantified\": \"chebi:27389\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C05145\",\r\n    \"cas:144-90-1\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.7690521840476926,\r\n   \"metabolite_quantified\": \"chebi:405237\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C00308\",\r\n    \"cas:543-38-4\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.9209851991930492,\r\n   \"metabolite_quantified\": \"chebi:16413\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C02497\",\r\n    \"cas:110-65-6\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.8070344025495375,\r\n   \"metabolite_quantified\": \"chebi:44423\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C07044\",\r\n    \"cas:127-07-1\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.8177428452682696,\r\n   \"metabolite_quantified\": \"chebi:139272\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:None\",\r\n    \"cas:10237-77-1\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.43389701178809453,\r\n   \"metabolite_quantified\": \"chebi:21717\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:None\",\r\n    \"cas:2491-15-8\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.6750708223369789,\r\n   \"metabolite_quantified\": \"chebi:32329\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C12313\",\r\n    \"cas:1792-81-0\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.8792212085791417,\r\n   \"metabolite_quantified\": \"chebi:16016\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C00184\",\r\n    \"cas:96-26-4\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.8279158662757127,\r\n   \"metabolite_quantified\": \"chebi:17308\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C00902\",\r\n    \"cas:2492-75-3\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.6783819156437387,\r\n   \"metabolite_quantified\": \"chebi:17115\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C00065\",\r\n    \"cas:56-45-1\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.6694550460274845,\r\n   \"metabolite_quantified\": \"chebi:16931\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C03739\",\r\n    \"cas:1460-57-7\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.5754330767675611,\r\n   \"metabolite_quantified\": \"chebi:28837\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C06423\",\r\n    \"cas:124-07-2\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.7308051352474184,\r\n   \"metabolite_quantified\": \"chebi:17754\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C00116\",\r\n    \"cas:56-81-5\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.6060117369397744,\r\n   \"metabolite_quantified\": \"chebi:15698\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C00881\",\r\n    \"cas:951-77-9\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.6030451596806666,\r\n   \"metabolite_quantified\": \"chebi:149\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C11396\",\r\n    \"cas:20549-47-7\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.43080822244007383,\r\n   \"metabolite_quantified\": \"chebi:15603\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C00123\",\r\n    \"cas:61-90-5\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.678668890239193,\r\n   \"metabolite_quantified\": \"chebi:28718\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C05519\",\r\n    \"cas:28954-12-3\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.49836533373737174,\r\n   \"metabolite_quantified\": \"chebi:16857\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C00188\",\r\n    \"cas:72-19-5\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.730263809949754,\r\n   \"metabolite_quantified\": \"chebi:18135\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C15571\",\r\n    \"cas:120-80-9\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.6436569289887909,\r\n   \"metabolite_quantified\": \"chebi:15741\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C00042\",\r\n    \"cas:110-15-6\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.426729471337197,\r\n   \"metabolite_quantified\": \"chebi:15428\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C00037\",\r\n    \"cas:56-40-6\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.5150028281510777,\r\n   \"metabolite_quantified\": \"chebi:131454\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:None\",\r\n    \"cas:16867-04-2\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.4634469397364457,\r\n   \"metabolite_quantified\": \"chebi:None\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C09541\",\r\n    \"cas:3019-51-0\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.6464253213894418,\r\n   \"metabolite_quantified\": \"chebi:15888\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C02129\",\r\n    \"cas:3128-06-1\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.5050437987239537,\r\n   \"metabolite_quantified\": \"chebi:None\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:None\",\r\n    \"cas:93-51-6\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.6977943441161536,\r\n   \"metabolite_quantified\": \"chebi:36436\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:None\",\r\n    \"cas:591-12-8\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.47120030003234953,\r\n   \"metabolite_quantified\": \"chebi:115156\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:None\",\r\n    \"cas:17013-01-3\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.6457962758584374,\r\n   \"metabolite_quantified\": \"chebi:17626\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C02226\",\r\n    \"cas:498-23-7\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.3803532435174449,\r\n   \"metabolite_quantified\": \"chebi:36751\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C05942\",\r\n    \"cas:634-97-9\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.7134893502583765,\r\n   \"metabolite_quantified\": \"chebi:17447\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C01500\",\r\n    \"cas:106-24-1\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.5479443521080083,\r\n   \"metabolite_quantified\": \"chebi:\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:\",\r\n    \"cas:608-39-9,608-40-2,57694-62-9\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.6078145085833287,\r\n   \"metabolite_quantified\": \"chebi:16913\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C03711\",\r\n    \"cas:68579-60-2\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.6606490816644252,\r\n   \"metabolite_quantified\": \"chebi:17957\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C04294\",\r\n    \"cas:137-00-8\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.6337865765564044,\r\n   \"metabolite_quantified\": \"chebi:89836\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:None\",\r\n    \"cas:21709-90-0\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.5418222178771255,\r\n   \"metabolite_quantified\": \"chebi:16934\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C02512\",\r\n    \"cas:6232-19-5\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.7793755630896766,\r\n   \"metabolite_quantified\": \"chebi:17869\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C06103\",\r\n    \"cas:1191-25-9\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.9958623629155837,\r\n   \"metabolite_quantified\": \"chebi:17053\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C00049\",\r\n    \"cas:56-84-8\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.6958680459159086,\r\n   \"metabolite_quantified\": \"chebi:17869\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C06103\",\r\n    \"cas:1191-25-9\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.5178083857513684,\r\n   \"metabolite_quantified\": \"chebi:30794\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C04025\",\r\n    \"cas:141-82-2\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.7970961291364534,\r\n   \"metabolite_quantified\": \"chebi:18112\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C01987\",\r\n    \"cas:95-55-6\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.4019581408613613,\r\n   \"metabolite_quantified\": \"chebi:87840\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C04397\",\r\n    \"cas:4298-08-2\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.6781402156002239,\r\n   \"metabolite_quantified\": \"chebi:16464\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C02323\",\r\n    \"cas:90-01-7\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.6533454168678582,\r\n   \"metabolite_quantified\": \"chebi:28341\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C07189\",\r\n    \"cas:582-24-1\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.8090886326625689,\r\n   \"metabolite_quantified\": \"chebi:\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:\",\r\n    \"cas:108-13-4\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.6459179964854367,\r\n   \"metabolite_quantified\": \"chebi:\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:\",\r\n    \"cas:\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.5279158063308256,\r\n   \"metabolite_quantified\": \"chebi:16958\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C00099\",\r\n    \"cas:107-95-9\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.5803254305997901,\r\n   \"metabolite_quantified\": \"chebi:29045\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C01596\",\r\n    \"cas:557-24-4\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.4977761375522372,\r\n   \"metabolite_quantified\": \"chebi:70979\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:None\",\r\n    \"cas:15926-18-8\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.490453413892699,\r\n   \"metabolite_quantified\": \"chebi:29063\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C04771\",\r\n    \"cas:500-44-7\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.38052778762709294,\r\n   \"metabolite_quantified\": \"chebi:40538\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C15562\",\r\n    \"cas:100-46-9\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.8142460876100749,\r\n   \"metabolite_quantified\": \"chebi:28587\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C06463\",\r\n    \"cas:95-43-2\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.7012059829426629,\r\n   \"metabolite_quantified\": \"chebi:30813\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C01571\",\r\n    \"cas:334-48-5\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.6220102077789929,\r\n   \"metabolite_quantified\": \"chebi:30744\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C00036\",\r\n    \"cas:328-42-7\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.4818529104497346,\r\n   \"metabolite_quantified\": \"chebi:16562\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C02505\",\r\n    \"cas:103-81-1\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.568004547028631,\r\n   \"metabolite_quantified\": \"chebi:41674\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C06105\",\r\n    \"cas:765-87-7\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.9491782131506442,\r\n   \"metabolite_quantified\": \"chebi:24786\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C19911\",\r\n    \"cas:142-73-4\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.47581636419654794,\r\n   \"metabolite_quantified\": \"chebi:17561\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C00097\",\r\n    \"cas:52-90-4\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.639598644106793,\r\n   \"metabolite_quantified\": \"chebi:64564\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:None\",\r\n    \"cas:444-27-9\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.42759783062023893,\r\n   \"metabolite_quantified\": \"chebi:16879\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C04067\",\r\n    \"cas:759-65-9\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.7830029263723,\r\n   \"metabolite_quantified\": \"chebi:37245\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:None\",\r\n    \"cas:5746-90-7\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.8006803078293226,\r\n   \"metabolite_quantified\": \"chebi:15584\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C00815\",\r\n    \"cas:597-44-4\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.6338491687505704,\r\n   \"metabolite_quantified\": \"chebi:80636\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C16650\",\r\n    \"cas:53660-23-4\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.8249583275127094,\r\n   \"metabolite_quantified\": \"chebi:141700\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:None\",\r\n    \"cas:934-00-9\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.8895425441794954,\r\n   \"metabolite_quantified\": \"chebi:30796\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C00497\",\r\n    \"cas:636-61-3\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.6044419954295325,\r\n   \"metabolite_quantified\": \"chebi:\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:\",\r\n    \"cas:3685-26-5\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.46211934204695004,\r\n   \"metabolite_quantified\": \"chebi:17645\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C02946\",\r\n    \"cas:3025-96-5\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.4349529096217458,\r\n   \"metabolite_quantified\": \"chebi:17533\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C00624\",\r\n    \"cas:1188-37-0\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.6843375508472886,\r\n   \"metabolite_quantified\": \"chebi:18280\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C02137\",\r\n    \"cas:611-73-4\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.4709649132987196,\r\n   \"metabolite_quantified\": \"chebi:15728\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C01035\",\r\n    \"cas:463-00-3\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.5270779982299778,\r\n   \"metabolite_quantified\": \"chebi:17397\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C02366\",\r\n    \"cas:1504-06-9\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.6415761411685773,\r\n   \"metabolite_quantified\": \"chebi:16164\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C01108\",\r\n    \"cas:87-66-1\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.6118701156137635,\r\n   \"metabolite_quantified\": \"chebi:None\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:None\",\r\n    \"cas:2734-48-7\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.8608898399219226,\r\n   \"metabolite_quantified\": \"chebi:30915\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C00026\",\r\n    \"cas:328-50-7\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.7319509786916678,\r\n   \"metabolite_quantified\": \"chebi:33404\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C01013\",\r\n    \"cas:503-66-2\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.767981192738988,\r\n   \"metabolite_quantified\": \"chebi:28635\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:None\",\r\n    \"cas:3237-44-3\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.4778844253112197,\r\n   \"metabolite_quantified\": \"chebi:73018\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:None\",\r\n    \"cas:35842-45-6\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.4456182869820163,\r\n   \"metabolite_quantified\": \"chebi:17605\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C03057\",\r\n    \"cas:119-67-5\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.3671244044891142,\r\n   \"metabolite_quantified\": \"chebi:16737\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C00791\",\r\n    \"cas:60-27-5\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.7482219396343183,\r\n   \"metabolite_quantified\": \"chebi:16831\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C03761\",\r\n    \"cas:503-49-1\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.8122315068612199,\r\n   \"metabolite_quantified\": \"chebi:30531\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C02656\",\r\n    \"cas:111-16-0\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.6884518242495268,\r\n   \"metabolite_quantified\": \"chebi:87897\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:None\",\r\n    \"cas:51568-18-4\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.7532000193496652,\r\n   \"metabolite_quantified\": \"chebi:17196\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C00152\",\r\n    \"cas:70-47-3\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.9609629915899104,\r\n   \"metabolite_quantified\": \"chebi:17295\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C00079\",\r\n    \"cas:63-91-2\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.7300974572701854,\r\n   \"metabolite_quantified\": \"chebi:15671\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C00898\",\r\n    \"cas:87-69-4\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.4022654548178048,\r\n   \"metabolite_quantified\": \"chebi:16204\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C02183\",\r\n    \"cas:108-73-6\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.6507686012430698,\r\n   \"metabolite_quantified\": \"chebi:15725\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C00986\",\r\n    \"cas:109-76-2\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.7554164599264231,\r\n   \"metabolite_quantified\": \"chebi:18101\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C00642\",\r\n    \"cas:156-38-7\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.663670887164799,\r\n   \"metabolite_quantified\": \"chebi:15753\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C00322\",\r\n    \"cas:3184-35-8\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.6616717041289656,\r\n   \"metabolite_quantified\": \"chebi:\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:\",\r\n    \"cas:39840-37-4\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.43517999406730745,\r\n   \"metabolite_quantified\": \"chebi:30805\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C02679\",\r\n    \"cas:143-07-7\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.7032488130298753,\r\n   \"metabolite_quantified\": \"chebi:21547\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C01042\",\r\n    \"cas:997-55-7\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.49428600206379425,\r\n   \"metabolite_quantified\": \"chebi:10696\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C11511\",\r\n    \"cas:7298-99-9\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.43059942986667366,\r\n   \"metabolite_quantified\": \"chebi:84212\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C20450\",\r\n    \"cas:3238-40-2\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.636098921296401,\r\n   \"metabolite_quantified\": \"chebi:15887\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C00431\",\r\n    \"cas:660-88-8\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.784799226138759,\r\n   \"metabolite_quantified\": \"chebi:37440\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C00846\",\r\n    \"cas:689-31-6\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.6699996565892525,\r\n   \"metabolite_quantified\": \"chebi:17196\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C00152\",\r\n    \"cas:70-47-3\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.6288177988274924,\r\n   \"metabolite_quantified\": \"chebi:27469\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C06473\",\r\n    \"cas:669-90-9\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.6308578077763797,\r\n   \"metabolite_quantified\": \"chebi:18383\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C06393\",\r\n    \"cas:515-94-6\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.5341614660622405,\r\n   \"metabolite_quantified\": \"chebi:53455\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C00181\",\r\n    \"cas:58-86-6\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.5313647031780145,\r\n   \"metabolite_quantified\": \"chebi:16789\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C00476\",\r\n    \"cas:1114-34-7\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.6619107974509035,\r\n   \"metabolite_quantified\": \"chebi:17140\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C00310\",\r\n    \"cas:551-84-8\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.5469156946283686,\r\n   \"metabolite_quantified\": \"chebi:27957\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C05235\",\r\n    \"cas:116-09-6\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.567299070892801,\r\n   \"metabolite_quantified\": \"chebi:47013\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C00121\",\r\n    \"cas:50-69-1\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.5887552592863831,\r\n   \"metabolite_quantified\": \"chebi:29069\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C01606\",\r\n    \"cas:88-99-3\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.5864252731321978,\r\n   \"metabolite_quantified\": \"chebi:16347\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C00318\",\r\n    \"cas:541-15-1\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.8350046987387281,\r\n   \"metabolite_quantified\": \"chebi:28939\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C06809\",\r\n    \"cas:616-91-1\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.7418923595210808,\r\n   \"metabolite_quantified\": \"chebi:16151\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C02274\",\r\n    \"cas:119-84-6\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.5942648116156016,\r\n   \"metabolite_quantified\": \"chebi:\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:\",\r\n    \"cas:2503-46-0\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.5638310923233428,\r\n   \"metabolite_quantified\": \"chebi:28508\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C05585\",\r\n    \"cas:1194-98-5\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.4740603946345034,\r\n   \"metabolite_quantified\": \"chebi:17138\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C00661\",\r\n    \"cas:142-10-9\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.5980243767020731,\r\n   \"metabolite_quantified\": \"chebi:37023\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C00956\",\r\n    \"cas:542-32-5\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.4002388151655255,\r\n   \"metabolite_quantified\": \"chebi:16343\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C02735\",\r\n    \"cas:7568-93-6\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.7179726715036194,\r\n   \"metabolite_quantified\": \"chebi:18333\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C01904\",\r\n    \"cas:488-82-4\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.4708572918717758,\r\n   \"metabolite_quantified\": \"chebi:132089\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:None\",\r\n    \"cas:819-83-0\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.35766036971687204,\r\n   \"metabolite_quantified\": \"chebi:1427\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C11457\",\r\n    \"cas:621-54-5\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.8369130080908634,\r\n   \"metabolite_quantified\": \"chebi:16318\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C02235\",\r\n    \"cas:3316-09-4\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.5804602350528877,\r\n   \"metabolite_quantified\": \"chebi:17016\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C02989\",\r\n    \"cas:3226-65-1\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.7728425665104501,\r\n   \"metabolite_quantified\": \"chebi:41941\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C01161\",\r\n    \"cas:102-32-9\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.673621338812686,\r\n   \"metabolite_quantified\": \"chebi:143268\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:None\",\r\n    \"cas:93-62-9\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.6750449873671542,\r\n   \"metabolite_quantified\": \"chebi:41941\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C01161\",\r\n    \"cas:102-32-9\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.5306154623983572,\r\n   \"metabolite_quantified\": \"chebi:\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:\",\r\n    \"cas:60658-41-5\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.5687060169848213,\r\n   \"metabolite_quantified\": \"chebi:37525\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C12147\",\r\n    \"cas:1114-81-4\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.9145822021173217,\r\n   \"metabolite_quantified\": \"chebi:15760\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C00483\",\r\n    \"cas:51-67-2\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.5873396048939045,\r\n   \"metabolite_quantified\": \"chebi:27480\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C05598\",\r\n    \"cas:500-98-1\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.4496746687074059,\r\n   \"metabolite_quantified\": \"chebi:13022\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:None\",\r\n    \"cas:3615-56-3\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.7593889965021027,\r\n   \"metabolite_quantified\": \"chebi:15676\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C01551\",\r\n    \"cas:97-59-6\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.5481079272828725,\r\n   \"metabolite_quantified\": \"chebi:7563\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C05380\",\r\n    \"cas:583-08-4\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.7267746249864583,\r\n   \"metabolite_quantified\": \"chebi:71028\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C05829\",\r\n    \"cas:1188-38-1\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.5646163266944946,\r\n   \"metabolite_quantified\": \"chebi:32357\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C12621\",\r\n    \"cas:14755-02-3\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.6473725957814226,\r\n   \"metabolite_quantified\": \"chebi:17521\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C00296\",\r\n    \"cas:77-95-2\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.6286637430378332,\r\n   \"metabolite_quantified\": \"chebi:16050\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C02172\",\r\n    \"cas:574-17-4\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.6385545393934421,\r\n   \"metabolite_quantified\": \"chebi:17268\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C00137\",\r\n    \"cas:87-89-8\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.8840262116550605,\r\n   \"metabolite_quantified\": \"chebi:28729\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C00936\",\r\n    \"cas:3458-28-4\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.8590593876193888,\r\n   \"metabolite_quantified\": \"chebi:17924\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C00794\",\r\n    \"cas:50-70-4\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.6290857905457774,\r\n   \"metabolite_quantified\": \"chebi:17405\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C00847\",\r\n    \"cas:82-82-6\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.6448734426630998,\r\n   \"metabolite_quantified\": \"chebi:27373\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C05944\",\r\n    \"cas:81-13-0\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.6950109285554729,\r\n   \"metabolite_quantified\": \"chebi:46905\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C00864\",\r\n    \"cas:79-83-4\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.4308743704009236,\r\n   \"metabolite_quantified\": \"chebi:17895\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C00082\",\r\n    \"cas:60-18-4\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.4854555010156476,\r\n   \"metabolite_quantified\": \"chebi:16349\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C00327\",\r\n    \"cas:372-75-8\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.8251435945870037,\r\n   \"metabolite_quantified\": \"chebi:27956\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C05422\",\r\n    \"cas:490-83-5\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.8451080373495999,\r\n   \"metabolite_quantified\": \"chebi:15903\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C00221\",\r\n    \"cas:492-61-5\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.9052449384729453,\r\n   \"metabolite_quantified\": \"chebi:70744\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:None\",\r\n    \"cas:704-15-4\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.5719159708945706,\r\n   \"metabolite_quantified\": \"chebi:16002\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C00818\",\r\n    \"cas:87-73-0\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.42276321807984746,\r\n   \"metabolite_quantified\": \"chebi:17361\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C00055\",\r\n    \"cas:63-37-6\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.45787640451665196,\r\n   \"metabolite_quantified\": \"chebi:87248\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:None\",\r\n    \"cas:17685-04-0\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.7533559896994455,\r\n   \"metabolite_quantified\": \"chebi:33198\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C00257\",\r\n    \"cas:526-95-4\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.6389527201019071,\r\n   \"metabolite_quantified\": \"chebi:17784\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C03752\",\r\n    \"cas:3646-68-2\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.992423154232201,\r\n   \"metabolite_quantified\": \"chebi:150326\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:None\",\r\n    \"cas:64519-82-0\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.6276628087373703,\r\n   \"metabolite_quantified\": \"chebi:73828\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:None\",\r\n    \"cas:6157-06-8\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.6337990558077677,\r\n   \"metabolite_quantified\": \"chebi:16705\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C02954\",\r\n    \"cas:551-16-6\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.6296216825215527,\r\n   \"metabolite_quantified\": \"chebi:29750\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C00331\",\r\n    \"cas:392-12-1\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.9854573104048074,\r\n   \"metabolite_quantified\": \"chebi:28842\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C01530\",\r\n    \"cas:57-11-4\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.8757073594856993,\r\n   \"metabolite_quantified\": \"chebi:18358\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C01864\",\r\n    \"cas:298-81-7\"\r\n   ]\r\n  },\r\n  {\r\n   \"highest_similarity_score\": 0.6233158748981933,\r\n   \"metabolite_quantified\": \"chebi:18047\",\r\n   \"alternate_identifiers\": [\r\n    \"kegg:C02147\",\r\n    \"cas:462-20-4\"\r\n   ]\r\n  }\r\n ]\r\n}\r\n```",
"body": "@cmungall @dehays @wdduncan \r\nand here is the data product registration file, which only contain one DataObj, and a mockup url, for now: \r\n```json\r\n[\r\n {\r\n  \"id\": \"nmdc:91545873ce109f9b81e21368dfb7ae65\",\r\n  \"name\": \"4-AA_L-AsparticAcid.cdf\",\r\n  \"description\": \"MetaMS GC-MS metabolomics output detail CSV file\",\r\n  \"file_size_bytes\": 7396316,\r\n  \"md5_checksum\": \"91545873ce109f9b81e21368dfb7ae65\",\r\n  \"url\": \"https://data.corems.emsl.pnnl.gov\",\r\n  \"was_generated_by\": \"nmdc:b00cbf1a0506499f873cd795543f8a7a\"\r\n }\r\n]\r\n```",
"body": "Dependent on #170 \r\n\r\nThe json output should validate against nmdc.json\r\n",
"body": "My current understanding is that metaG/T/P and metaB/OMC will be linked through sample only for GSP, but that this would be added in the future. Does that match your expectation or conversations @cmungall?",
"body": "in order to support search of metaG/T/P by compound we need linkages.  See #176",
"body": "@scanon does this look right to you?",
"body": "",
"body": "Required for #176 \r\n\r\n",
"body": "This is exactly the kind of picture I was thinking of, thanks. Makes sense that these relationships are independent of a particular system like KEGG.\r\n\r\nWould **Organic Matter Classification analysis** also link to compound? It's my understanding that those analyses could include many more compounds with different IDs. Similar question for **Lipidomics analysis**. It's unclear whether all of these analysis types are targeted for Feb.\r\n\r\nIt would be good to start to understand the least-surprise joins that a user would expect upon search. So, for example, would searching by one **Genome feature** match any **megaB analysis** containing any **Compounds** linked to the **Function Descriptor** of the **Genome feature**? If you bounce around between joins enough (esp. if they are many to many), you might start capturing much more in your search than you expected.",
"body": "@jeffbaumes  Yes, both organic matter characterization and lipidomics would follow the same path through that diagram as metabolomics.  And Yuri intends to include the same structure in  for including compound terms for all three.",
"body": "This picture is really helpful, thanks, Chris!\r\n\r\nFor Feb we have discussed metaG, metaT (if we've got processed data), metaP, and metaB since we should have NMDC pipelines for each of those types. \r\n\r\nFor lipidomics and organic matter, we'd like to include the data (with guidance on which data would be useful), but only show the data as being connected to a study. If there are pipelines and appropriate annotation information, then functional links would be great. I don't think it's a priority for February. \r\n",
"body": "@jeffbaumes It looks like he still working on it, but that document Chris linked has a user story section that you might find useful",
"body": "@jeffbaumes @dehays don't worry about the linked document for now, I updated the first comment to include the relevant text",
"body": "![annotation schema](https://user-images.githubusercontent.com/50745/101949125-f9b68e00-3ba7-11eb-96a8-e85617c3adf2.png)\r\n\r\nFor orientation: the genome feature class corresponds to the main entry in a GFF3 file, and the link to a descriptor corresponds to col9\r\n\r\nSee [this doc](https://docs.google.com/document/d/12ndhKQdGWHoRiWFw4TRqfIjObJSov6NmrkT3ozsSrus/edit#) for the source of the image\r\n\r\nThis shows a generalized annotation schema for functional annotation in NMDC (todo: link to actual schema). It is neutral w.r.t system used. The various subclasses of ControlledTerm are for different aspects of function, and may be covered differently by different systems (see the courier font text to the side of each box). E.g. KEGG has reactions, pathways, compounds, and links between them.\r\n\r\nVery rough sketch of some user stories to help us think about how search would be implemented:\r\n\r\n - User is interested in ammonifying microbes in soil. They come to NMDC to find datasets or explore hypotheses.\r\n    - Chemical search: They enter \u201cNH3\u201d as a search term, and they see all metaP/B/G/T datasets that are associated. They see in faceted search (from mixs metadata)  this is 30% soil datasets, 20% ocean, .. they further drill down on soil. They see 80% metagenomic, 20% metaproteomics, they drill down\r\n        - The user\u2019s term NH3 maps to equivalent IDs in KEGG.compound, CHEBI, \u2026 if the metaB dataset is annotated with any of these it is included\r\n        - The user\u2019s term NH3 maps to equivalent IDs in KEGG.compound, CHEBI, \u2026. These are linked from pathways and reactions in GO, KEGG, Rhea, MetaCyc via substrate/product relations. These pathway/reaction IDs are used in metaP/G/T annotations (linked via protein IDs)\r\n         - In both cases, hierarchy needs to be used; E.g data annotated to L-homocysteine will be returned in queries for homocysteine or amino acid\r\n     - Function search: They enter a function (reaction) term like \u201cnitrogen fixation\u201d, and see metaP/B/G/T datasets that are associated and drill down in the same way\r\n          - The user\u2019s search term maps to equivalent IDs in Rhea, KEGG (https://www.genome.jp/kegg-bin/show_module?M00175) and other databases.\r\n         - We could potentially find the products (e.g NH3) and return metaB sets, but would have to be clear why this was returned\r\n         - metaG/T/P queries would return gene products annotated to this or a descendant, and could link to datasets from here\r\n",
"body": "Add `make test` in #188 ",
"body": "Add `make test` to `.travis.yaml`.\r\n\r\n@cmungall Are you wanting to test the json output from the ETL?",
"body": "Does bml-1.6.0 require `python 3.8`?  \r\nI made local branch of the PR (see here for how: https://gist.github.com/adam-p/15413fabef6cffecd897)\r\n\r\nI ran `make clean` and `make all`. I received this message:\r\n\r\n```\r\nERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\ntox 3.14.1 requires importlib-metadata<1,>=0.12; python_version < \"3.8\", but you have importlib-metadata 1.6.1 which is incompatible.\r\n```\r\nI'm currently running python 3.7.8.\r\n",
"body": "@wdduncan Looks like this branch is running fine locally (with Python 3.7.3) and on Travis (with Python 3.7.1).\r\n\r\nPerhaps the above error has to do with your local environment?\r\n\r\nEither way - the bug is originating from a dependency that Tox needs.\r\n\r\n",
"body": "The @deepakunni3!\r\nHow did you run it locally to test?",
"body": "I did the following after checkout of the branch:\r\n```sh\r\nmake clean\r\nmake all\r\n```\r\n\r\nThe Python that is running is:\r\n```sh\r\npipenv run python --version\r\nPython 3.7.3\r\n```\r\n\r\nHere is the dependency graph as provided by pipenv:\r\n```sh\r\nbiolinkml==1.5.10\r\n  - argparse [required: >=1.4.0, installed: 1.1]\r\n  - click [required: ~=7.0, installed: 7.1.2]\r\n  - env [required: Any, installed: 0.1.0]\r\n  - graphviz [required: >=0.10.1, installed: 0.14.2]\r\n  - isodate [required: >=0.6.0, installed: 0.6.0]\r\n    - six [required: Any, installed: 1.15.0]\r\n  - jsonasobj [required: ~=1.2.1, installed: 1.2.1]\r\n  - jsonschema [required: >=3.0.1, installed: 3.2.0]\r\n    - attrs [required: >=17.4.0, installed: 20.2.0]\r\n    - importlib-metadata [required: Any, installed: 2.0.0]\r\n      - zipp [required: >=0.5, installed: 3.3.1]\r\n    - pyrsistent [required: >=0.14.0, installed: 0.17.3]\r\n    - setuptools [required: Any, installed: 50.3.1]\r\n    - six [required: >=1.11.0, installed: 1.15.0]\r\n  - prefixcommons [required: >=0.1.7, installed: 0.1.9]\r\n    - pyyaml [required: Any, installed: 5.3.1]\r\n    - requests [required: Any, installed: 2.24.0]\r\n      - certifi [required: >=2017.4.17, installed: 2020.6.20]\r\n      - chardet [required: >=3.0.2,<4, installed: 3.0.4]\r\n      - idna [required: >=2.5,<3, installed: 2.10]\r\n      - urllib3 [required: >=1.21.1,<1.26,!=1.25.1,!=1.25.0, installed: 1.25.10]\r\n  - prologterms [required: >=0.0.6, installed: 0.0.6]\r\n  - pyjsg [required: >=0.9.1, installed: 0.10.0]\r\n    - antlr4-python3-runtime [required: >=4.7, installed: 4.8]\r\n    - jsonasobj [required: >=1.2.0, installed: 1.2.1]\r\n    - requests [required: Any, installed: 2.24.0]\r\n      - certifi [required: >=2017.4.17, installed: 2020.6.20]\r\n      - chardet [required: >=3.0.2,<4, installed: 3.0.4]\r\n      - idna [required: >=2.5,<3, installed: 2.10]\r\n      - urllib3 [required: >=1.21.1,<1.26,!=1.25.1,!=1.25.0, installed: 1.25.10]\r\n  - pyshex [required: ~=0.7.14, installed: 0.7.14]\r\n    - cfgraph [required: >=0.2.1, installed: 0.2.1]\r\n      - rdflib [required: >=0.4.2, installed: 5.0.0]\r\n        - isodate [required: Any, installed: 0.6.0]\r\n          - six [required: Any, installed: 1.15.0]\r\n        - pyparsing [required: Any, installed: 2.4.7]\r\n        - six [required: Any, installed: 1.15.0]\r\n    - pyshexc [required: >=0.5.4, installed: 0.8.2]\r\n      - antlr4-python3-runtime [required: ~=4.8, installed: 4.8]\r\n      - certifi [required: Any, installed: 2020.6.20]\r\n      - jsonasobj [required: >=1.2.1, installed: 1.2.1]\r\n      - pyjsg [required: ~=0.10, installed: 0.10.0]\r\n        - antlr4-python3-runtime [required: >=4.7, installed: 4.8]\r\n        - jsonasobj [required: >=1.2.0, installed: 1.2.1]\r\n        - requests [required: Any, installed: 2.24.0]\r\n          - certifi [required: >=2017.4.17, installed: 2020.6.20]\r\n          - chardet [required: >=3.0.2,<4, installed: 3.0.4]\r\n          - idna [required: >=2.5,<3, installed: 2.10]\r\n          - urllib3 [required: >=1.21.1,<1.26,!=1.25.1,!=1.25.0, installed: 1.25.10]\r\n      - rdflib [required: ~=5.0, installed: 5.0.0]\r\n        - isodate [required: Any, installed: 0.6.0]\r\n          - six [required: Any, installed: 1.15.0]\r\n        - pyparsing [required: Any, installed: 2.4.7]\r\n        - six [required: Any, installed: 1.15.0]\r\n      - rdflib-jsonld [required: ~=0.5, installed: 0.5.0]\r\n        - rdflib [required: >=4.2.2, installed: 5.0.0]\r\n          - isodate [required: Any, installed: 0.6.0]\r\n            - six [required: Any, installed: 1.15.0]\r\n          - pyparsing [required: Any, installed: 2.4.7]\r\n          - six [required: Any, installed: 1.15.0]\r\n      - requests [required: >=2.21, installed: 2.24.0]\r\n        - certifi [required: >=2017.4.17, installed: 2020.6.20]\r\n        - chardet [required: >=3.0.2,<4, installed: 3.0.4]\r\n        - idna [required: >=2.5,<3, installed: 2.10]\r\n        - urllib3 [required: >=1.21.1,<1.26,!=1.25.1,!=1.25.0, installed: 1.25.10]\r\n      - shexjsg [required: ~=0.7, installed: 0.7.0]\r\n        - pyjsg [required: ~=0.10, installed: 0.10.0]\r\n          - antlr4-python3-runtime [required: >=4.7, installed: 4.8]\r\n          - jsonasobj [required: >=1.2.0, installed: 1.2.1]\r\n          - requests [required: Any, installed: 2.24.0]\r\n            - certifi [required: >=2017.4.17, installed: 2020.6.20]\r\n            - chardet [required: >=3.0.2,<4, installed: 3.0.4]\r\n            - idna [required: >=2.5,<3, installed: 2.10]\r\n            - urllib3 [required: >=1.21.1,<1.26,!=1.25.1,!=1.25.0, installed: 1.25.10]\r\n    - rdflib [required: >=4.2.2, installed: 5.0.0]\r\n      - isodate [required: Any, installed: 0.6.0]\r\n        - six [required: Any, installed: 1.15.0]\r\n      - pyparsing [required: Any, installed: 2.4.7]\r\n      - six [required: Any, installed: 1.15.0]\r\n    - rdflib-jsonld [required: >=0.4.0, installed: 0.5.0]\r\n      - rdflib [required: >=4.2.2, installed: 5.0.0]\r\n        - isodate [required: Any, installed: 0.6.0]\r\n          - six [required: Any, installed: 1.15.0]\r\n        - pyparsing [required: Any, installed: 2.4.7]\r\n        - six [required: Any, installed: 1.15.0]\r\n    - requests [required: Any, installed: 2.24.0]\r\n      - certifi [required: >=2017.4.17, installed: 2020.6.20]\r\n      - chardet [required: >=3.0.2,<4, installed: 3.0.4]\r\n      - idna [required: >=2.5,<3, installed: 2.10]\r\n      - urllib3 [required: >=1.21.1,<1.26,!=1.25.1,!=1.25.0, installed: 1.25.10]\r\n    - shexjsg [required: >=0.6.5, installed: 0.7.0]\r\n      - pyjsg [required: ~=0.10, installed: 0.10.0]\r\n        - antlr4-python3-runtime [required: >=4.7, installed: 4.8]\r\n        - jsonasobj [required: >=1.2.0, installed: 1.2.1]\r\n        - requests [required: Any, installed: 2.24.0]\r\n          - certifi [required: >=2017.4.17, installed: 2020.6.20]\r\n          - chardet [required: >=3.0.2,<4, installed: 3.0.4]\r\n          - idna [required: >=2.5,<3, installed: 2.10]\r\n          - urllib3 [required: >=1.21.1,<1.26,!=1.25.1,!=1.25.0, installed: 1.25.10]\r\n    - sparql-slurper [required: >=0.2.1, installed: 0.3.4]\r\n      - pbr [required: Any, installed: 5.5.0]\r\n      - rdflib [required: >=4.2.2, installed: 5.0.0]\r\n        - isodate [required: Any, installed: 0.6.0]\r\n          - six [required: Any, installed: 1.15.0]\r\n        - pyparsing [required: Any, installed: 2.4.7]\r\n        - six [required: Any, installed: 1.15.0]\r\n      - sparqlwrapper [required: >=1.8.2, installed: 1.8.5]\r\n        - rdflib [required: >=4.0, installed: 5.0.0]\r\n          - isodate [required: Any, installed: 0.6.0]\r\n            - six [required: Any, installed: 1.15.0]\r\n          - pyparsing [required: Any, installed: 2.4.7]\r\n          - six [required: Any, installed: 1.15.0]\r\n    - sparqlwrapper [required: Any, installed: 1.8.5]\r\n      - rdflib [required: >=4.0, installed: 5.0.0]\r\n        - isodate [required: Any, installed: 0.6.0]\r\n          - six [required: Any, installed: 1.15.0]\r\n        - pyparsing [required: Any, installed: 2.4.7]\r\n        - six [required: Any, installed: 1.15.0]\r\n    - urllib3 [required: Any, installed: 1.25.10]\r\n  - pyshexc [required: ~=0.8, installed: 0.8.2]\r\n    - antlr4-python3-runtime [required: ~=4.8, installed: 4.8]\r\n    - certifi [required: Any, installed: 2020.6.20]\r\n    - jsonasobj [required: >=1.2.1, installed: 1.2.1]\r\n    - pyjsg [required: ~=0.10, installed: 0.10.0]\r\n      - antlr4-python3-runtime [required: >=4.7, installed: 4.8]\r\n      - jsonasobj [required: >=1.2.0, installed: 1.2.1]\r\n      - requests [required: Any, installed: 2.24.0]\r\n        - certifi [required: >=2017.4.17, installed: 2020.6.20]\r\n        - chardet [required: >=3.0.2,<4, installed: 3.0.4]\r\n        - idna [required: >=2.5,<3, installed: 2.10]\r\n        - urllib3 [required: >=1.21.1,<1.26,!=1.25.1,!=1.25.0, installed: 1.25.10]\r\n    - rdflib [required: ~=5.0, installed: 5.0.0]\r\n      - isodate [required: Any, installed: 0.6.0]\r\n        - six [required: Any, installed: 1.15.0]\r\n      - pyparsing [required: Any, installed: 2.4.7]\r\n      - six [required: Any, installed: 1.15.0]\r\n    - rdflib-jsonld [required: ~=0.5, installed: 0.5.0]\r\n      - rdflib [required: >=4.2.2, installed: 5.0.0]\r\n        - isodate [required: Any, installed: 0.6.0]\r\n          - six [required: Any, installed: 1.15.0]\r\n        - pyparsing [required: Any, installed: 2.4.7]\r\n        - six [required: Any, installed: 1.15.0]\r\n    - requests [required: >=2.21, installed: 2.24.0]\r\n      - certifi [required: >=2017.4.17, installed: 2020.6.20]\r\n      - chardet [required: >=3.0.2,<4, installed: 3.0.4]\r\n      - idna [required: >=2.5,<3, installed: 2.10]\r\n      - urllib3 [required: >=1.21.1,<1.26,!=1.25.1,!=1.25.0, installed: 1.25.10]\r\n    - shexjsg [required: ~=0.7, installed: 0.7.0]\r\n      - pyjsg [required: ~=0.10, installed: 0.10.0]\r\n        - antlr4-python3-runtime [required: >=4.7, installed: 4.8]\r\n        - jsonasobj [required: >=1.2.0, installed: 1.2.1]\r\n        - requests [required: Any, installed: 2.24.0]\r\n          - certifi [required: >=2017.4.17, installed: 2020.6.20]\r\n          - chardet [required: >=3.0.2,<4, installed: 3.0.4]\r\n          - idna [required: >=2.5,<3, installed: 2.10]\r\n          - urllib3 [required: >=1.21.1,<1.26,!=1.25.1,!=1.25.0, installed: 1.25.10]\r\n  - pyyaml [required: ~=5.1, installed: 5.3.1]\r\n  - rdflib [required: >=4.2.2, installed: 5.0.0]\r\n    - isodate [required: Any, installed: 0.6.0]\r\n      - six [required: Any, installed: 1.15.0]\r\n    - pyparsing [required: Any, installed: 2.4.7]\r\n    - six [required: Any, installed: 1.15.0]\r\n  - rdflib-jsonld [required: >=0.5.0, installed: 0.5.0]\r\n    - rdflib [required: >=4.2.2, installed: 5.0.0]\r\n      - isodate [required: Any, installed: 0.6.0]\r\n        - six [required: Any, installed: 1.15.0]\r\n      - pyparsing [required: Any, installed: 2.4.7]\r\n      - six [required: Any, installed: 1.15.0]\r\n  - requests [required: >=2.22, installed: 2.24.0]\r\n    - certifi [required: >=2017.4.17, installed: 2020.6.20]\r\n    - chardet [required: >=3.0.2,<4, installed: 3.0.4]\r\n    - idna [required: >=2.5,<3, installed: 2.10]\r\n    - urllib3 [required: >=1.21.1,<1.26,!=1.25.1,!=1.25.0, installed: 1.25.10]\r\n  - watchdog [required: >=0.9.0, installed: 0.10.3]\r\n    - pathtools [required: >=0.1.1, installed: 0.1.2]\r\njupyter==1.0.0\r\n  - ipykernel [required: Any, installed: 5.3.4]\r\n    - appnope [required: Any, installed: 0.1.0]\r\n    - ipython [required: >=5.0.0, installed: 7.18.1]\r\n      - appnope [required: Any, installed: 0.1.0]\r\n      - backcall [required: Any, installed: 0.2.0]\r\n      - decorator [required: Any, installed: 4.4.2]\r\n      - jedi [required: >=0.10, installed: 0.17.2]\r\n        - parso [required: >=0.7.0,<0.8.0, installed: 0.7.1]\r\n      - pexpect [required: >4.3, installed: 4.8.0]\r\n        - ptyprocess [required: >=0.5, installed: 0.6.0]\r\n      - pickleshare [required: Any, installed: 0.7.5]\r\n      - prompt-toolkit [required: >=2.0.0,<3.1.0,!=3.0.1,!=3.0.0, installed: 3.0.8]\r\n        - wcwidth [required: Any, installed: 0.2.5]\r\n      - pygments [required: Any, installed: 2.7.1]\r\n      - setuptools [required: >=18.5, installed: 50.3.1]\r\n      - traitlets [required: >=4.2, installed: 5.0.5]\r\n        - ipython-genutils [required: Any, installed: 0.2.0]\r\n    - jupyter-client [required: Any, installed: 6.1.7]\r\n      - jupyter-core [required: >=4.6.0, installed: 4.6.3]\r\n        - traitlets [required: Any, installed: 5.0.5]\r\n          - ipython-genutils [required: Any, installed: 0.2.0]\r\n      - python-dateutil [required: >=2.1, installed: 2.8.1]\r\n        - six [required: >=1.5, installed: 1.15.0]\r\n      - pyzmq [required: >=13, installed: 19.0.2]\r\n      - tornado [required: >=4.1, installed: 6.0.4]\r\n      - traitlets [required: Any, installed: 5.0.5]\r\n        - ipython-genutils [required: Any, installed: 0.2.0]\r\n    - tornado [required: >=4.2, installed: 6.0.4]\r\n    - traitlets [required: >=4.1.0, installed: 5.0.5]\r\n      - ipython-genutils [required: Any, installed: 0.2.0]\r\n  - ipywidgets [required: Any, installed: 7.5.1]\r\n    - ipykernel [required: >=4.5.1, installed: 5.3.4]\r\n      - appnope [required: Any, installed: 0.1.0]\r\n      - ipython [required: >=5.0.0, installed: 7.18.1]\r\n        - appnope [required: Any, installed: 0.1.0]\r\n        - backcall [required: Any, installed: 0.2.0]\r\n        - decorator [required: Any, installed: 4.4.2]\r\n        - jedi [required: >=0.10, installed: 0.17.2]\r\n          - parso [required: >=0.7.0,<0.8.0, installed: 0.7.1]\r\n        - pexpect [required: >4.3, installed: 4.8.0]\r\n          - ptyprocess [required: >=0.5, installed: 0.6.0]\r\n        - pickleshare [required: Any, installed: 0.7.5]\r\n        - prompt-toolkit [required: >=2.0.0,<3.1.0,!=3.0.1,!=3.0.0, installed: 3.0.8]\r\n          - wcwidth [required: Any, installed: 0.2.5]\r\n        - pygments [required: Any, installed: 2.7.1]\r\n        - setuptools [required: >=18.5, installed: 50.3.1]\r\n        - traitlets [required: >=4.2, installed: 5.0.5]\r\n          - ipython-genutils [required: Any, installed: 0.2.0]\r\n      - jupyter-client [required: Any, installed: 6.1.7]\r\n        - jupyter-core [required: >=4.6.0, installed: 4.6.3]\r\n          - traitlets [required: Any, installed: 5.0.5]\r\n            - ipython-genutils [required: Any, installed: 0.2.0]\r\n        - python-dateutil [required: >=2.1, installed: 2.8.1]\r\n          - six [required: >=1.5, installed: 1.15.0]\r\n        - pyzmq [required: >=13, installed: 19.0.2]\r\n        - tornado [required: >=4.1, installed: 6.0.4]\r\n        - traitlets [required: Any, installed: 5.0.5]\r\n          - ipython-genutils [required: Any, installed: 0.2.0]\r\n      - tornado [required: >=4.2, installed: 6.0.4]\r\n      - traitlets [required: >=4.1.0, installed: 5.0.5]\r\n        - ipython-genutils [required: Any, installed: 0.2.0]\r\n    - ipython [required: >=4.0.0, installed: 7.18.1]\r\n      - appnope [required: Any, installed: 0.1.0]\r\n      - backcall [required: Any, installed: 0.2.0]\r\n      - decorator [required: Any, installed: 4.4.2]\r\n      - jedi [required: >=0.10, installed: 0.17.2]\r\n        - parso [required: >=0.7.0,<0.8.0, installed: 0.7.1]\r\n      - pexpect [required: >4.3, installed: 4.8.0]\r\n        - ptyprocess [required: >=0.5, installed: 0.6.0]\r\n      - pickleshare [required: Any, installed: 0.7.5]\r\n      - prompt-toolkit [required: >=2.0.0,<3.1.0,!=3.0.1,!=3.0.0, installed: 3.0.8]\r\n        - wcwidth [required: Any, installed: 0.2.5]\r\n      - pygments [required: Any, installed: 2.7.1]\r\n      - setuptools [required: >=18.5, installed: 50.3.1]\r\n      - traitlets [required: >=4.2, installed: 5.0.5]\r\n        - ipython-genutils [required: Any, installed: 0.2.0]\r\n    - nbformat [required: >=4.2.0, installed: 5.0.8]\r\n      - ipython-genutils [required: Any, installed: 0.2.0]\r\n      - jsonschema [required: >=2.4,!=2.5.0, installed: 3.2.0]\r\n        - attrs [required: >=17.4.0, installed: 20.2.0]\r\n        - importlib-metadata [required: Any, installed: 2.0.0]\r\n          - zipp [required: >=0.5, installed: 3.3.1]\r\n        - pyrsistent [required: >=0.14.0, installed: 0.17.3]\r\n        - setuptools [required: Any, installed: 50.3.1]\r\n        - six [required: >=1.11.0, installed: 1.15.0]\r\n      - jupyter-core [required: Any, installed: 4.6.3]\r\n        - traitlets [required: Any, installed: 5.0.5]\r\n          - ipython-genutils [required: Any, installed: 0.2.0]\r\n      - traitlets [required: >=4.1, installed: 5.0.5]\r\n        - ipython-genutils [required: Any, installed: 0.2.0]\r\n    - traitlets [required: >=4.3.1, installed: 5.0.5]\r\n      - ipython-genutils [required: Any, installed: 0.2.0]\r\n    - widgetsnbextension [required: ~=3.5.0, installed: 3.5.1]\r\n      - notebook [required: >=4.4.1, installed: 6.1.4]\r\n        - argon2-cffi [required: Any, installed: 20.1.0]\r\n          - cffi [required: >=1.0.0, installed: 1.14.3]\r\n            - pycparser [required: Any, installed: 2.20]\r\n          - six [required: Any, installed: 1.15.0]\r\n        - ipykernel [required: Any, installed: 5.3.4]\r\n          - appnope [required: Any, installed: 0.1.0]\r\n          - ipython [required: >=5.0.0, installed: 7.18.1]\r\n            - appnope [required: Any, installed: 0.1.0]\r\n            - backcall [required: Any, installed: 0.2.0]\r\n            - decorator [required: Any, installed: 4.4.2]\r\n            - jedi [required: >=0.10, installed: 0.17.2]\r\n              - parso [required: >=0.7.0,<0.8.0, installed: 0.7.1]\r\n            - pexpect [required: >4.3, installed: 4.8.0]\r\n              - ptyprocess [required: >=0.5, installed: 0.6.0]\r\n            - pickleshare [required: Any, installed: 0.7.5]\r\n            - prompt-toolkit [required: >=2.0.0,<3.1.0,!=3.0.1,!=3.0.0, installed: 3.0.8]\r\n              - wcwidth [required: Any, installed: 0.2.5]\r\n            - pygments [required: Any, installed: 2.7.1]\r\n            - setuptools [required: >=18.5, installed: 50.3.1]\r\n            - traitlets [required: >=4.2, installed: 5.0.5]\r\n              - ipython-genutils [required: Any, installed: 0.2.0]\r\n          - jupyter-client [required: Any, installed: 6.1.7]\r\n            - jupyter-core [required: >=4.6.0, installed: 4.6.3]\r\n              - traitlets [required: Any, installed: 5.0.5]\r\n                - ipython-genutils [required: Any, installed: 0.2.0]\r\n            - python-dateutil [required: >=2.1, installed: 2.8.1]\r\n              - six [required: >=1.5, installed: 1.15.0]\r\n            - pyzmq [required: >=13, installed: 19.0.2]\r\n            - tornado [required: >=4.1, installed: 6.0.4]\r\n            - traitlets [required: Any, installed: 5.0.5]\r\n              - ipython-genutils [required: Any, installed: 0.2.0]\r\n          - tornado [required: >=4.2, installed: 6.0.4]\r\n          - traitlets [required: >=4.1.0, installed: 5.0.5]\r\n            - ipython-genutils [required: Any, installed: 0.2.0]\r\n        - ipython-genutils [required: Any, installed: 0.2.0]\r\n        - jinja2 [required: Any, installed: 2.11.2]\r\n          - MarkupSafe [required: >=0.23, installed: 1.1.1]\r\n        - jupyter-client [required: >=5.3.4, installed: 6.1.7]\r\n          - jupyter-core [required: >=4.6.0, installed: 4.6.3]\r\n            - traitlets [required: Any, installed: 5.0.5]\r\n              - ipython-genutils [required: Any, installed: 0.2.0]\r\n          - python-dateutil [required: >=2.1, installed: 2.8.1]\r\n            - six [required: >=1.5, installed: 1.15.0]\r\n          - pyzmq [required: >=13, installed: 19.0.2]\r\n          - tornado [required: >=4.1, installed: 6.0.4]\r\n          - traitlets [required: Any, installed: 5.0.5]\r\n            - ipython-genutils [required: Any, installed: 0.2.0]\r\n        - jupyter-core [required: >=4.6.1, installed: 4.6.3]\r\n          - traitlets [required: Any, installed: 5.0.5]\r\n            - ipython-genutils [required: Any, installed: 0.2.0]\r\n        - nbconvert [required: Any, installed: 6.0.7]\r\n          - bleach [required: Any, installed: 3.2.1]\r\n            - packaging [required: Any, installed: 20.4]\r\n              - pyparsing [required: >=2.0.2, installed: 2.4.7]\r\n              - six [required: Any, installed: 1.15.0]\r\n            - six [required: >=1.9.0, installed: 1.15.0]\r\n            - webencodings [required: Any, installed: 0.5.1]\r\n          - defusedxml [required: Any, installed: 0.6.0]\r\n          - entrypoints [required: >=0.2.2, installed: 0.3]\r\n          - jinja2 [required: >=2.4, installed: 2.11.2]\r\n            - MarkupSafe [required: >=0.23, installed: 1.1.1]\r\n          - jupyter-core [required: Any, installed: 4.6.3]\r\n            - traitlets [required: Any, installed: 5.0.5]\r\n              - ipython-genutils [required: Any, installed: 0.2.0]\r\n          - jupyterlab-pygments [required: Any, installed: 0.1.2]\r\n            - pygments [required: >=2.4.1,<3, installed: 2.7.1]\r\n          - mistune [required: >=0.8.1,<2, installed: 0.8.4]\r\n          - nbclient [required: >=0.5.0,<0.6.0, installed: 0.5.1]\r\n            - async-generator [required: Any, installed: 1.10]\r\n            - jupyter-client [required: >=6.1.5, installed: 6.1.7]\r\n              - jupyter-core [required: >=4.6.0, installed: 4.6.3]\r\n                - traitlets [required: Any, installed: 5.0.5]\r\n                  - ipython-genutils [required: Any, installed: 0.2.0]\r\n              - python-dateutil [required: >=2.1, installed: 2.8.1]\r\n                - six [required: >=1.5, installed: 1.15.0]\r\n              - pyzmq [required: >=13, installed: 19.0.2]\r\n              - tornado [required: >=4.1, installed: 6.0.4]\r\n              - traitlets [required: Any, installed: 5.0.5]\r\n                - ipython-genutils [required: Any, installed: 0.2.0]\r\n            - nbformat [required: >=5.0, installed: 5.0.8]\r\n              - ipython-genutils [required: Any, installed: 0.2.0]\r\n              - jsonschema [required: >=2.4,!=2.5.0, installed: 3.2.0]\r\n                - attrs [required: >=17.4.0, installed: 20.2.0]\r\n                - importlib-metadata [required: Any, installed: 2.0.0]\r\n                  - zipp [required: >=0.5, installed: 3.3.1]\r\n                - pyrsistent [required: >=0.14.0, installed: 0.17.3]\r\n                - setuptools [required: Any, installed: 50.3.1]\r\n                - six [required: >=1.11.0, installed: 1.15.0]\r\n              - jupyter-core [required: Any, installed: 4.6.3]\r\n                - traitlets [required: Any, installed: 5.0.5]\r\n                  - ipython-genutils [required: Any, installed: 0.2.0]\r\n              - traitlets [required: >=4.1, installed: 5.0.5]\r\n                - ipython-genutils [required: Any, installed: 0.2.0]\r\n            - nest-asyncio [required: Any, installed: 1.4.1]\r\n            - traitlets [required: >=4.2, installed: 5.0.5]\r\n              - ipython-genutils [required: Any, installed: 0.2.0]\r\n          - nbformat [required: >=4.4, installed: 5.0.8]\r\n            - ipython-genutils [required: Any, installed: 0.2.0]\r\n            - jsonschema [required: >=2.4,!=2.5.0, installed: 3.2.0]\r\n              - attrs [required: >=17.4.0, installed: 20.2.0]\r\n              - importlib-metadata [required: Any, installed: 2.0.0]\r\n                - zipp [required: >=0.5, installed: 3.3.1]\r\n              - pyrsistent [required: >=0.14.0, installed: 0.17.3]\r\n              - setuptools [required: Any, installed: 50.3.1]\r\n              - six [required: >=1.11.0, installed: 1.15.0]\r\n            - jupyter-core [required: Any, installed: 4.6.3]\r\n              - traitlets [required: Any, installed: 5.0.5]\r\n                - ipython-genutils [required: Any, installed: 0.2.0]\r\n            - traitlets [required: >=4.1, installed: 5.0.5]\r\n              - ipython-genutils [required: Any, installed: 0.2.0]\r\n          - pandocfilters [required: >=1.4.1, installed: 1.4.2]\r\n          - pygments [required: >=2.4.1, installed: 2.7.1]\r\n          - testpath [required: Any, installed: 0.4.4]\r\n          - traitlets [required: >=4.2, installed: 5.0.5]\r\n            - ipython-genutils [required: Any, installed: 0.2.0]\r\n        - nbformat [required: Any, installed: 5.0.8]\r\n          - ipython-genutils [required: Any, installed: 0.2.0]\r\n          - jsonschema [required: >=2.4,!=2.5.0, installed: 3.2.0]\r\n            - attrs [required: >=17.4.0, installed: 20.2.0]\r\n            - importlib-metadata [required: Any, installed: 2.0.0]\r\n              - zipp [required: >=0.5, installed: 3.3.1]\r\n            - pyrsistent [required: >=0.14.0, installed: 0.17.3]\r\n            - setuptools [required: Any, installed: 50.3.1]\r\n            - six [required: >=1.11.0, installed: 1.15.0]\r\n          - jupyter-core [required: Any, installed: 4.6.3]\r\n            - traitlets [required: Any, installed: 5.0.5]\r\n              - ipython-genutils [required: Any, installed: 0.2.0]\r\n          - traitlets [required: >=4.1, installed: 5.0.5]\r\n            - ipython-genutils [required: Any, installed: 0.2.0]\r\n        - prometheus-client [required: Any, installed: 0.8.0]\r\n        - pyzmq [required: >=17, installed: 19.0.2]\r\n        - Send2Trash [required: Any, installed: 1.5.0]\r\n        - terminado [required: >=0.8.3, installed: 0.9.1]\r\n          - ptyprocess [required: Any, installed: 0.6.0]\r\n          - tornado [required: >=4, installed: 6.0.4]\r\n        - tornado [required: >=5.0, installed: 6.0.4]\r\n        - traitlets [required: >=4.2.1, installed: 5.0.5]\r\n          - ipython-genutils [required: Any, installed: 0.2.0]\r\n  - jupyter-console [required: Any, installed: 6.2.0]\r\n    - ipykernel [required: Any, installed: 5.3.4]\r\n      - appnope [required: Any, installed: 0.1.0]\r\n      - ipython [required: >=5.0.0, installed: 7.18.1]\r\n        - appnope [required: Any, installed: 0.1.0]\r\n        - backcall [required: Any, installed: 0.2.0]\r\n        - decorator [required: Any, installed: 4.4.2]\r\n        - jedi [required: >=0.10, installed: 0.17.2]\r\n          - parso [required: >=0.7.0,<0.8.0, installed: 0.7.1]\r\n        - pexpect [required: >4.3, installed: 4.8.0]\r\n          - ptyprocess [required: >=0.5, installed: 0.6.0]\r\n        - pickleshare [required: Any, installed: 0.7.5]\r\n        - prompt-toolkit [required: >=2.0.0,<3.1.0,!=3.0.1,!=3.0.0, installed: 3.0.8]\r\n          - wcwidth [required: Any, installed: 0.2.5]\r\n        - pygments [required: Any, installed: 2.7.1]\r\n        - setuptools [required: >=18.5, installed: 50.3.1]\r\n        - traitlets [required: >=4.2, installed: 5.0.5]\r\n          - ipython-genutils [required: Any, installed: 0.2.0]\r\n      - jupyter-client [required: Any, installed: 6.1.7]\r\n        - jupyter-core [required: >=4.6.0, installed: 4.6.3]\r\n          - traitlets [required: Any, installed: 5.0.5]\r\n            - ipython-genutils [required: Any, installed: 0.2.0]\r\n        - python-dateutil [required: >=2.1, installed: 2.8.1]\r\n          - six [required: >=1.5, installed: 1.15.0]\r\n        - pyzmq [required: >=13, installed: 19.0.2]\r\n        - tornado [required: >=4.1, installed: 6.0.4]\r\n        - traitlets [required: Any, installed: 5.0.5]\r\n          - ipython-genutils [required: Any, installed: 0.2.0]\r\n      - tornado [required: >=4.2, installed: 6.0.4]\r\n      - traitlets [required: >=4.1.0, installed: 5.0.5]\r\n        - ipython-genutils [required: Any, installed: 0.2.0]\r\n    - ipython [required: Any, installed: 7.18.1]\r\n      - appnope [required: Any, installed: 0.1.0]\r\n      - backcall [required: Any, installed: 0.2.0]\r\n      - decorator [required: Any, installed: 4.4.2]\r\n      - jedi [required: >=0.10, installed: 0.17.2]\r\n        - parso [required: >=0.7.0,<0.8.0, installed: 0.7.1]\r\n      - pexpect [required: >4.3, installed: 4.8.0]\r\n        - ptyprocess [required: >=0.5, installed: 0.6.0]\r\n      - pickleshare [required: Any, installed: 0.7.5]\r\n      - prompt-toolkit [required: >=2.0.0,<3.1.0,!=3.0.1,!=3.0.0, installed: 3.0.8]\r\n        - wcwidth [required: Any, installed: 0.2.5]\r\n      - pygments [required: Any, installed: 2.7.1]\r\n      - setuptools [required: >=18.5, installed: 50.3.1]\r\n      - traitlets [required: >=4.2, installed: 5.0.5]\r\n        - ipython-genutils [required: Any, installed: 0.2.0]\r\n    - jupyter-client [required: Any, installed: 6.1.7]\r\n      - jupyter-core [required: >=4.6.0, installed: 4.6.3]\r\n        - traitlets [required: Any, installed: 5.0.5]\r\n          - ipython-genutils [required: Any, installed: 0.2.0]\r\n      - python-dateutil [required: >=2.1, installed: 2.8.1]\r\n        - six [required: >=1.5, installed: 1.15.0]\r\n      - pyzmq [required: >=13, installed: 19.0.2]\r\n      - tornado [required: >=4.1, installed: 6.0.4]\r\n      - traitlets [required: Any, installed: 5.0.5]\r\n        - ipython-genutils [required: Any, installed: 0.2.0]\r\n    - prompt-toolkit [required: >=2.0.0,<3.1.0,!=3.0.1,!=3.0.0, installed: 3.0.8]\r\n      - wcwidth [required: Any, installed: 0.2.5]\r\n    - pygments [required: Any, installed: 2.7.1]\r\n  - nbconvert [required: Any, installed: 6.0.7]\r\n    - bleach [required: Any, installed: 3.2.1]\r\n      - packaging [required: Any, installed: 20.4]\r\n        - pyparsing [required: >=2.0.2, installed: 2.4.7]\r\n        - six [required: Any, installed: 1.15.0]\r\n      - six [required: >=1.9.0, installed: 1.15.0]\r\n      - webencodings [required: Any, installed: 0.5.1]\r\n    - defusedxml [required: Any, installed: 0.6.0]\r\n    - entrypoints [required: >=0.2.2, installed: 0.3]\r\n    - jinja2 [required: >=2.4, installed: 2.11.2]\r\n      - MarkupSafe [required: >=0.23, installed: 1.1.1]\r\n    - jupyter-core [required: Any, installed: 4.6.3]\r\n      - traitlets [required: Any, installed: 5.0.5]\r\n        - ipython-genutils [required: Any, installed: 0.2.0]\r\n    - jupyterlab-pygments [required: Any, installed: 0.1.2]\r\n      - pygments [required: >=2.4.1,<3, installed: 2.7.1]\r\n    - mistune [required: >=0.8.1,<2, installed: 0.8.4]\r\n    - nbclient [required: >=0.5.0,<0.6.0, installed: 0.5.1]\r\n      - async-generator [required: Any, installed: 1.10]\r\n      - jupyter-client [required: >=6.1.5, installed: 6.1.7]\r\n        - jupyter-core [required: >=4.6.0, installed: 4.6.3]\r\n          - traitlets [required: Any, installed: 5.0.5]\r\n            - ipython-genutils [required: Any, installed: 0.2.0]\r\n        - python-dateutil [required: >=2.1, installed: 2.8.1]\r\n          - six [required: >=1.5, installed: 1.15.0]\r\n        - pyzmq [required: >=13, installed: 19.0.2]\r\n        - tornado [required: >=4.1, installed: 6.0.4]\r\n        - traitlets [required: Any, installed: 5.0.5]\r\n          - ipython-genutils [required: Any, installed: 0.2.0]\r\n      - nbformat [required: >=5.0, installed: 5.0.8]\r\n        - ipython-genutils [required: Any, installed: 0.2.0]\r\n        - jsonschema [required: >=2.4,!=2.5.0, installed: 3.2.0]\r\n          - attrs [required: >=17.4.0, installed: 20.2.0]\r\n          - importlib-metadata [required: Any, installed: 2.0.0]\r\n            - zipp [required: >=0.5, installed: 3.3.1]\r\n          - pyrsistent [required: >=0.14.0, installed: 0.17.3]\r\n          - setuptools [required: Any, installed: 50.3.1]\r\n          - six [required: >=1.11.0, installed: 1.15.0]\r\n        - jupyter-core [required: Any, installed: 4.6.3]\r\n          - traitlets [required: Any, installed: 5.0.5]\r\n            - ipython-genutils [required: Any, installed: 0.2.0]\r\n        - traitlets [required: >=4.1, installed: 5.0.5]\r\n          - ipython-genutils [required: Any, installed: 0.2.0]\r\n      - nest-asyncio [required: Any, installed: 1.4.1]\r\n      - traitlets [required: >=4.2, installed: 5.0.5]\r\n        - ipython-genutils [required: Any, installed: 0.2.0]\r\n    - nbformat [required: >=4.4, installed: 5.0.8]\r\n      - ipython-genutils [required: Any, installed: 0.2.0]\r\n      - jsonschema [required: >=2.4,!=2.5.0, installed: 3.2.0]\r\n        - attrs [required: >=17.4.0, installed: 20.2.0]\r\n        - importlib-metadata [required: Any, installed: 2.0.0]\r\n          - zipp [required: >=0.5, installed: 3.3.1]\r\n        - pyrsistent [required: >=0.14.0, installed: 0.17.3]\r\n        - setuptools [required: Any, installed: 50.3.1]\r\n        - six [required: >=1.11.0, installed: 1.15.0]\r\n      - jupyter-core [required: Any, installed: 4.6.3]\r\n        - traitlets [required: Any, installed: 5.0.5]\r\n          - ipython-genutils [required: Any, installed: 0.2.0]\r\n      - traitlets [required: >=4.1, installed: 5.0.5]\r\n        - ipython-genutils [required: Any, installed: 0.2.0]\r\n    - pandocfilters [required: >=1.4.1, installed: 1.4.2]\r\n    - pygments [required: >=2.4.1, installed: 2.7.1]\r\n    - testpath [required: Any, installed: 0.4.4]\r\n    - traitlets [required: >=4.2, installed: 5.0.5]\r\n      - ipython-genutils [required: Any, installed: 0.2.0]\r\n  - notebook [required: Any, installed: 6.1.4]\r\n    - argon2-cffi [required: Any, installed: 20.1.0]\r\n      - cffi [required: >=1.0.0, installed: 1.14.3]\r\n        - pycparser [required: Any, installed: 2.20]\r\n      - six [required: Any, installed: 1.15.0]\r\n    - ipykernel [required: Any, installed: 5.3.4]\r\n      - appnope [required: Any, installed: 0.1.0]\r\n      - ipython [required: >=5.0.0, installed: 7.18.1]\r\n        - appnope [required: Any, installed: 0.1.0]\r\n        - backcall [required: Any, installed: 0.2.0]\r\n        - decorator [required: Any, installed: 4.4.2]\r\n        - jedi [required: >=0.10, installed: 0.17.2]\r\n          - parso [required: >=0.7.0,<0.8.0, installed: 0.7.1]\r\n        - pexpect [required: >4.3, installed: 4.8.0]\r\n          - ptyprocess [required: >=0.5, installed: 0.6.0]\r\n        - pickleshare [required: Any, installed: 0.7.5]\r\n        - prompt-toolkit [required: >=2.0.0,<3.1.0,!=3.0.1,!=3.0.0, installed: 3.0.8]\r\n          - wcwidth [required: Any, installed: 0.2.5]\r\n        - pygments [required: Any, installed: 2.7.1]\r\n        - setuptools [required: >=18.5, installed: 50.3.1]\r\n        - traitlets [required: >=4.2, installed: 5.0.5]\r\n          - ipython-genutils [required: Any, installed: 0.2.0]\r\n      - jupyter-client [required: Any, installed: 6.1.7]\r\n        - jupyter-core [required: >=4.6.0, installed: 4.6.3]\r\n          - traitlets [required: Any, installed: 5.0.5]\r\n            - ipython-genutils [required: Any, installed: 0.2.0]\r\n        - python-dateutil [required: >=2.1, installed: 2.8.1]\r\n          - six [required: >=1.5, installed: 1.15.0]\r\n        - pyzmq [required: >=13, installed: 19.0.2]\r\n        - tornado [required: >=4.1, installed: 6.0.4]\r\n        - traitlets [required: Any, installed: 5.0.5]\r\n          - ipython-genutils [required: Any, installed: 0.2.0]\r\n      - tornado [required: >=4.2, installed: 6.0.4]\r\n      - traitlets [required: >=4.1.0, installed: 5.0.5]\r\n        - ipython-genutils [required: Any, installed: 0.2.0]\r\n    - ipython-genutils [required: Any, installed: 0.2.0]\r\n    - jinja2 [required: Any, installed: 2.11.2]\r\n      - MarkupSafe [required: >=0.23, installed: 1.1.1]\r\n    - jupyter-client [required: >=5.3.4, installed: 6.1.7]\r\n      - jupyter-core [required: >=4.6.0, installed: 4.6.3]\r\n        - traitlets [required: Any, installed: 5.0.5]\r\n          - ipython-genutils [required: Any, installed: 0.2.0]\r\n      - python-dateutil [required: >=2.1, installed: 2.8.1]\r\n        - six [required: >=1.5, installed: 1.15.0]\r\n      - pyzmq [required: >=13, installed: 19.0.2]\r\n      - tornado [required: >=4.1, installed: 6.0.4]\r\n      - traitlets [required: Any, installed: 5.0.5]\r\n        - ipython-genutils [required: Any, installed: 0.2.0]\r\n    - jupyter-core [required: >=4.6.1, installed: 4.6.3]\r\n      - traitlets [required: Any, installed: 5.0.5]\r\n        - ipython-genutils [required: Any, installed: 0.2.0]\r\n    - nbconvert [required: Any, installed: 6.0.7]\r\n      - bleach [required: Any, installed: 3.2.1]\r\n        - packaging [required: Any, installed: 20.4]\r\n          - pyparsing [required: >=2.0.2, installed: 2.4.7]\r\n          - six [required: Any, installed: 1.15.0]\r\n        - six [required: >=1.9.0, installed: 1.15.0]\r\n        - webencodings [required: Any, installed: 0.5.1]\r\n      - defusedxml [required: Any, installed: 0.6.0]\r\n      - entrypoints [required: >=0.2.2, installed: 0.3]\r\n      - jinja2 [required: >=2.4, installed: 2.11.2]\r\n        - MarkupSafe [required: >=0.23, installed: 1.1.1]\r\n      - jupyter-core [required: Any, installed: 4.6.3]\r\n        - traitlets [required: Any, installed: 5.0.5]\r\n          - ipython-genutils [required: Any, installed: 0.2.0]\r\n      - jupyterlab-pygments [required: Any, installed: 0.1.2]\r\n        - pygments [required: >=2.4.1,<3, installed: 2.7.1]\r\n      - mistune [required: >=0.8.1,<2, installed: 0.8.4]\r\n      - nbclient [required: >=0.5.0,<0.6.0, installed: 0.5.1]\r\n        - async-generator [required: Any, installed: 1.10]\r\n        - jupyter-client [required: >=6.1.5, installed: 6.1.7]\r\n          - jupyter-core [required: >=4.6.0, installed: 4.6.3]\r\n            - traitlets [required: Any, installed: 5.0.5]\r\n              - ipython-genutils [required: Any, installed: 0.2.0]\r\n          - python-dateutil [required: >=2.1, installed: 2.8.1]\r\n            - six [required: >=1.5, installed: 1.15.0]\r\n          - pyzmq [required: >=13, installed: 19.0.2]\r\n          - tornado [required: >=4.1, installed: 6.0.4]\r\n          - traitlets [required: Any, installed: 5.0.5]\r\n            - ipython-genutils [required: Any, installed: 0.2.0]\r\n        - nbformat [required: >=5.0, installed: 5.0.8]\r\n          - ipython-genutils [required: Any, installed: 0.2.0]\r\n          - jsonschema [required: >=2.4,!=2.5.0, installed: 3.2.0]\r\n            - attrs [required: >=17.4.0, installed: 20.2.0]\r\n            - importlib-metadata [required: Any, installed: 2.0.0]\r\n              - zipp [required: >=0.5, installed: 3.3.1]\r\n            - pyrsistent [required: >=0.14.0, installed: 0.17.3]\r\n            - setuptools [required: Any, installed: 50.3.1]\r\n            - six [required: >=1.11.0, installed: 1.15.0]\r\n          - jupyter-core [required: Any, installed: 4.6.3]\r\n            - traitlets [required: Any, installed: 5.0.5]\r\n              - ipython-genutils [required: Any, installed: 0.2.0]\r\n          - traitlets [required: >=4.1, installed: 5.0.5]\r\n            - ipython-genutils [required: Any, installed: 0.2.0]\r\n        - nest-asyncio [required: Any, installed: 1.4.1]\r\n        - traitlets [required: >=4.2, installed: 5.0.5]\r\n          - ipython-genutils [required: Any, installed: 0.2.0]\r\n      - nbformat [required: >=4.4, installed: 5.0.8]\r\n        - ipython-genutils [required: Any, installed: 0.2.0]\r\n        - jsonschema [required: >=2.4,!=2.5.0, installed: 3.2.0]\r\n          - attrs [required: >=17.4.0, installed: 20.2.0]\r\n          - importlib-metadata [required: Any, installed: 2.0.0]\r\n            - zipp [required: >=0.5, installed: 3.3.1]\r\n          - pyrsistent [required: >=0.14.0, installed: 0.17.3]\r\n          - setuptools [required: Any, installed: 50.3.1]\r\n          - six [required: >=1.11.0, installed: 1.15.0]\r\n        - jupyter-core [required: Any, installed: 4.6.3]\r\n          - traitlets [required: Any, installed: 5.0.5]\r\n            - ipython-genutils [required: Any, installed: 0.2.0]\r\n        - traitlets [required: >=4.1, installed: 5.0.5]\r\n          - ipython-genutils [required: Any, installed: 0.2.0]\r\n      - pandocfilters [required: >=1.4.1, installed: 1.4.2]\r\n      - pygments [required: >=2.4.1, installed: 2.7.1]\r\n      - testpath [required: Any, installed: 0.4.4]\r\n      - traitlets [required: >=4.2, installed: 5.0.5]\r\n        - ipython-genutils [required: Any, installed: 0.2.0]\r\n    - nbformat [required: Any, installed: 5.0.8]\r\n      - ipython-genutils [required: Any, installed: 0.2.0]\r\n      - jsonschema [required: >=2.4,!=2.5.0, installed: 3.2.0]\r\n        - attrs [required: >=17.4.0, installed: 20.2.0]\r\n        - importlib-metadata [required: Any, installed: 2.0.0]\r\n          - zipp [required: >=0.5, installed: 3.3.1]\r\n        - pyrsistent [required: >=0.14.0, installed: 0.17.3]\r\n        - setuptools [required: Any, installed: 50.3.1]\r\n        - six [required: >=1.11.0, installed: 1.15.0]\r\n      - jupyter-core [required: Any, installed: 4.6.3]\r\n        - traitlets [required: Any, installed: 5.0.5]\r\n          - ipython-genutils [required: Any, installed: 0.2.0]\r\n      - traitlets [required: >=4.1, installed: 5.0.5]\r\n        - ipython-genutils [required: Any, installed: 0.2.0]\r\n    - prometheus-client [required: Any, installed: 0.8.0]\r\n    - pyzmq [required: >=17, installed: 19.0.2]\r\n    - Send2Trash [required: Any, installed: 1.5.0]\r\n    - terminado [required: >=0.8.3, installed: 0.9.1]\r\n      - ptyprocess [required: Any, installed: 0.6.0]\r\n      - tornado [required: >=4, installed: 6.0.4]\r\n    - tornado [required: >=5.0, installed: 6.0.4]\r\n    - traitlets [required: >=4.2.1, installed: 5.0.5]\r\n      - ipython-genutils [required: Any, installed: 0.2.0]\r\n  - qtconsole [required: Any, installed: 4.7.7]\r\n    - ipykernel [required: >=4.1, installed: 5.3.4]\r\n      - appnope [required: Any, installed: 0.1.0]\r\n      - ipython [required: >=5.0.0, installed: 7.18.1]\r\n        - appnope [required: Any, installed: 0.1.0]\r\n        - backcall [required: Any, installed: 0.2.0]\r\n        - decorator [required: Any, installed: 4.4.2]\r\n        - jedi [required: >=0.10, installed: 0.17.2]\r\n          - parso [required: >=0.7.0,<0.8.0, installed: 0.7.1]\r\n        - pexpect [required: >4.3, installed: 4.8.0]\r\n          - ptyprocess [required: >=0.5, installed: 0.6.0]\r\n        - pickleshare [required: Any, installed: 0.7.5]\r\n        - prompt-toolkit [required: >=2.0.0,<3.1.0,!=3.0.1,!=3.0.0, installed: 3.0.8]\r\n          - wcwidth [required: Any, installed: 0.2.5]\r\n        - pygments [required: Any, installed: 2.7.1]\r\n        - setuptools [required: >=18.5, installed: 50.3.1]\r\n        - traitlets [required: >=4.2, installed: 5.0.5]\r\n          - ipython-genutils [required: Any, installed: 0.2.0]\r\n      - jupyter-client [required: Any, installed: 6.1.7]\r\n        - jupyter-core [required: >=4.6.0, installed: 4.6.3]\r\n          - traitlets [required: Any, installed: 5.0.5]\r\n            - ipython-genutils [required: Any, installed: 0.2.0]\r\n        - python-dateutil [required: >=2.1, installed: 2.8.1]\r\n          - six [required: >=1.5, installed: 1.15.0]\r\n        - pyzmq [required: >=13, installed: 19.0.2]\r\n        - tornado [required: >=4.1, installed: 6.0.4]\r\n        - traitlets [required: Any, installed: 5.0.5]\r\n          - ipython-genutils [required: Any, installed: 0.2.0]\r\n      - tornado [required: >=4.2, installed: 6.0.4]\r\n      - traitlets [required: >=4.1.0, installed: 5.0.5]\r\n        - ipython-genutils [required: Any, installed: 0.2.0]\r\n    - ipython-genutils [required: Any, installed: 0.2.0]\r\n    - jupyter-client [required: >=4.1, installed: 6.1.7]\r\n      - jupyter-core [required: >=4.6.0, installed: 4.6.3]\r\n        - traitlets [required: Any, installed: 5.0.5]\r\n          - ipython-genutils [required: Any, installed: 0.2.0]\r\n      - python-dateutil [required: >=2.1, installed: 2.8.1]\r\n        - six [required: >=1.5, installed: 1.15.0]\r\n      - pyzmq [required: >=13, installed: 19.0.2]\r\n      - tornado [required: >=4.1, installed: 6.0.4]\r\n      - traitlets [required: Any, installed: 5.0.5]\r\n        - ipython-genutils [required: Any, installed: 0.2.0]\r\n    - jupyter-core [required: Any, installed: 4.6.3]\r\n      - traitlets [required: Any, installed: 5.0.5]\r\n        - ipython-genutils [required: Any, installed: 0.2.0]\r\n    - pygments [required: Any, installed: 2.7.1]\r\n    - pyzmq [required: >=17.1, installed: 19.0.2]\r\n    - qtpy [required: Any, installed: 1.9.0]\r\n    - traitlets [required: Any, installed: 5.0.5]\r\n      - ipython-genutils [required: Any, installed: 0.2.0]\r\npipenv-to-requirements==0.9.0\r\n  - pbr [required: >=3.0, installed: 5.5.0]\r\n  - pipenv [required: Any, installed: 2020.8.13]\r\n    - certifi [required: Any, installed: 2020.6.20]\r\n    - pip [required: >=18.0, installed: 20.2.3]\r\n    - setuptools [required: >=36.2.1, installed: 50.3.1]\r\n    - virtualenv [required: Any, installed: 20.0.35]\r\n      - appdirs [required: >=1.4.3,<2, installed: 1.4.4]\r\n      - distlib [required: >=0.3.1,<1, installed: 0.3.1]\r\n      - filelock [required: >=3.0.0,<4, installed: 3.0.12]\r\n      - importlib-metadata [required: >=0.12,<3, installed: 2.0.0]\r\n        - zipp [required: >=0.5, installed: 3.3.1]\r\n      - six [required: >=1.9.0,<2, installed: 1.15.0]\r\n    - virtualenv-clone [required: >=0.2.5, installed: 0.5.4]\r\n\r\n```\r\n",
"body": "Hmmm... the `make clean; make all` is pretty much what did.\r\nWhich branch did you check out? Did you make a branch from PR like I did?",
"body": "note also that travis passes, and it is using python 3.7:\r\n\r\nhttps://travis-ci.org/github/microbiomedata/nmdc-metadata/builds/749888189#L184",
"body": "@cmungall: yes ... this is why it is quite confusing to me :(  \r\nI'm just trying to figure out what is different. Sorry, if I'm not understanding something.\r\n",
"body": "@wdduncan \r\n\r\n```\r\ngit clone https://github.com/microbiomedata/nmdc-metadata\r\ngit checkout blml-1.6.0\r\n```\r\n\r\nIt could be that there is some package installed system-wide on your machine that might be causing the conflict. Dependency resolution has always been a problem when working with python.\r\n\r\n",
"body": "Success! At when I run using a virtual environment :)\r\n\r\nSorry for the hassle.",
"body": "",
"body": "The value of this new term will likely NOT be available when the DataObject metadata JSON is initially created - but will need to be present before the NMDC prototype application can support file downloads.\r\n\r\nThat is, when workflow execution provides DataObjects for output files we likely will not know yet where those files will be moved to be accessible from the application client interface.  We can already begin to think about where the DataObject files output from processes need to be moved and begin updating those DataObjects",
"body": "",
"body": "Yuri @corilo - will produce JSON document for a single execution of his workflow.  Then get feedback (Chris, Bill, David)  and possibly iterate before continuing to do remaining metabolomics workflow instances - structure will then be used for lipidomics and OM workflow execution metadata",
"body": "@dehays, @cmungall @wdduncan\r\nHere is the first draft of the JSON document. Please provide feedback on the structure, labels, and any missing data as required.\r\n\r\nI forgot what the \"was_informed_by\" and what it should contain. Please help?\r\n\r\nhttps://drive.google.com/file/d/1BnP8q-iDQP2vmswN9v68WDQfNG4uDek5/view?usp=sharing\r\n\r\nThanks",
"body": "```\r\n\"has_input\": [\r\n            \"emsl:sha256:37417faf2c1b07ef9c59868683e41577bb3a745128bdc88b6cc59e579b5b30d0\"\r\n        ]\r\n```\r\nThis ID (the sha256 hash) doesn't match the ID of any instrument output EMSL has provided to NMDC.  This uses that dataset ID (that some parts of EMSL use and some parts do not) with a prefix of \"output_\".  Looks like \"emsl:output_500097\".     We can revisit how EMSL sets unique IDs, but the IDs need to be consistent so that there is a path back from analysis to sample and study.\r\n\r\n\"was_informed_by\" is a relationship on an analysis execution activity (i.e. instance of running the metabolomics analysis workflow) that refers to the instrument run (OmicsProcessing) entity.   Again, the ID currently looks like \"emsl:500097\" and uses the dataset ID of the instrument run.\r\n\r\nThe Metabolites object - I was expecting an array rather than an object, but a more important conversation is in how this will relate to the structure @cmungall is describing in #176  I hope to understand this better after speaking with Chris on Wednesday",
"body": "C-MS based metabolomics workflow output examples from @corilo here:\r\n\r\nhttps://drive.google.com/drive/u/1/folders/1_dHFvIK9PwJCKVJznwqWgqvfOIhTCkvx\r\n\r\nExpected changes:\r\n\r\nMetadata JSON file: structure will change after the adoption of the labels defined on AIM 1,\r\nDataTable CSV file: metabolite names will change (removing comments and extra fields), and more columns will be added to include CAS and KEGG compound ID\r\n\r\nNOTE: for now, make comments on @dehays google doc https://docs.google.com/document/d/15fga30d619WRxAUk8LyrojwIN1m89_K-sIrmUg4Y3tY/edit rather that commenting in ticket. We will still use this ticket to track status\r\n\r\nAs a first pass we will not try and capture everything from a metabolomics workflow, just the aspects that are necessary for search",
"body": "@SamuelPurvine will iterate with @cmungall @wdduncan and @dehays  on structure and content.  @anubhav0fnu will modify the script that produces JSON once he has returned (Congratulations!) in January.",
"body": "> @SamuelPurvine will iterate with @cmungall @wdduncan and @dehays on structure and content. @anubhav0fnu will modify the script that produces JSON once he has returned (Congratulations!) in January.\r\n\r\nthank you @dehays, yes, I'll do it asap, I'm working with Sam on it. ",
"body": "@dehays @SamuelPurvine \r\nTrying to clean up some tickets now that GSP has passed. Can we close this ticket?",
"body": "metaP analysis activity schema changes and JSON produced for GSP studies - closing issue",
"body": "Rough example from @SamuelPurvine here: \r\n\r\nhttps://github.com/microbiomedata/nmdc-metadata/blob/master/scratch/metaproteomics-example-Sam.json\r\n\r\nNOTE: for now, make comments on @dehays google doc https://docs.google.com/document/d/15fga30d619WRxAUk8LyrojwIN1m89_K-sIrmUg4Y3tY/edit rather that commenting in ticket. We will still use this ticket to track status\r\n\r\n",
"body": "Hi Chris and Pier\r\n@cmungall\r\n@pbuttigieg\r\n@TBKReddy\r\n@wdduncan\r\n\r\nThe following new terms are required for plant-associated biosamples; all of them are described in the other ontologies, so, I have provided them as pair, term: IDs.\r\n \r\nbark: PO_0004518\r\nspikelet: PO_0009051\r\nroot tip: PO_0000025\r\nfine root: BTO_0005194\r\npanicle: BTO_0005436\r\nseedling: BTO_0001228\r\npollen: PO_0025281\r\nradicle: PO_0020031\r\nrhizoid: PO_0030078\r\nstalk: PO_0025066\r\nrhizome: PO_0004542\r\nstem: PO_0009047",
"body": "Hi Pier and Chris\r\n@pbuttigieg\r\n@cmungall\r\n@TBKReddy\r\n@wdduncan \r\n\r\nThe following three terms were previously found in the EnvO, but not now; we are using them for some of the plant-associated biosamples in the NMDC & GOLD. Can you please make them available again in the EnvO:\r\n\r\nflower\tPO_0009046\r\nseed\tPO_0009010\r\nfruit\tPO_0009001",
"body": "For experimental factor we have:\r\n\r\n```yaml\r\n  experimental_factor:\r\n    aliases:\r\n      - experimental factor\r\n    description: >-\r\n       \"Experimental factors are essentially the variable aspects of an experiment design which can be used to describe an experiment, or set of experiments, in an increasingly detailed manner. This field accepts ontology terms from Experimental Factor Ontology (EFO) and/or Ontology for Biomedical Investigations (OBI). For a browser of EFO (v 2.95) terms, please see http://purl.bioontology.org/ontology/EFO; for a browser of OBI (v 2018-02-12) terms please see http://purl.bioontology.org/ontology/OBI\"\r\n    multivalued: false\r\n    is_a: attribute\r\n    range: controlled term value  ## syntax: {termLabel} {[termID]}|{text}\r\n    mappings:\r\n      - MIxS:experimental_factor\r\n    in_subset:\r\n      - investigation\r\n```\r\n\r\nThis is very biomedical focused guidelines\r\n\r\nWe need some recommendations for non-biomedical scenarios\r\n\r\ne.g.\r\n\r\n - http://obofoundry.org/ontology/peco Plant Experimental Conditions Ontology\r\n      - [example terms e.g. soil treatments](https://www.ebi.ac.uk/ols/search?q=treatment+soil&groupField=iri&start=0&ontology=peco)\r\n\r\ncc @mslarae13 ",
"body": "This PR does the following,\r\n- Differentiate between core and dev dependencies\r\n- Surface all notebook related dependencies and add it to Pipfile as dev dependencies\r\n- Remove redundant requirements.txt and any package declaration that was pinned to a specific version\r\n- Go all in on Pipenv\r\n- Add Installation instructions for working with this repository with Python venv and Pipenv\r\n",
"body": "- add a module for transform operations\r\n- add module for extract operations",
"body": "Fixes #110 ",
"body": "Note: We will only use skos:extactMatch when mapping GOLD fields to MIxS.",
"body": "",
"body": "\r\n\r\n```\r\ngold.vocab:soil_annual_season_temp     soil_annual_season_temp skos:exactMatch mixs:season_temp or annual_temp?        season_temp or annual_temp?     SSSOMC:HumanCurated     gold.vocab      mixs    1.0     .\r\ngold.vocab:soil_annual_season_precpt   soil_annual_season_precpt       skos:exactMatch mixs:season_precpt or annual_precpt?    season_precpt or annual_precpt? SSSOMC:HumanCurated     gold.vocab      mixs    1.0     .\r\n```\r\n\r\nthe object_id field must be a CURIE. You can't do free text with keywords like OR. This is to be machine readable. Put stuff intended for humans in the comments column.\r\n\r\nIn this case if we don't know how to map 1:1 then we can use skos:close\r\n",
"body": "That's the link for the studies, or rather the link in our separate analysis project\r\n\r\nThe source for the studies csv is https://zenodo.org/record/890000/files/emp_studies.csv?download=1\r\n\r\nWe also need the samples: ftp://ftp.microbio.me/emp/release1/mapping_files/emp_qiime_mapping_release1.tsv\r\n\r\nThere are 26 fields in the study table, 76 in the sample table. We could run these through metadata_converter to semi-automate the mapping but may be fastest to do manually.\r\n\r\nAll: do we want to exclude the human subset of EMP?\r\n\r\nNote that EMP use both ENVO and EMPO, but confusingly the communicate different things (even though I thought EMPO was a subset of ENVO, cc @pbuttigieg?). \r\n\r\nFor example, if we look at the line for ID=632.Agricultural.soil.soy\r\n\r\nunpivoted:\r\n\r\n```\r\n52            env_biome: cropland biome\r\n53          env_feature: agricultural feature\r\n54         env_material: soil\r\n55         envo_biome_0: biome\r\n56         envo_biome_1: terrestrial biome\r\n57         envo_biome_2: anthropogenic terrestrial biome\r\n58         envo_biome_3: cropland biome\r\n59         envo_biome_4: \r\n60         envo_biome_5: \r\n61               empo_0: EMP sample\r\n62               empo_1: Free-living\r\n63               empo_2: Non-saline\r\n64               empo_3: Soil (non-saline)\r\n```\r\n\r\nhere you need both ENVO and EMPO to give the complete picture (the salinity is only in EMPO). \r\n\r\nI think a lot of this can be automated but we'll need to do some analysis on existing contents first",
"body": "Here is a summary of correlations between ENVO triads and EMPO triads\r\n\r\n|COUNT|env_biome|env_feature|env_material|empo_1|empo_2|empo_3|\r\n|---|---|---|---|---|---|---|\r\n|1999|Large river biome|animal-associated habitat|feces|Host-associated|Animal|Animal distal gut|\r\n|1816|urban biome|human-associated habitat|sebum|Host-associated|Animal|Animal surface|\r\n|1614|Small lake biome|freshwater habitat|fresh water|Free-living|Non-saline|Water (non-saline)|\r\n|1602|Small lake biome|freshwater lake|fresh water|Free-living|Non-saline|Water (non-saline)|\r\n|1388|marine biome|kelp forest|organic material|Host-associated|Plant|Plant surface|\r\n|1192|Large lake biome|freshwater lake|fresh water|Free-living|Non-saline|Water (non-saline)|\r\n|949|freshwater biome|freshwater habitat|fresh water|Free-living|Non-saline|Water (non-saline)|\r\n|918|urban biome|biofilter|sand|Free-living|Non-saline|Soil (non-saline)|\r\n|708|urban biome|field soil|soil|Free-living|Non-saline|Soil (non-saline)|\r\n|689|urban biome|anthropogenic environmental material|dust|Free-living|Non-saline|Surface (non-saline)|\r\n|671|urban biome|human-associated habitat|saliva|Host-associated|Animal|Animal secretion|\r\n|660|urban biome|human-associated habitat|feces|Host-associated|Animal|Animal distal gut|\r\n|648|rangeland biome|animal-associated habitat|feces|Host-associated|Animal|Animal distal gut|\r\n|608|mediterranean shrubland biome|nest of bird|avian egg product|Host-associated|Animal|Animal surface|\r\n|570|mediterranean woodland biome|nest of bird|avian egg product|Host-associated|Animal|Animal surface|\r\n|400|rangeland biome|hot spring|microbial mat|Free-living|Non-saline|Surface (non-saline)|\r\n|388|village biome|insecta-associated habitat|organic material|Host-associated|Animal|Animal corpus|\r\n|353|Small lake biome|pond|lake sediment|Free-living|Non-saline|Sediment (non-saline)|\r\n|338|marine biome|kelp forest|biofilm|Host-associated|Plant|Plant surface|\r\n|338|urban biome|animal-associated habitat|feces|Host-associated|Animal|Animal distal gut|\r\n|323|aquatic biome|water|sterile water|Control|Negative|Sterile water blank|\r\n|320|cropland biome|alluvial paddy field soil|soil|Free-living|Non-saline|Soil (non-saline)|\r\n|316|urban biome|animal-associated habitat|organic material|Host-associated|Animal|Animal proximal gut|\r\n|313|urban biome|human-associated habitat|mucus|Host-associated|Animal|Animal secretion|\r\n|310|cropland biome|rice field|rhizosphere|Host-associated|Plant|Plant rhizosphere|\r\n|295|cropland biome|cultivated habitat|soil|Free-living|Non-saline|Soil (non-saline)|\r\n|276|marine biome|neritic zone|marine sediment|Free-living|Saline|Sediment (saline)|\r\n|269|urban biome|animal-associated habitat|sebum|Host-associated|Animal|Animal surface|\r\n|268|marine biome|fjord|sea water|Free-living|Saline|Water (saline)|\r\n|260|tropical moist broadleaf forest biome|animal-associated habitat|feces|Host-associated|Animal|Animal distal gut|\r\n|255|tundra biome|tundra|soil|Free-living|Non-saline|Soil (non-saline)|\r\n|228|freshwater biome|animal-associated habitat|mucus|Host-associated|Animal|Animal surface|\r\n|207|forest biome|forest soil|soil|Free-living|Non-saline|Soil (non-saline)|\r\n|206|montane grassland biome|steppe soil|soil|Free-living|Non-saline|Soil (non-saline)|\r\n|189|urban biome|insecta-associated habitat|bodily fluid|Host-associated|Animal|Animal secretion|\r\n|186|freshwater biome|freshwater habitat|biofilm|Free-living|Non-saline|Surface (non-saline)|\r\n|184|dense settlement biome|animal-associated habitat|feces|Host-associated|Animal|Animal distal gut|\r\n|167|cropland biome|vineyard|rhizosphere|Host-associated|Plant|Plant rhizosphere|\r\n|162|cropland biome|vineyard|bulk soil|Free-living|Non-saline|Soil (non-saline)|\r\n|161|marine biome|animal-associated habitat|mucus|Host-associated|Animal|Animal surface|\r\n|156|cropland biome|vineyard|organic material|Host-associated|Plant|Plant corpus|\r\n|154|urban biome|insecta-associated habitat|organic material|Host-associated|Animal|Animal corpus|\r\n|153|cropland biome|vineyard|organic material|Host-associated|Plant|Plant rhizosphere|\r\n|151|urban biome|garden soil|soil|Free-living|Non-saline|Soil (non-saline)|\r\n|146|marine biome|strait|sea water|Free-living|Saline|Water (saline)|\r\n|128|shrubland biome|grassland soil|soil|Free-living|Non-saline|Soil (non-saline)|\r\n|127|tropical shrubland biome|volcano|soil|Free-living|Non-saline|Soil (non-saline)|\r\n|118|polar desert biome|cold temperature habitat|sand|Free-living|Non-saline|Soil (non-saline)|\r\n|106|marine benthic biome|marine sediment|contaminated sediment|Free-living|Saline|Sediment (saline)|\r\n|102|freshwater biome|freshwater habitat|sediment|Free-living|Non-saline|Sediment (non-saline)|\r\n|98|marine pelagic biome|cold temperature habitat|sea water|Free-living|Saline|Water (saline)|\r\n|95|aquatic biome|contaminated water|fresh water|Free-living|Non-saline|Water (non-saline)|\r\n|95|Large river biome|dam|soil|Free-living|Non-saline|Soil (non-saline)|\r\n|93|terrestrial biome|animal-associated habitat|feces|Host-associated|Animal|Animal distal gut|\r\n|93|Small river biome|stream|fresh water|Free-living|Non-saline|Water (non-saline)|\r\n|89|tundra biome|dry lake|fresh water|Free-living|Non-saline|Water (non-saline)|\r\n|88|village biome|human-associated habitat|mucus|Host-associated|Animal|Animal secretion|\r\n|88|urban biome|city|air|Free-living|Non-saline|Aerosol (non-saline)|\r\n|77|urban biome|biofilter|fresh water|Free-living|Non-saline|Water (non-saline)|\r\n|74|tundra biome|tundra|underground water|Free-living|Non-saline|Water (non-saline)|\r\n|72|marine biome|ocean|sea water|Free-living|Saline|Water (saline)|\r\n|72|tropical broadleaf forest biome|animal-associated habitat|feces|Host-associated|Animal|Animal distal gut|\r\n|71|cropland biome|agricultural soil|soil|Free-living|Non-saline|Soil (non-saline)|\r\n|70|village biome|human-associated habitat|feces|Host-associated|Animal|Animal distal gut|\r\n|68|village biome|human-associated habitat|sebum|Host-associated|Animal|Animal surface|\r\n|67|marine benthic biome|hydrothermal vent|biofilm|Free-living|Saline|Surface (saline)|\r\n|66|Small lake biome|freshwater habitat|biofilm|Free-living|Non-saline|Surface (non-saline)|\r\n|65|cropland biome|field|soil|Free-living|Non-saline|Soil (non-saline)|\r\n|64|freshwater biome|animal-associated habitat|feces|Host-associated|Animal|Animal distal gut|\r\n|62|cropland biome|coffee plantation|soil|Free-living|Non-saline|Soil (non-saline)|\r\n|61|marine benthic biome|contaminated sediment|marine sediment|Free-living|Saline|Sediment (saline)|\r\n|60|tropical moist broadleaf forest biome|forest soil|soil|Free-living|Non-saline|Soil (non-saline)|\r\n|60|marine biome|continental shelf|marine sediment|Free-living|Saline|Sediment (saline)|\r\n|58|cropland biome|agricultural feature|soil|Free-living|Non-saline|Soil (non-saline)|\r\n|57|grassland biome|grassland soil|soil|Free-living|Non-saline|Soil (non-saline)|\r\n|56|shrubland biome|animal-associated habitat|excreta|Host-associated|Animal|Animal proximal gut|\r\n|56|tundra biome|dry lake|soil|Free-living|Non-saline|Soil (non-saline)|\r\n|54|mixed forest biome|animal-associated habitat|anthropogenic environmental material|Host-associated|Animal|Animal distal gut|\r\n|53|urban biome|animal-associated habitat|saliva|Host-associated|Animal|Animal secretion|\r\n|51|marine biome|alkaline habitat|sediment|Free-living|Saline|Sediment (saline)|\r\n|50|Small lake biome|freshwater habitat|underground water|Free-living|Non-saline|Water (non-saline)|\r\n|50|Small lake biome|freshwater habitat|lake sediment|Free-living|Non-saline|Sediment (non-saline)|\r\n|49|marine coral reef biome|coral reef|organic material|Host-associated|Animal|Animal corpus|\r\n|44|urban biome|animal-associated habitat|mucus|Host-associated|Animal|Animal surface|\r\n|44|Small river biome|fresh water|stream sediment|Free-living|Non-saline|Sediment (non-saline)|\r\n|43|forest biome|forest|soil|Free-living|Non-saline|Soil (non-saline)|\r\n|42|tundra biome|permafrost|soil|Free-living|Non-saline|Soil (non-saline)|\r\n|37|marine biome|intertidal zone|biofilm|Free-living|Saline|Surface (saline)|\r\n|36|tundra biome|dry lake|biofilm material|Free-living|Non-saline|Soil (non-saline)|\r\n|36|urban biome|animal-associated habitat|sebum|Host-associated|Animal|Animal secretion|\r\n|35|rangeland biome|farm soil|soil|Free-living|Non-saline|Soil (non-saline)|\r\n|35|marine biome|coastal water body|coastal water|Free-living|Saline|Water (saline)|\r\n|34|Small river biome|freshwater habitat|fresh water|Free-living|Non-saline|Water (non-saline)|\r\n|34|mixed forest biome|animal-associated habitat|feces|Host-associated|Animal|Animal distal gut|\r\n|29|marine benthic biome|alkaline habitat|travertine|Free-living|Saline|Surface (saline)|\r\n|28|cropland biome|grassland soil|soil|Free-living|Non-saline|Soil (non-saline)|\r\n|28|tropical moist broadleaf forest biome|tropical soil|soil|Free-living|Non-saline|Soil (non-saline)|\r\n|27|polar desert biome|oil contaminated soil|soil|Free-living|Non-saline|Soil (non-saline)|\r\n|26|marine biome|bay|marine sediment|Free-living|Saline|Sediment (saline)|\r\n|26|tundra biome|bog|soil|Free-living|Non-saline|Soil (non-saline)|\r\n|26|tropical moist broadleaf forest biome|national park|soil|Free-living|Non-saline|Soil (non-saline)|\r\n|25|marine biome|marine feature|marine sediment|Free-living|Saline|Sediment (saline)|\r\n|24|cropland biome|pasture|soil|Free-living|Non-saline|Soil (non-saline)|\r\n|23|shrubland biome|animal-associated habitat|excreta|Host-associated|Animal|Animal distal gut|\r\n|22|montane shrubland biome|mountain|soil|Free-living|Non-saline|Soil (non-saline)|\r\n|22|marine biome|abyssalpelagic zone|sea water|Free-living|Saline|Water (saline)|\r\n|21|Large river biome|river|sediment|Free-living|Non-saline|Sediment (non-saline)|\r\n|21|marine biome|marine habitat|sea water|Free-living|Saline|Water (saline)|\r\n|21|Small river biome|creek|fresh water|Free-living|Non-saline|Water (non-saline)|\r\n|21|urban biome|cultured habitat|organic material|Control|Positive|Mock community|\r\n|20|temperate grassland biome|luvisol|soil|Free-living|Non-saline|Soil (non-saline)|\r\n|20|desert biome|dry soil|soil|Free-living|Non-saline|Soil (non-saline)|\r\n|19|coniferous forest biome|forest soil|soil|Free-living|Non-saline|Soil (non-saline)|\r\n|18|urban biome|animal-associated habitat|animal habitation|Host-associated|Plant|Plant corpus|\r\n|18|Small lake biome|stromatolite mat|stromatolite mat|Free-living|Non-saline|Surface (non-saline)|\r\n|18|urban biome|animal-associated habitat|excreta|Host-associated|Animal|Animal proximal gut|\r\n|18|polar desert biome|surface soil|soil|Free-living|Non-saline|Soil (non-saline)|\r\n|17|urban biome|animal-associated habitat|surface layer|Free-living|Non-saline|Surface (non-saline)|\r\n|17|cropland biome|farm soil|soil|Free-living|Non-saline|Soil (non-saline)|\r\n|16|forest biome|animal-associated habitat|feces|Host-associated|Animal|Animal distal gut|\r\n|16|anthropogenic terrestrial biome|animal-associated habitat|feces|Host-associated|Animal|Animal distal gut|\r\n|16|marine biome|photic zone|sea water|Free-living|Saline|Water (saline)|\r\n|14|rangeland biome|hot spring|fresh water|Free-living|Non-saline|Water (non-saline)|\r\n|13|Small lake biome|lake|sediment|Free-living|Saline|Sediment (saline)|\r\n|12|Large river biome|coastal water body|marine sediment|Free-living|Saline|Sediment (saline)|\r\n|12|montane grassland biome|fluvisol|soil|Free-living|Non-saline|Soil (non-saline)|\r\n|12|montane grassland biome|forest soil|soil|Free-living|Non-saline|Soil (non-saline)|\r\n|10|forest biome|animal-associated habitat|excreta|Host-associated|Animal|Animal proximal gut|\r\n|10|Large river biome|marine feature|marine sediment|Free-living|Saline|Sediment (saline)|\r\n|10|cropland biome|rice field|fresh water|Free-living|Non-saline|Water (non-saline)|\r\n|10|marine coral reef biome|coral reef|organic material|Host-associated|Plant|Plant corpus|\r\n|9|cropland biome|plant-associated habitat|soil|Free-living|Non-saline|Soil (non-saline)|\r\n|9|cropland biome|plant-associated habitat|organic material|Host-associated|Plant|Plant rhizosphere|\r\n|9|tropical moist broadleaf forest biome|Oil palm plantation|soil|Free-living|Non-saline|Soil (non-saline)|\r\n|8|marine biome|mesopelagic zone|sea water|Free-living|Saline|Water (saline)|\r\n|8|marine benthic biome|sea vent|sea water|Free-living|Saline|Water (saline)|\r\n|8|Small lake biome|haline habitat|hypersaline water|Free-living|Saline|Hypersaline (saline)|\r\n|7|urban biome|animal-associated habitat|wood|Free-living|Non-saline|Surface (non-saline)|\r\n|7|desert biome|shrubland|soil|Free-living|Non-saline|Soil (non-saline)|\r\n|7|marine benthic biome|ocean floor|marine sediment|Free-living|Saline|Sediment (saline)|\r\n|7|freshwater biome|freshwater lake|fresh water|Free-living|Non-saline|Water (non-saline)|\r\n|6|urban biome|animal-associated habitat|excreta|Host-associated|Animal|Animal distal gut|\r\n|5|forest biome|animal-associated habitat|excreta|Host-associated|Animal|Animal distal gut|\r\n|5|aquatic biome|sinkhole|brackish water|Free-living|Saline|Water (saline)|\r\n|5|Small lake biome|lake|sediment|Free-living|Non-saline|Sediment (non-saline)|\r\n|5|marine biome|bathypelagic zone|sea water|Free-living|Saline|Water (saline)|\r\n|5|aquatic biome|sinkhole|fresh water|Free-living|Non-saline|Water (non-saline)|\r\n|5|marginal sea biome|sea beach|sea water|Free-living|Saline|Water (saline)|\r\n|5|aquatic biome|sinkhole|saline water|Free-living|Saline|Water (saline)|\r\n|4|tropical broadleaf forest biome|forest soil|soil|Free-living|Non-saline|Soil (non-saline)|\r\n|4|forest biome|taiga|soil|Free-living|Non-saline|Soil (non-saline)|\r\n|4|temperate grassland biome|basin|soil|Free-living|Non-saline|Soil (non-saline)|\r\n|4|marine biome|organism-associated habitat|biofilm|Host-associated|Animal|Animal corpus|\r\n|4|tropical grassland biome|grassland soil|soil|Free-living|Non-saline|Soil (non-saline)|\r\n|4|urban biome|animal-associated habitat|soil|Free-living|Non-saline|Soil (non-saline)|\r\n|4|marine biome|neritic zone|sea water|Free-living|Saline|Water (saline)|\r\n|4|temperate coniferous forest biome|podzol|soil|Free-living|Non-saline|Soil (non-saline)|\r\n|4|mangrove biome|marine habitat|ocean water|Free-living|Saline|Water (saline)|\r\n|4|Large river biome|freshwater habitat|fresh water|Free-living|Non-saline|Water (non-saline)|\r\n|4|temperate mixed forest biome|forest soil|soil|Free-living|Non-saline|Soil (non-saline)|\r\n|3|freshwater biome|stream|fresh water|Free-living|Non-saline|Water (non-saline)|\r\n|3|tropical coniferous forest biome|extreme high temperature habitat|soil|Free-living|Non-saline|Soil (non-saline)|\r\n|3|marine biome|organism-associated habitat|biofilm|Free-living|Saline|Water (saline)|\r\n|3|Small lake biome|microbial mat|microbial mat material|Free-living|Non-saline|Surface (non-saline)|\r\n|3|marine biome|marine habitat|saline lake sediment|Free-living|Saline|Sediment (saline)|\r\n|3|marine biome|haline habitat|hypersaline water|Free-living|Saline|Hypersaline (saline)|\r\n|3|tropical coniferous forest biome|forest soil|soil|Free-living|Non-saline|Soil (non-saline)|\r\n|3|mangrove biome|plant-associated habitat|marine sediment|Free-living|Saline|Sediment (saline)|\r\n|3|Small lake biome|marine habitat|saline lake sediment|Free-living|Saline|Sediment (saline)|\r\n|3|tundra biome|forest soil|soil|Free-living|Non-saline|Soil (non-saline)|\r\n|3|urban biome|animal-associated habitat|fresh water|Free-living|Non-saline|Water (non-saline)|\r\n|3|estuarine biome|estuary|estuary water|Free-living|Saline|Water (saline)|\r\n|2|tropical coniferous forest biome|high temperature habitat|biofilm|Free-living|Non-saline|Surface (non-saline)|\r\n|2|Small lake biome|haline habitat|saline lake sediment|Free-living|Saline|Sediment (saline)|\r\n|2|cropland biome|animal-associated habitat|excreta|Host-associated|Animal|Animal proximal gut|\r\n|2|urban biome|human-associated habitat|breast milk|Host-associated|Animal|Animal secretion|\r\n|2|aquatic biome|sinkhole|saline water|Free-living|Saline|Sediment (saline)|\r\n|2|aquatic biome|water well|brackish water|Free-living|Saline|Water (saline)|\r\n|2|marginal sea biome|lagoon|hypersaline water|Free-living|Saline|Hypersaline (saline)|\r\n|2|marine benthic biome|cove|marine sediment|Free-living|Saline|Sediment (saline)|\r\n|2|temperate mixed forest biome|oil contaminated soil|soil|Free-living|Non-saline|Soil (non-saline)|\r\n|2|marine benthic biome|bay|marine sediment|Free-living|Saline|Sediment (saline)|\r\n|2|tundra biome|clay soil|soil|Free-living|Non-saline|Soil (non-saline)|\r\n|2|tropical moist broadleaf forest biome|animal-associated habitat|excreta|Host-associated|Animal|Animal proximal gut|\r\n|2|marine biome|organism-associated habitat|biofilm|Free-living|Saline|Surface (saline)|\r\n|2|marine benthic biome|cove|sea water|Free-living|Saline|Water (saline)|\r\n|2|polar desert biome|cold temperature habitat|carcass|Host-associated|Animal|Animal corpus|\r\n|2|aquatic biome|water well|fresh water|Free-living|Non-saline|Water (non-saline)|\r\n|2|dense settlement biome|field soil|soil|Free-living|Non-saline|Soil (non-saline)|\r\n|2|marine benthic biome|bay|sea water|Free-living|Saline|Water (saline)|\r\n|2|dense settlement biome|human-associated habitat|sebum|Host-associated|Animal|Animal surface|\r\n|1|dense settlement biome|compost soil|soil|Free-living|Non-saline|Soil (non-saline)|\r\n|1|marine biome|marine feature|microbial mat|Free-living|Saline|Surface (saline)|\r\n|1|estuarine biome|estuary|fresh water|Free-living|Non-saline|Water (non-saline)|\r\n|1|tropical moist broadleaf forest biome|animal-associated habitat|sebum|Host-associated|Animal|Animal surface|\r\n|1|montane shrubland biome|wetland|soil|Free-living|Non-saline|Soil (non-saline)|\r\n|1|freshwater biome|freshwater habitat|fresh water|Control|Negative|Sterile water blank|\r\n|1|Small lake biome|freshwater lake|lake sediment|Free-living|Non-saline|Sediment (non-saline)|\r\n|1|tropical moist broadleaf forest biome|animal-associated habitat|excreta|Host-associated|Animal|Animal distal gut|\r\n|1|urban biome|human-associated habitat|mucus|Free-living|Non-saline|Surface (non-saline)|\r\n|1|tropical shrubland biome|animal-associated habitat|feces|Host-associated|Animal|Animal distal gut|\r\n|1|estuarine biome|estuary|estuary sediment|Free-living|Saline|Sediment (saline)|\r\n|1|urban biome|garden|soil|Free-living|Non-saline|Soil (non-saline)|\r\n|1|tundra biome|tundra|fresh water|Free-living|Non-saline|Water (non-saline)|\r\n|1|marginal sea biome|lagoon|sediment|Free-living|Saline|Sediment (saline)|\r\n|1|cropland biome|animal-associated habitat|excreta|Host-associated|Animal|Animal distal gut|\r\n|1|polar desert biome|rocky desert|sand|Free-living|Non-saline|Soil (non-saline)|\r\n|1|marginal sea biome|lagoon|marine sediment|Free-living|Saline|Sediment (saline)|\r\n|1|tundra biome|peatland|soil|Free-living|Non-saline|Soil (non-saline)|\r\n|1|marginal sea biome|sea beach|marine sediment|Free-living|Saline|Sediment (saline)|\r\n|1|temperate grassland biome|compost soil|soil|Free-living|Non-saline|Soil (non-saline)|\r\n",
"body": "OK, I have questions for EMP, still formulating\r\n\r\nI am looking at the study 'Geographic distance and pH drive bacterial distribution in alkaline lake sediments across Tibetan Plateau' and the associated samples, e.g. 1627.AWC\r\n\r\nWhen I look in mgnify at this study:\r\n\r\nhttps://www.ebi.ac.uk/metagenomics/studies/MGYS00003699\r\n\r\nAnd the samples:\r\n\r\nhttps://www.ebi.ac.uk/metagenomics/samples/ERS1296654\r\n\r\nI see that mgnify has better metadata than EMP. For example, mgnify includes a value for the salinity, whereas EMP only has this categorically.\r\n\r\nmgnify also has more precise country information (e.g Tibet + China; EMP just has China - this may be a bad example as this is political..). Of course the country is redundant with the geolocation but the question stands, if mgnify have done additional curation then it makes sense to get it from there rather than EMP\r\n\r\nI'm not sure if mgnify added this or they got it from upstream\r\n\r\nThis is the EBI biosample record:\r\n\r\nhttps://www.ebi.ac.uk/biosamples/samples/SAMEA4385205\r\n\r\nit's confusing as the metadata is slightly different. In EBI it is:\r\n\r\nenv biome | small lake biome\r\n-- | --\r\nenv feature | lake\r\nenv matter | sediment\r\nenv package | sediment\r\nenv_material | lake sediment\r\n\r\nWhereas EMP and Mgnify have:\r\n\r\n```\r\n           env_biome: Small lake biome\r\n         env_feature: lake\r\n        env_material: sediment\r\n```\r\n\r\nI don't think this sample is in gold but I may not be searching correctly, cc @jagadishcs \r\n\r\nIn NCBI it's slightly different:\r\n\r\nhttps://www.ncbi.nlm.nih.gov/biosample/?term=SAMEA4385205\r\n\r\n```\r\nbroad-scale environmental context\tsmall lake biome\r\nlocal-scale environmental context\tlake\r\nenvironmental medium\tlake sediment\r\nenvironmental package\tsediment\r\n```\r\n\r\nNCBI and EBI have values for things like carbon/nitrogen ratio, but this isn't in the EMP tsvs - maybe we have the wrong URL for the EMP tsvs.\r\n\r\nAlso it looks like the values for phosphates conflict between the two?\r\n",
"body": "They actually have quite a bit more metadata here\nhttps://www.ebi.ac.uk/biosamples/samples/SAMEA4385205\n\nincluding phosphate, but the numbers don't quite match and they don't\nreport units for phosphate (but do other measurements)\n\nOn Mon, Sep 21, 2020 at 3:31 PM Chris Mungall <notifications@github.com>\nwrote:\n\n> OK, I have questions for EMP, still formulating\n>\n> I am looking at the study 'Geographic distance and pH drive bacterial\n> distribution in alkaline lake sediments across Tibetan Plateau' and the\n> associated samples, e.g. 1627.AWC\n>\n> When I look in mgnify at this study:\n>\n> https://www.ebi.ac.uk/metagenomics/studies/MGYS00003699\n>\n> And the samples:\n>\n> https://www.ebi.ac.uk/metagenomics/samples/ERS1296654\n>\n> I see that mgnify has better metadata than EMP. For example, mgnify\n> includes a value for the salinity, whereas EMP only has this categorically\n>\n> mgnify also has more precise country information (e.g Tibet + China; EMP\n> just has China - this may be a bad example as this is political..). Of\n> course the country is redundant with the geolocation but the question\n> stands, if mgnify have done additional curation then it makes sense to get\n> it from there rather than EMP\n>\n> \u2014\n> You are receiving this because you are subscribed to this thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/microbiomedata/nmdc-metadata/issues/158#issuecomment-696413269>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/ADFUG4QJR4VOOYEHYG2BZ2TSG7H2TANCNFSM4RVBBWGQ>\n> .\n>\n\n\n-- \nElisha M Wood-Charlson, PhD (she/her)\nKBase <https://kbase.us/> User Engagement Lead\nNMDC <http://microbiomedata.org/> Leadership Team; @microbiomedata\n<https://twitter.com/MicrobiomeData>\nLawrence Berkeley National Laboratory\nLinkedIn <http://www.linkedin.com/in/elishawc>, Twitter\n<https://twitter.com/ElishaMariePhD> (personal)\n",
"body": "I'm going to call this done, findings collected in https://docs.google.com/presentation/d/1cPlur01uhJrRutJkOHS_mOgw4fVbxnU5Yis5KJtSjJ4/edit#slide=id.g5377561ea4_0_430\r\n\r\nfor EMP metadata we should get from NCBI by way of GOLD, will be coordinated with @jagadishcs via different ticket",
"body": "EMP data is located here:\r\nhttps://github.com/INCATools/biosample-analysis/blob/master/target/emp_studies.tsv\r\n\r\nWe'll want to formally represent mappings such as: `altitude_m: 0.0 --> altitude: 0.0 m` using SSSOM.\r\n\r\ncc @cmungall\r\n",
"body": "fixes #153",
"body": "Fixes #151 ",
"body": "",
"body": "https://zenodo.org/record/3707985#.X1-brGdKj6A\r\n\r\n(Stub ticket, I will flesh out later, also need to add to a GH project)",
"body": "Mapping information in the Excel files found in the `mapping-files` directory, needs to be add to the SSSOM file located in `schema/mappings/gold-to-mixs.sssom.tsv`.\r\n\r\ncc @cmungall @jagadishcs ",
"body": null,
"body": "@kfagnan suggested a \"coverage\" metric of sorts to assign to each externally sourced entry. For example, you recently pulled ~40k entries from the NCBI SRA, correct? For each entry x, we could give a score of M/N where N is the number of NMDC-schema attributes available(/applicable?) and M is the number of (non-null-valued) NMDC-schema attributes included in the entry x.\r\n\r\nIt sounds like this would happen nearly for free as a by-product of ETL, i.e. we could just instrument the process to also log these scores as it does the mapping for each entry.\r\n\r\nI'd be happy to have a look at something like this, e.g. draft a PR. I would need access to the SRA dump for dev/test.",
"body": null,
"body": "Done. See PR https://github.com/microbiomedata/nmdc-metadata/pull/156",
"body": "Also, do some cleanup, e.g.:\r\n- remove references to notebooks\r\n- add version 5 of raw database dump",
"body": "What the range type could be? I set them float for now.   Those value are all numeric including float, integer. ",
"body": "This should be modeled using a generic mappings/xrefs field",
"body": "The code base in `data_operations.py` has gotten a bit hairy. It should refactored if we have time.\r\n\r\n@cmungall Not sure where to place this on the priority list.",
"body": "@wdduncan Good catch! Yes, this is a bug at the time of documentation generation.\r\n\r\nWill look into this.",
"body": "@deepakunni3  I merged the PR ... but the link the is-a is still broken :(\r\n\r\nI notice the is-a link points `https://microbiomedata.github.io/nmdc-metadata/docs/gold_path_field.md`. Note the `.md` on the end. \r\n\r\nIs that expected?",
"body": "Yes, it seems like the markdown generator is not generating a markdown for `gold_path_field` or its parent, `attribute`.\r\n\r\nWill investigate and report back.",
"body": "The is-a link is broken for GOLD path fields; e.g.: https://microbiomedata.github.io/nmdc-metadata/docs/ecosystem.html.\r\n\r\n@deepakunni3 could this be a problem with how the documentation is generated? Could the lack of a blank line after \"TODO\" cause this?\r\n\r\nHere is an example of they yaml:\r\n```\r\ngold_path_field:\r\n    is_a: attribute\r\n    range: attribute value\r\n    abstract: true\r\n    description: >-\r\n      This is a grouping for any of the gold path fields\r\n    \r\n  ecosystem:\r\n    is_a: gold_path_field\r\n    description: >-\r\n      TODO\r\necosystem:\r\n    is_a: gold_path_field\r\n    description: >-\r\n      TODO\r\n  ecosystem_category:\r\n    is_a: gold_path_field\r\n    description: >-\r\n      TODO\r\n  ecosystem_type:\r\n    is_a: gold_path_field\r\n    description: >-\r\n      TODO\r\n  ecosystem_subtype:\r\n    is_a: gold_path_field\r\n    description: >-\r\n      TODO\r\n  specific_ecosystem:\r\n    is_a: gold_path_field\r\n    description: >-\r\n      TODO\r\n```\r\n\r\ncc @cmungall ",
"body": "nmdc.yaml has been updated to include terms not in mixs.yaml or core.yaml. The jsons validation is now passing.   \r\nStill need to update the sssom lookup code. Don't merge yet.",
"body": "",
"body": "Add `jekyll-docs` target to Makefile",
"body": "Add Jekyll compatible Markdown generator",
"body": "@wdduncan Looks good! \ud83d\udc4d \r\n",
"body": "Add subsets to the `nmdc.yaml` file:\r\n```\r\nsubsets:\r\n  workflow execution activity:\r\n    description: >-\r\n      Subset consisting of just the workflow exectution activities\r\n\r\n  sample:\r\n    description: >-\r\n      Subset consisting of entities linked to the processing of samples. \r\n      Currently, this subset consists of study, omics process, and biosample.\r\n  \r\n  data object:\r\n    description: >-\r\n      Subset consisting of the data objects that either inputs or outputs of processes or workflows.\r\n```",
"body": "Subsets added.",
"body": "For UML generation, we need to be able only certain subsets of the schema. Add an `in_subset` slot to specify subset and annotate schema with subsets.\r\n\r\ncc @deepakunni3 @cmungall ",
"body": "I updated to biolinkml `1.5.4` and ran `make all`. In the `nmdc.py` file, we now have slots of the for <x value>_has_raw_ value, <x value>_has_unit, etc. For example:\r\n```\r\nslots.quantity_value_has_raw_value = Slot(uri=NMDC.has_raw_value, name=\"quantity value_has raw value\", curie=NMDC.curie('has_raw_value'),\r\n                      model_uri=NMDC.quantity_value_has_raw_value, domain=QuantityValue, range=Optional[str])\r\n\r\nslots.quantity_value_has_unit = Slot(uri=NMDC.has_unit, name=\"quantity value_has unit\", curie=NMDC.curie('has_unit'),\r\n                      model_uri=NMDC.quantity_value_has_unit, domain=QuantityValue, range=Optional[str])\r\n\r\nslots.quantity_value_has_numeric_value = Slot(uri=NMDC.has_numeric_value, name=\"quantity value_has numeric value\", curie=NMDC.curie('has_numeric_value'),\r\n                      model_uri=NMDC.quantity_value_has_numeric_value, domain=QuantityValue, range=Optional[float])\r\n\r\nslots.person_value_has_raw_value = Slot(uri=NMDC.has_raw_value, name=\"person value_has raw value\", curie=NMDC.curie('has_raw_value'),\r\n                      model_uri=NMDC.person_value_has_raw_value, domain=PersonValue, range=Optional[str])\r\n\r\nslots.geolocation_value_has_raw_value = Slot(uri=NMDC.has_raw_value, name=\"geolocation value_has raw value\", curie=NMDC.curie('has_raw_value'),\r\n                      model_uri=NMDC.geolocation_value_has_raw_value, domain=GeolocationValue, range=Optional[str])\r\n\r\n```\r\nThe good news is that the owl file is now built, but the aforementioned slots create object properties like in the screenshot below.\r\n\r\n![image](https://user-images.githubusercontent.com/3186638/89944346-a3cbdc80-dbed-11ea-9024-71a5e135741a.png)\r\n",
"body": "Tested. See PR https://github.com/microbiomedata/nmdc-metadata/pull/139.   \r\nAlso submitted ticket to biolinkml about extra slots produced. See https://github.com/biolink/biolinkml/issues/228",
"body": null,
"body": "This is now fixed.",
"body": "Running `gen-owl` is failing with `nmdc.yaml` as input.\r\nHere is my output log for a simple command `gen-owl schema/nmdc.yaml > temp.owl`:\r\n```\r\ngen-owl schema/nmdc.yaml > temp.owl\r\nWARNING:OwlSchemaGenerator:Unrecognized prefix: rdf\r\nWARNING:OwlSchemaGenerator:Unrecognized prefix: rdfs\r\nWARNING:OwlSchemaGenerator:Unrecognized prefix: skos\r\nWARNING:OwlSchemaGenerator:Unrecognized prefix: MIxS\r\nWARNING:root:\tSlot \"has output\" owner (omics processing) does not match workflow execution activity\r\nWARNING:root:\tSlot \"has input\" owner (biosample processing) does not match workflow execution activity\r\nWARNING:root:\tSlot \"ecosystem_category\" owner (study) does not match biosample\r\nWARNING:root:\tSlot \"ecosystem\" owner (study) does not match biosample\r\nWARNING:root:\tSlot \"ecosystem_type\" owner (study) does not match biosample\r\nWARNING:root:\tSlot \"specific_ecosystem\" owner (study) does not match biosample\r\nWARNING:root:\tSlot \"ecosystem_subtype\" owner (study) does not match biosample\r\nWARNING:root:\tSlot \"was informed by\" owner (agent) does not match activity\r\nTraceback (most recent call last):\r\n  File \"/Users/wdduncan/opt/anaconda3/bin/gen-owl\", line 8, in <module>\r\n    sys.exit(cli())\r\n  File \"/Users/wdduncan/opt/anaconda3/lib/python3.7/site-packages/click/core.py\", line 829, in __call__\r\n    return self.main(*args, **kwargs)\r\n  File \"/Users/wdduncan/opt/anaconda3/lib/python3.7/site-packages/click/core.py\", line 782, in main\r\n    rv = self.invoke(ctx)\r\n  File \"/Users/wdduncan/opt/anaconda3/lib/python3.7/site-packages/click/core.py\", line 1066, in invoke\r\n    return ctx.invoke(self.callback, **ctx.params)\r\n  File \"/Users/wdduncan/opt/anaconda3/lib/python3.7/site-packages/click/core.py\", line 610, in invoke\r\n    return callback(*args, **kwargs)\r\n  File \"/Users/wdduncan/.local/lib/python3.7/site-packages/biolinkml/generators/owlgen.py\", line 271, in cli\r\n    print(OwlSchemaGenerator(yamlfile, **kwargs).serialize(**kwargs))\r\n  File \"/Users/wdduncan/.local/lib/python3.7/site-packages/biolinkml/generators/owlgen.py\", line 37, in __init__\r\n    self.metamodel.resolve()\r\n  File \"/Users/wdduncan/.local/lib/python3.7/site-packages/biolinkml/utils/schemaloader.py\", line 121, in resolve\r\n    self.raise_value_error(f'Class \"{cls.name}\" - unknown slot: \"{slotname}\"', slotname)\r\n  File \"/Users/wdduncan/.local/lib/python3.7/site-packages/biolinkml/utils/schemaloader.py\", line 494, in raise_value_error\r\n    raise ValueError(f'{\"\" if loc_str is None or not getattr(loc_str, \"loc\") else (loc_str.loc() + \" \")} {error}')\r\n  File \"/Users/wdduncan/.local/lib/python3.7/site-packages/biolinkml/utils/yamlutils.py\", line 111, in loc\r\n    return f\"{self._s.name}: line {self._s.line + 1} col {self._s.column + 1}\"\r\nAttributeError: 'NoneType' object has no attribute 'name'\r\n```\r\ncc @deepakunni3 @cmungall ",
"body": "",
"body": "Makefile updated to build shex target. An error was raised for building the owl target. See #137 ",
"body": "Modify the build target in the makefile to also build owl and shex.",
"body": "",
"body": "",
"body": "@jagadishcs has documented information he used to create the ENVO triads here: https://docs.google.com/document/d/1_WkxKCw_Msb_4z2d0QkdnmyKyGtlSRlta8GeBSfCjVU/edit",
"body": "Can we generate a TSV with releases with columns\r\n\r\n - 1: Sample ID\r\n - 2-6: GOLD 5-tuple\r\n - 7-9: MIxS ENVO triad",
"body": "Yes. We can do this in a number of way:\r\n- SQL on the sqlite db\r\n- jq on the nmdc_database.json.zip (output of etl)\r\n- python script on nmdc_merged_database.tsv.zip",
"body": "Develop function/algorithm to map GOLD paths to mixs triads.  \r\n\r\nWe can start with the manually curated work, and find results such as given a GOLD paths, what are the top X mixs triads that were mapped to it.\r\n\r\nAdditional steps:\r\n* add other fields to as input to make algorithm better\r\n* use NLP/ML on description fields",
"body": "Add processing institution to gold omic_processing entities.  \r\nFixes #130",
"body": "E.g.\r\n```json\r\n{\r\n  \"id\": \"gold:Gp0108335\",\r\n  \"name\": \"Thawing permafrost microbial communities from the Arctic, studying carbon transformations - Permafrost 712P3D\",\r\n  \"has_input\": [\r\n    \"gold:Gb0108335\"\r\n  ],\r\n  \"part_of\": [\r\n    \"gold:Gs0112340\"\r\n  ],\r\n  \"has_output\": [\r\n    \"jgi:551a20d30d878525404e90d5\"\r\n  ],\r\n  \"omics_type\": {\r\n    \"has_raw_value\": \"Metagenome\"\r\n  },\r\n  \"type\": \"nmdc:OmicsProcessing\",\r\n  \"add_date\": {\r\n    \"has_raw_value\": \"30-OCT-14 12.00.00.000000000 AM\"\r\n  },\r\n  \"mod_date\": {\r\n    \"has_raw_value\": \"22-MAY-20 06.13.12.927000000 PM\"\r\n  },\r\n  \"ncbi_project_name\": {\r\n    \"has_raw_value\": \"Thawing permafrost microbial communities from the Arctic, studying carbon transformations - Permafrost 712P3D\"\r\n  },\r\n  \"principal_investigator_name\": {\r\n    \"has_raw_value\": \"Virginia Rich\"\r\n  }\r\n}\r\n```",
"body": "Fixes #126",
"body": "Fixes #125 \r\nProjects with an omics type of \"Whole Genome Sequencing\" have been removed.\r\n\r\n@dehays I also checked the PROJECT_BIOSAMPLE table in the source data. Projects with \"Whole Genome Sequencing\" were not present. Queries used to check below.\r\n\r\nQuery 1 looking as project IDs extracted from the json:\r\n```\r\nselect * from PROJECT_BIOSAMPLE\r\nwhere project_id in \r\n(\r\n'114905',\r\n'114906',\r\n'114933',\r\n'114934',\r\n'114939',\r\n'114940',\r\n'114941',\r\n'115128',\r\n'115129',\r\n'115135',\r\n'115137',\r\n'115138',\r\n'115140',\r\n'115141',\r\n'115142',\r\n'115145',\r\n'115146',\r\n'115147',\r\n'115148',\r\n'115149',\r\n'115157',\r\n'115158',\r\n'115159',\r\n'115160',\r\n'115194',\r\n'115195',\r\n'115197',\r\n'115198',\r\n'115199',\r\n'115200',\r\n'115201',\r\n'115203',\r\n'115204',\r\n'115205',\r\n'156920',\r\n'156921',\r\n'156922',\r\n'156924',\r\n'156925',\r\n'156926'\r\n)\r\n```\r\nQuery 2: looking for any project with type \"Whole Genome Sequencing\":\r\n```\r\nselect * from PROJECT_BIOSAMPLE\r\nwhere project_id in \r\n( select project_id from PROJECT where SEQUENCING_STRATEGY = \"Whole Genome Sequencing\" )\r\n```",
"body": "@cmungall Looking at the difference in `schema/nmdc.schema.json`, I see that that `part_of` slots were deleted. I may have to recant that the new BML is fine :(",
"body": "Re-ran the ETL codes using biolinkml 1.5.3. Before running, I made a copy of nmdc database named  `nmdc_database_1.json`. After running, I compared the MD5 checksums of `nmdc_database_1.json`, the newly created `nmdc_database.json`, and the `nmdc_database.json` on the master branch. Here is the summary:\r\n```\r\nMD5 (nmdc_database_1.json) = d555079dd496690bd754d02811898a71\r\n  MD5 (nmdc_database.json) = d555079dd496690bd754d02811898a71\r\n  MD5 (nmdc_database.json) = d555079dd496690bd754d02811898a71 ** copy on master branch\r\n```\r\nAll three checksums match. \r\n\r\nAlso recreated the `nmdc.py` file using `make clean` followed by `make all`.\r\n\r\nThis gives me confidence that the new version of biolinkml did not break our site.",
"body": "cc @anubhav0fnu @dehays ",
"body": "This will involve the removal of 40 biosamples and 40 omics_processing objects.  If I give you a set of IDs can you you remove them.  Or how best to ensure that they stay removed with you your ETL starting with the GOLD DB exports for FICUS?",
"body": "Yes. I can remove the records from the GOLD biosample and project tables. The solution will be hacky ... Hopefully the next GOLD export excludes them :)",
"body": "cc @dehays ",
"body": "",
"body": "We tested this. See PR https://github.com/microbiomedata/nmdc-metadata/pull/127",
"body": null,
"body": "Fixes #121 ",
"body": null,
"body": "Not sure why, but I had to remove `get`, `post`, `request` from the `requirements.txt` file. The pip information for these was odd too. E.g., `pip show`:\r\n```\r\nName: request\r\nVersion: 2019.4.13\r\nSummary: UNKNOWN\r\nHome-page: https://github.com/looking-for-a-job/request.py\r\nAuthor: None\r\nAuthor-email: None\r\nLicense: UNKNOWN\r\nLocation: ~/repos/NMDC/nmdc-metadata/.env/lib/python3.7/site-packages\r\nRequires: get, post, setuptools\r\n```\r\nThe `Home-page` is odd. Returns a 404 error.\r\n",
"body": "Fixes #119 \r\n",
"body": null,
"body": "why are the checks failing?",
"body": "https://travis-ci.org/github/microbiomedata/nmdc-metadata/builds/708493074#L250-L252",
"body": "Fixes #117",
"body": "- Change stub workflow activity classes in NMDC.yaml to match names used by Aim 2. E.g., change  annotation activity to metagenome annotation active.\r\n\r\n- Update stat slots to match Aim 2 files.",
"body": "Fixes #115 ",
"body": "need stat slots for read analysis (QC) workflow statistics:\r\n\r\n - input read count\r\n - input read bases\r\n - output read count\r\n  - output read  bases\r\n    ",
"body": "The work thus far from @scanon and @chienchi has been the following three. I suggest addressing them in this order.\r\n\r\n1) readQC (in one example it is marked as \"SampleQC\" but that is a misnomer.  This takes in raw reads and produces filtered reads and some statistics.)\r\n\r\n2) metagenome assembly\r\n\r\n3) metagenome annotation",
"body": "We're settled on this ... so closing.",
"body": "@dehays @cmungall @scanon @hubin-keio \r\n\r\nIf I recall, Kitware needs the dataset settled by Friday 7/17. Can we prioritize what workflows we might be able to get to them? E.g.:  \r\n- readQC\r\n- nucleotide assembly\r\n- genome annotation\r\n- none of the above?",
"body": "PROV is a nice structure but we should not be too hamstrung by it at this stage. I am confident if we come up with the right structure it will align well to PROV.",
"body": "@cmungall I think this we've tackled this one with Aim 2 workflows (e.g., assembly file `was generated by` metagenome assembly (workflow execution activity).\r\n\r\nLet me know if you want to re-open.",
"body": "How are planning to integrate PROV with the NMDC schema?   \r\nCurrently, we have a place to put PROV activities in the `activity set` slot. But, other questions follow:  \r\n1. Should biosample processing (and omics processing) be a subtype of PROV activity?\r\n2. Do we want PROV `wasGeneratedBy` to act as inverse relation to `has_output`?\r\n3. Do you want to relate NMDC data processings (workflows?) to GOLD projects using `wasInformedBy` (https://www.w3.org/TR/prov-o/#wasInformedBy)? I think `wasGeneratedBy` could be more appropriate.  \r\n\r\ncc @cmungall @dehays ",
"body": "This has been resolved. We are using process sense of 'workflow', which we call a 'workflow execution activity'.",
"body": "I posted this message question in Slack, but I'm reposting here.\r\nBy 'workflow' is @scanon referring to the protocol sense of workflow: the predefined steps that the workflow activity should follow, or the workflow activity/process itself? \r\n\r\ncc @dehays @cmungall ",
"body": "\r\n> OBI has the concept of assay, e.g. sequencing assay\r\n> - Seems odd to classify as an assay\r\n> - omics_processing may be the combination of the material processing step and the sequencing assay. \r\n\r\nLet's look at the definitions.\r\n- **omics processing**: A process that takes one or more biosamples as inputs and generates one or as outputs. Examples of outputs include samples cultivated from another sample or data objects created by instruments runs.\r\n- **assay**:  A planned process with the objective to produce information about the material entity that is the evaluant, by physically examining it or its proxies.\r\n  - **sequencing assay**: An assay the uses chemical or biochemical means to infer the sequence of a biomaterial\r\n\r\nThese seem pretty close to me.\r\n > workflows. \r\n\r\nDepends on what you mean by 'workflow'. Do you mean: \r\n1. the pre-thought out set of steps to follow (i.e., the plan specification) \r\n2. the actual process that was carried out\r\n3. both 1 & 2  \r\n\r\nShane's comments seem closer to 1, but he could have meant 2 also.\r\n",
"body": "We should add mappings between relevant schema classes and OBI:\r\nhttps://www.ebi.ac.uk/ols/ontologies/obi/\r\n\r\n - biosample -> obi:material sample\r\n - omics_processing\r\n      - not clear how best to map this\r\n      - OBI has the concept of assay, e.g. [sequencing assay](https://www.ebi.ac.uk/ols/ontologies/obi/terms?iri=http%3A%2F%2Fpurl.obolibrary.org%2Fobo%2FOBI_0600047&viewMode=All&siblings=false)\r\n       - Seems odd to classify as an assay\r\n       - omics_processing may be the combination of the [material processing](https://www.ebi.ac.uk/ols/ontologies/obi/terms?iri=http%3A%2F%2Fpurl.obolibrary.org%2Fobo%2FOBI_0000094) step and the sequencing assay\r\n - workflows\r\n     - not in scope of OBI?\r\n     - there are some algorithms under [algorithm](https://www.ebi.ac.uk/ols/ontologies/obi/terms?iri=http%3A%2F%2Fpurl.obolibrary.org%2Fobo%2FIAO_0000064)",
"body": "This PR #100 introduced the sssom file\r\n\r\nWe should get rid of the other ones, and use this in the ETL code\r\n\r\nWe should also add blank lines for unmapped gold fields",
"body": "",
"body": "The ETL now has GOLD biosamples as inputs into EMSL processes. We still have more investigation into the multiple samples used for some process, and it seems some samples weren't mapped to EMSL processes.\r\n\r\nFixes #107 ",
"body": "Use Sam's mappings in https://docs.google.com/spreadsheets/d/1Vx1X7APaqSVHoRJRhZEMf1WnkCQ85tkQ2PZzUR_uXj4/edit#gid=0 to specify the biosamples that were input into the EMSL processes.",
"body": "Fixes #105 ",
"body": "This makes sense. It was useful having them there as exemplars/placeholders, but time to get rid of them. ",
"body": "Done. See PR https://github.com/microbiomedata/nmdc-metadata/pull/106",
"body": "Based on conversation with @dehays:  \r\nIn the schema, we want the data objects that represent the assembly files (i.e., faa and fna files) to come from AIM 2's pipeline (i.e., NMDC).   \r\nCurrently, the files come from JGI. So, need to remove the JGI faa and fna data objects from data. We only want to keep the JGI fastq files.\r\n\r\ncc @cmungall ",
"body": "fixes #103 ",
"body": "Fixed with PR https://github.com/microbiomedata/nmdc-metadata/pull/104/\r\n",
"body": null,
"body": "",
"body": "as my mistake, we have a part-of from the sample to the project",
"body": "our schema has:\r\n\r\n```yaml\r\n  omics processing:\r\n    is_a: biosample processing\r\n    description: >-\r\n      The methods and processes used to generate omics data from a biosample or organism.\r\n    slots:\r\n      - part of\r\n      - has output\r\n    slot_usage:\r\n      id:\r\n        description: >-\r\n          The primary identifier for the omics processing. E.g. GOLD:GpNNNN\r\n      name:\r\n        description: >-\r\n          A human readable name or description of the omics processing.\r\n      alternate identifiers:\r\n        description: >-\r\n          The same omics processing may have distinct identifiers in different databases (e.g. GOLD and EMSL)\r\n      part of:\r\n        range: study\r\n      has output:\r\n        range: data object\r\n```\r\n\r\nso an omics_processing object is linked to a study, but not a sample\r\n\r\nExample instance data:\r\n\r\n```yaml\r\n  omics_processing_set: \r\n    - \r\n      id: \"gold:Gp0108335\"\r\n      name: \"Thawing permafrost microbial communities from the Arctic, studying carbon transformations - Permafrost 712P3D\"\r\n      part_of: \r\n        - \"gold:Gs0112340\"\r\n      has_output: \r\n        - \"nmdc:5af44fd364d0b33747747ddb\"\r\n        - \"nmdc:5af44fd264d0b33747747dd9\"\r\n        - \"jgi:551a20d30d878525404e90d5\"\r\n      type: \"nmdc:OmicsProcessing\"\r\n      add_date: \r\n        has_raw_value: \"30-OCT-14 12.00.00.000000000 AM\"\r\n      mod_date: \r\n        has_raw_value: \"22-MAY-20 06.13.12.927000000 PM\"\r\n      ncbi_project_name: \r\n        has_raw_value: \"Thawing permafrost microbial communities from the Arctic, studying carbon transformations - Permafrost 712P3D\"\r\n      omics_type: \r\n        has_raw_value: \"Metagenome\"\r\n      principal_investigator_name: \r\n        has_raw_value: \"Virginia Rich\"\r\n```\r\n\r\nwhich corresponds to https://gold.jgi.doe.gov/project?id=Gp0108335 -- note this has a link \r\nhttps://gold.jgi.doe.gov/project?id=Gp0108335",
"body": "",
"body": "Do you want me to merge? Thanks for fixing \"flooding\". I need to check to Jagadish about the other issues I raised in the other PR.",
"body": "comment from @wdduncan on other PR:\r\n\r\nThe reason for the fields that look like:\r\n\r\nsoil_annual_season_temp or season_temp or annual_temp?\r\nseason_precpt or annual_precpt?\r\nis b/c we don't know what the correct mixs term should be. Should gold:soil_annual_season_temp map to mixs:season_temp or mixs:annual_temp. Should gold:soil_annual_season_precpt map to mixs:season_precpt or mixs:annual_precpt?\r\n\r\nMy answer:\r\n\r\nuse SSSOM and indicate uncertaintly using appropriate fields\r\n\r\nThis PR is an intermediate step and at least makes the tsv machin interpretable",
"body": "> use SSSOM and indicate uncertaintly using appropriate fields. \r\n\r\nWhat would the SSSOM predicate would be?",
"body": "skos:exactMatch for exact, anything else eg skos:close or broadMatch for inexct",
"body": "",
"body": "The reason for the fields that look like:\r\n```\r\nsoil_annual_season_temp or season_temp or annual_temp?\r\nseason_precpt or annual_precpt?\r\n```\r\nis b/c we don't know what the correct mixs term should be. Should `gold:soil_annual_season_temp` map to `mixs:season_temp` or `mixs:annual_temp`. Should `gold:soil_annual_season_precpt` map to `mixs:season_precpt` or `mixs:annual_precpt`?\r\n",
"body": "Sorry, addition of this commit was a mistake https://github.com/microbiomedata/nmdc-metadata/pull/98/commits/cda769d52902edab40c1b5103537859ddc84d8d3\r\n\r\nthere is a separate PR for this here: #99 ",
"body": "",
"body": "- mixs triad values are now controlled term values\r\n- depth is now a quantity value\r\n- updated nmdc_database file with new data\r\n- added nmdc-03.json with new example data",
"body": "",
"body": "```\r\n$ grep '?' ./metadata-translation/src/data/GOLD-to-mixs-map.tsv \r\ngold    biosample       soil_annual_season_temp season_temp or annual_temp?\r\ngold    biosample       soil_annual_season_precpt       season_precpt or annual_precpt?\r\n```\r\n\r\nthe value of c4 should be a single atomic string. Information such as certainty should be indicated in a separate field. If a mapping is not one to one consider using a scheme like skos/sssom to explicitly distinguish exact/1:1 from imprecise",
"body": "Looks great go ahead and merge\n\nOn Wed, Jul 1, 2020, 12:34 Bill Duncan <notifications@github.com> wrote:\n\n>\n>    - moved etl code out of notebook into code module:\n>    execute_etl_pipeline.py\n>    - added basic validation code ... much more work to do ... many more\n>    tests to add: validate_json.py\n>    - made changes to supporting modules so that etl can be in separate\n>    module (i.e., execute_etl_pipeline.py)\n>    - need to work on retrieve data type for each attribute!\n>\n> ------------------------------\n> You can view, comment on, or merge this pull request online at:\n>\n>   https://github.com/microbiomedata/nmdc-metadata/pull/94\n> Commit Summary\n>\n>    - prettify data\n>    - add module to execute etl pipeline\n>    - add basic validation code using pytest\n>    - add constructor and attribute properties to data classes\n>    - modify code to work with new syntax present in nmdc_data_source.yaml\n>    - change file_size to file_size_bytes\n>    - compiled one schema based on change to nmdc.yaml\n>    - change file_size to file_size_bytes\n>    - simple changes to notebook; not of consequence\n>    - add __init__.py files in order to navigate modules\n>\n> File Changes\n>\n>    - *A* __init__.py\n>    <https://github.com/microbiomedata/nmdc-metadata/pull/94/files#diff-743b1adbf37db12e16e01ef62a6f7d72>\n>    (0)\n>    - *M* examples/nmdc-02.json\n>    <https://github.com/microbiomedata/nmdc-metadata/pull/94/files#diff-2e95ea4e0c19245be39f180f9946eb93>\n>    (609)\n>    - *A* metadata-translation/__init__.py\n>    <https://github.com/microbiomedata/nmdc-metadata/pull/94/files#diff-81b9ecaaa350b04b7e34783be7f06552>\n>    (0)\n>    - *M* metadata-translation/notebooks/test-pipeline.ipynb\n>    <https://github.com/microbiomedata/nmdc-metadata/pull/94/files#diff-ecfc945380de74fc9b27ffe5b9977f41>\n>    (154)\n>    - *A* metadata-translation/src/__init__.py\n>    <https://github.com/microbiomedata/nmdc-metadata/pull/94/files#diff-8644e4de4aaa3fb0ca9db0fbc71ba2fe>\n>    (0)\n>    - *A* metadata-translation/src/bin/__init__.py\n>    <https://github.com/microbiomedata/nmdc-metadata/pull/94/files#diff-01a7bf4e7d8b33c74f1afefeed3d7d9d>\n>    (0)\n>    - *A* metadata-translation/src/bin/execute_etl_pipeline.py\n>    <https://github.com/microbiomedata/nmdc-metadata/pull/94/files#diff-e90009bb6f7b1ebf3331a17ebc5b7040>\n>    (107)\n>    - *M* metadata-translation/src/bin/lib/data_operations.py\n>    <https://github.com/microbiomedata/nmdc-metadata/pull/94/files#diff-53fa9753e8c694ff4cd0526f9fc75f2b>\n>    (29)\n>    - *M* metadata-translation/src/bin/lib/nmdc_data_source.yaml\n>    <https://github.com/microbiomedata/nmdc-metadata/pull/94/files#diff-2e6b58b7c1dcc409c52b9f27b8b184ce>\n>    (250)\n>    - *A* metadata-translation/src/bin/validate_json.py\n>    <https://github.com/microbiomedata/nmdc-metadata/pull/94/files#diff-3b2828a654a128dc72b0cabb8c9a349c>\n>    (40)\n>    - *A* schema/__init__.py\n>    <https://github.com/microbiomedata/nmdc-metadata/pull/94/files#diff-68ce2364a4ed92ecc4cfef7d3220e05d>\n>    (0)\n>    - *M* schema/nmdc.py\n>    <https://github.com/microbiomedata/nmdc-metadata/pull/94/files#diff-21be449b969b7abbdaba911af82374fe>\n>    (26)\n>    - *M* schema/nmdc.schema.json\n>    <https://github.com/microbiomedata/nmdc-metadata/pull/94/files#diff-44b7ff9111870c2ec7bc90943d02bbe4>\n>    (21)\n>    - *M* schema/nmdc.yaml\n>    <https://github.com/microbiomedata/nmdc-metadata/pull/94/files#diff-c1b6b55ece439e2e11a08164c00974e7>\n>    (28)\n>\n> Patch Links:\n>\n>    - https://github.com/microbiomedata/nmdc-metadata/pull/94.patch\n>    - https://github.com/microbiomedata/nmdc-metadata/pull/94.diff\n>\n> \u2014\n> You are receiving this because your review was requested.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/microbiomedata/nmdc-metadata/pull/94>, or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AAAMMOJHDZXGESPIDEK6R6LRZOFRXANCNFSM4ON4ZFHQ>\n> .\n>\n",
"body": "- moved etl code out of notebook into code module: `execute_etl_pipeline.py`\r\n- added basic validation code ... much more work to do ... many more tests to add: `validate_json.py`\r\n- made changes to supporting modules so that etl can be in separate module (i.e., `execute_etl_pipeline.py`)\r\n- need to work on retrieve data type for each attribute!",
"body": "",
"body": "done see PR https://github.com/microbiomedata/nmdc-metadata/pull/96",
"body": "Modify data objects attribute 'file_size_bytes' to be a simple integer.\r\n\r\ncc @cmungall ",
"body": "done see PR https://github.com/microbiomedata/nmdc-metadata/pull/97",
"body": "JSON failing for env_broad, env_local, env_medium with errors:\r\n```\r\n{'has_raw_value': 'ENVO_00000446', 'type': 'nmdc:ControlledTermValue'}: Additional properties are not allowed ('type' was unexpected)\r\n{'has_raw_value': 'ENVO_00000489', 'type': 'nmdc:ControlledTermValue'}: Additional properties are not allowed ('type' was unexpected)\r\n{'has_raw_value': 'ENVO_00000134', 'type': 'nmdc:ControlledTermValue'}: Additional properties are not allowed ('type' was unexpected)\r\n```\r\nModify ETL to output a ControlledTerm object, for may leave label blank.\r\n\r\ncc @cmungall ",
"body": "How does location differ from geographic_location (which maps to mixs:geo_loc_name)? Same Q sample_collection_site. for We should have blank rows in gold-to-mixs.sssom.tsv for these\r\n\r\nI suggest simply going ahead and adding these to the schema. However, add a `status: draft` to each of these until we have established their meaning.",
"body": "Re:  \r\n> How does location differ from geographic_location (which maps to mixs:geo_loc_name)? \r\n\r\nI asked Reddy about the difference between the location and geographic location fields. Here is the email:  \r\n\r\n> Hi Reddy,\r\n> When I run the query:\r\n\r\n> select distinct GEOGRAPHIC_LOCATION, LOCATION from BIOSAMPLE\r\n\r\n> I see a lot of values that are syntactically different, but are very close equivalent semantically; e.g. \"USA: Ohio\" vs \"Ohio, USA\". > Sometimes one of the values is more specific than the other.  \r\n\r\nWe follow USA: Ohio convention, other variations are something we may not yet have touched or reviewed. \r\n \r\n> The online documentation (https://gold.jgi.doe.gov/resources/Standardized_Metagenome_Naming.pdf), defines \"Location\" as:\r\n> Location, which provides information about the geographic location of the sample\r\n> For purposes of mapping to MIxS, this seems to be the same as geographic location. This is defined in MIxS as:\r\n\r\n> The geographical origin of the sample as defined by the country or sea name followed by specific region name. Country or sea names should be chosen from the INSDC country list (http://insdc.org/country.html), or the GAZ ontology (v 1.512) (http://purl.bioontology.org/ontology/GAZ)\r\n\r\nWe also have a country filed. This essentially same as INSDC country list including oceans. Our geographic location is a free text field following the above format like \"USA: Ohio\"\r\n\r\nYes, this part of the canonical naming conventions we follow for environmental samples.\r\nhttps://gold.jgi.doe.gov/resources/Standardized_Metagenome_Naming.pdf\r\n\r\n",
"body": "Fields added to schema. See PR: https://github.com/microbiomedata/nmdc-metadata/pull/145",
"body": "Gold biosample json fails validation:\r\n```\r\nAdditional properties are not allowed ('location', 'mod_date', 'identifier', 'sample_collection_site', 'add_date', 'ncbi_taxonomy_name', 'community', 'habitat', 'type' were unexpected)\r\n```\r\nAdd properties to nmdc schema\r\n\r\ncc @cmungall ",
"body": "slots added. See PR: https://github.com/microbiomedata/nmdc-metadata/pull/145",
"body": "Gold study objects fail validation:\r\n```\r\nAdditional properties are not allowed ('mod_date', 'principal_investigator_name', 'add_date', 'ncbi_project_name', 'omics_type', 'type' were unexpected)\r\n```\r\nNeed to add to nmdc schema.\r\n\r\ncc @cmungall ",
"body": "",
"body": "@cmungall \r\n`make test` fails for `nmdc-02.json`:\r\n```\r\n{'has_raw_value': 'Environmental'}: {'has_raw_value': 'Environmental'} is not of type 'string'\r\n{'has_raw_value': 'Terrestrial'}: {'has_raw_value': 'Terrestrial'} is not of type 'string'\r\n{'has_raw_value': 'Wetlands'}: {'has_raw_value': 'Wetlands'} is not of type 'string'\r\n{'has_raw_value': 'Soil'}: {'has_raw_value': 'Soil'} is not of type 'string'\r\n{'has_raw_value': 'Permafrost'}: {'has_raw_value': 'Permafrost'} is not of type 'string'\r\n```\r\nCan we add `{'has_raw_value': string}' as a valid schema?",
"body": "Use json schema to validate ETL output",
"body": "Changed makefile to use requirements.txt and replaced 'pipenv run' with 'python ...'.",
"body": "fixed with PR https://github.com/microbiomedata/nmdc-metadata/pull/85",
"body": "Travis build is failing for some Pipenv reason. Here is some of the log:\r\n```\r\nAdding requests to Pipfile's [packages]\u2026\r\nPipfile.lock not found, creating\u2026\r\nLocking [dev-packages] dependencies\u2026\r\nLocking [packages] dependencies\u2026\r\nFAIL\r\n[pipenv.exceptions.ResolutionFailure]:   File \"/home/travis/virtualenv/python3.7.1/lib/python3.7/site-packages/pipenv/resolver.py\", line 69, in resolve\r\n.....\r\n\r\n```\r\nI'm going try out some various makefile configurations.",
"body": "",
"body": "Done. See PR https://github.com/microbiomedata/nmdc-metadata/pull/83",
"body": null,
"body": "E.g. fastq, gff, ko summary table, ...",
"body": "In terms of general schema structure, we are thinking of following PROV:\r\n\r\n![img](https://www.w3.org/TR/prov-o/diagrams/starting-points.svg)\r\n\r\nWe have the prov base classes here: https://github.com/microbiomedata/nmdc-metadata/blob/master/schema/prov.yaml\r\n\r\nStraw man:\r\n\r\n![image](https://user-images.githubusercontent.com/50745/86680601-964e8180-bfb3-11ea-8278-ef59366aea96.png)\r\n\r\nTBD: which direction to traverse the json tree? currently we have omics processing, which has a non-imlined list of output objects, each of which has inlined metaadata about workflow execution\r\n\r\n\r\n\r\n",
"body": "See https://microbiomedata.github.io/nmdc-metadata/docs/WorkflowExecutionActivity",
"body": "Parking some slides of relevance from @stain here, will provide context later: http://slides.com/soilandreyes/2018-01-15-interoperable-provenance",
"body": "draft json file: \r\nhttps://gist.github.com/chienchi/8bf29a5501b479d332bbd44cd240821f",
"body": "Do want to have an inverse relation to has_input. The biosample data has associated project ids. This makes it easier to model `biosample is_input_to sequencing project` in one pass over the data.",
"body": "Here is an example for metagenome annotation activity:\r\n```\r\n[\r\n  {\r\n    \"id\": \"\", ## need to specify a URI to identify the activity ##\r\n    \"name\": \"\", ## If you don't have names in the data, you can just name it 'metagenome annotation activity' ##\r\n    \"started_at_time\": \"2020-06-12\", \r\n    \"ended_at_time\": \"2020-06-12\", \r\n    \"was_informed_by\": \"gold:Gp0095966\",\r\n    \"type\": \"annotation activity\", ## is this specific enough? is there more than one type of annotation activity? ##\r\n    \"has_input\": [\r\n      \"nmdc:e08985ca1c68cf494875a19802bb535a\" # is this a data object?\r\n    ], \r\n    \"git_url\": \"https://github.com/microbiomedata/mg_annotation/releases/tag/0.1\", ## Does this subsume workflow version 1.0\r\n    \"has_output\": [\r\n      \"nmdc:d184ae225006c3cf9282775289aa0c06\", \r\n      \"nmdc:bfcf65ba9992cd019c6e88427efac84c\", \r\n      \"nmdc:071da0907650de9024c225da758d2f16\", \r\n      \"nmdc:749ff7a21de61359f78c52648b472539\"\r\n    ], \r\n    \"execution_resource\": \"NERSC - Cori\"\r\n  },\r\n  {\r\n    ... second annotation activity\r\n  },\r\n  ... etc.\r\n]\r\n```",
"body": "Does the git_url also imply that the workflow version is 0.1.0? If so, the workflow version is redundant info. Also, need to decide on \"metadata\" element.",
"body": "Thanks for the example.  Follow this example, I did the read QC.\r\n```json\r\n{\r\n    \"ReadQC\": {\r\n        \"id\": \"\",\r\n        \"name\": \"ReadQC activiity 1472_51289\",\r\n        \"was_informed_by\": \"gold:Gp0061285\",\r\n        \"started_at_time\": \"2020-03-19\",\r\n        \"ended_at_time\": \"2020-03-19\",\r\n        \"type\": \"ReadQC activity\",\r\n        \"execution_resource\": \"NERSC - Cori\",\r\n        \"git_url\": \"https://github.com/microbiomedata/ReadsQC/releases/tag/1.0.0\",\r\n        \"has_input\": [\r\n            \"jgi:5bd6893146d1e604fecfb2fd\"\r\n        ],\r\n        \"has_output\": [\r\n            \"nmdc:6b58ac1c6c086b4bb2c318ace84901e6\",\r\n            \"nmdc:fa4c5cb8f6d7fb9143fc0d8d802e2c6b\"\r\n        ],\r\n        \"stats\": {\r\n            \"input_read_count\": 97750956,\r\n            \"input_read_bases\": 14662643400,\r\n            \"output_read_count\": 96006306,\r\n            \"output_read_bases\": 14341531952\r\n        }\r\n    }\r\n}\r\n```",
"body": "@chienchi Thanks. I would change as follows:\r\n```\r\n[\r\n  {\r\n\t\t\"id\": \"\", \r\n\t\t\"name\": \"ReadQC activiity 1472_51289\",\r\n\t\t\"was_informed_by\": \"gold:Gp0061285\",\r\n\t\t\"started_at_time\": \"2020-03-19\",\r\n\t\t\"ended_at_time\": \"2020-03-19\",\r\n\t\t\"type\": \"read analysis activity\",\r\n\t\t\"execution_resource\": \"NERSC - Cori\",\r\n\t\t\"git_url\": \"https://github.com/microbiomedata/ReadsQC/releases/tag/1.0.0\",\r\n\t\t\"has_input\": [\r\n\t\t\t\t\"jgi:5bd6893146d1e604fecfb2fd\"\r\n\t\t],\r\n\t\t\"has_output\": [\r\n\t\t\t\t\"nmdc:6b58ac1c6c086b4bb2c318ace84901e6\",\r\n\t\t\t\t\"nmdc:fa4c5cb8f6d7fb9143fc0d8d802e2c6b\"\r\n\t\t],\r\n\t\t\"input_read_count\": 97750956,\r\n\t\t\"input_read_bases\": 14662643400,\r\n\t\t\"output_read_count\": 96006306,\r\n\t\t\"output_read_bases\": 14341531952\r\n  },\r\n  { ... next read QC activity ...},\r\n  ... etc.\r\n]\r\n```\r\nWe still need to define a URI scheme for the IDs.\r\n",
"body": "This concrete example is looking good, and we've confirmed that the `was_informed_by` property links into an omics processing identifier we have in an earlier data dump so this would potentially be able to be linked into the DB and UI. We do not seem to have the data objects referenced in the `has_input` and `has_output` fields, but I'm less concerned about getting all of those (we could stub out dummy data objects for the time being if needed).",
"body": " \r\n> We still need to define a URI scheme for the IDs.\r\n\r\nGot it. For the output data object, currently Shane and I used md5 for the object id. Here is the corresponding output from the previous read analysis activity json file. \r\n```json\r\n[\r\n    {\r\n        \"id\": \"nmdc:6b58ac1c6c086b4bb2c318ace84901e6\",\r\n        \"name\": \"filterStats.txt\",\r\n        \"description\": \"Filtered read data stats for gold:Gp0061285\",\r\n        \"file_size_bytes\": 289,\r\n        \"type\": \"nmdc:DataObject\"\r\n    },\r\n    {\r\n        \"id\": \"nmdc:fa4c5cb8f6d7fb9143fc0d8d802e2c6b\",\r\n        \"name\": \"12718.2.279671.TGGATCAC-GTGATCCA.fastq.gz\",\r\n        \"description\": \"Filtered read data for gold:Gp0061285\",\r\n        \"file_size_bytes\": 7230036234,\r\n        \"type\": \"nmdc:DataObject\"\r\n    }\r\n]\r\n```",
"body": "@jeffbaumes @chienchi  Shane and Chien-Chi will be producing new DataObject JSON objects for the outputs as Chien-Chi has shown above.  I think using the md5 as IDs on the new file objects is fine. Jeff - you don't have JSON for these new DataObjects yet.\r\n\r\nThere is an issue we need to address in linking to the existing raw fastq DataObjects.  I had thought those were also using md5 hash values as IDs but I learned that they are not (They are 24 hex character mongo IDs.). That difference is why Jeff is not finding them by ID among the DataObject JSON that was previously generated.  My suggestion is to regenerate those DataObjects to use md5 hash values as IDs so that everything representing a file is currently an md5",
"body": "For Annotation:\r\nhttps://portal.nersc.gov/project/m3408/meta/data_objects.json\r\nhttps://portal.nersc.gov/project/m3408/meta/mg_annotation_objects.json\r\nFor readQC:\r\nhttps://portal.nersc.gov/project/m3408/meta/readQC_activity_data_objects.json\r\nhttps://portal.nersc.gov/project/m3408/meta/readQC_activity.json\r\nFor Assembly:\r\nhttps://portal.nersc.gov/project/m3408/meta/metagenomeAssembly_activity.json\r\nhttps://portal.nersc.gov/project/m3408/meta/metagenomeAssembly_data_objects.json\r\n\r\nThe sync meeting yesterday is very helpful. Please take a look for the current json files Shane and I have for the three workflow activities. ",
"body": "Thanks for links @chienchi !\r\nCould you make a few minor adjustments to the annotations?\r\n\r\n1. change \"has_inputs\" to \"has_input\" (no \"s\")\r\n2. change \"has_outputs\" to \"has_output\" (no \"s\")\r\n3. change \"type\": \"metagenomeAnnotation\" to \"type\": \"nmdc:MetagenomeAnnotation\" (the first letter in the name of the class is capitalized)\r\n4. put all the objects in a list. Here is an example of the first two \r\n```json\r\n[\r\n\t{\r\n\t\t\"git_url\": \"https://github.com/microbiomedata/mg_annotation/releases/tag/0.1\", \r\n\t\t\"name\": \"MetagenomeAnnotation activity for gold:Gp0095966\", \r\n\t\t\"has_output\": [\r\n\t\t\t\"nmdc:749ff7a21de61359f78c52648b472539\", \r\n\t\t\t\"nmdc:071da0907650de9024c225da758d2f16\", \r\n\t\t\t\"nmdc:b1eb2d186c809f9b82eb1d3f7b02dfbc\", \r\n\t\t\t\"nmdc:d184ae225006c3cf9282775289aa0c06\", \r\n\t\t\t\"nmdc:bfcf65ba9992cd019c6e88427efac84c\"\r\n\t\t], \r\n\t\t\"has_inputs\": [\r\n\t\t\t\"nmdc:e08985ca1c68cf494875a19802bb535a\"\r\n\t\t], \r\n\t\t\"started_at_time\": \"2020-06-12\", \r\n\t\t\"was_informed_by\": \"gold:Gp0095966\", \r\n\t\t\"execution_resource\": \"NERSC - Cori\", \r\n\t\t\"type\": \"nmdc:MetagenomeAnnotation\", \r\n\t\t\"id\": \"nmdc:5f7db4508abbc9b240e0ef7697484eea\", \"ended_at_time\": \"2020-06-12\"\r\n\t},\r\n\t{\r\n\t\t\"git_url\": \"https://github.com/microbiomedata/mg_annotation/releases/tag/0.1\", \r\n\t\t\"name\": \"MetagenomeAnnotation activity for gold:Gp0095967\", \r\n\t\t\"has_output\": [\r\n\t\t\t\"nmdc:d4dbb7b34652f1ff7a50e5478aa99dfe\", \r\n\t\t\t\"nmdc:9e6e96602abf283db692530a2d21aebe\", \r\n\t\t\t\"nmdc:c1a557ab082bcd0136d72fa182fb8e34\", \r\n\t\t\t\"nmdc:cda8b935443d68a54d9ba6f67fb05e81\", \r\n\t\t\t\"nmdc:9c57f6f6249a66a10e0b988930c9b1e3\"\r\n\t\t], \r\n\t\t\"has_inputs\": [\r\n\t\t\t\"nmdc:575ece1811785c074c0dc94d67d22b02\"\r\n\t\t], \r\n\t\t\"started_at_time\": \"2020-06-12\", \r\n\t\t\"was_informed_by\": \"gold:Gp0095967\", \r\n\t\t\"execution_resource\": \"NERSC - Cori\", \r\n\t\t\"type\": \"nmdc:MetagenomeAnnotation\", \r\n\t\t\"id\": \"nmdc:5f7db4508abbc9b240e0ef7697484eea\", \r\n\t\t\"ended_at_time\": \"2020-06-12\"\r\n\t}\r\n]\r\n```\r\n\r\nTHANKS!\r\n",
"body": "The format of the **data object** files seems fine:\r\n- https://portal.nersc.gov/project/m3408/meta/data_objects.json\r\n- https://portal.nersc.gov/project/m3408/meta/readQC_activity_data_objects.json\r\n- https://portal.nersc.gov/project/m3408/meta/metagenomeAssembly_data_objects.json\r\n",
"body": "@chienchi  are all the data objects \"https://portal.nersc.gov/project/m3408/meta/data_objects.json\" associated with a particular kind of workflow activity?   \r\n\r\nE.g., readQC_activity_data_objects.json is associated with a readQC activity and metagenomeAssembly_data_objects.json is associated with metagenome assembly activity.\r\n",
"body": "Yes.  The data_objects.json should associated with annotation workflow. I have rename it \r\nhttps://portal.nersc.gov/project/m3408/meta/mg_annotation_data_objects.json\r\n\r\n",
"body": "@chienchi Thanks!",
"body": "@wdduncan , @cmungall , @dehays , @dehays , @jeffbaumes, @chienchi \r\nHere is a sample JSON object for the meta-proteomics pipeline:\r\nhttps://jsonblob.com/400362ef-c70c-11ea-bf3d-05dfba40675b\r\nPlease provide your suggestions.",
"body": "@anubhav0fnu \r\nI looked at this: [https://jsonblob.com/400362ef-c70c-11ea-bf3d-05dfba40675b](url) and this: [https://github.com/microbiomedata/metaPro/blob/master/docs/index.rst](url)\r\n\r\nand compared with metagenomeAssembly_activity.json and Bill\u2019s comment with examples 5 comments above in this thread.\r\n\r\n\r\nFirst, both the mmdc:OmicsProcessing object and the mmdc:DataObject that represents its file output already exist.  These were created by Bill in February based on the instrument run metadata that EMSL provided.\r\n\r\nYou can look at the full set of JSON at [https://github.com/microbiomedata/nmdc-metadata/blob/master/metadata-translation/notebooks/output/test-pipeline.zip](url)\r\n\r\nThis is what they look like: \r\n\r\n```\r\n   {\r\n      \"id\": \"emsl:404590\",\r\n      \"name\": \"FECB_21_5093B_01_23Dec14_Tiger_14-11-12\",\r\n      \"description\": \"High res MS with low res CID MSn\",\r\n      \"part_of\": [\r\n        \"gold:Gs0110132\"\r\n      ],\r\n      \"has_output\": [\r\n        \"emsl:output_404590\"\r\n      ],\r\n      \"type\": \"nmdc:OmicsProcessing\"\r\n    }\r\n\r\n   {\r\n      \"id\": \"emsl:output_404590\",\r\n      \"name\": \"output: FECB_21_5093B_01_23Dec14_Tiger_14-11-12\",\r\n      \"description\": \"High res MS with low res CID MSn\",\r\n      \"file_size_bytes\": 503296678,\r\n      \"type\": \"nmdc:DataObject\"\r\n    }\r\n```\r\n\r\n You do not need to go find each of these, I just include them to point out that both their ID values are based on the EMSL dataset ID.  This means that for the mmdc:metaPro object you create you can figure out the was_informed_by property ID (ID of the nmdcOmicsProcessing object above) and the MSMS output file DataObject ID (the nmdc:DataObject above).\r\n\r\nSo for your example, the was_informed_by property would be:\r\n\r\n`\"was_informed_by\": \"emsl:404590\", `\r\n\r\nThe analysis execution objects you create will not be referencing sequencing projects (like \"gold:Gp0095970\u201d) they will be referencing MSMS runs like \"emsl:404590\"\r\n\r\nYour first input is the output of the MSMS run and Bill created IDs for those by prefixing the EMSL dataset ID with \u201coutput_\u201d so as you see above, the ID of that nmdc:DataObject is \"emsl:output_404590\"\r\nYour other input is the DataObject that represents the faa file produced by metagenome annotation.  Shane produced the JSON for that DataObject because it is the output of a mmdc:MetagenomeAnnotation workflow activity.  Because Shane is using md5 for the IDs of mmdc:DataObject objects, you should not need to hunt that one down either.  It\u2019s ID should be \u201cnmdc:be112c8aeccd5d730d802a60eb63cf75\u201d as long as you are both referring to the same faa file (which you should be). \r\n\r\nI don\u2019t know that you need to include new nmdc:DataObject objects for the parameter file, the msgfplus and the contaminant file as inputs.  Do these change with each execution of Paul\u2019s workflow?  Are these something a researcher coming to NMDC would want to download?\r\n\r\nWithout those - your has_input list (Per Bill\u2019s comments, the property is \u201chas_input\u201d and NOT \u201chas_inputs\u201d.  Same deal for \u201chas_output\u201d and not \u201chas_outputs\u201d) would look like this:\r\n\r\n```\r\n\"has_input\": [\r\n\t\t\t\"emsl:output_404590\u201d,\r\n                 \u201cnmdc:be112c8aeccd5d730d802a60eb63cf75\u201d\r\n\t\t], \r\n```\r\n\r\nYou will need to create nmdc:DataObject JSON for each of your outputs.  They should not be embedded in your nmdc:metaPro object.  Following Shane\u2019s md5 ID scheme makes it easy to know their IDs so your has_output list would look like:\r\n\r\n```\r\n\"has_output\": [\r\n\t\t\t\"nmdc:e0c70280a7a23c7c5cc1e589f72e896e\", \r\n\t\t\t\"nmdc:73c390c95a2337925b9bedd89f94d0e7\"\r\n\t\t]\r\n```\r\n\r\n\r\nYou have some other empty stuff in your outputs section in your example but I just see the two files referenced above.  The two nmdc:DataObject objects you\u2019d need would then be:\r\n\r\n```\r\n{\r\n      \"id\": \"nmdc:e0c70280a7a23c7c5cc1e589f72e896e\",\r\n      \"name\": \"404590_resultant.tsv\",\r\n      \"description\": \u201cresultant file\u201c,\r\n      \"file_size_bytes\": \"10948480\",\r\n      \"type\": \"nmdc:DataObject\"\r\n    },\r\n\r\n{\r\n      \"id\": \"nmdc:73c390c95a2337925b9bedd89f94d0e7\",\r\n      \"name\": \"404590_data_out_table.tsv\",\r\n      \"description\": \u201cdata out table\u201c,\r\n      \"file_size_bytes\": 20581,\r\n      \"type\": \"nmdc:DataObject\"\r\n    }\r\n```\r\n\r\nPut the list of these nmdc:DataObject objects in another file for Bill with a name like emsl_analysis_data_objects.json.\r\n\r\nOther comments\r\n\r\nWe do not charge by the character when naming your class.  Might I suggest \u201cnmdc:MetaProteomicAnalysis\u201d rather than \u201cnmdc:metaPro\u201d?  (Bill is asking that we name classes starting with a capital too.)\r\n\r\nNot so sure about your scheme for the name property that results in \"Metagenome:1393_65601:1045042\u201d.  I see you are building that from the JGI proposal ID, sample ID and sequencing project ID. Maybe talk to Shane and/or Paul about naming for the metaproteomic analysis workflow instances.\r\n\r\nThe dataset_id and dataset_name properties you have are of the input dataset.  Seems those might be redundant with what is in the input DataObject.\r\n\r\nHere\u2019s what I end up with for JSON: [https://jsonblob.com/991cd7ec-c740-11ea-bf3d-a56db33087e2](url)",
"body": "I've added @scanon and @chienchi data:\r\n\r\nannotation files:   \r\nmetagenome_annotation_activities.json   \r\nmetagenome_annotation_data_objects.json  \r\n\r\nassembly files:   \r\nmetagenome_assembly_activities.json   \r\nmetagenome_assembly_data_objects.json  \r\n\r\nreadQC files:  \r\nreadQC_activities.json  \r\nreadQC_data_objects.json\r\n\r\nFiles are located in the [data/aim-2-workflows](https://github.com/microbiomedata/nmdc-metadata/tree/master/metadata-translation/src/data/aim-2-workflows) directory.  \r\n\r\n@anubhav0fnu let me know when you ready :)\r\n\r\n",
"body": "@wdduncan , @dehays \r\nFiles are here `/global/cfs/cdirs/m3408/www/meta/MetaProteomicAnalysis/  `\r\n```\r\n.\r\n|-- [Jul 17  2:38]  hessMetaProteomicAnalysis_activity.json\r\n|-- [Jul 17  2:38]  hessemsl_analysis_data_objects.json\r\n|-- [Jul 17  1:16]  stegenMetaProteomicAnalysis_activity.json\r\n`-- [Jul 17  1:16]  stegenemsl_analysis_data_objects.json\r\n```",
"body": "Can you change the permissions for the files so that I can access them without having to log in. \r\n\r\nE.g., make https://portal.nersc.gov/project/m3408/meta/MetaProteomicAnalysis/hessMetaProteomicAnalysis_activity.json public.",
"body": "Where there any \"stats\" you wanted to add for the nmdc:MetaProteomicAnalysis files?:\r\n\r\nhttps://portal.nersc.gov/project/m3408/meta/MetaProteomicAnalysis/hessMetaProteomicAnalysis_activity.json  \r\nhttps://portal.nersc.gov/project/m3408/meta/MetaProteomicAnalysis/stegenMetaProteomicAnalysis_activity.json\r\n\r\nThe data object files seem fine:\r\nhttps://portal.nersc.gov/project/m3408/meta/MetaProteomicAnalysis/hessemsl_analysis_data_objects.json   \r\nhttps://portal.nersc.gov/project/m3408/meta/MetaProteomicAnalysis/stegenemsl_analysis_data_objects.json",
"body": "> I've added @scanon and @chienchi data:\r\n> \r\n> annotation files:\r\n> metagenome_annotation_activities.json\r\n> metagenome_annotation_data_objects.json\r\n> \r\n> assembly files:\r\n> metagenome_assembly_activities.json\r\n> metagenome_assembly_data_objects.json\r\n> \r\n> readQC files:\r\n> readQC_activities.json\r\n> readQC_data_objects.json\r\n> \r\n> Files are located in the [data/aim-2-workflows](https://github.com/microbiomedata/nmdc-metadata/tree/master/metadata-translation/src/data/aim-2-workflows?rgh-link-date=2020-07-16T23%3A25%3A07Z) directory.\r\n\r\nI realize you may not be finished yet, but I tried using these files and found a couple of issues.\r\n\r\nThere are missing data objects:\r\n```\r\nnmdc:7977dbf7c5e883dec263fe8f23922313\r\nnmdc:8d23c95a2ec52192478379e558bed026\r\nnmdc:9e529a9d01aec09f0401e806e71bfa2a\r\nnmdc:56a10842285cfe56534eeaf60fa829bf\r\n```\r\nand a few duplicates in the activities:\r\n```\r\nmetagenome_annotation nmdc:5f7db4508abbc9b240e0ef7697484eea\r\nreads_qc nmdc:d8aef565dc0a18a0a17ebeb77a3a7153\r\nreads_qc nmdc:f289238604e30ce43a735d47f027e086\r\n```\r\n",
"body": "@jbeezley Thanks Jon - we will investigate why there are references to missing data objects before giving you JSON today. We are looking at the metaproteomicsAnalysis json now.",
"body": "@jbeezley Thanks.  Those are missing data objects are from reads_qc. I will fix that and the duplicate reads_qc.\r\n",
"body": "Hess & Stegen metaprotemics data has been merged. See PR https://github.com/microbiomedata/nmdc-metadata/pull/122",
"body": "I think we are good for now. Closing this ticket.",
"body": "Shane's draft:\r\n\r\nhttps://docs.google.com/document/d/12a8c6ZDp4fyiRjYYBtJQjkyn7rZyAe_6y7EX7LJYuiM/edit#heading=h.as9kdn9iw81k\r\n\r\nChienchi's example:\r\nhttps://jsonblob.com/2137bcc9-c165-11ea-bf47-77ac2761baa8",
"body": "This PR updates the documentation on gh-pages branch",
"body": "Update. Just tried change required field in `nmdc.yaml` for `biosample` to false. Still getting an error telling me it is required. Hmmm....",
"body": "Closing this issue. The problem was I forgot to rebuild the nmdc.py after changing the yaml.\r\n\r\n**DOH!**",
"body": "How strict do we want the required attributes to be?\r\nFor example, I am testing the translation of biosample data. The schema requires each biosample have a lat_lon:\r\n```\r\n```\r\nThe biosample table doesn't have a `lat_lon` field. Rather, it has `latitude` and `longitude` fields. I can of course combine those fields. In the mean time, I am simple adding a `lat _lon` to my data, like so:\r\n``\r\nbiosample['lat_lon'] = 'test lat_lon'\r\n``\r\nThis gets transformed in into a dictionary, and the value is present:\r\n```\r\n{\r\n 'nmdc_record_id': '108335',\r\n 'add_date': '30-OCT-14 12.00.00.000000000 AM',\r\n 'altitude': 0.0,\r\n .....\r\n 'project_gold_ids': 'Gp0108335',\r\n  'lat_lon': 'test lat_lon'\r\n}\r\n```\r\n\r\nBut, it seems that `lat_lon` requires to more than a `TextValue`, but a `GeolocationValue`. Here is the error:\r\n```\r\n~/repos/NMDC/nmdc-metadata/metadata-translation/src/bin/lib/nmdc.py in __post_init__(self, **kwargs)\r\n    142             self.depth = TextValue(**self.depth)\r\n    143         if self.lat_lon is None:\r\n--> 144             raise ValueError(f\"lat_lon must be supplied\")\r\n    145         if not isinstance(self.lat_lon, GeolocationValue):\r\n    146             self.lat_lon = GeolocationValue(**self.lat_lon)\r\n\r\n``\r\nYou can see my schema testing code in the `test-schema.ipynb`notebook:\r\nhttps://github.com/microbiomedata/nmdc-metadata/blob/issue-73/metadata-translation/notebooks/test-schema.ipynb\r\n\r\nQuestions:\r\n- Do we want in the `nmdc.yaml`, to specify a field that raises a warning instead of an error if a required field isn't present? This might not make sense for biosample, but it might in other data models.\r\n- Do want the requirement to be that a `GelocationValue` is required or can we relax to `TextValue`. I don't think so, but thought I would pose the question.\r\n\r\ncc @cmungall @deepakunni3 ",
"body": "Code is still a work in progress but the yaml file spec for creating data sources is finished.  \r\nWorking on code to use field names on slots.",
"body": "JSON version of Table 3 in Collection 6 Modis Land Cover MCD12Q1 and\r\nMCD12C1) Product User Guide",
"body": "",
"body": "Fixes issue with the JSON schema and updates the UML",
"body": "This is out of date by now",
"body": "",
"body": "Closing this ticket, since we are doing this now. E.g.:\r\n```\r\n{\r\n    \"id\": \"Gs0110115\",\r\n    \"name\": \"Avena fatua rhizosphere microbial communities ...\",\r\n   \"description\": \"Using analytical expertise at both the JGI and EMSL, we plan to follow  ...\",\r\n \"add_date\": {\r\n        \"has_raw_value\": \"11-NOV-13 12.00.00.000000000 AM\"\r\n    },\r\n    \"ecosystem\": {\r\n        \"has_raw_value\": \"Host-associated\"\r\n    },\r\n    \"ecosystem_category\": {\r\n        \"has_raw_value\": \"Plants\"\r\n    },\r\n    \"ecosystem_path_id\": {\r\n        \"has_raw_value\": 3948\r\n    },\r\n    \"ecosystem_subtype\": {\r\n        \"has_raw_value\": \"Epiphytes\"\r\n    },\r\n    \"ecosystem_type\": {\r\n        \"has_raw_value\": \"Phylloplane\"\r\n    },\r\n    \"gold_study_name\": {\r\n        \"has_raw_value\": \"Mapping soil carbon from cradle to grave: using ....\"\r\n    },\r\n    \"mod_date\": {\r\n        \"has_raw_value\": \"29-MAY-14 12.00.00.000000000 AM\"\r\n    },\r\n    \"specific_ecosystem\": {\r\n        \"has_raw_value\": \"Unclassified\"\r\n    },\r\n    \"principal_investigator_name\": {\r\n        \"has_raw_value\": \"Mary Firestone\"\r\n    },\r\n    \"doi\": {\r\n        \"has_raw_value\": \"10.25585/1487760\"\r\n    }\r\n}\r\n```",
"body": "Instead of modeling data like this:\r\n```\r\n {\r\n     id: \"sample123\",\r\n     \"annotations\": \r\n     [\r\n        \"has_characteristic\": {\r\n          \"name\": \"depth\"\r\n        },\r\n        \"has_raw_value\": \"10m\"\r\n      }\r\n   ]\r\n}\r\n```\r\nmodel data like:\r\n```\r\n {\r\n     id: \"sample123\",\r\n      \"depth\":\r\n      {\r\n        \"value\": \"10m\",\r\n        \"type\": \"QuantityValue\"\r\n      }\r\n}\r\n```\r\n\r\ncc @cmungall @deepakunni3 \r\n",
"body": "Requirements for NMDC data portal as described in 1.5 of the work plan will come out of further NMDC data portal design with input from BioScales.  Work distribution will be determined by scoping of work with CEDAR.  (This issue may be reopened, but at this point in time it is premature to do work here without specifics defined for the metadata submission portal.)",
"body": "Stan is going to give this a whirl ...\r\n\r\n",
"body": "closing this ... overlaps with @cmungall work.",
"body": "Instead of accessing characteristics via an annotation, have instances use the has_characteristic relation to access the characteristics directly. For example, suppose a sample was collected at a certain depth. The current schema would represent this as:\r\n```\r\n{\r\n id: ... ,\r\n name: ... ,\r\n annotations:\r\n [\r\n   {\r\n     id: ... ,\r\n    has_characteristic: {name: \"depth\"},\r\n    has_raw_value: 100\r\n   }\r\n}\r\n```\r\nSimply use the has_characteristic relation directly like so:\r\n```\r\n{\r\n id: ... ,\r\n name: ... ,\r\n has_characteristic:\r\n [\r\n   {\r\n     id: ... ,\r\n    name: \"depth\",\r\n    has_raw_value: 100\r\n   }\r\n}\r\n```\r\nThe reasons for this changer are:\r\n* It will make the json-ld context easier to write and understand.\r\n* It will make the sparql queries easier to write.\r\n\r\ncc @cmungall \r\n",
"body": "We will potentially use all at some point, but the ones we use will be driven by the datasets we bring in. For FICUS we only need a handful (e.g. soil). Human-associated is not required until we bring in human data in the future.",
"body": "Do we have a list of the MixS packages that will be used for NMDC articulated somewhere or are we simply using all 17 packages?",
"body": "Closed in favor of #66 ",
"body": "Stan will gather information about vocabularies and layers to share with the team & upload to the Github site.\r\n - 17 layers, some are repetitive.\r\n- This is instrument specific. This will be in the doc shared by Stan.\r\n- Not all layers will have all resolutions.\r\n\r\nFurther tasks include:\r\n- Determining wich MIxS fields can be mapped to.\r\n",
"body": "",
"body": "We can discuss here requirements and preferences for the service\r\n\r\nMy own preferences:\r\n\r\n - should be described using openapi3/swagger (alternative: HATEOS)\r\n - all IDs in the system should follow NMDC identifier policy (see #2) \r\n - payloads should be JSON (ideally json-ld)\r\n\r\nI'm imagining two main endpoints/routes:\r\n\r\n * `/layers/`\r\n    - input: none\r\n    - output: returns list of layers. ideally each is identified by a unique ID, plus any necessary metadata about \r\nthat layer (e.g `{id: DAAC:1, name: \"soil\", description: \".....\", ...}`\r\n * `/identify/` \r\n     - Input: \r\n         - lat, long,\r\n          - [optional] time\r\n          - [list] layer IDs\r\n          - [optional] precision? \r\n          - [optional] vocabulary e.g. ENVO [TBD: does the API map or does the client map?]\r\n     - Output: json(ld)\r\n       - one object per layer\r\n       - layer ID\r\n       - precision\r\n       - EITHER\r\n       - vocabulary name (e.g. USDA soil layer)\r\n       - vocabulary term ID (e.g 12)\r\n       - vocabular term value (e.g. \"alluvial soil\")\r\n       - OR\r\n       - unit + value\r\n       - plus any other provenance info\r\n\r\nHappy to advise on any implementation aspects (esp if Python/flask). @kfagnan aim3 may want to weigh in here",
"body": "Start with the soil ZOBLER layer.  \r\nGlobal soil type in the tsv file/layer.  \r\n\r\n@Blancohl  If possible add provence metadata about the layers. Who made it? When was it made?",
"body": "Need to set up workflow for adding terms to ENVO.",
"body": "We need to deploy an Identify REST service.\r\n\r\nInput: lat, long, [optional] time; optional precision? + layer IDs\r\nOutput: json payload for each requested layer\r\n\r\nSee also\r\n\r\n - #66 - these mappings will be composed with REST payloads OR the REST service will use these to return ENVO for qualitative payloads\r\n - #55 \r\n - #21 - once we have the service\r\n\r\nNote: this ticket to be assigned to @usethedata or Yaxing (I invited Bruce to org, don't have GH for Yaxing)",
"body": "Where do we see the GH invites? I am not seeing any under my profile?",
"body": "@StantonMartin the invite was for Bruce and Hannah, it looks like they have accepted the invite.\r\n\r\nCan we make a start on this task? Is there anything unclear here. You can ping me on the aim1 slack if there are any questions.",
"body": "\r\n[IGBP.json.TXT](https://github.com/microbiomedata/nmdc-metadata/files/4713641/IGBP.json.TXT)\r\n\r\nUploading IGBP JSON",
"body": "[UMD.json.TXT](https://github.com/microbiomedata/nmdc-metadata/files/4713648/UMD.json.TXT)\r\n UMD Json",
"body": "Note IGBP is a legacy standard:\r\nhttp://www.igbp.net/\r\n\r\n",
"body": "Thanks! So I assume despite being a legacy standard it is still used by some of the data layers we will access via the API, so we'll want to map them.\r\n\r\nNote the header of the UMD file says it is \"IGBP_V6\", not UMD. Is this expected?\r\n\r\nI assume that when the API is functional there will be an unambiguous way to map to one of these tables?\r\n\r\nThe two are largely identical except code 15 has a different meaning in both, and IGBP has an extra code, 16.\r\n\r\nI noted a discrepancy with\r\nhttps://lpdaac.usgs.gov/documents/101/MCD12_User_Guide_V6.pdf\r\n\r\nIn this version, there is no `0` code for IGBP\r\n\r\nI'm inclined not to trust the codes and just map the labels\r\n\r\n",
"body": "The discrepancy is due to different versions of the standard, the current identify tool was using version 005 which I cannot find documentation for. I found some old documentation for  5.1 but even it has a slight discrepancy with the legend that is surfaced through the current identify tool.   My opinion is that we should adopt the latest version (v6) as in the user guide above as the standard, and surface the classifications from that standard.  So the JSON files should map identically to the MCD12_User_Guide_V6.pdf tables regardless of what the current identify tool does.   From the doc:\r\n\r\nThe product contains 13 Science Data Sets (SDS;\r\nTable 1), including 5 legacy classification schemes (IGBP, UMD, LAI, BGC, and PFT; Tables 3- 7) and a new three layer legend based on the Land Cover \r\n\r\nSo if we want to be complete we would do all 5 legacies using the version in the tables as well as the new three layer legend.  I would expect that the three layer legend would be the \"default\" option that is surfaced if the classification argument is not passed as a parameter to the function call. \r\n\r\n",
"body": "List of all potential data products from the MODIS satellite that the new identify tool could query is here:\r\n\r\nhttps://modis.ornl.gov/rst/api/v1/products\r\n",
"body": "[Identify_layers.zip](https://github.com/microbiomedata/nmdc-metadata/files/4806177/Identify_layers.zip)\r\nThe table is organized by layer, code, and definition. All of which were pulled directly from the identify tool. I assumed that the only information pulled by the tool would be from the datasets that are already highlighted if you go through the Identify Tool to SDAT. \r\n\r\nI feel it's important to point out that I had to pull the legends directly from the tool. For the majority of the layers I couldn't find any documentation about the classification systems at all.",
"body": "Perfect, thanks! We'll do a first-pass automated alignment then let's talk\nabout curating the mappings (should not be a large task)\n\nOn Fri, Jun 19, 2020 at 11:25 AM Blancohl <notifications@github.com> wrote:\n\n> Identify_layers.zip\n> <https://github.com/microbiomedata/nmdc-metadata/files/4806177/Identify_layers.zip>\n> The table is organized by layer, code, and definition. All of which were\n> pulled directly from the identify tool. I assumed that the only information\n> pulled by the tool would be from the datasets that are already highlighted\n> if you go through the Identify Tool to SDAT.\n>\n> I feel it's important to point out that I had to pull the legends directly\n> from the tool. For the majority of the layers I couldn't find any\n> documentation about the classification systems at all.\n>\n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/microbiomedata/nmdc-metadata/issues/66#issuecomment-646805650>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AAAMMOKFFJR3RV6DCJKA2X3RXOURLANCNFSM4MOP7XEQ>\n> .\n>\n",
"body": "Sounds good.\r\n\r\nFrom: Chris Mungall <notifications@github.com>\r\nSent: Friday, June 19, 2020 2:37 PM\r\nTo: microbiomedata/nmdc-metadata <nmdc-metadata@noreply.github.com>\r\nCc: Martin, Stanton <martins@ornl.gov>; Mention <mention@noreply.github.com>\r\nSubject: [EXTERNAL] Re: [microbiomedata/nmdc-metadata] Map individual ORNL/DAAC data layer vocabularies (#66)\r\n\r\nPerfect, thanks! We'll do a first-pass automated alignment then let's talk\r\nabout curating the mappings (should not be a large task)\r\n\r\nOn Fri, Jun 19, 2020 at 11:25 AM Blancohl <notifications@github.com> wrote:\r\n\r\n> Identify_layers.zip\r\n> <https://github.com/microbiomedata/nmdc-metadata/files/4806177/Identify_layers.zip>\r\n> The table is organized by layer, code, and definition. All of which were\r\n> pulled directly from the identify tool. I assumed that the only information\r\n> pulled by the tool would be from the datasets that are already highlighted\r\n> if you go through the Identify Tool to SDAT.\r\n>\r\n> I feel it's important to point out that I had to pull the legends directly\r\n> from the tool. For the majority of the layers I couldn't find any\r\n> documentation about the classification systems at all.\r\n>\r\n> \u2014\r\n> You are receiving this because you authored the thread.\r\n> Reply to this email directly, view it on GitHub\r\n> <https://github.com/microbiomedata/nmdc-metadata/issues/66#issuecomment-646805650>,\r\n> or unsubscribe\r\n> <https://github.com/notifications/unsubscribe-auth/AAAMMOKFFJR3RV6DCJKA2X3RXOURLANCNFSM4MOP7XEQ>\r\n> .\r\n>\r\n\r\n\r\n\u2014\r\nYou are receiving this because you were mentioned.\r\nReply to this email directly, view it on GitHub<https://github.com/microbiomedata/nmdc-metadata/issues/66#issuecomment-646809932>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AO4B7EL7WCFOP7PNL4GUTHTRXOV6NANCNFSM4MOP7XEQ>.\r\n",
"body": "Can you shine any light on this, is there something further that\ndifferentiates these:\n\nBailey Ecoregion Province,1,ice,\n\nBailey Ecoregion Province,2,ice,\n\nOn Fri, Jun 19, 2020 at 11:36 AM Chris Mungall <cjmungall@lbl.gov> wrote:\n\n> Perfect, thanks! We'll do a first-pass automated alignment then let's talk\n> about curating the mappings (should not be a large task)\n>\n> On Fri, Jun 19, 2020 at 11:25 AM Blancohl <notifications@github.com>\n> wrote:\n>\n>> Identify_layers.zip\n>> <https://github.com/microbiomedata/nmdc-metadata/files/4806177/Identify_layers.zip>\n>> The table is organized by layer, code, and definition. All of which were\n>> pulled directly from the identify tool. I assumed that the only information\n>> pulled by the tool would be from the datasets that are already highlighted\n>> if you go through the Identify Tool to SDAT.\n>>\n>> I feel it's important to point out that I had to pull the legends\n>> directly from the tool. For the majority of the layers I couldn't find any\n>> documentation about the classification systems at all.\n>>\n>> \u2014\n>> You are receiving this because you authored the thread.\n>> Reply to this email directly, view it on GitHub\n>> <https://github.com/microbiomedata/nmdc-metadata/issues/66#issuecomment-646805650>,\n>> or unsubscribe\n>> <https://github.com/notifications/unsubscribe-auth/AAAMMOKFFJR3RV6DCJKA2X3RXOURLANCNFSM4MOP7XEQ>\n>> .\n>>\n>\n",
"body": "@cmungall I'm sorry, but no. There was no documentation I could easily pull about how the legends were put together or how the classifications were designated. My only thought is that most of the legends were numerical values associated with a color gradient; if the legend is supposed to be read primarily by color, then I think it could be that the two colors were both ice, but because they weren't identical they couldn't use the same number. \r\n\r\nThat's the best logical guess I can make with my rudimentary understanding of remote sensing and imaging. But otherwise, no. I don't have a solid explanation. ",
"body": "Long term goal is to use [SSSOM](https://github.com/OBOFoundry/SSSOM) to represent mappings.",
"body": "We will start with Zobler soil layers. This is \"Global Soil Type\" in the csv",
"body": "@StantonMartin added metadata about the Zobler layers in #133 -- this is similar to what is in the Identify_layers.csv provided by @Blancohl but includes additional metadata about the layer itself:\r\n\r\nhttps://github.com/microbiomedata/nmdc-metadata/blob/54a482cb5e06d2c5183b9b57255ea230dbb2062d/identify/Zobler_Definitions.txt#L1-L19\r\n\r\nAdditionally, each class has a mnemonic associated with it, e.g.AF for ferric acrisol:\r\n\r\nhttps://github.com/microbiomedata/nmdc-metadata/blob/54a482cb5e06d2c5183b9b57255ea230dbb2062d/identify/Zobler_Definitions.txt#L20-L24",
"body": "Any updates on this thread? I see the Zobler types were mapped to the ontology. What about the Land use characterization from Modis?  Have these terms been mapped or is it still outstanding?\r\n\r\nT",
"body": "on aim1 call yesterday honing in on 1.2 deliverables we identified the individual data layer vocabs for Identify as higher priority than GCMD\r\n\r\nFor each vocab there are 3 phases:\r\n\r\n 1. [ ] Extract individual vocabularies (ORNL)\r\n 2. [ ] First pass automated mapping to ENVO and other vocabs (LBNL)\r\n 3. [ ] Validate mappings (ORNL)\r\n\r\nFor the extraction, any format is fine. I suggest either skos/rdf, or simply a TSV, e.g.\r\n\r\n 1. stable id (these seem to be numeric IDs)\r\n 2. name\r\n 3. description (if available)\r\n\r\nany metadata about the layer/vocab also welcome\r\n\r\nall files should be checked into github, this repo. Ideally a makefile for orchestrating any wget/curl steps\r\n\r\nFor 2, we will use our mapping framework and produce mappings in SSSOM format, and deposited in this repo\r\n\r\nFor 3 the procedure will be to manually spot-check the SSSOM files in this repo and make requested changes via PR/ticket\r\n\r\nNot sure which of @usethedata and @stantonmartin and @Blancohl will do tasks 1 and 3. Note I can't assign Bruce or Stan, they need to accept my GH invites first",
"body": "Opening this thread for comment and discussion on how we can implement / utilize FDO's with NMDC.  See:\r\nhttps://github.com/GEDE-RDA-Europe/GEDE/tree/master/FAIR%20Digital%20Objects\r\n\r\nFor the most current information regarding FDO's.\r\n\r\n\r\n",
"body": "And make sure this is aligned with:\r\n\r\nhttps://microbiomedata.org/infrastructure/\r\nhttps://microbiomedata.org/introduction-to-metadata-and-ontologies/",
"body": "We want to include a link to the repo/readme in advance of the SAB, we should do another pass on the README",
"body": "Need metrics to measure progress in FAIRification of NMDC data. Ideally these would map to FAIR metrics produced by International GO-FAIR consortium.\r\n\r\n",
"body": "test comment",
"body": "this a description of my issue.\r\n\r\nTest linking to https://github.com/GenomicsStandardsConsortium/mixs/issues/42\r\n\r\n",
"body": "Looks good @wdduncan thanks for adding the provenance info. ",
"body": "I have added a column for just the FICUS studies based on the work done by @jagadishcs in issue #58 \r\nThe column name is 'FICUS study'. I placed an 'x' in those path ids identified as FICUS studies.",
"body": "see #35 ",
"body": "The GOLD paths and some partial mappings have been uploaded to:\r\n\r\nhttps://docs.google.com/spreadsheets/d/1Tfbj0QCckk_S6ldyVJZcTdJKZHd1D9Y4whWz2CjeIcI/edit#gid=1310900750\r\n\r\nThe mappings need to be reviewed. Reviewers should fill in their initials and date when completed. Please fill in the notes column if you disagree with a mapping or find other problems.",
"body": "Hi Bill,\r\n\r\nThanks for checking with us.\r\n\r\nNo these two paths are not referring to oil-contaminated sediment. One is specific for oil-contaminated sediment and the other is for anything oil-contatminated.\r\n\r\nThe following links on GOLD website showing what are the different samples using these paths. \r\n\r\nhttps://gold.jgi.doe.gov/biosamples?page=1&asc=Biosample.Specific+Ecosystem&Biosample.Ecosystem+Path+Id=%3D4011&count=25\r\n\r\nhttps://gold.jgi.doe.gov/biosamples?page=1&asc=Biosample.Specific+Ecosystem&Biosample.Ecosystem+Path+Id=4007&count=25\r\n\r\nWhenever you see some seemingly similar paths or something that you may have some doubt, please feel free to explore GOLD website to see samples using those paths.\r\nThat should help you in seeing these paths in the context of their use.\r\nHope this helps.\r\n\r\nLet me know if you have any questions.\r\n\r\nCheers,\r\n\r\nReddy.",
"body": "This ticket is referring to neritic zone sediment. I think you may have confused this with another email I sent about oil-contaminated sediment.",
"body": "@TBKReddy \r\nHere are the oil-contaminated paths I think you are referring to:\r\n\r\n4011 | Environmental | Aquatic | Marine | Oceanic | Oil-contaminated\r\n-- | -- | -- | -- | -- | --\r\n4007 | Environmental | Aquatic | Marine | Oceanic | Oil-contaminated sediment\r\n\r\nAs you can see, these are different than the ones I posted the issue about.\r\n",
"body": "The path Environmental::Aquatic::Marine::Neritic zone::Sediment is now assigned only to ID 4048. \r\n",
"body": "In the most recent download of the GOLD path ids:  \r\nhttps://gold.jgi.doe.gov/downloads\r\n\r\nThere is a row in which the GOLD values are duplicated.\r\n\r\n4035 | Environmental | Aquatic | Marine | Neritic zone | Sediment | \u00a0 \r\n-- | -- | -- | -- | -- | -- | --\r\n4048 | Environmental | Aquatic | Marine | Neritic zone | Sediment | \u00a0\r\n",
"body": "The files have been uploaded to the Metadata files directory on the google drive:\r\n\r\n**NMDC_GCMD Mapping:**\r\nhttps://docs.google.com/spreadsheets/d/10kQDZbaGIZL27ZMvlAmwuLaGmgekti6sind8t0zcGE8/edit#gid=1656108356\r\n\r\n**sciencekeywords:**\r\nhttps://docs.google.com/spreadsheets/d/1BGbOWId327pLW71BA4N9zMriluTyEvcteHL9DLxZ8FI/edit#gid=1618241051\r\n",
"body": "@StantonMartin - can you make sure Hannah has a github username and is added to the nmdc project?\r\n\r\n\r\nthere are some things that are a bit dubious.\r\n\r\nE.g. GCMD:Icebergs is mapped to two sweet-envo pairs:\r\n\r\niceberg | iceberg | Icebergs | 4d95ccc8-3ef9-40df-85e7-db36cb815499 | \u00a0 | \u00a0 | \u00a0 | \u00a0 | \u00a0 | \u00a0 | \u00a0 | \u00a0 | \u00a0 | \u00a0 | \u00a0 | \u00a0 | \u00a0 | \u00a0 | \u00a0 | \u00a0 | \u00a0 | \u00a0 | \u00a0 | \u00a0 | \u00a0 | \u00a0\r\n-- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | --\r\ntabular iceberg | tabular iceberg | Icebergs | 4d95ccc8-3ef9-40df-85e7-db36cb815499 | \u00a0 | \u00a0 | \u00a0 | \u00a0 | \u00a0 | \u00a0 | \u00a0 | \u00a0 | \u00a0 | \u00a0 | \u00a0 | \u00a0 | \u00a0 | \u00a0 | \u00a0 | \u00a0 | \u00a0 | \u00a0 | \u00a0 | \u00a0 | \u00a0 | \u00a0\r\n\r\nI think the first one is appropriate, not the second\r\n\r\nSee also line 244, this is a mapping between \"mouth\" (as in hole in an animals head throiugh which it consumes food) and \"mouth\" (as in river), which is incorrect\r\n\r\nI think bioportal mappings are being used - these are not reliable. @wdduncan and I have better mapping tools\r\n\r\nI don't see any blank columns for SWEET or for ENVO, this is a bit odd, as we expect some GCMD terms to map to one or the other but not both\r\n\r\nWhy don't we start with Hannah providing an export of GCMD terms plus all associated metadata (IDs, names, synomnyms), then we can work on mapping as a separate task\r\n",
"body": "We might need to accelerate the purchase of paid plan. I think we are maxed\nout and I kicked off everyone that was low priority.\n\nOn Wed, Apr 1, 2020 at 2:02 PM Chris Mungall <notifications@github.com>\nwrote:\n\n> @StantonMartin <https://github.com/StantonMartin> - can you make sure\n> Hannah has a github username and is added to the nmdc project?\n>\n> there are some things that are a bit dubious.\n>\n> E.g. GCMD:Icebergs is mapped to two sweet-envo pairs:\n> iceberg iceberg Icebergs 4d95ccc8-3ef9-40df-85e7-db36cb815499\n>\n> tabular iceberg tabular iceberg Icebergs\n> 4d95ccc8-3ef9-40df-85e7-db36cb815499\n>\n>\n> I think the first one is appropriate, not the second\n>\n> See also line 244, this is a mapping between \"mouth\" (as in hole in an\n> animals head throiugh which it consumes food) and \"mouth\" (as in river),\n> which is incorrect\n>\n> I think bioportal mappings are being used - these are not reliable.\n> @wdduncan <https://github.com/wdduncan> and I have better mapping tools\n>\n> I don't see any blank columns for SWEET or for ENVO, this is a bit odd, as\n> we expect some GCMD terms to map to one or the other but not both\n>\n> Why don't we start with Hannah providing an export of GCMD terms plus all\n> associated metadata (IDs, names, synomnyms), then we can work on mapping as\n> a separate task\n>\n> \u2014\n> You are receiving this because you are subscribed to this thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/microbiomedata/nmdc-metadata/issues/59#issuecomment-607488091>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/ADFUG4UI663KEWMHE7Q2BULRKOTWZANCNFSM4LPVXE7Q>\n> .\n>\n\n\n-- \nElisha M Wood-Charlson, PhD (she/her)\nKBase <https://kbase.us/> User Engagement Lead\nNMDC <http://microbiomedata.org/> Leadership Team; @microbiomedata\n<https://twitter.com/MicrobiomeData>\nLawrence Berkeley National Laboratory\nLinkedIn <http://www.linkedin.com/in/elishawc>, Twitter\n<https://twitter.com/ElishaMariePhD> (personal)\n",
"body": "Hannah has been added! We had one seat left :)\n\nOn Wed, Apr 1, 2020 at 2:30 PM Elisha Wood-Charlson <emwood-charlson@lbl.gov>\nwrote:\n\n> We might need to accelerate the purchase of paid plan. I think we are\n> maxed out and I kicked off everyone that was low priority.\n>\n> On Wed, Apr 1, 2020 at 2:02 PM Chris Mungall <notifications@github.com>\n> wrote:\n>\n>> @StantonMartin <https://github.com/StantonMartin> - can you make sure\n>> Hannah has a github username and is added to the nmdc project?\n>>\n>> there are some things that are a bit dubious.\n>>\n>> E.g. GCMD:Icebergs is mapped to two sweet-envo pairs:\n>> iceberg iceberg Icebergs 4d95ccc8-3ef9-40df-85e7-db36cb815499\n>>\n>> tabular iceberg tabular iceberg Icebergs\n>> 4d95ccc8-3ef9-40df-85e7-db36cb815499\n>>\n>>\n>> I think the first one is appropriate, not the second\n>>\n>> See also line 244, this is a mapping between \"mouth\" (as in hole in an\n>> animals head throiugh which it consumes food) and \"mouth\" (as in river),\n>> which is incorrect\n>>\n>> I think bioportal mappings are being used - these are not reliable.\n>> @wdduncan <https://github.com/wdduncan> and I have better mapping tools\n>>\n>> I don't see any blank columns for SWEET or for ENVO, this is a bit odd,\n>> as we expect some GCMD terms to map to one or the other but not both\n>>\n>> Why don't we start with Hannah providing an export of GCMD terms plus all\n>> associated metadata (IDs, names, synomnyms), then we can work on mapping as\n>> a separate task\n>>\n>> \u2014\n>> You are receiving this because you are subscribed to this thread.\n>> Reply to this email directly, view it on GitHub\n>> <https://github.com/microbiomedata/nmdc-metadata/issues/59#issuecomment-607488091>,\n>> or unsubscribe\n>> <https://github.com/notifications/unsubscribe-auth/ADFUG4UI663KEWMHE7Q2BULRKOTWZANCNFSM4LPVXE7Q>\n>> .\n>>\n>\n>\n> --\n> Elisha M Wood-Charlson, PhD (she/her)\n> KBase <https://kbase.us/> User Engagement Lead\n> NMDC <http://microbiomedata.org/> Leadership Team; @microbiomedata\n> <https://twitter.com/MicrobiomeData>\n> Lawrence Berkeley National Laboratory\n> LinkedIn <http://www.linkedin.com/in/elishawc>, Twitter\n> <https://twitter.com/ElishaMariePhD> (personal)\n>\n\n\n-- \nElisha M Wood-Charlson, PhD (she/her)\nKBase <https://kbase.us/> User Engagement Lead\nNMDC <http://microbiomedata.org/> Leadership Team; @microbiomedata\n<https://twitter.com/MicrobiomeData>\nLawrence Berkeley National Laboratory\nLinkedIn <http://www.linkedin.com/in/elishawc>, Twitter\n<https://twitter.com/ElishaMariePhD> (personal)\n",
"body": "Great! Thanks :)",
"body": "@StantonMartin Well, the mouth example was a mistake, sorry. Otherwise, I can review the work I did for this mapping. But perhaps this needs a more in-depth conversation about the expectations for this mapping and a set of eyes with a scientific background. There is only one 'iceberg' in the GCMD keywords. ",
"body": "@Blancohl \r\nyou've been tagged :)",
"body": "@StantonMartin:\r\n>But perhaps this needs a more in-depth conversation about the expectations for this mapping and a set of eyes with a scientific background. There is only one 'iceberg' in the GCMD keywords.\r\n\r\nYes, I suggest starting with the suggestion in my original comment:\r\n\r\n> Why don't we start with Hannah providing an export of GCMD terms plus all associated metadata (IDs, names, synonyms), then we can work on mapping as a separate task\r\n\r\nThis would be a great start. @wdduncan and I don't have the knowledge of GCMD to do this. The output could be a FAIR representation of GCMD in RDF - or just a tsv in github.\r\n\r\nOnce we have this we can work together on mapping. We have tools we can use and I would use these over the bioportal mappings. We are also working separately on ENVO to SWEET mapping and wouldn't try and duplicate here. I would do this as 2 sets of pairwise mappings: GCMD to ENVO, GCMD to SWEET.",
"body": "@cmungall Sorry for the slow response.  Hannah and I discussed this.  Is this useful:  https://gcmdservices.gsfc.nasa.gov/kms/concepts/concept_scheme/sciencekeywords/?format=rdf. That provides an export of the GCMD Science keywords in RDF format.  There is a listing of the keyword sets and export formats here:  https://gcmdservices.gsfc.nasa.gov/static/kms/. If this isn't what you're after, maybe a quick web conference would be in order and I can then reach back to the folks in GCMD to work out what we need.  FWIW, I'm the ORNL DAAC manager and Hanna's primary mentor following Alison's departure.",
"body": "@cmungall \r\n\r\n```\r\nI don't see any blank columns for SWEET or for ENVO, this is a bit odd, as we expect some GCMD terms to map to one or the other but not both\r\n```\r\nThe reason for this is that ENVO is already included in SWEET. We don't know who did these mappings, though. Perhaps we can track this down.\r\n\r\nBut, we still can work the SWEET/EVNO mappings to GCMD.\r\n\r\n",
"body": "We are working on the SSSOM standard for ontology mappings\r\n\r\nI propose we use this for ENVO to GCMD among others\r\n\r\nhttps://docs.google.com/document/d/1CHM6UFAqtp0MxE2Nz-R2R9NTPqsTzetkn8gZHh7zurw/edit#heading=h.pvloahwbh9fq",
"body": "The effort to support Identify tool use replaces this GCMD-EnvO mapping with the layer specific mapping work in #66 \r\n\r\nThere is related work for GCMD-EnvO active in the EnvironmentOntology/obo-to-gcmd-mapping repo -- this relates to ESS-DIVE / NMDC coordination for common metadata",
"body": "Is there any further work to be done here?  The OBO-GCMD mapping work is at EnvironmentOntology/obo-to-gcmd-mapping and the work here has been replaced by #66.",
"body": "Yes, this is now duplicated elsewhere.  Closing",
"body": "\r\n[NMDC_GCMD Mapping.xlsx](https://github.com/microbiomedata/nmdc-metadata/files/4356985/NMDC_GCMD.Mapping.xlsx)\r\n\r\n\r\n\r\n[sciencekeywords.csv.txt](https://github.com/microbiomedata/nmdc-metadata/files/4356987/sciencekeywords.csv.txt)\r\nThe EnvO and GCMD do not have a great deal of overlap even though it seems like it should. The GCMD terms were either very general or too specific. For instance, there were several EnvO terms like gravel, and pebble where the closest term in the GCMD was Rocks/Minerals/Crystals or Sediments. I did my best, however, there are many areas where the GCMD simply did not have a corresponding term. These terms were marked with a backslash (/) through the column labeled \u2018GCMD Term\u2019 for clarity. Additionally, each GCMD term has its own unique identifier, a UUID, in the last column which corresponds to the exact term in the Keyword Version 9.1.5 from NASA that I used as a source. ",
"body": "Hi @wdduncan and @cmungall \r\nYou can please access the list of ecosystem paths by biosample for FICUS studies from here:\r\nhttps://docs.google.com/spreadsheets/d/1AMMsDYPjngNAe0CaZkY8xL7Yf751r5iO4xPSj69HX1A/edit#gid=1478189118\r\n ",
"body": "Thanks @jagadishcs!\r\nI did a check for the unique paths. There is a total of 15 unique path ids for use to focus on:\r\n\r\nECOSYSTEM_PATH_ID_Biosamples\r\n--\r\n4564\r\n4287\r\n4203\r\n4023\r\n4212\r\n4533\r\n4205\r\n4012\r\n4024\r\n3937\r\n4003\r\n4245\r\n4234\r\n4206\r\n4318\r\n\r\n",
"body": "I added a tab to spreadsheet with the unique paths.",
"body": "Hi @jagadishcs \r\nFor FICUS projects, can you get list of the GOLD paths that are used? This will help us focus on which paths need to be the MIxS/ENVO triad of biome-material-feature.\r\n\r\nAdd @cmungall to the conversation.",
"body": "Thanks. The MIxS water package is in this folder:\r\n\r\nhttps://drive.google.com/drive/u/1/folders/13DVA0GGoypGIwzCTdKWS4eNh3Y8tjX3y\r\n\r\nIf you can't find a v5 term, you can look in the v4 spreadsheet too.\r\n",
"body": "@wdduncan \r\n@cmungall \r\n\r\nI have completed the mapping of\u00a0water package and placed it in the shared folder 'GOLD Database Mappings'.\r\nBill, would you like to verify/validate before start using and closing the ticket.\r\nPlease let me know if you have any suggestion or question. \r\n\r\nhttps://docs.google.com/spreadsheets/d/1cfrkPF8wuyfUJ6L_byaaQ-Mly9ePBxCt6y1UqYeBBr4/edit#gid=1365761771\r\n\r\nThanks",
"body": "@wdduncan @jagadishcs  Is this complete?",
"body": "@dehays \r\n@wdduncan \r\n\r\nYes, it has been completed.",
"body": "@cmungall  \r\n@wdduncan\r\n\r\nI will be mapping water package MIxS (v5) terms with GOLD biosample fields using the package specific spreadsheet that was shared by Bill.\r\n\r\nhttps://docs.google.com/spreadsheets/d/1xbSmHbzZWTUCXY4SCe3zZ6_YFxmuW4ht5s5_3jdgyyQ/edit#gid=994826157\r\n",
"body": "GOLD site registered @https://registry.identifiers.org/registry/gold that let anyone connect using any of the 5 GOLD id types and straight go to that page. ",
"body": "This is great, thanks so much!",
"body": "See also #2 and https://github.com/microbiomedata/pilot/issues/16\r\n\r\nWe want to use unambiguous prefixed identifiers for entities in GOLD\r\n\r\nIdentifiers.org has an entry `gold.meta`:\r\n\r\nhttps://registry.identifiers.org/registry/gold.meta\r\n\r\nThis uses legacy IDs. The example is https://identifiers.org/gold.meta:Gm00047\r\n\r\nThis redirects to a study https://gold.jgi.doe.gov/study?id=Gs0056621\r\n\r\nSame for http://n2t.net/gold.meta:Gm00047\r\n\r\nI think we need to register prefixes that can be used to access samples, as well as studies. I think there are two ways\r\n\r\n 1. Register `gold.sample` and `gold.study`\r\n 2. Register a blanker `gold` prefix, have this go to a generic URL such as https://gold.jgi.doe.gov/entity?id=Gs0056621 and have the GOLD website redirect this to the appropriate URL based on the two letter code.\r\n\r\nI prefer 2 as it avoids proliferating prefixes",
"body": "We have cases where the lat-long info is wrong (or at least has confused semantics: location of processing vs location of collection). This was spotted due to expert knowledge about pre-existing pipelines. We want to be able to scale this up and do this more efficiently.\r\n\r\nSome possible automated and semi-automated checks:\r\n\r\n 1. [ ] if the location corresponds to JGI or PNNL flag it. While it is possible there was environmental sampling at these sites, the most likely explanation is that the semantics of location of sample vs source of sample were confused\r\n 2. [ ] manual spot checks, e.g. through the pilot UI it should be possible to spot anomalies\r\n 3. [ ] if the ENVO class is very unlikely for the location. For example, an abyssal plain sample from Kansas. To implement this check we can use methods such as\r\n    - use ORNL Identify on location\r\n    - do a Wikidata lookup on the location\r\n",
"body": "The ESIP folks (including @lewismc) have put together a nice doc on RDF modeling in earth sciences\r\n\r\n@elishawc pointed me at this section:\r\n\r\nhttps://github.com/ESIPFed/science-on-schema.org/blob/feature_13_specifying_identifiers/guides/Dataset.md#attaching-physical-samples-to-a-dataset\r\n\r\nthis describes modeling of samples in ESIP.\r\n\r\n@wdduncan you will be co-located with @lewismc next week, the two of you could talk about this",
"body": "Fixes #52 \r\nUsing papermill at this point is overkill. You can simply use the magic command `%run notebook.ipynb`. Perhaps papermill might be appropriate in the future.",
"body": "The translation pipeline consists of running of three notebooks. This can be automated using [papermill](https://papermill.readthedocs.io/en/latest/)",
"body": "see #50 ",
"body": "Bumps [bleach](https://github.com/mozilla/bleach) from 3.1.0 to 3.1.1.\n<details>\n<summary>Changelog</summary>\n\n*Sourced from [bleach's changelog](https://github.com/mozilla/bleach/blob/master/CHANGES).*\n\n> Version 3.1.1 (February 13th, 2020)\n> -----------------------------------\n> \n> **Security fixes**\n> \n> * ``bleach.clean`` behavior parsing ``noscript`` tags did not match\n>   browser behavior.\n> \n>   Calls to ``bleach.clean`` allowing ``noscript`` and one or more of\n>   the raw text tags (``title``, ``textarea``, ``script``, ``style``,\n>   ``noembed``, ``noframes``, ``iframe``, and ``xmp``) were vulnerable\n>   to a mutation XSS.\n> \n>   This security issue was confirmed in Bleach versions v2.1.4, v3.0.2,\n>   and v3.1.0. Earlier versions are probably affected too.\n> \n>   Anyone using Bleach <=v3.1.0 is highly encouraged to upgrade.\n> \n>   https://bugzilla.mozilla.org/show_bug.cgi?id=1615315\n> \n> **Backwards incompatible changes**\n> \n> None\n> \n> **Features**\n> \n> None\n> \n> **Bug fixes**\n> \n> None\n> \n> Bleach changes\n> ==============\n</details>\n<details>\n<summary>Commits</summary>\n\n- [`0d88dd8`](https://github.com/mozilla/bleach/commit/0d88dd83e425c4ba381d5b83fe61bfae5bbbd627) Update for v3.1.1 release\n- [`996cde7`](https://github.com/mozilla/bleach/commit/996cde7a2439a2323f9c4b2567c8b8449d393351) fix bug 1615315\n- See full diff in [compare view](https://github.com/mozilla/bleach/compare/v3.1.0...v3.1.1)\n</details>\n<br />\n\n[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=bleach&package-manager=pip&previous-version=3.1.0&new-version=3.1.1)](https://help.github.com/articles/configuring-automated-security-fixes)\n\nDependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.\n\n[//]: # (dependabot-automerge-start)\n[//]: # (dependabot-automerge-end)\n\n---\n\n<details>\n<summary>Dependabot commands and options</summary>\n<br />\n\nYou can trigger Dependabot actions by commenting on this PR:\n- `@dependabot rebase` will rebase this PR\n- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it\n- `@dependabot merge` will merge this PR after your CI passes on it\n- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it\n- `@dependabot cancel merge` will cancel a previously requested merge and block automerging\n- `@dependabot reopen` will reopen this PR if it is closed\n- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually\n- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language\n- `@dependabot use these reviewers` will set the current reviewers as the default for future PRs for this repo and language\n- `@dependabot use these assignees` will set the current assignees as the default for future PRs for this repo and language\n- `@dependabot use this milestone` will set the current milestone as the default for future PRs for this repo and language\n\nYou can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/microbiomedata/nmdc-metadata/network/alerts).\n\n</details>",
"body": "Unfortunately the JSONSchema being generated is incorrect which leads to validation errors, at the moment.",
"body": "thanks! We also want to incorporate this into a travis test, where we start from sample source tsvs and make json and test",
"body": "The issue with JSONSchema is upstream. Ticket here: https://github.com/biolink/biolinkml/issues/108\r\n",
"body": "@wdduncan @cmungall Script for validating instances of a class against NDMC metadata JSONSchema.\r\n",
"body": "This was fixed when the new documentation was built. Thanks @deepakunni3 !",
"body": "The OmicsProessing class is not listed in the documentation site: https://microbiomedata.github.io/nmdc-metadata/",
"body": "- Add notebook to translate EMSL data",
"body": "Fixes #43 \r\n\r\n",
"body": "1. Sequencing project has been changed to omics processing.\r\n2. Each omics processing object has a \"processing_institution\" annotation.\r\n3. Each omics processing object has a \"omics_type\" annotation.\r\n3. Each omics processing object has a \"has_output\" annotation that contains a list of file ids that identify the data objects  created by the omics processing. In many cases, this is a one to many relationship.\r\n4. Each data object has an id (its file id), name, description, and file size annotation.\r\n",
"body": "\r\nJAMO is the archive of files generated by JGI from a projects sequencing and analysis output.  Metadata from GOLD goes as far as specifying a project ID, but JAMO holds the files/datasets that were produced.\r\n\r\nI've added three files:  ficus_project_fastq.tsv, ficus_project_fna.tsv and ficus_project_faa.tsv to the shared directory here: \r\n\r\n https://drive.google.com/drive/u/0/folders/1frzGlz8EB8inpVokNTSwD6Ia94eVUlsZ\r\n\r\nI've provided a column - gold_project_id - for mapping these data objects to the existing projects (omics_processing) entities from GOLD.  (When producing data objects from EMSL data the ID would not be a GOLD project ID, but the ID of the omics_processing entity representing the EMSL experiment.)",
"body": "@deepakunni3 @cmungall \r\nThe UML schema image has the string \"124\" in the classes that list the slots. Any idea why?",
"body": "The only EMSL proposal ID that I find in the spreadsheet is 49991. This doesn't seem to map to any of the study gold ids I have:\r\nGs0114432\r\nGs0114663\r\nGs0114298\r\nGs0111539\r\nGs0110148\r\nGs0110115\r\nGs0110132\r\nGs0110198\r\nGs0121594\r\nGs0112340\r\nGs0128781\r\nGs0114675\r\nGs0133461\r\nGs0128849\r\nGs0130354\r\nGs0135149\r\nGs0135152\r\nGs0134277\r\nGs0120351\r\n",
"body": "@wdduncan Find the mapping from EMSL proposal ID to GOLD Study ID here:  https://docs.google.com/spreadsheets/d/1BX35JZsRkA5cZ-3Y6x217T3Aif30Ptxe_SjIC7JqPx4/edit\r\n\r\nBut the main question to be resolved is which fields to map",
"body": "Hi @dehays to summarize action items from our call:\r\n\r\n* Change `sequencing_strategy` to `omics_type`.\r\n* Create an `omics processing` entity (subtype of `biosample processing`) in which to represent GOLD sequencing projects as well as instrument runs from EMSL.\r\n* Proposed characteristics for omics processing entities from EMSL:\r\n  - `Dataset ID` to be used as the identifier for the process.\r\n  -  `Dataset Type Description` (e.g., \"High resolution MS spectra only\")\r\n  - `Instrument Name` (e.g., \"12T_FTICR_B\")\r\n  - `Experimental Data Type`: This will be called `omics type` (e.g., \"Organic Matter Characterization\").\r\n* Proposed characteristics for `data objects` that are output by EMSL `omics processing`:\r\n  -  `Dataset File Size Bytes` (e.g., \"30074294\")\r\n  -  `Dataset Name` (e.g. \"Brodie_134A_CHCl3_15Oct18_IAT_p1_1_01_35922\") to be used **label**?\r\n\r\nI will also discuss with @cmungall ",
"body": "\r\nThe fields of the data_object metadata I gave to Kitware generated from JAMO had the following fields:\r\n\r\nGOLD Project ID   --> . This should map to the ids in the projects.json you have.\r\nJAMO hash ID . --> unique file identifier\r\nFile Name . --> Not necessarily unique\r\nCategory . --> this is derived from a field used by JGI's Genome Portal\r\nFile Type --> doesn't look useful for display, I may use it to filter\r\nFile Size --> . Useful for display\r\n\r\nFrom the EMSL data for a data_object, we will want to represent the omics_processing entity ID in the data_object.  So a study has one-to-many omic_preocessing things which has one-to-many data objects.  omics_processing is 1:1 with data object for EMSL but not for JGI.\r\n\r\nI propose using the 'Data Set Name' from the EMSL spreadsheet for both the omics_processing name and for the data_object name.  (In the JGI cases, data objects have names like based on whether they represent read files or assembly files (and later types of annotation).\r\n\r\n* Important for the omics_processing - we need a field like \"processing_institution\" which will be either \"Joint Genome Institute\" . (all the projects from GOLD) or \"Environmental Molecular Sciences Lab\" (all the EMSL instrument runs)",
"body": "@dehays Where is the JAMO file?",
"body": "@wdduncan Working right now to produce a set from JAMO metadata for the fastq and assemblies. ",
"body": "@wdduncan I've added a tsv (including headers) for the fastq files here:\r\nhttps://drive.google.com/drive/u/0/folders/1frzGlz8EB8inpVokNTSwD6Ia94eVUlsZ\r\n\r\nI need to query differently for the fna and faa because they have no GOLD project metadata keys in JAMO, but those tsv files will have the same fields.",
"body": "EMSL data has been integrated. So, I'm going to close this.",
"body": "The EMSL instrument run metadata has been added as Excel spreadsheet here:\r\n\r\nhttps://drive.google.com/drive/u/0/folders/1frzGlz8EB8inpVokNTSwD6Ia94eVUlsZ\r\n\r\nMapping is currently to EMSL proposal ID which we need to map to the GOLD study IDs \r\n\r\nThese include the omics type (proteomics, metabolomics, ...) field.   \r\n\r\nWe need to select which fields to map into our project and data_object JSON",
"body": "",
"body": "I have been working on soil biosample fields of FICUS proposals; I am trying to give you this spreadsheet by tomorrow evening.",
"body": "Can you link to sheet from here? Thanks!",
"body": "Hess spreadsheet that Jagadish is working on:\r\n\r\nhttps://docs.google.com/spreadsheets/d/1LdOJkz1ActBMl0VGa4lXBuHhpLISi6OuLssg_PBKytw/edit#gid=1332866498",
"body": "Here is spreadsheet that lists the MIxS package that is relevant to each FICUS study:\r\n\r\nhttps://docs.google.com/spreadsheets/d/1jECObgTnMADlh3a8RLW6bfQmxxgKnHUMBeodBW04Gw4/edit#gid=1372256758\r\n",
"body": "I think this can be closed, OBE. 2020 FICUS projects are mostly closed out. Expressed interest in re-opening a couple but I suggested we re-visit our method of metadata collection for use of submission portal",
"body": null,
"body": "There is also field called `sequencing_strategy_full`. Do you know the difference?\r\nperhaps @jagadishcs does?",
"body": "To follow up:\r\nThis query:\r\n```\r\nselect distinct SEQUENCING_STRATEGY from PROJECT\r\n```\r\nreturns:\r\n```\r\nMetagenome\r\nTargeted Gene Survey\r\nMetatranscriptome\r\nWhole Genome Sequencing\r\nTranscriptome\r\n```\r\n\r\nThis query:\r\n```\r\nselect distinct SEQUENCING_STRATEGY_FULL from PROJECT\r\n```\r\nreturns:\r\n```\r\nMetagenome\r\nTargeted Gene Survey\r\nMetatranscriptome\r\nWhole Genome Sequencing\r\nTranscriptome\r\nMetagenome - Cell Enrichment\r\n```\r\nSo, the difference is the `Metagenome - Cell Enrichment` value. Does this matter?",
"body": "I\u2019d thought the SEQUENCING_STATEGY_FULL  field would be more specific than\nSEQUENCING_STATEGY.  I hadn\u2019t expected them to overlap.\n\nWhat you have in your PROJECT table is only the 913 FICUS projects?  I\u2019m\nreally curious about the projects that are neither Metagenome or\nMetatranscriptome\n\nDavid\n\n\n\nOn Tue, Feb 11, 2020 at 5:26 PM Bill Duncan <notifications@github.com>\nwrote:\n\n> To follow up:\n> This query:\n>\n> select distinct SEQUENCING_STRATEGY from PROJECT\n>\n> returns:\n>\n> Metagenome\n> Targeted Gene Survey\n> Metatranscriptome\n> Whole Genome Sequencing\n> Transcriptome\n>\n> This query:\n>\n> select distinct SEQUENCING_STRATEGY_FULL from PROJECT\n>\n> returns:\n>\n> Metagenome\n> Targeted Gene Survey\n> Metatranscriptome\n> Whole Genome Sequencing\n> Transcriptome\n> Metagenome - Cell Enrichment\n>\n> So, the difference is the Metagenome - Cell Enrichment value. Does this\n> matter?\n>\n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/microbiomedata/nmdc-metadata/issues/39?email_source=notifications&email_token=AJMGAX6YPCJEVJ376UM27YTRCNF5TA5CNFSM4KTK44F2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOELO7AZQ#issuecomment-584970342>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AJMGAX4E53VD3IGUYCSU27LRCNF5TANCNFSM4KTK44FQ>\n> .\n>\n",
"body": "Based on Reddy's comments at the meeting today (2/12/2020), we should use the `SEQUENCING_STRATEGY` field.",
"body": "\r\nEach project entity needs to include a category which is available from the SEQUENCING_STRATEGY field of the PROJECT table in GOLD.\r\n\r\nThe only two values we should see from GOLD for the FICUS project metadata are:\r\n\r\nMetagenome\r\nMetatranscriptome\r\n\r\n(EMSL will be providing 4 additional categories for their projects)",
"body": "![image](https://user-images.githubusercontent.com/54855373/74303441-b0d74400-4d0e-11ea-99b1-8a66f1091dbd.png)\r\n",
"body": "@jagadishcs  Thanks for the explanation!\r\nI'm going to close this issues.",
"body": "@cmungall \r\nWe need to determine the meaning of GOLD classifications in which the ecosystem subtype is unclassified, but the the specific ecosystem has a value.\r\n\r\nThere aren't many of them (~17). See screenshot. But, in general, what does the value 'Unclassified' mean? Does it mean 'missing' or 'unknown' or something else?\r\n\r\nI am hoping @jagadishcs can shed light on this.\r\n\r\n<img width=\"1087\" alt=\"Screen Shot 2020-02-10 at 4 51 17 PM\" src=\"https://user-images.githubusercontent.com/3186638/74204235-31227a00-4c27-11ea-8331-7968174c0e90.png\">\r\n",
"body": "@wdduncan  As I understand this, it depends upon the GOLD-MixS work and the outcome is that the biosample fields and characteristics include the display terms from MixS",
"body": "@dehays Yes. For those fields that have been mapped. For those that have not been mapped, then, no (of course).",
"body": null,
"body": "Human readable labels have been added in mixs_label column for the **soil package**. Similar mappings to done for other packages. The MIxS spreadsheet is available here:\r\n\r\nhttps://docs.google.com/spreadsheets/d/1P4v7sGSXW4sKWVwOXASYuXxQBWVq7X-ueeiTcoHjLGY/edit#gid=2022235624\r\n\r\nThere are still issues that need to be resolved:\r\n\r\n1. Some GOLD fields cannot be mapped to MIxS terms, for example the GOLD field `habitat` does not map to MIxS. Terms have been marked in orange.\r\n\r\n2. Some MIxS terms do not map to GOLD fields, for example the MIxS term `extreme salinity` does not map to a GOLD field. This term has been marked in purple.\r\n\r\n3. Some GOLD terms are ambiguous. See terms marked in yellow.\r\n\r\nIf the GOLD to MIxS term mapping is accurate, place a **1** in the `is_map` field. If it is not a mapping, you can leave the `is_map` field blank. I also added a `notes` column.",
"body": "@jagadishcs In the google sheet, you marked `heavy_metals` as \"1\" even thought the definition was wrong. Is it still correct?\r\n\r\nOther questions/issues:\r\n1. I unmarked the `is_map` for the `annual_season_temp/precpt` fields. We need to come up with a resolution plan.\r\n2. You marked \"1\" for the `salinity_meth` field (row 64), but the label reads \"extreme_unusual_properties/salinity method\". Does this still sound correct to you? The definition seems right.\r\n3. Also, any update on the missing fields?",
"body": "![image](https://user-images.githubusercontent.com/54855373/74473953-61515f00-4e59-11ea-8910-2d386ce516ed.png)\r\n",
"body": "MIxS v5 package specific spreadsheets uploaded to google drive folder https://drive.google.com/drive/u/1/folders/13DVA0GGoypGIwzCTdKWS4eNh3Y8tjX3y:\r\n* Soil: https://docs.google.com/spreadsheets/d/1HoEw9pCAQgrmEeWO8xqkyy1GDAzuzFSAF7s5fFrjbVM/edit#gid=731424353\r\n* Plant associated: https://docs.google.com/spreadsheets/d/1WQhIogbLqGSM_zwjSiUJ77IJB-Uh6hf_DeJNR-755Ho/edit#gid=695895006\r\n* Water: https://docs.google.com/spreadsheets/d/1ECsrSW48BXeSy3RgaBuPJt5E16qKpssPpuQcpDN-OUI/edit#gid=1810499511\r\n* Sediment: https://docs.google.com/spreadsheets/d/1ECsrSW48BXeSy3RgaBuPJt5E16qKpssPpuQcpDN-OUI/edit#gid=1810499511\r\n",
"body": "@wdduncan\r\n@cmungall  \r\n\r\nPlease note that the link given above for Water package is pointing to Sediment package.\r\n\r\nFor water package, please refer this one: \r\nhttps://docs.google.com/spreadsheets/d/1xbSmHbzZWTUCXY4SCe3zZ6_YFxmuW4ht5s5_3jdgyyQ/edit#gid=994826157",
"body": "Sorry about the typo.\r\nAll the packages are in this folder:\r\nhttps://drive.google.com/drive/u/1/folders/13DVA0GGoypGIwzCTdKWS4eNh3Y8tjX3y",
"body": "@cmungall \r\n@wdduncan \r\n\r\nPlease note that I revisited the soil biosample mapping using the latest reference\u00a0file (MIxSsoil_20180621)\u00a0you shared. \r\n\r\nYou can access the revised the file from here:\r\nhttps://docs.google.com/spreadsheets/d/1mFOlEzDCaMn2AwBcJiJMpmj6QXDmb3jUs-o3-2SesaI/edit#gid=891466449\r\n\r\nThank you Chris and Bill.\r\nJagadish",
"body": "@cmungall \r\n@wdduncan \r\n\r\nThere are two descriptors in MIxS packages (17),\u00a0\r\nspecific_host\r\nand\r\nhost_spec_range,\r\nreferring to the NCBI taxid.\r\n\r\nSince, 'specific_host' value syntax is 'text' and 'taxid', I have taken it for Host-name while mapping and preparing metadata files for PIs. Please let me know if this is OK. \r\n\r\nYou can please check them to update the definition in the MIxS, if needed.\r\n\r\nBest\u00a0\r\n",
"body": "@cmungall \r\n@wdduncan \r\n\r\nI have prepared and shared a document describing MIxS packages; you can please access it from here:\r\nhttps://docs.google.com/document/d/141BWGbWdTuCQ_QoqdsO_BvHW37wJuLU9xZnvnHTEtNU/edit\r\n\r\nBest\r\n",
"body": "@jagadishcs \r\nI'm not sure what you mean by 'Host-name'. Do you mean the scientific name?",
"body": "I placed the out my script looking for terms shared across MIxS packages in the google drive. The files are:\r\n\r\n1. mixs-package-term: this lists each term and the packages that contain the term\r\nhttps://drive.google.com/drive/u/1/folders/1frzGlz8EB8inpVokNTSwD6Ia94eVUlsZ\r\n\r\n2. multi-package-mixs-terms-only: same as #1, but only lists terms that appear in multiple packages\r\nhttps://docs.google.com/spreadsheets/d/1vnw-YTX60Sf5qLbESrKRKYIho53YMvfK3sNJv-9XJAs/edit#gid=934350375\r\n\r\ncc @cmungall @jagadishcs ",
"body": "@cmungall \r\n@wdduncan \r\n\r\nI have completed the mapping of 17 MIxS environmental packages with GOLD fields that can be accessed from here:\r\nhttps://drive.google.com/drive/u/0/folders/18941r1aZelhNFoaNakPvMj6K9JZgMcWo\r\n\r\nBest\r\n",
"body": "@cmungall \r\n@wdduncan \r\n\r\nMapping of MIxS environmental packages with GOLD fields can be accessed from here:\r\n\r\n[MIxSair_20180621_GOLD_Mapping_04132020.xlsx](https://github.com/microbiomedata/nmdc-metadata/files/4505780/MIxSair_20180621_GOLD_Mapping_04132020.xlsx)\r\n[MIxSbuiltenv_20180621_GOLD_Mapping_04172020.xlsx](https://github.com/microbiomedata/nmdc-metadata/files/4505781/MIxSbuiltenv_20180621_GOLD_Mapping_04172020.xlsx)\r\n[MIxShostassoc_20180621_GOLD_Mapping.xlsx](https://github.com/microbiomedata/nmdc-metadata/files/4505782/MIxShostassoc_20180621_GOLD_Mapping.xlsx)\r\n[MIxShumanassoc_20180621_GOLD_Mapping_04142020.xlsx](https://github.com/microbiomedata/nmdc-metadata/files/4505783/MIxShumanassoc_20180621_GOLD_Mapping_04142020.xlsx)\r\n[MIxShumangut_20180621_GOLD_Mapping_04152020.xlsx](https://github.com/microbiomedata/nmdc-metadata/files/4505784/MIxShumangut_20180621_GOLD_Mapping_04152020.xlsx)\r\n[MIxShumanoral_20180621_GOLD_Mapping_04152020.xlsx](https://github.com/microbiomedata/nmdc-metadata/files/4505785/MIxShumanoral_20180621_GOLD_Mapping_04152020.xlsx)\r\n[MIxShumanskin_20180621_GOLD_Mapping_04162020.xlsx](https://github.com/microbiomedata/nmdc-metadata/files/4505786/MIxShumanskin_20180621_GOLD_Mapping_04162020.xlsx)\r\n[MIxShumanvaginal_20180621_GOLD_04162020.xlsx](https://github.com/microbiomedata/nmdc-metadata/files/4505787/MIxShumanvaginal_20180621_GOLD_04162020.xlsx)\r\n[MIxShydrocarbCores_20180621_Mapping_GOLD.xlsx](https://github.com/microbiomedata/nmdc-metadata/files/4505788/MIxShydrocarbCores_20180621_Mapping_GOLD.xlsx)\r\n[MIxShydrocarbfs_20180621_v5_GOLD_Mapping.xlsx](https://github.com/microbiomedata/nmdc-metadata/files/4505789/MIxShydrocarbfs_20180621_v5_GOLD_Mapping.xlsx)\r\n[MIxSmatbiofilm_20180621_v5_GOLD_Mapping.xlsx](https://github.com/microbiomedata/nmdc-metadata/files/4505790/MIxSmatbiofilm_20180621_v5_GOLD_Mapping.xlsx)\r\n[MIxSmisc_20180621_GOLD_Mapping.xlsx](https://github.com/microbiomedata/nmdc-metadata/files/4505791/MIxSmisc_20180621_GOLD_Mapping.xlsx)\r\n[MIxSplantassoc_20180621_v5_GOLD_Mapping.xlsx](https://github.com/microbiomedata/nmdc-metadata/files/4505792/MIxSplantassoc_20180621_v5_GOLD_Mapping.xlsx)\r\n[MIxSsediment_20180621_GOLD_Mapping_04102020.xlsx](https://github.com/microbiomedata/nmdc-metadata/files/4505793/MIxSsediment_20180621_GOLD_Mapping_04102020.xlsx)\r\n[MIxSsoil_20180621_GOLD_Mapping_04102020.xlsx](https://github.com/microbiomedata/nmdc-metadata/files/4505794/MIxSsoil_20180621_GOLD_Mapping_04102020.xlsx)\r\n[MIxSwastesludge_20180621_GOLD_Mapping_04102020.xlsx](https://github.com/microbiomedata/nmdc-metadata/files/4505795/MIxSwastesludge_20180621_GOLD_Mapping_04102020.xlsx)\r\n[MIxSwater_20180621_GOLD_Mapping_04122020.xlsx](https://github.com/microbiomedata/nmdc-metadata/files/4505796/MIxSwater_20180621_GOLD_Mapping_04122020.xlsx)\r\n",
"body": "@jagadishcs can you convert these to google sheets? That way people can edit them in a web browser.",
"body": "Does that have to be on both the package level and on MIxS as a whole?  \r\nWill NMDC min set be different that MIxS mandatory fields?  \r\n\r\nUse MIxS mandatory fields as a seed. Then edit from there.",
"body": "@cmungall \r\n@wdduncan \r\n@dehays \r\n\r\nYou can access the MIxS mandatory descriptors from here that can be used to decide minimal metadata fields.\r\nhttps://docs.google.com/spreadsheets/d/1trmfp9UMsctXWio6H-17GZXSw_Qi10k777I9trzW3ds/edit#gid=221947830",
"body": "We should have a csv in the repo consisting of the 6 mixs minimal fields and link from README",
"body": "@dehays Do you think we are ready to close this?",
"body": "We want to take a subset of metadata fields and prioritize these for display in the pilot. This will be a union of\r\n\r\n - fields that have values in FICUS set\r\n - fields that are part of the corresponding MIxS package\r\n - Fields that are important for the community even though there may not be any data (include as null)\r\n - Fields that need to appear on the UI\r\n\r\n\r\n@wdduncan made a start:\r\n\r\nhttps://docs.google.com/spreadsheets/u/1/d/1mk9VNf9fWsczA6ZMi627CPSOMONuhVYADLY8qP8cx6o/edit#gid=0\r\n\r\nThis spreadsheet is the ground truth for this task.\r\n\r\n@wdduncan will add the display names from mixs, we will use these by default\r\n\r\nReddy and @jagadishcs will take a pass at this. Then we will have Emiley and aim 3 and aim 4 teams look over",
"body": "I sent you the GOLD paths mapping to MIxS style ENVO triads. It should work for your first pass. If I can get some funding to work on NMDC I can help this effort in the future. ",
"body": "I integrated what you sent with other GOLD path info. see:\r\n\r\nhttps://docs.google.com/spreadsheets/d/1Tfbj0QCckk_S6ldyVJZcTdJKZHd1D9Y4whWz2CjeIcI/edit#gid=1310900750",
"body": "@wdduncan  What is the scope of this issue?  Does this include all GOLD biosample environment paths or the subset of paths present in samples for the FICUS studies?",
"body": "@dehays Ultimately, it is all GOLD paths. Currently, we are focusing on the FICUS studies.",
"body": "Update: Jagadish has completed mapping biosample GOLD paths to MIxS triads for the FICUS studies.",
"body": "cc @kaiiam @pbuttigieg",
"body": "",
"body": "E.g. biosample should be mapped to OBI sample",
"body": "DOIs have been added to study.json.",
"body": "Use [mapping spreadsheet](https://docs.google.com/spreadsheets/d/1sowTCYooDrOMq0ErD4s3xtgH3PLoxwa7/edit#gid=1363834365) to add DOIs to study characteristics.",
"body": "I've put this on the agenda for Monday.",
"body": "@wdduncan can you add link to google sheet",
"body": "Link to the agenda:\r\nhttps://docs.google.com/document/d/1ZkC2hdnTGIVlKyHiJ2UxH4-tRVqDy5mHramhuj-dndA/edit",
"body": "@cmungall here is an update on the status:\r\nWe have linked EMSL instrument runs / omics processings to their data objects (outputs), and to the GOLD studies (proposals). \r\n\r\nWe are yet able to link to the GOLD biosamples.",
"body": null,
"body": "@cmungall Yes, there are ways to set event triggers and use their APIs to connect Smartsheet and GitHub.  Before someone spends time on that - you could just add the link to an issue here for anything you add to a Smartsheet.  \r\n\r\nTwo things I think I understand 1) Aim 1 is happy managing work at the GitHub level (Are EMSL A1 people using this repo?) . 2) While providing the 'what's the plan' Smartsheet interface to Emiley and other leadership minimizing the time burden in maintaining that it hugely important (if it's too expensive in time it just won't happen).\r\nToward the interaction between Smartsheet and GitHub - I think even the issues labeled as high priority, while they are high priority, are at a finer-grained resolution than what Emiley is interested in.",
"body": "Closing this after last weeks discussion - \r\n\r\nGroup issues by Milestones with expected completion dates - Shweta will use these to update A1 Smartsheet\r\n\r\nEnriched Curation work in issues for this repo\r\n\r\nEMSL work (sample mapping, experiment metadata) can be managed directly in Smartsheet\r\n\r\nEmiley / Jagadish FICUS curation can be managed directly in Smartsheet\r\n\r\nJagadish work with Bill on GOLD - MixS mapping managed in GitHub issues",
"body": "We use GitHub for fine-grained issues. I have added a [high priority](https://github.com/microbiomedata/nmdc-metadata/labels/high%20priority) label to this tracker so that I can communicate leadership priorities. Currently these are mostly things we need for GSP.\r\n\r\nI had also considered making a GH project for tracking GSP items (this could be used for both pilot and this repo) but this would create confusion as to what goes in smartsheets vs GH, cc @dehays \r\n\r\nThere are ways to hook these systems together: https://www.google.com/search?q=smartsheet+github+integration but not sure if it's worth exploring",
"body": "The PI table needs to be included in the data dump. If this is not possible, I might be able to grab the PI name from the analysis project table.",
"body": "@wdduncan  I am looking at the data from GOLD (aka 'the data dump') . and the PI information is there though I can see how it might not be easy to see because the relevant field on the STUDY table is not called PI it is called CONTACT_ID.  That is the FK to the CONTACT table.\r\n\r\nExample:  If I look at the study record for STUDY_ID = 110132 (GOLD_ID is Gs0110132) . I see a CONTACT_ID of 100043.  In the CONTACT table, the record where CONTACT_ID = 100043 is the record for Matthias Hess - the PI for that study.",
"body": "Thanks @dehays \r\nIn the CONTACT table, I see two contact_ids for Matthias Hess: 100043 and 115767",
"body": "@wdduncan But in the case of study 110132 the contact record to associate as PI is the one the study record points to, 100043.\r\n\r\nThere is another thing that Reddy reminded me of today - both the study and the project will have PIs and they are not required to be the same.  I don't think that case occurs in the 13 studies being used for the NMDC pilot, but with GOLD as your source for metadata that will need to be accounted for in the future. ",
"body": "PI name has been added at both the study and project level. For now, it is a characteristic of the study/project. We look into developing a more adequate schema at a later iteration.",
"body": null,
"body": "Relates to sample representation and coordinating common sample metadata with ESS-DIVE and KBase.  ",
"body": "We should coordinate our metadata with the IGSN metadata. Here is a link to the IGSN metadata doc:\r\n\r\nhttps://docs.google.com/spreadsheets/d/1pV1zmqRFbAhA9kxcbOnz2RDWO8siXjnlfL2VhYJHDiM/edit#gid=0",
"body": "I believe this is now being done as part of https://github.com/microbiomedata/nmdc-metadata/blob/master/GOLD-ontology-translation/notebooks/translate-study-project-biosample.ipynb notebook. \r\n\r\n@wdduncan Thoughts? ",
"body": "Projects are being filtered for only records where \"active = 'Yes'\"\r\n```\r\nq = \"\"\"\r\nselect \r\n    *\r\nfrom\r\n    project\r\nwhere\r\n    active = 'Yes'\r\n\"\"\"\r\nproject = sqldf(q)\r\n```\r\nSame for studies and biosamples.",
"body": "The project and biosample JSON produced includes several hundred more biosamples than projects with many of the biosamples referring to projects not represented in the JSON.   I believe this is due to the inclusion of biosample records from GOLD that are not ACTIVE.",
"body": "Yes. I remember seeing that. I'm not seeing a security warning now though.\r\nThe link you posted now has a 404 error.",
"body": "Since we can't access the vulnerably page anymore, I am going to close this.",
"body": "still there",
"body": "we also need to reduce our requirements.txt to only actual requirements",
"body": "See also #50 ",
"body": "The vulnerability has been addressed.",
"body": "Fixed by #51 ",
"body": "GitHub report: https://github.com/microbiomedata/nmdc-metadata/network/alert/GOLD-ontology-translation/notebooks/requirements.txt/pycrypto/open\r\n\r\nNot sure if this is of concern, but would be good to see if we can avoid depending on the vulnerable packages altogether.",
"body": "@wdduncan If you feel this is ready, then feel free to merge.",
"body": "Thanks. I was going to merge soon. I have some changes to the notebooks I want to make first.",
"body": "Created new notebook and schema for NMDC data.",
"body": "What's the status of this?",
"body": "@cmungall Closing this PR as the changes in this PR are already in master branch, via another PR. ",
"body": "Do not merge until Jan 21.",
"body": "data object has been added",
"body": "@wdduncan If this is done then feel free to close this ticket (but do refer the PR that contains the addition)",
"body": "Data object added to schema.",
"body": "Required for linking data objects (e.g. fasta files) to samples",
"body": "Addresses #17 ",
"body": "I put this on the agenda for Monday. I think part of this needs to be implemented by Kitware. But, if an api is available, there may be some characteristics I can enrich the data with.",
"body": "The name of this issue is misleading.  (It isn't validation being described here - validation sounds like the issue duplicates #55 but this is about mapping a location name to lat/long.\r\n\r\n- If this is done - it needs to be clearly identified because it impacts other automatic metadata curation that is based on lat/long.  The accuracy of the lat/long derived from location name is likely insufficient to do elevation/altitude/soil type sorts of lat/long based enrichment.\r\n\r\n- Enrichment and curation of metadata is an Aim 1 task - I don't see this as something that Kitware would take on.",
"body": "We have worked on other projects were this kind of capability was needed.  Outside of commercial services like Google's geocoding API, the best option we found is Nominatim, which seems to be the service integrated in the Leaflet snippet included.\r\n\r\nThe thing to keep in mind about these services is that there won't be 100% accuracy in the responses to plain text queries.  The entity you are looking for is *usually* in the top results, but quite often it isn't the number one result, so integrating into an automated workflow has to come with an assumption of a certain error rate.  You can do slightly better if you can provide \"tagged\" queries rather than freeform text.  For example, searching for \"city=Houston and state=Texas\" rather than \"query=Houston, Texas\".\r\n\r\nYou can pretty easily evaluate whether Nominatim provides the necessary fidelity by trying it out in the public instance at https://nominatim.openstreetmap.org/.  If the top search result for typical queries is accurate and there is room for the inevitable geocoding error, then I think we can talk about how we would spin up a dedicated instance for use as a microservice in the pipeline.",
"body": "From @tbkreddy:\r\n\r\nAs per our conversation and action item for me in today's meeting, I am providing the code below the code used by GOLD website to convert/verify user-entered geolocation name into lat/long information. \r\n\r\nTo obtain coordinates from an address/location we use the Leafletjs javascript library. The main library plus the geocode javascript needs to be available plus the css. Examples for using it are at the leaflet mapping website.\r\n\r\n<script src=\"https://gold.jgi.doe.gov:443/js/leaflet/leaflet.1.3.4.js\"></script>\r\n <script src=\"https://gold.jgi.doe.gov:443/js/leaflet/leaflet-providers.js\"></script>   \r\n<link rel=\"stylesheet\" href=\"https://gold.jgi.doe.gov:443/css/leaflet/Leaflet.Control.Geocoder.css\" />\r\n<script src=\"https://gold.jgi.doe.gov:443/js/leaflet/Leaflet.Control.Geocoder.js\"></script>\r\n\r\n\r\nExample javascript:\r\n\r\n<script type=\"text/javascript\">\r\n\r\nfunction codeAddress() {\r\n    //alert(\"OPEN geocode\");\r\n    var geocoder = new L.Control.Geocoder.Nominatim();\r\n   \r\ngeocoder.geocode(document.getElementById(\"geocodeMe\").value, function(results) {    \r\n        //latLng= new L.LatLng(results[0].center.lat, results[0].center.lng);\r\n        //console.log(\"RESULTS: \" + [0].center.lat);\r\n        //alert(\"RES: \" + results[0].center.lat + \" -- \" + results[0].center.lng);\r\n        if (results[0].center.lat != '' && results[0].center.lng != '') {\r\n        document.getElementById(\"Latitude\").value = roundToFour(results[0].center.lat);\r\n      document.getElementById(\"Longitude\").value = roundToFour(results[0].center.lng);\r\n     \r\n      $(\"#showHideMap\").show();\r\n      autoCompleteMap(roundToFour(results[0].center.lat), roundToFour(results[0].center.lng));\r\n     \r\n      $(\".latlonginformationList option[value='Inferred']\").attr('selected', 'selected');\r\n     \r\n      }  else {\r\n        alert(\"Geocode lookup could not find your location.\");\r\n      }\r\n});\r\n\r\n  }\r\n",
"body": "Do we want to do this once the pipeline is a little more in place? I have the libraries that needed to transform data into json, but we get the data through ad-hoc methods right now.\r\n\r\nAlso, I am unsure what travis does regarding this.",
"body": "This is already done. We run travis on each commit on `master` branch. \r\nCurrently the travis test involves just doing a dry run of generating artifacts, to ensure that the schema YAML is valid.\r\n",
"body": "`make test` fails\r\n\r\ntravis should always run make test which should pass",
"body": "`make test` passes now.",
"body": "I recommend cribbing directly from:\r\n\r\nhttps://github.com/biolink/biolink-model/blob/master/.travis.yml",
"body": "@deepakunni3 I believe you did this. Can you share your script? Did you use JSON-schema? I've never used it.\r\n\r\n@cmungall If we can't validate inherited classes, should we convert to RDF and use ShEx?",
"body": "@deepakunni3 Did you put the validation script in the repo?",
"body": null,
"body": "This PR sets up `gh-pages` branch to be the driver of the documentation.\r\nAll generated docs go to `docs`folder.\r\n\r\nThe Jekyll configuration driving the site is in `_config.yaml`",
"body": "I think we may be able to close this. We are using the Makefile to generate the full schema.\r\nThe call to build the schema in python is:\r\n```\r\npython schema/generate_uml.py schema/nmdc.yaml schema/nmdc_schema_uml.png\r\n```",
"body": "This is done and we have a target in the Makefile too.",
"body": "See https://github.com/biolink/biolinkml/blob/master/notebooks/examples.ipynb for an example",
"body": "",
"body": "The biosample_id field comes from the database. I can ignore it, but I find such information is good for tracking down errors. \r\nHow do you want to treat such fields?  I would say it could be treated as some kind of provenance information. Do you have a principle in mind for distinguishing between annotations and provenance information?",
"body": "E.g. in\r\n\r\n```\r\n\"annotations\": [\r\n      {\r\n         \"has_raw_value\": 173480,\r\n         \"has_characteristic\": {\r\n            \"name\": \"biosample_id\"\r\n         }\r\n      },\r\n```",
"body": "@dehays we are merging this. This makes the schema less generic and models the mixs properties directly in the schema. This makes certain things clearer as there is no longer a '2-level' schema. The downside is that we introduce a sync issue but we are developing tools to make this easier.\r\n\r\nThis will make the schema more like:\r\nhttps://docs.google.com/spreadsheets/d/16CpepPDm4a0I4mOHJYFJi8LZltTyeSpb9PB6rGPjzY0/edit#gid=0",
"body": "on master we have a generic annotation model, where properties such as depth, moisture, etc are treated as controlled terms outside the schema\r\n\r\nE.g\r\n\r\n```\r\nsample1\r\n  anns:\r\n   - characteristic: {name: depth, id: mixs:nnn}\r\n      value: 2cm\r\n   ...\r\n     \r\n```\r\n\r\nthis PR treats the fields as part of the schema e.g\r\n\r\n```\r\nsample 1:\r\n  depth: ...\r\n  material: ...\r\n```\r\n\r\nNote the implications of merging this PR. Rather than having the fields live outside the schema (and be determined by some separate json or rdf that would ultimately come from gsc/mixs-ng) the fields would be determined by the schema. This would necessitate either:\r\n\r\n - periodic synchronization (semi-automatic?) between nmdc schema and mixs-ng efforts?\r\n - tighter coupling, and having one master file for the schema and the field definitions. For example, this could take the form of biolinkml managed in mixs-ng",
"body": "Make `has_characteristic` property as inline.\r\n\r\nRelated discussion: https://github.com/biolink/biolinkml/issues/88",
"body": "For now the output is here https://github.com/microbiomedata/GOLD-ontology-translation/tree/master/notebooks/output can we put in this repo @wdduncan ?",
"body": "Added study and project to the schema, and moved external repos into nmdc-metadata repo.",
"body": "We are using the NMDC python classes to generate JSON. Schema, now has study, project, biosample, and data object classes. \r\n\r\nNeeds:\r\n* PI table - #29 \r\n* Links to data objects (e.g., EMSL metabolomics data, JGI sequence data)\r\n* Links across samples (eg EMLS to JGI)\r\n",
"body": "TBD: use the generated python classes vs direct creation of json\r\n\r\nAt first we will select the most used fields in GOLD and prioritize these for mapping to mixs ",
"body": "@deepakunni3 told me not load the *.md files on the github site. I can recall the reason why. The *.md files are being used to generate documentation on https://microbiomedata.github.io/nmdc-metadata/.\r\n",
"body": "@wdduncan The MD files generated for the documentation may have formatting and other things that are specific to GitHub pages. And these formatting can be rendered incorrectly in traditional markdown.\r\n\r\nBut is there a use-case for having the markdown files all by itself, in addition to the documentation site:  https://microbiomedata.github.io/nmdc-metadata/\r\n\r\nIIRC, in this ticket @cmungall was referring to setting up a documentation site. Which we have done. So perhaps we can close this ticket (unless I missed something here)",
"body": "@cmungall I think we can close this ticket. Agree?",
"body": "@deepakunni3 can help with this",
"body": "Study has been added to schema.",
"body": null,
"body": "",
"body": "@wdduncan compare with Torben's analysis.",
"body": "Didn't Jagadish also do a mapping of the GOLD 5 tuples to ENVO triads separately from what I did? If so perhaps also include that too?",
"body": "@kaiiam Yes. He did. That is what are going to compare against.",
"body": "Using #7 and @kaiiam's mapping of GOLD 5-tuples to ENVO tuples, take samples in the NMDC flagship set, and compare resulting ENVO annotations to Torben's ENVO annotations of sample samples.\r\n\r\nI suggest we use a simple jaccard measure: combine all ENVO terms in 3-tuple, include isa/partof closure, compute jaccard sim\r\n\r\nontobio has code for this",
"body": "@cmungall \r\nOntology based on data in `Biosample_all.tsv.gz` has been created in the `microbiomedata/GOLD-ontology-translation` repo.  \r\n\r\nPath to ontology is `GOLD-ontology-translation/notebooks/output/gold-dataset-translation.owl`.",
"body": "@wdduncan can this ticket be closed?\r\n\r\nI recall discussion:\r\n\r\n> GOLD ecosystem path information is not consistent across tables. The five tuples used to describe the sample may differ even though they have the same path ids.\r\n\r\nIs this the case? If so we should follow up with @jagadishcs and Reddy on the Monday meeting",
"body": "As far as I know, this has not been done yet. Let's follow up on Monday morning.",
"body": "We will track this using ticket #35 ",
"body": "Algorithm:\r\n\r\nfor any 5 tuple, with depth N (1 <= N <=5), i.e. t1,t2,...,tn\r\ncreate a class:\r\n\r\n * uri: hash of t1,..,tn\r\n * rdfs:label \"t1 t2 ... tn\"\r\n * rdfs:subClassOf id of t1,..,t(n-1)",
"body": "We have a lot NaN and unclassified values. Do we want special class to identify unclassified data? NaN can mean missing data, while (perhaps) means the data is present, but there isn't an appropriate label/value to tag it with.",
"body": "### ECOSYSTEM_TYPE values\r\n\r\n|    | ECOSYSTEM       |\r\n|---:|:----------------|\r\n|  0 | Environmental   |\r\n|  1 | Host-associated |\r\n|  2 | Engineered      |\r\n\r\n## proposed mappings\r\nHost-associated -> **envo:ENVO_01001000**; rdfs:label \"environmental system determined by an organism\"@en  \r\nnote: this is subclass of envo:ecosystem\r\n\r\nEngineered -> **envo:ENVO_01000313**; rdfs:label \"anthropogenic environment\"@en  \r\nnote: this is NOT a subclass of envo:ecosystem\r\n\r\nEnvironmental -> **envo:ENVO_01000951**; rdfs:label \"natural environment\"@en    \r\nnote: this is NOT a subclass of envo:ecosystem\r\n",
"body": "### ECOSYSTEM_CATEGORY values (top 7 most occurring)\r\n\r\n|    | ECOSYSTEM       | ECOSYSTEM_CATEGORY   |\r\n|---:|:----------------|:---------------------|\r\n|  0 | Engineered      | Built environment    |\r\n|  1 | Engineered      | Wastewater           |\r\n|  2 | Environmental   | Aquatic              |\r\n|  3 | Environmental   | Terrestrial          |\r\n|  4 | Host-associated | Human                |\r\n|  5 | Host-associated | Mammals              |\r\n|  6 | Host-associated | Plants               |\r\n\r\n## proposed mappings\r\nEngineered / Built environment -> ???  \r\nnote: unsure of the distinction 'engineered' and 'built'; perhaps a building?  \r\n  \r\nEngineered / Wastewater -> ???  \r\nnote: perhaps add class 'environmental system determined by waste water' unless they mean a portion of waste water differing labels with 'environment determined by' and 'environmental system determined'; \r\n  \r\nEnvironmental / Aquatic -> **envo:ENVO_00002030**; rdfs:label \"aquatic biome\" **OR** **envo:ENVO_01000317**; rdfs:label \"aquatic environment\"  \r\nnote: not sure of the distinction between biome and environment here; environment seem more general, so might be more appropriate  \r\n  \r\nEnvironmental / Terrestrial ->  **envo:ENVO_01001226**; rdfs:label \"terrestrial natural environment\"@en  \r\n  \r\nHost-associated / Mammals -> ???  \r\nnote: perhaps add class 'mammal-associated environment' as subclass of 'animal-associated environment'\r\n  \r\nHost-associated / Human -> ???  \r\nnote: perhaps add class 'human-associated enviroment' as subclass of 'mammal-associated enviroment' (referrenced above)\r\n  \r\nHost-associated / Plants ->  **envo:ENVO_01001001**; rdfs:label \"plant-associated environment\"@en",
"body": "### ECOSYSTEM_TYPE values (top 7 most occurring)\r\n\r\n|    | ECOSYSTEM       | ECOSYSTEM_CATEGORY   | ECOSYSTEM_TYPE   |\r\n|---:|:----------------|:---------------------|:-----------------|\r\n|  0 | Engineered      | Built environment    | Unclassified     |\r\n|  1 | Engineered      | Built environment    | City             |\r\n|  2 | Engineered      | Wastewater           | Unclassified     |\r\n|  3 | Environmental   | Aquatic              | Freshwater       |\r\n|  4 | Environmental   | Terrestrial          | Soil             |\r\n|  5 | Environmental   | Aquatic              | Marine           |\r\n|  6 | Environmental   | Aquatic              | Unclassified     |\r\n|  7 | Environmental   | Terrestrial          | Unclassified     |\r\n|  8 | Environmental   | Aquatic              | Thermal springs  |\r\n|  9 | Host-associated | Human                | Digestive system |\r\n| 10 | Host-associated | Mammals              | Digestive system |\r\n| 11 | Host-associated | Human                | Unclassified     |\r\n| 12 | Host-associated | Mammals              | Unclassified     |\r\n| 13 | Host-associated | Plants               | Unclassified     |\r\n\r\n## Proposed mappings\r\n* Engineered / Built environment / City -> **envo:ENVO_01000248**; rdfs:label \"dense settlement biome\" **OR** **envo:ENVO_01000249**; rdfs:label \"urban biome\"\r\nnote: 'city' might refer to a type of environment zone; if so, this might require adding new classes\r\n\r\n* Engineered / Wastewater / Unclassified ->  ???  \r\nnote: Do we want special class to identify unclassified data?  \r\n\r\n* Environmental / Aquatic / Freshwater -> **envo:ENVO_01000306**; rdfs:label \"freshwater environment\"  \r\n\r\n* Environmental / Terrestrial / Soil -> **envo:ENVO_01001044**; rdfs:label \"soil environment\"@en\r\n\r\n* Environmental / Aquatic / Marine -> **ENVO_01000307**; rdfs:label \"saline water environment\"  \r\n\r\n* Environmental / Aquatic / Thermal springs -> ???  \r\nnote: add as subclass of 'aquatic environment'  \r\n\r\n* Host-associated / Mammals / Digestive system -> ???  \r\nnote: add class 'mammalian digestive tract enviroment' as subclass of 'digestive tract environment'  \r\n\r\n* Host-associated / Human / Digestive system -> ???  \r\nnote: note: add class 'human digestive tract environment' as subclass of 'mammalian digestive tract environment' (referenced above)  \r\n\r\n## Unclassified values\r\n* Engineered / Built environment / Unclassified -> ???  \r\n* Host-associated / Plants / Unclassified -> ???  \r\n* Host-associated / Human / Unclassified -> ???  \r\n* Host-associated / Mammals / Unclassified -> ???  \r\n* Environmental / Aquatic / Unclassified -> ???  \r\n* Environmental / Terrestrial / Unclassified -> ???  ",
"body": "### ECOSYSTEM_SUBTYPE values (top 7 most occurring)\r\n\r\n|    | ECOSYSTEM       | ECOSYSTEM_CATEGORY   | ECOSYSTEM_TYPE   | ECOSYSTEM_SUBTYPE   |\r\n|---:|:----------------|:---------------------|:-----------------|:--------------------|\r\n|  0 | Engineered      | Built environment    | Unclassified     | Unclassified        |\r\n|  1 | Engineered      | Built environment    | City             | Unclassified        |\r\n|  2 | Engineered      | Wastewater           | Unclassified     | Unclassified        |\r\n|  3 | Engineered      | Built environment    | City             | Subway              |\r\n|  4 | Environmental   | Aquatic              | Freshwater       | Lake                |\r\n|  5 | Environmental   | Terrestrial          | Soil             | Unclassified        |\r\n|  6 | Environmental   | Aquatic              | Marine           | Oceanic             |\r\n|  7 | Environmental   | Aquatic              | Unclassified     | Unclassified        |\r\n|  8 | Environmental   | Aquatic              | Freshwater       | Unclassified        |\r\n|  9 | Environmental   | Aquatic              | Marine           | Unclassified        |\r\n| 10 | Environmental   | Terrestrial          | Unclassified     | Unclassified        |\r\n| 11 | Environmental   | Aquatic              | Freshwater       | Groundwater         |\r\n| 12 | Environmental   | Aquatic              | Thermal springs  | Unclassified        |\r\n| 13 | Host-associated | Human                | Digestive system | Large intestine     |\r\n| 14 | Host-associated | Mammals              | Digestive system | Large intestine     |\r\n| 15 | Host-associated | Human                | Digestive system | Oral                |\r\n| 16 | Host-associated | Human                | Digestive system | Unclassified        |\r\n| 17 | Host-associated | Mammals              | Digestive system | Unclassified        |\r\n| 18 | Host-associated | Human                | Unclassified     | Unclassified        |\r\n| 19 | Host-associated | Mammals              | Unclassified     | Unclassified        |\r\n| 20 | Host-associated | Plants               | Unclassified     | Unclassified        |\r\n\r\n### Proposed mappings\r\n* Engineered / Built environment / City / Subway -> ???\r\nnote: add new classes 1) 'Subway' as subclass of 'transportation feature'; 2) 'environmental system determined by transportation feature'; 3) 'environmental system determined by subway'\r\n\r\n* Environmental / Aquatic / Freshwater / Lake -> ???\r\nnote: add new class 'lake environment' as subclass of 'freshwater environment'\r\n\r\n* Environmental / Aquatic / Marine / Oceanic -> **envo:ENVO_01000321**; rdfs:label \"sea water environment\" **OR** **envo:ENVO_01000048**; rdfs:label \"ocean biome\"\r\nnote: Do we want to create a subclass of 'sea water environment' called 'ocean environment'? Also, is 'Oceanic' intended to reference an environmental system or a biome?\r\n\r\n* Environmental / Aquatic / Freshwater / Groundwater -> ???  \r\nnote: add class 'groundwater environment' as subclass of 'freshwater environment'\r\n\r\n* Host-associated / Mammals / Digestive system / Large intestine -> ???  \r\nnote: add class 'mammalian large intestine environment' as subclass of 'mammalian digestive tract environment' \r\n\r\n* Host-associated / Human / Digestive system / Large intestine -> ???  \r\nnote: add class 'human large intestine environment' as subclass of 'mammalian large intestine environment' (referenced above)\r\n\r\n* Host-associated / Human / Digestive system / Oral -> ???  \r\nnote: add class 'human oral environment' as subclass of 'human digestive tract environment'\r\n\r\n### Unclassifed values\r\n* Engineered / Built environment / Unclassified / Unclassified -> ???  \r\n* Engineered / Built environment / City / Unclassified -> ???  \r\n* Engineered / Wastewater / Unclassified / Unclassified -> ???  \r\n* Environmental / Terrestrial / Soil / Unclassified -> ???  \r\n* Environmental / Aquatic / Unclassified / Unclassified -> ???  \r\n* Environmental / Aquatic / Freshwater / Unclassified -> ???  \r\n* Environmental / Aquatic / Marine / Unclassified -> ???  \r\n* Environmental / Terrestrial / Unclassified / Unclassified -> ???  \r\n* Environmental / Aquatic / Thermal springs / Unclassified -> ???  \r\n* Host-associated / Human / Digestive system / Unclassified -> ???  \r\n* Host-associated / Mammals / Digestive system / Unclassified -> ???  \r\n* Host-associated / Human / Unclassified / Unclassified -> ???  \r\n* Host-associated / Mammals / Unclassified / Unclassified -> ???  \r\n* Host-associated / Plants / Unclassified / Unclassified -> ???  \r\n",
"body": "### SPECIFIC_ECOSYSTEM values (top 7 most occurring)\r\n\r\n|    | ECOSYSTEM       | ECOSYSTEM_CATEGORY   | ECOSYSTEM_TYPE   | ECOSYSTEM_SUBTYPE   |\r\n|---:|:----------------|:---------------------|:-----------------|:--------------------|\r\n|  0 | Engineered      | Built environment    | Unclassified     | Unclassified        |\r\n|  1 | Engineered      | Built environment    | City             | Unclassified        |\r\n|  2 | Engineered      | Wastewater           | Unclassified     | Unclassified        |\r\n|  3 | Engineered      | Built environment    | City             | Subway              |\r\n|  4 | Environmental   | Aquatic              | Freshwater       | Lake                |\r\n|  5 | Environmental   | Terrestrial          | Soil             | Unclassified        |\r\n|  6 | Environmental   | Aquatic              | Marine           | Oceanic             |\r\n|  7 | Environmental   | Aquatic              | Unclassified     | Unclassified        |\r\n|  8 | Environmental   | Aquatic              | Freshwater       | Unclassified        |\r\n|  9 | Environmental   | Aquatic              | Marine           | Unclassified        |\r\n| 10 | Environmental   | Terrestrial          | Unclassified     | Unclassified        |\r\n| 11 | Environmental   | Aquatic              | Freshwater       | Groundwater         |\r\n| 12 | Environmental   | Aquatic              | Thermal springs  | Unclassified        |\r\n| 13 | Host-associated | Human                | Digestive system | Large intestine     |\r\n| 14 | Host-associated | Mammals              | Digestive system | Large intestine     |\r\n| 15 | Host-associated | Human                | Digestive system | Oral                |\r\n| 16 | Host-associated | Human                | Digestive system | Unclassified        |\r\n| 17 | Host-associated | Mammals              | Digestive system | Unclassified        |\r\n| 18 | Host-associated | Human                | Unclassified     | Unclassified        |\r\n| 19 | Host-associated | Mammals              | Unclassified     | Unclassified        |\r\n| 20 | Host-associated | Plants               | Unclassified     | Unclassified        |\r\n\r\n### Proposed mappings\r\n#### Need to verify that data refers to an environment or the sample itself. For example, when I look at the descriptions for SPECIFIC_ECOSYSTEM == 'Fecal', I see descriptions like \"Human feces microbial communities from a cholera patient\". The physical specimen is the microbes ... right?\r\n\r\n* Environmental / Aquatic / Freshwater / Lake / Sediment -> **envo:ENVO_01001049**; rdfs:label \"non-saline sediment environment\"  \r\nnote: Need to add classes that the sediment is from a lake. \r\n\r\n* Environmental / Terrestrial / Soil / Unclassified / Forest Soil -> ???   \r\nnote: Add class \"forest soil enviroment\" as subclass of \"soil enviroment\".  \r\nAlso, this is interesting b/c the **\"ECOSYSTEM_SUBTYPE\" value is \"Unclassified\"**. \r\n\r\n* Environmental / Aquatic / Marine / Oceanic / Sediment -> **envo:ENVO_01001050**; rdfs:label \"saline sediment environment\"@en     \r\nnote: add information that the sediment is from an ocean  \r\n\r\n* Environmental / Terrestrial / Soil / Unclassified / Agricultural land -> **envo:ENVO_01000311**; rdfs:label \"cultivated environment\"  \r\nnote: Do we need to further specify that the cultivated environment is used for growing food?  \r\nAlso, the **\"ECOSYSTEM_SUBTYPE\" value is \"Unclassified\"**. \r\n\r\n* Host-associated / Mammals / Digestive system / Large intestine / Fecal -> ???   \r\nnote: add subclass 'mammalian fecal environment' as subclass of 'fecal environment'  \r\n\r\n* Host-associated / Human / Digestive system / Large intestine / Fecal -> ???     \r\nnote: add subclass 'human fecal environment' as subclass of 'mammalian fecal environment' (referenced above)  \r\n\r\n### Unclassified values\r\n* Engineered / Built environment / Unclassified / Unclassified / Unclassified -> ???  \r\n* Engineered / Built environment / City / Unclassified / Unclassified -> ???  \r\n* Engineered / Wastewater / Unclassified / Unclassified / Unclassified -> ???  \r\n* Engineered / Built environment / City / Subway / Unclassified -> ???  \r\n* Environmental / Aquatic / Freshwater / Lake / Unclassified -> ???  \r\n* Environmental / Aquatic / Marine / Oceanic / Unclassified -> ???  \r\n* Environmental / Aquatic / Unclassified / Unclassified / Unclassified -> ???  \r\n* Environmental / Terrestrial / Soil / Unclassified / Unclassified -> ???  \r\n* Environmental / Aquatic / Freshwater / Unclassified / Unclassified -> ???  \r\n* Environmental / Aquatic / Marine / Unclassified / Unclassified -> ???  \r\n* Environmental / Terrestrial / Unclassified / Unclassified / Unclassified -> ???  \r\n* Environmental / Aquatic / Freshwater / Groundwater / Unclassified -> ???  \r\n* Environmental / Aquatic / Thermal springs / Unclassified / Unclassified -> ???  \r\n* Host-associated / Human / Digestive system / Oral / Unclassified -> ???  \r\n* Host-associated / Human / Digestive system / Unclassified / Unclassified -> ???  \r\n* Host-associated / Mammals / Digestive system / Unclassified / Unclassified -> ???  \r\n* Host-associated / Mammals / Digestive system / Large intestine / Unclassified -> ???  \r\n* Host-associated / Human / Unclassified / Unclassified / Unclassified -> ???  \r\n* Host-associated / Mammals / Unclassified / Unclassified / Unclassified -> ???  \r\n* Host-associated / Human / Digestive system / Large intestine / Unclassified -> ???  \r\n* Host-associated / Plants / Unclassified / Unclassified / Unclassified -> ??? ",
"body": "@cmungall I did an analysis looking for null values followed by a non-null values. I did not find any such rows. Details are found in the notebook: `gold-env-null-value-analysis.ipynb`",
"body": "This is v useful. We can compare this with kai's mappings. But for now let's switch focus to #6 and #7 ",
"body": null,
"body": "I updated the mapping file see: `gold-env-top7-mapping.ipynb`.\r\nI also got the code to create bipartite graphs working see: `gold-env-elevels-analysis.ipynb`\r\n\r\nCan the bipartite approach yield interesting analysis? I'm out of my depth here regarding graph theory.\r\n\r\nThis article looks interesting: https://academic.oup.com/gigascience/article/7/4/giy014/4875933",
"body": "Closing this ticket. We can track progress in #35 ",
"body": null,
"body": "https://whondrs.pnnl.gov/studies/water.stm\r\n\r\nWork is by James Stegen, one of our FICUS PI's at PNNL",
"body": "KBase is having a mtg w/ WHONDRs et al on Friday to discuss data for a summer course. I have been working w/ Amy Goldman (PNNL) and Joan (ESS-DIVE) re: metadata. They should have it registered in ESS-DIVE in less that 2 weeks. \r\n\r\nWould be a good project to beta-test as Kelly is going to have a LOT of metaG and metaM data from a CSP later this year. \r\n",
"body": "sorry - wrong button...",
"body": "e.g. the WHONDRS Metabolite Biogeography Metadata profile, ",
"body": null,
"body": "I will link ESS-DIVE/ISGN presentation here later",
"body": "When we use gold IDs etc we should always use CURIEs/prefixed IDs, and have these registered",
"body": "Do we want to identify a namespace curie for the URIs?\r\ne.g., nmdc: -> http:purl.nmdc.org\r\n\r\nWe use append custom obo-style ids.\r\ne.g., nmdc:GOLD_0001, nmdc:EMSL_00001, nmdc:ESS-DIVE_00001 etc.",
"body": "Yes, we should use jsonld contexts to map prefixes\r\n\r\nbut we shouldn't mint new IDs for GOLD. We can register GOLD etc on n2t/identifiers.org",
"body": "Update to the above:\r\n\r\n> but we shouldn't mint new IDs for GOLD. We can register GOLD etc on n2t/identifiers.org\r\n\r\nReddy did this (https://registry.identifiers.org/registry/gold), so identifiers will now resolve\r\n\r\nE.g. the CURIE `GOLD:Gp0119849`\r\n\r\nCan be resolved via\r\n\r\nhttp://identifiers.org/GOLD:Gp0108335\r\n\r\nThis doesn't work on nt2.net though, I will follow up with them\r\n\r\n",
"body": "@cmungall  anything left to do here?",
"body": "Should NMDC mint new identifiers, or reuse? Does this depend on the source? Do we also maintain mappings, e.g. between gold and ncbi?",
"body": "Draft here: https://docs.google.com/document/d/1L7grygL3KLAc9H_2amwRxE6FgBnIuH-kmcdMjH6b1PY/edit",
"body": "The ontologies we use such as ENVO will change over time. We need to document procedures implemented in NMDC for managing these changes.",
