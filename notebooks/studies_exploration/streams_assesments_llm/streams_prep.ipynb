{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-11T17:47:03.659635Z",
     "start_time": "2025-02-11T17:47:03.065549Z"
    }
   },
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import time\n",
    "import fitz\n",
    "import os\n",
    "import re\n",
    "from datetime import datetime"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T17:47:03.669995Z",
     "start_time": "2025-02-11T17:47:03.664651Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def fetch_all_study_set(base_url=\"https://api.microbiomedata.org/nmdcschema/study_set\", max_page_size=20):\n",
    "    all_resources = []\n",
    "    page_token = None\n",
    "\n",
    "    while True:\n",
    "        # Construct request URL with pagination\n",
    "        params = {\"max_page_size\": max_page_size}\n",
    "        if page_token:\n",
    "            params[\"page_token\"] = page_token\n",
    "\n",
    "        response = requests.get(base_url, params=params)\n",
    "        response.raise_for_status()  # Raise error for failed requests\n",
    "        data = response.json()\n",
    "\n",
    "        # Store results\n",
    "        if \"resources\" in data:\n",
    "            all_resources.extend(data[\"resources\"])\n",
    "\n",
    "        # Check for next_page_token\n",
    "        page_token = data.get(\"next_page_token\")\n",
    "        if not page_token:\n",
    "            break  # Exit loop when no more pages\n",
    "\n",
    "    return all_resources"
   ],
   "id": "a0b7b452ccfb3be6",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T17:47:08.500883Z",
     "start_time": "2025-02-11T17:47:03.816208Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Fetch all documents\n",
    "study_set_data = fetch_all_study_set()"
   ],
   "id": "85f2c675da63410f",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T17:47:08.516005Z",
     "start_time": "2025-02-11T17:47:08.512589Z"
    }
   },
   "cell_type": "code",
   "source": "print(f\"Retrieved {len(study_set_data)} documents from study_set collection.\")",
   "id": "1eea80f0468ffbbf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 32 documents from study_set collection.\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T17:47:08.568220Z",
     "start_time": "2025-02-11T17:47:08.552570Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Save to JSON file\n",
    "with open(\"study_set_data.json\", \"w\") as json_file:\n",
    "    json.dump(study_set_data, json_file, indent=4)\n",
    "print(\"Saved study_set_data.json\")"
   ],
   "id": "351ba07738144be6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved study_set_data.json\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T17:47:08.631203Z",
     "start_time": "2025-02-11T17:47:08.603181Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Convert main study set data to TSV\n",
    "columns = [\n",
    "    \"id\", \"name\", \"description\", \"ecosystem\", \"ecosystem_category\",\n",
    "    \"ecosystem_type\", \"ecosystem_subtype\", \"specific_ecosystem\", \"title\",\n",
    "    \"study_category\", \"funding_sources\", \"gold_study_identifiers\",\n",
    "    \"part_of\", \"websites\", \"pi_name\", \"pi_email\", \"pi_orcid\", \"pi_profile_image_url\", \"study_dois\"\n",
    "]\n",
    "\n",
    "tsv_rows = []\n",
    "credit_association_rows = []\n",
    "dois_rows = []\n",
    "publication_dois = []\n",
    "\n",
    "for record in study_set_data:\n",
    "    pi = record.get(\"principal_investigator\", {})\n",
    "    study_dois = \"|\".join([doi.get(\"doi_value\", \"\") for doi in record.get(\"associated_dois\", [])])\n",
    "    row = {\n",
    "        \"id\": record.get(\"id\", \"\"),\n",
    "        \"name\": record.get(\"name\", \"\"),\n",
    "        \"description\": record.get(\"description\", \"\"),\n",
    "        \"ecosystem\": record.get(\"ecosystem\", \"\"),\n",
    "        \"ecosystem_category\": record.get(\"ecosystem_category\", \"\"),\n",
    "        \"ecosystem_type\": record.get(\"ecosystem_type\", \"\"),\n",
    "        \"ecosystem_subtype\": record.get(\"ecosystem_subtype\", \"\"),\n",
    "        \"specific_ecosystem\": record.get(\"specific_ecosystem\", \"\"),\n",
    "        \"title\": record.get(\"title\", \"\"),\n",
    "        \"study_category\": record.get(\"study_category\", \"\"),\n",
    "        \"funding_sources\": \"|\".join(record.get(\"funding_sources\", [])),\n",
    "        \"gold_study_identifiers\": \"|\".join(record.get(\"gold_study_identifiers\", [])),\n",
    "        \"part_of\": \"|\".join(record.get(\"part_of\", [])),\n",
    "        \"websites\": \"|\".join(record.get(\"websites\", [])),\n",
    "        \"pi_name\": pi.get(\"has_raw_value\", \"\"),\n",
    "        \"pi_email\": pi.get(\"email\", \"\"),\n",
    "        \"pi_orcid\": pi.get(\"orcid\", \"\"),\n",
    "        \"pi_profile_image_url\": pi.get(\"profile_image_url\", \"\"),\n",
    "        \"study_dois\": study_dois\n",
    "    }\n",
    "    tsv_rows.append(row)\n",
    "\n",
    "    # Process credit associations separately\n",
    "    for credit in record.get(\"has_credit_associations\", []):\n",
    "        credit_row = {\n",
    "            \"study_id\": record.get(\"id\", \"\"),\n",
    "            \"name\": credit[\"applies_to_person\"].get(\"name\", \"\"),\n",
    "            \"email\": credit[\"applies_to_person\"].get(\"email\", \"\"),\n",
    "            \"orcid\": credit[\"applies_to_person\"].get(\"orcid\", \"\"),\n",
    "            \"applied_roles\": \"|\".join(credit.get(\"applied_roles\", []))\n",
    "        }\n",
    "        credit_association_rows.append(credit_row)\n",
    "\n",
    "    # Process associated DOIs separately\n",
    "    for doi in record.get(\"associated_dois\", []):\n",
    "        doi_row = {\n",
    "            \"study_id\": record.get(\"id\", \"\"),\n",
    "            \"doi_value\": doi.get(\"doi_value\", \"\"),\n",
    "            \"doi_category\": doi.get(\"doi_category\", \"\"),\n",
    "            \"doi_provider\": doi.get(\"doi_provider\", \"\")\n",
    "        }\n",
    "        dois_rows.append(doi_row)\n",
    "\n",
    "        # Filter publication DOIs\n",
    "        if doi.get(\"doi_category\") == \"publication_doi\":\n",
    "            publication_dois.append(doi.get(\"doi_value\"))\n",
    "\n",
    "# Save main study set TSV\n",
    "df = pd.DataFrame(tsv_rows, columns=columns)\n",
    "ts_file_path = \"study_set_data.tsv\"\n",
    "df.to_csv(ts_file_path, sep=\"\\t\", index=False)\n",
    "print(\"Saved study_set_data.tsv\")\n",
    "\n",
    "# Save credit associations TSV\n",
    "df_credit = pd.DataFrame(credit_association_rows, columns=[\"study_id\", \"name\", \"email\", \"orcid\", \"applied_roles\"])\n",
    "credit_ts_file_path = \"credit_associations.tsv\"\n",
    "df_credit.to_csv(credit_ts_file_path, sep=\"\\t\", index=False)\n",
    "print(\"Saved credit_associations.tsv\")\n",
    "\n",
    "# Save associated DOIs TSV\n",
    "df_dois = pd.DataFrame(dois_rows, columns=[\"study_id\", \"doi_value\", \"doi_category\", \"doi_provider\"])\n",
    "dois_ts_file_path = \"associated_dois.tsv\"\n",
    "df_dois.to_csv(dois_ts_file_path, sep=\"\\t\", index=False)\n",
    "print(\"Saved associated_dois.tsv\")\n"
   ],
   "id": "5579d0308c768bd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved study_set_data.tsv\n",
      "Saved credit_associations.tsv\n",
      "Saved associated_dois.tsv\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T17:47:08.674354Z",
     "start_time": "2025-02-11T17:47:08.669447Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_crossref_metadata(doi):\n",
    "    \"\"\"Fetch metadata from CrossRef API for a given DOI.\"\"\"\n",
    "    doi = doi.replace(\"doi:\", \"\")  # Ensure consistency in DOI format\n",
    "    url = f\"https://api.crossref.org/works/{doi}\"\n",
    "    response = requests.get(url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        return response.json().get(\"message\", {})\n",
    "\n",
    "    print(f\"Failed to retrieve metadata for {doi} (Status Code: {response.status_code})\")\n",
    "    return None"
   ],
   "id": "c7dea25f134783ea",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T17:47:08.720892Z",
     "start_time": "2025-02-11T17:47:08.717586Z"
    }
   },
   "cell_type": "code",
   "source": [
    "eloe_fadrosh_dois = [\n",
    "    \"doi:10.1128/MRA.01361-19\",\n",
    "    \"doi:10.1128/mra.01080-23\",\n",
    "    \"doi:10.1038/s41597-019-0132-4\",\n",
    "    \"doi:10.1038/s41597-024-04013-5\",\n",
    "    \"doi:10.1186/s40168-020-00889-8\",\n",
    "]"
   ],
   "id": "1d53c45182a24964",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T17:47:08.769240Z",
     "start_time": "2025-02-11T17:47:08.765079Z"
    }
   },
   "cell_type": "code",
   "source": [
    "misc_dois = [\n",
    "    \"doi:10.1093/nar/gkab990\",\n",
    "    \"doi:10.1126/sciadv.adg7888\",\n",
    "    \"doi:10.1371/journal.pone.0228165\",\n",
    "    \"doi:10.3390/microorganisms9020357\",\n",
    "    \"doi:10.3897/tdwgproceedings.1.20637\",\n",
    "    \"doi:10.5194/acp-23-15783-2023\",\n",
    "]"
   ],
   "id": "4144bb286771d030",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T17:47:08.817157Z",
     "start_time": "2025-02-11T17:47:08.813257Z"
    }
   },
   "cell_type": "code",
   "source": "combined_dois = publication_dois + eloe_fadrosh_dois + misc_dois",
   "id": "b60a095c6776c3bd",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T17:47:39.230869Z",
     "start_time": "2025-02-11T17:47:08.860413Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Dictionary to store metadata\n",
    "citations = {}\n",
    "\n",
    "# Fetch metadata and handle \"is-preprint-of\"\n",
    "for doi in combined_dois:\n",
    "    clean_doi = doi.replace(\"doi:\", \"\")  # Remove \"doi:\" prefix\n",
    "    print(f\"Fetching metadata for {clean_doi}\")\n",
    "    metadata = get_crossref_metadata(clean_doi)\n",
    "\n",
    "    updated_doi = None\n",
    "    updated_metadata = None\n",
    "\n",
    "    if metadata:\n",
    "        citations[clean_doi] = metadata\n",
    "\n",
    "        # Extract \"is-preprint-of\" DOI from relation field\n",
    "        relation = metadata.get(\"relation\", {}).get(\"is-preprint-of\", [])\n",
    "        if relation and isinstance(relation, list) and isinstance(relation[0], dict):\n",
    "            updated_doi = relation[0].get(\"id\")\n",
    "            if updated_doi:\n",
    "                print(f\"{clean_doi} was found to be a pre-print of {updated_doi}\")\n",
    "                print(f\"Fetching metadata for published version: {updated_doi}\")\n",
    "                updated_metadata = get_crossref_metadata(updated_doi)\n",
    "                if updated_metadata:\n",
    "                    citations[updated_doi] = updated_metadata  # Save updated citation metadata\n",
    "\n",
    "    time.sleep(1)  # Avoid rate limits\n",
    "\n",
    "# Save the citation data as JSON\n",
    "with open(\"doi_metadata.json\", \"w\") as json_file:\n",
    "    json.dump(citations, json_file, indent=4)\n",
    "print(\"Saved DOI metadata to doi_metadata.json\")\n",
    "\n"
   ],
   "id": "9355fddbed21e801",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching metadata for 10.1128/mSystems.00045-18\n",
      "Fetching metadata for 10.1101/2022.12.12.520098\n",
      "10.1101/2022.12.12.520098 was found to be a pre-print of 10.3389/fsoil.2023.1120425\n",
      "Fetching metadata for published version: 10.3389/fsoil.2023.1120425\n",
      "Fetching metadata for 10.1038/s41564-022-01266-x\n",
      "Fetching metadata for 10.1111/1462-2920.16314\n",
      "Fetching metadata for 10.1111/mec.16891\n",
      "Fetching metadata for 10.1021/acs.estlett.0c00748\n",
      "Fetching metadata for 10.1128/msystems.00768-19\n",
      "Fetching metadata for 10.1371/journal.pone.0228165\n",
      "Fetching metadata for 10.1016/j.geoderma.2021.115674\n",
      "Fetching metadata for 10.1029/2022JG006889\n",
      "Fetching metadata for 10.1002/ppp.2200\n",
      "Fetching metadata for 10.1038/s41467-023-36515-y\n",
      "Fetching metadata for 10.1002/lno.11306\n",
      "Fetching metadata for 10.1038/s41597-024-03069-7\n",
      "Fetching metadata for 10.1038/s41564-020-00861-0\n",
      "Fetching metadata for 10.1128/MRA.01361-19\n",
      "Fetching metadata for 10.1128/mra.01080-23\n",
      "Fetching metadata for 10.1038/s41597-019-0132-4\n",
      "Fetching metadata for 10.1038/s41597-024-04013-5\n",
      "Fetching metadata for 10.1186/s40168-020-00889-8\n",
      "Fetching metadata for 10.1093/nar/gkab990\n",
      "Fetching metadata for 10.1126/sciadv.adg7888\n",
      "Fetching metadata for 10.1371/journal.pone.0228165\n",
      "Fetching metadata for 10.3390/microorganisms9020357\n",
      "Fetching metadata for 10.3897/tdwgproceedings.1.20637\n",
      "Fetching metadata for 10.5194/acp-23-15783-2023\n",
      "Saved DOI metadata to doi_metadata.json\n",
      "Saved parsed citations to parsed_citations.tsv\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T17:50:21.833248Z",
     "start_time": "2025-02-11T17:50:21.821126Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Prepare list to store rows for TSV\n",
    "rows = []\n",
    "\n",
    "# Ranked date fields for extracting Year\n",
    "DATE_FIELDS = [\n",
    "    \"published-print\", \"published\", \"issued\", \"posted\", \"accepted\", \"created\", \"indexed\"\n",
    "]\n",
    "\n",
    "for doi in combined_dois:  # Only include original DOIs in the TSV\n",
    "    clean_doi = doi.replace(\"doi:\", \"\")\n",
    "    metadata = citations.get(clean_doi, {})\n",
    "    updated_doi = None\n",
    "\n",
    "    # Check if there's an updated DOI\n",
    "    relation = metadata.get(\"relation\", {}).get(\"is-preprint-of\", [])\n",
    "    if relation and isinstance(relation, list) and isinstance(relation[0], dict):\n",
    "        updated_doi = relation[0].get(\"id\")\n",
    "\n",
    "    # Prefer metadata from the updated DOI if available\n",
    "    source_metadata = citations.get(updated_doi, metadata)\n",
    "\n",
    "    # Extract the best available Year\n",
    "    year = \"\"\n",
    "    year_type = \"\"\n",
    "    for field in DATE_FIELDS:\n",
    "        date_parts = source_metadata.get(field, {}).get(\"date-parts\", [[None]])\n",
    "        if date_parts and date_parts[0][0]:\n",
    "            year = str(int(date_parts[0][0]))  # Convert to integer-like string\n",
    "            year_type = field\n",
    "            break\n",
    "\n",
    "    row = {\n",
    "        \"DOI\": clean_doi,\n",
    "        \"Updated DOI\": updated_doi if updated_doi else \"\",\n",
    "        \"Title\": \"; \".join(source_metadata.get(\"title\", [])),\n",
    "        \"Journal\": \"; \".join(source_metadata.get(\"container-title\", [])),\n",
    "        \"Year\": year,\n",
    "        \"Year Type\": year_type,\n",
    "        \"Publisher\": source_metadata.get(\"publisher\", \"\"),\n",
    "        \"Authors\": \"; \".join([f\"{a.get('given', '')} {a.get('family', '')}\" for a in source_metadata.get(\"author\", [])]),\n",
    "        \"Volume\": source_metadata.get(\"volume\", \"\"),\n",
    "        \"Issue\": source_metadata.get(\"issue\", \"\"),\n",
    "        \"Pages\": source_metadata.get(\"page\", \"\"),\n",
    "        \"DOI URL\": source_metadata.get(\"URL\", \"\"),\n",
    "    }\n",
    "    rows.append(row)\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "# Save as TSV\n",
    "df.to_csv(\"doi_metadata.tsv\", sep=\"\\t\", index=False)\n",
    "print(\"Saved parsed citations to doi_metadata.tsv\")"
   ],
   "id": "4440342252d8fc29",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved parsed citations to parsed_citations.tsv\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T17:47:39.255402Z",
     "start_time": "2025-02-11T17:47:39.249844Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def extract_pdf_metadata(pdf_path):\n",
    "    \"\"\"Extract metadata from a PDF file.\"\"\"\n",
    "    try:\n",
    "        doc = fitz.open(pdf_path)\n",
    "        metadata = doc.metadata  # Extract metadata dictionary\n",
    "        return metadata if metadata else {}\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting metadata from {pdf_path}: {e}\")\n",
    "        return {}\n",
    "\n",
    "def parse_pdf_date(pdf_date):\n",
    "    \"\"\"Convert Adobe PDF date format to YYYY-MM-DD.\"\"\"\n",
    "    match = re.match(r\"D:(\\d{4})(\\d{2})(\\d{2})\", pdf_date)\n",
    "    if match:\n",
    "        year, month, day = match.groups()\n",
    "        return f\"{year}-{month}-{day}\"\n",
    "    return \"\"\n",
    "\n",
    "def extract_doi(text):\n",
    "    \"\"\"Extract DOI from text.\"\"\"\n",
    "    match = re.search(r\"10\\.\\d{4,9}/[-._;()/:A-Za-z0-9]+\", text)\n",
    "    return match.group(0) if match else \"\"\n",
    "\n",
    "def extract_journal_info(text):\n",
    "    \"\"\"Extract volume, issue, and page numbers from subject field.\"\"\"\n",
    "    match = re.search(r\"(\\d{4})\\.(\\d+):?([\\w\\d-]*)\", text)\n",
    "    if match:\n",
    "        year, volume, pages = match.groups()\n",
    "        return year, volume, pages\n",
    "    return \"\", \"\", \"\"\n",
    "\n",
    "\n"
   ],
   "id": "c1b9dd048483d383",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T17:47:39.357382Z",
     "start_time": "2025-02-11T17:47:39.291016Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Directory containing PDFs\n",
    "pdf_dir = \"../../../local/pdfs/\"\n",
    "\n",
    "# Collect metadata from all PDFs\n",
    "pdf_metadata = {}\n",
    "\n",
    "for filename in os.listdir(pdf_dir):\n",
    "    if filename.lower().endswith(\".pdf\"):\n",
    "        pdf_path = os.path.join(pdf_dir, filename)\n",
    "        print(f\"Processing: {filename}\")\n",
    "        pdf_metadata[filename] = extract_pdf_metadata(pdf_path)\n",
    "\n",
    "# Save metadata to JSON\n",
    "json_output_path = \"pdf_metadata.json\"\n",
    "with open(json_output_path, \"w\") as json_file:\n",
    "    json.dump(pdf_metadata, json_file, indent=4)\n",
    "\n",
    "print(f\"Saved PDF metadata to {json_output_path}\")\n",
    "\n",
    "# Convert to TSV format\n",
    "rows = []\n",
    "for filename, metadata in pdf_metadata.items():\n",
    "    year, volume, pages = extract_journal_info(metadata.get(\"subject\", \"\"))\n",
    "    row = {\n",
    "        \"Filename\": filename,\n",
    "        \"DOI\": extract_doi(metadata.get(\"subject\", \"\")),\n",
    "        \"Year\": year,\n",
    "        \"Volume\": volume,\n",
    "        \"Pages\": pages,\n",
    "        \"Title\": metadata.get(\"title\", \"\"),\n",
    "        \"Author\": metadata.get(\"author\", \"\"),\n",
    "        \"Subject\": metadata.get(\"subject\", \"\"),\n",
    "        \"Keywords\": metadata.get(\"keywords\", \"\"),\n",
    "        \"Creation Date\": parse_pdf_date(metadata.get(\"creationDate\", \"\")),\n",
    "        \"Modification Date\": parse_pdf_date(metadata.get(\"modDate\", \"\")),\n",
    "        \"Producer\": metadata.get(\"producer\", \"\"),\n",
    "        \"Creator\": metadata.get(\"creator\", \"\"),\n",
    "    }\n",
    "    rows.append(row)\n",
    "\n",
    "# Save as TSV\n",
    "df = pd.DataFrame(rows)\n",
    "tsv_output_path = \"pdf_metadata.tsv\"\n",
    "df.to_csv(tsv_output_path, sep=\"\\t\", index=False)\n",
    "\n",
    "print(f\"Saved PDF metadata to {tsv_output_path}\")\n"
   ],
   "id": "c21e325457b27104",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: acp-23-15783-2023.pdf\n",
      "Processing: bell-et-al-2020-metatranscriptomic-sequencing-of-a-cyanobacterial-soil-surface-consortium-with-and-without-a-diverse.pdf\n",
      "Processing: Soil_Bacterial_Diversity_Is_Positively_Correlated_.pdf\n",
      "Processing: BISS_article_20637.pdf\n",
      "Processing: s40168-020-00889-8.pdf\n",
      "Processing: sciadv.adg7888.pdf\n",
      "Processing: s41597-024-04013-5.pdf\n",
      "Processing: s41564-020-00861-0.pdf\n",
      "Processing: 41564_2019_Article_449.pdf\n",
      "Processing: gkab990.pdf\n",
      "Processing: blair-et-al-2018-exploration-of-the-biosynthetic-potential-of-the-populus-microbiome.pdf\n",
      "Processing: s41597-019-0132-4.pdf\n",
      "Processing: Limnology   Oceanography - 2019 - Linz - Time‐series metatranscriptomes reveal conserved patterns between phototrophic and.pdf\n",
      "Processing: file.pdf\n",
      "Processing: microorganisms-09-00357-v2.pdf\n",
      "Processing: Environmental Microbiology - 2022 - Olmsted - Environmental predictors of electroactive bacterioplankton in small boreal.pdf\n",
      "Processing: 1-s2.0-S0016706121007540-main.pdf\n",
      "Processing: Molecular Ecology - 2023 - He - Diversity  distribution  and expression of opsin genes in freshwater lakes.pdf\n",
      "Processing: JGR Biogeosciences - 2022 - Rooney - The Impact of Freeze‐Thaw History on Soil Carbon Response to Experimental Freeze‐Thaw.pdf\n",
      "Processing: s41564-022-01266-x.pdf\n",
      "Processing: s41467-023-36515-y.pdf\n",
      "Processing: nguyen-et-al-2024-metatranscriptomes-of-two-biological-soil-crust-types-from-the-mojave-desert-in-response-to-wetting.pdf\n",
      "Processing: 2022.12.12.520098v2.full.pdf\n",
      "Processing: s41597-024-03069-7.pdf\n",
      "Processing: alteio-et-al-2020-complementary-metagenomic-approaches-improve-reconstruction-of-microbial-diversity-in-a-forest-soil.pdf\n",
      "Processing: New Phytologist - 2018 - Sasse - Multilab EcoFAB study shows highly reproducible physiology and depletion of soil.pdf\n",
      "Saved PDF metadata to pdf_metadata.json\n",
      "Saved PDF metadata to pdf_metadata.tsv\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T17:47:40.173237Z",
     "start_time": "2025-02-11T17:47:39.379245Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Google Sheet URL (STREAMS guidelines -> STREAMS_final)\n",
    "sheet_url = \"https://docs.google.com/spreadsheets/d/1lrwZZCHf9ik-TRrMEyN-NJrmZ8uhG4NyDuPH9xl5G1E/export?format=csv&gid=2118203602\"\n",
    "\n",
    "# Load the Google Sheet into a Pandas DataFrame\n",
    "df = pd.read_csv(sheet_url)\n",
    "\n",
    "# Save as TSV file\n",
    "tsv_file_path = \"streams_final.tsv\"\n",
    "\n",
    "\n",
    "# Drop the 6th and 7th columns (index-based, zero-indexed)\n",
    "# deleting: Yes/No/NA,Comments or location in manuscript\n",
    "# which still leaves: Example(s), Present in the manuscript?, Comments or location in manuscript\n",
    "df = df.drop(df.columns[[5, 6]], axis=1)\n",
    "df.to_csv(tsv_file_path, sep=\"\\t\", index=False)\n",
    "\n",
    "print(f\"Saved data to {tsv_file_path}\")\n"
   ],
   "id": "4491b5a02b49800a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved data to streams_final.tsv\n"
     ]
    }
   ],
   "execution_count": 14
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
