{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-11T13:35:02.076844Z",
     "start_time": "2025-02-11T13:35:02.073607Z"
    }
   },
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import time"
   ],
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T22:32:00.087936Z",
     "start_time": "2025-02-10T22:32:00.082544Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def fetch_all_study_set(base_url=\"https://api.microbiomedata.org/nmdcschema/study_set\", max_page_size=20):\n",
    "    all_resources = []\n",
    "    page_token = None\n",
    "\n",
    "    while True:\n",
    "        # Construct request URL with pagination\n",
    "        params = {\"max_page_size\": max_page_size}\n",
    "        if page_token:\n",
    "            params[\"page_token\"] = page_token\n",
    "\n",
    "        response = requests.get(base_url, params=params)\n",
    "        response.raise_for_status()  # Raise error for failed requests\n",
    "        data = response.json()\n",
    "\n",
    "        # Store results\n",
    "        if \"resources\" in data:\n",
    "            all_resources.extend(data[\"resources\"])\n",
    "\n",
    "        # Check for next_page_token\n",
    "        page_token = data.get(\"next_page_token\")\n",
    "        if not page_token:\n",
    "            break  # Exit loop when no more pages\n",
    "\n",
    "    return all_resources"
   ],
   "id": "a0b7b452ccfb3be6",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T22:32:05.278146Z",
     "start_time": "2025-02-10T22:32:00.224112Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Fetch all documents\n",
    "study_set_data = fetch_all_study_set()"
   ],
   "id": "85f2c675da63410f",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T22:32:05.323486Z",
     "start_time": "2025-02-10T22:32:05.319827Z"
    }
   },
   "cell_type": "code",
   "source": "print(f\"Retrieved {len(study_set_data)} documents from study_set collection.\")",
   "id": "1eea80f0468ffbbf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 32 documents from study_set collection.\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T22:32:05.354746Z",
     "start_time": "2025-02-10T22:32:05.335929Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Save to JSON file\n",
    "with open(\"study_set_data.json\", \"w\") as json_file:\n",
    "    json.dump(study_set_data, json_file, indent=4)\n",
    "print(\"Saved study_set_data.json\")"
   ],
   "id": "351ba07738144be6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved study_set_data.json\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T13:34:38.912885Z",
     "start_time": "2025-02-11T13:34:38.886638Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Convert main study set data to TSV\n",
    "columns = [\n",
    "    \"id\", \"name\", \"description\", \"ecosystem\", \"ecosystem_category\",\n",
    "    \"ecosystem_type\", \"ecosystem_subtype\", \"specific_ecosystem\", \"title\",\n",
    "    \"study_category\", \"funding_sources\", \"gold_study_identifiers\",\n",
    "    \"part_of\", \"websites\", \"pi_name\", \"pi_email\", \"pi_orcid\", \"pi_profile_image_url\", \"study_dois\"\n",
    "]\n",
    "\n",
    "tsv_rows = []\n",
    "credit_association_rows = []\n",
    "dois_rows = []\n",
    "publication_dois = []\n",
    "\n",
    "for record in study_set_data:\n",
    "    pi = record.get(\"principal_investigator\", {})\n",
    "    study_dois = \"|\".join([doi.get(\"doi_value\", \"\") for doi in record.get(\"associated_dois\", [])])\n",
    "    row = {\n",
    "        \"id\": record.get(\"id\", \"\"),\n",
    "        \"name\": record.get(\"name\", \"\"),\n",
    "        \"description\": record.get(\"description\", \"\"),\n",
    "        \"ecosystem\": record.get(\"ecosystem\", \"\"),\n",
    "        \"ecosystem_category\": record.get(\"ecosystem_category\", \"\"),\n",
    "        \"ecosystem_type\": record.get(\"ecosystem_type\", \"\"),\n",
    "        \"ecosystem_subtype\": record.get(\"ecosystem_subtype\", \"\"),\n",
    "        \"specific_ecosystem\": record.get(\"specific_ecosystem\", \"\"),\n",
    "        \"title\": record.get(\"title\", \"\"),\n",
    "        \"study_category\": record.get(\"study_category\", \"\"),\n",
    "        \"funding_sources\": \"|\".join(record.get(\"funding_sources\", [])),\n",
    "        \"gold_study_identifiers\": \"|\".join(record.get(\"gold_study_identifiers\", [])),\n",
    "        \"part_of\": \"|\".join(record.get(\"part_of\", [])),\n",
    "        \"websites\": \"|\".join(record.get(\"websites\", [])),\n",
    "        \"pi_name\": pi.get(\"has_raw_value\", \"\"),\n",
    "        \"pi_email\": pi.get(\"email\", \"\"),\n",
    "        \"pi_orcid\": pi.get(\"orcid\", \"\"),\n",
    "        \"pi_profile_image_url\": pi.get(\"profile_image_url\", \"\"),\n",
    "        \"study_dois\": study_dois\n",
    "    }\n",
    "    tsv_rows.append(row)\n",
    "\n",
    "    # Process credit associations separately\n",
    "    for credit in record.get(\"has_credit_associations\", []):\n",
    "        credit_row = {\n",
    "            \"study_id\": record.get(\"id\", \"\"),\n",
    "            \"name\": credit[\"applies_to_person\"].get(\"name\", \"\"),\n",
    "            \"email\": credit[\"applies_to_person\"].get(\"email\", \"\"),\n",
    "            \"orcid\": credit[\"applies_to_person\"].get(\"orcid\", \"\"),\n",
    "            \"applied_roles\": \"|\".join(credit.get(\"applied_roles\", []))\n",
    "        }\n",
    "        credit_association_rows.append(credit_row)\n",
    "\n",
    "    # Process associated DOIs separately\n",
    "    for doi in record.get(\"associated_dois\", []):\n",
    "        doi_row = {\n",
    "            \"study_id\": record.get(\"id\", \"\"),\n",
    "            \"doi_value\": doi.get(\"doi_value\", \"\"),\n",
    "            \"doi_category\": doi.get(\"doi_category\", \"\"),\n",
    "            \"doi_provider\": doi.get(\"doi_provider\", \"\")\n",
    "        }\n",
    "        dois_rows.append(doi_row)\n",
    "\n",
    "        # Filter publication DOIs\n",
    "        if doi.get(\"doi_category\") == \"publication_doi\":\n",
    "            publication_dois.append(doi.get(\"doi_value\"))\n",
    "\n",
    "# Save main study set TSV\n",
    "df = pd.DataFrame(tsv_rows, columns=columns)\n",
    "ts_file_path = \"study_set_data.tsv\"\n",
    "df.to_csv(ts_file_path, sep=\"\\t\", index=False)\n",
    "print(\"Saved study_set_data.tsv\")\n",
    "\n",
    "# Save credit associations TSV\n",
    "df_credit = pd.DataFrame(credit_association_rows, columns=[\"study_id\", \"name\", \"email\", \"orcid\", \"applied_roles\"])\n",
    "credit_ts_file_path = \"credit_associations.tsv\"\n",
    "df_credit.to_csv(credit_ts_file_path, sep=\"\\t\", index=False)\n",
    "print(\"Saved credit_associations.tsv\")\n",
    "\n",
    "# Save associated DOIs TSV\n",
    "df_dois = pd.DataFrame(dois_rows, columns=[\"study_id\", \"doi_value\", \"doi_category\", \"doi_provider\"])\n",
    "dois_ts_file_path = \"associated_dois.tsv\"\n",
    "df_dois.to_csv(dois_ts_file_path, sep=\"\\t\", index=False)\n",
    "print(\"Saved associated_dois.tsv\")\n"
   ],
   "id": "5579d0308c768bd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved study_set_data.tsv\n",
      "Saved credit_associations.tsv\n",
      "Saved associated_dois.tsv\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T13:41:11.714239Z",
     "start_time": "2025-02-11T13:40:54.011950Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Query CrossRef for citation metadata\n",
    "def get_crossref_metadata(doi):\n",
    "    \"\"\"Fetch metadata from CrossRef API for a given DOI.\"\"\"\n",
    "    url = f\"https://api.crossref.org/works/{doi}\"\n",
    "    response = requests.get(url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        data = response.json().get(\"message\", {})\n",
    "        return data  # Store the entire useful response\n",
    "\n",
    "    print(f\"Failed to retrieve metadata for {doi} (Status Code: {response.status_code})\")\n",
    "    return None\n",
    "\n",
    "# Dictionary to store metadata\n",
    "citations = {}\n",
    "\n",
    "# Fetch metadata for each DOI\n",
    "for doi in publication_dois:\n",
    "    print(f\"Fetching metadata for {doi}\")\n",
    "    citations[doi] = get_crossref_metadata(doi)\n",
    "    time.sleep(1)  # Avoid rate limits\n",
    "\n",
    "# Save the citation data as JSON\n",
    "with open(\"doi_metadata.json\", \"w\") as json_file:\n",
    "    json.dump(citations, json_file, indent=4)\n",
    "\n",
    "print(\"Saved DOI metadata to doi_metadata.json\")"
   ],
   "id": "c71d6e7a45590722",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching metadata for doi:10.1128/mSystems.00045-18\n",
      "Fetching metadata for doi:10.1101/2022.12.12.520098\n",
      "Fetching metadata for doi:10.1038/s41564-022-01266-x\n",
      "Fetching metadata for doi:10.1111/1462-2920.16314\n",
      "Fetching metadata for doi:10.1111/mec.16891\n",
      "Fetching metadata for doi:10.1021/acs.estlett.0c00748\n",
      "Fetching metadata for doi:10.1128/msystems.00768-19\n",
      "Fetching metadata for doi:10.1371/journal.pone.0228165\n",
      "Fetching metadata for doi:10.1016/j.geoderma.2021.115674\n",
      "Fetching metadata for doi:10.1029/2022JG006889\n",
      "Fetching metadata for doi:10.1002/ppp.2200\n",
      "Fetching metadata for doi:10.1038/s41467-023-36515-y\n",
      "Fetching metadata for doi:10.1002/lno.11306\n",
      "Fetching metadata for doi:10.1038/s41597-024-03069-7\n",
      "Fetching metadata for doi:10.1038/s41564-020-00861-0\n",
      "Saved DOI metadata to doi_metadata.json\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T13:23:07.404309Z",
     "start_time": "2025-02-11T13:23:06.164970Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Google Sheet URL (STREAMS guidelines -> STREAMS_final)\n",
    "sheet_url = \"https://docs.google.com/spreadsheets/d/1lrwZZCHf9ik-TRrMEyN-NJrmZ8uhG4NyDuPH9xl5G1E/export?format=csv&gid=2118203602\"\n",
    "\n",
    "# Load the Google Sheet into a Pandas DataFrame\n",
    "df = pd.read_csv(sheet_url)\n",
    "\n",
    "# Save as TSV file\n",
    "tsv_file_path = \"streams_final.tsv\"\n",
    "\n",
    "\n",
    "# Drop the 6th and 7th columns (index-based, zero-indexed)\n",
    "# deleting: Yes/No/NA,Comments or location in manuscript\n",
    "# which still leaves: Example(s), Present in the manuscript?, Comments or location in manuscript\n",
    "df = df.drop(df.columns[[5, 6]], axis=1)\n",
    "df.to_csv(tsv_file_path, sep=\"\\t\", index=False)\n",
    "\n",
    "print(f\"Saved data to {tsv_file_path}\")\n"
   ],
   "id": "4491b5a02b49800a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved data to streams_final.tsv\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "9355fddbed21e801"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
