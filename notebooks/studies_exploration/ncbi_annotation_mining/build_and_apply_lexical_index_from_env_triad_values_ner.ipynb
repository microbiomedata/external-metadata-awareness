{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T00:41:30.553717Z",
     "start_time": "2025-03-18T00:41:27.816363Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import datetime\n",
    "import re\n",
    "import urllib.parse\n",
    "from collections import Counter\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "import requests_cache\n",
    "import yaml\n",
    "from curies import Converter\n",
    "from dotenv import dotenv_values\n",
    "from oaklib import get_adapter\n",
    "from oaklib.interfaces.text_annotator_interface import TextAnnotatorInterface\n",
    "from oaklib.utilities.lexical.lexical_indexer import load_lexical_index\n",
    "from prefixmaps.io.parser import load_converter\n",
    "from pymongo import MongoClient, ASCENDING, errors\n",
    "from pymongo.errors import DuplicateKeyError\n",
    "from tqdm.notebook import tqdm"
   ],
   "id": "b18043273e10d1b0",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "when should no results be saved as an empty record in mongodb, and when should the field be omitted?",
   "id": "b5832f5238b45241"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T00:41:32.087714Z",
     "start_time": "2025-03-18T00:41:32.084774Z"
    }
   },
   "cell_type": "code",
   "source": [
    "envo_adapter_string = 'sqlite:obo:envo'\n",
    "po_adapter_string = 'sqlite:obo:po'\n",
    "\n",
    "# consider using an aggregated adapter\n",
    "# that may not work with saving a YAML cache/index"
   ],
   "id": "7fdfc037095bcda6",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "requests_cache_filename = \"../../../external-metadata-awareness-requests-cache\"",
   "id": "7e7b95356b57cfb2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T00:41:34.089145Z",
     "start_time": "2025-03-18T00:41:34.086556Z"
    }
   },
   "cell_type": "code",
   "source": "requests_cache_expire_after = datetime.timedelta(days=30)",
   "id": "105bdfa02b4d695",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T00:41:32.585616Z",
     "start_time": "2025-03-18T00:41:32.582884Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 3,
   "source": "envo_inc_obsoletes_po_punct_free_index_yaml = \"envo_inc_obsoletes_po_punct_free_index.yaml\"",
   "id": "2db6c848d1f9a767"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T00:41:33.052197Z",
     "start_time": "2025-03-18T00:41:33.049580Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 4,
   "source": "mongo_url = \"mongodb://localhost:27017\"",
   "id": "8debb3359443c56e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T00:41:34.592464Z",
     "start_time": "2025-03-18T00:41:34.587821Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define threshold\n",
    "COMPONENT_COUNT_THRESHOLD = 2\n",
    "# COMPONENT_COUNT_THRESHOLD = 100\n",
    "MIN_LABEL_LEN = 3\n",
    "\n",
    "# # Database collection\n",
    "# triad_components_labels_collection = db[\"triad_components_labels\"]\n",
    "\n",
    "# OLS Search API URL\n",
    "OLS_SEARCH_URL = \"https://www.ebi.ac.uk/ols/api/search\"\n",
    "\n",
    "# Ontologies to search\n",
    "\n",
    "small_high_impact_targets_lc = [\n",
    "    \"envo\", # db 19 MB, 7 030 classes\n",
    "    \"po\", # db 24 MB\n",
    "]\n",
    "other_targets_lc = [\n",
    "    \"efo\", # db 779 MB\n",
    "    \"foodon\", # db 280 MB\n",
    "    \"mondo\", # doid has 18 897 classes\n",
    "    \"ncbitaxon\", # 736 927 classes\n",
    "    \"ohmi\", # db 13 MB\n",
    "    \"uberon\", # db 995 MB\n",
    "]\n",
    "\n",
    "# rethinking\n",
    "#   \"chebi\", # db ~ 3 700 MB, 220 816 classes\n",
    "#   \"gaz\", # 668 838 classes\n",
    "#   \"mmo\", # db 4 MB\n",
    "#   \"opl\", # 561 classes\n",
    "#   \"pato\", # db 151 MB (gets male, female, normal),\n",
    "#   \"pco\", # db 2 MB\n",
    "#   doid has 18 897 classes\n",
    "# obi? agro?\n",
    "# map FROM sources: bto, ncit, omit, agro, snomedct, dron\n",
    "\n",
    "OLS_LABEL_SEARCH_ONTS = other_targets_lc + small_high_impact_targets_lc\n",
    "\n",
    "FIELDLIST = \"ontology_name,is_defining_ontology,obo_id,label,synonym\"\n",
    "\n",
    "QUERYFIELDS = \"label,synonym\"\n",
    "\n",
    "OLS_REQ_EXACT_MATCH = \"true\"\n"
   ],
   "id": "aef225f50ce208ed",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T00:41:35.164783Z",
     "start_time": "2025-03-18T00:41:35.162281Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Specify the path to your .env file\n",
    "env_path = \"../../../local/.env\"\n",
    "bioportal_api_key_name = \"BIOPORTAL_API_KEY\"\n"
   ],
   "id": "dfd5522ff7f79f52",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T00:41:35.749386Z",
     "start_time": "2025-03-18T00:41:35.745772Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Enable request caching\n",
    "requests_cache.install_cache(requests_cache_filename,\n",
    "                             expire_after=requests_cache_expire_after)  # Cache expires after 30 days"
   ],
   "id": "98588cfc165aac08",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-18T00:41:36.398177Z",
     "start_time": "2025-03-18T00:41:36.389427Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Connect to local MongoDB on default port\n",
    "client = MongoClient(mongo_url)"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T00:41:36.941349Z",
     "start_time": "2025-03-18T00:41:36.938853Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Access the database and the collections\n",
    "# use the connection builder from core.py>\n",
    "db = client.ncbi_metadata"
   ],
   "id": "524d3cdc9b319df0",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T00:41:37.517973Z",
     "start_time": "2025-03-18T00:41:37.515308Z"
    }
   },
   "cell_type": "code",
   "source": "triad_values_collection = db.unique_triad_values",
   "id": "c020d8e73384bb2b",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T00:41:38.091302Z",
     "start_time": "2025-03-18T00:41:38.088751Z"
    }
   },
   "cell_type": "code",
   "source": "triad_components_labels_collection = db.triad_components_labels",
   "id": "dbbf5f88f7ce46bc",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T00:41:38.674982Z",
     "start_time": "2025-03-18T00:41:38.646938Z"
    }
   },
   "cell_type": "code",
   "source": [
    "envo_adapter = get_adapter(envo_adapter_string)\n",
    "po_adapter = get_adapter(po_adapter_string)"
   ],
   "id": "876673d512e2e325",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T00:41:39.199443Z",
     "start_time": "2025-03-18T00:41:39.195813Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Estimate document count for tqdm\n",
    "doc_count = triad_components_labels_collection.estimated_document_count()"
   ],
   "id": "d0b4587d13555376",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "This search only annotates a small fraction of the component_labels, ~ 6%\n",
    "\n",
    "OAK annotate does not return any knowledge about the matching entity, like its label, synonyms, obsolete status, ontology prefix, etc.\n",
    "\n",
    "there are entries in the lexical index that claim to be rdfs:labels, but really are de-obsoleted labels"
   ],
   "id": "a776927998769426"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T00:41:45.793437Z",
     "start_time": "2025-03-18T00:41:40.570388Z"
    }
   },
   "cell_type": "code",
   "source": "envo_inc_obsoletes_po_punct_free_index = load_lexical_index(envo_inc_obsoletes_po_punct_free_index_yaml)",
   "id": "5f1cd97e66c7327b",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T00:41:45.799667Z",
     "start_time": "2025-03-18T00:41:45.796772Z"
    }
   },
   "cell_type": "code",
   "source": [
    "envo_inc_obsoletes_po_punct_free_tai = TextAnnotatorInterface()\n",
    "envo_inc_obsoletes_po_punct_free_tai.lexical_index = envo_inc_obsoletes_po_punct_free_index"
   ],
   "id": "9436e4ccff7642d",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T00:42:53.811873Z",
     "start_time": "2025-03-18T00:41:45.880733Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Process each document\n",
    "# Initialize tqdm with manual updating\n",
    "with tqdm(total=doc_count, desc=\"Processing documents\") as pbar:\n",
    "    for doc in triad_components_labels_collection.find():\n",
    "        # todo skip excel formula_like values?\n",
    "        component_label = doc.get(\"component_label\")\n",
    "\n",
    "        if not component_label:\n",
    "            pbar.update(1)\n",
    "            continue  # Skip if component_label is missing or empty\n",
    "\n",
    "        annotations_from_custom_index = list(\n",
    "            envo_inc_obsoletes_po_punct_free_tai.annotate_text(component_label.lower()))\n",
    "\n",
    "        acceptable_predicates = [\n",
    "            \"rdfs:label\",\n",
    "            \"oio:hasExactSynonym\",\n",
    "        ]\n",
    "\n",
    "        # Use a set to track unique, whole-text keepers\n",
    "        unique_keepers = set()\n",
    "\n",
    "        keepers = []\n",
    "        for annotation in annotations_from_custom_index:\n",
    "            # todo skip if the predicate isn't rdfs:label, or oio:hasExactSynonym\n",
    "            #   also seeing oio:hasRelatedSynonym, oio:hasNarrowSynonym and oio:hasBroadSynonym\n",
    "            if annotation.matches_whole_text and annotation.predicate_id in acceptable_predicates:\n",
    "                keeper_tuple = (annotation.predicate_id, annotation.object_id)\n",
    "                if keeper_tuple not in unique_keepers:\n",
    "                    unique_keepers.add(keeper_tuple)\n",
    "                    keepers.append({\n",
    "                        \"predicate_id\": annotation.predicate_id,\n",
    "                        \"curie\": annotation.object_id,\n",
    "                    })\n",
    "\n",
    "        if keepers:\n",
    "            triad_components_labels_collection.update_one(\n",
    "                {\"_id\": doc[\"_id\"]},\n",
    "                {\"$set\": {\"oak_text_annotations\": keepers}}\n",
    "            )\n",
    "\n",
    "        pbar.update(1)\n",
    "\n",
    "# progress bar updates in spurts, possibly due to 100-document cursor size\n",
    "# there's a lag of ~ 15 seconds from building the lexical indices\n",
    "# 3 minutes"
   ],
   "id": "920b9e56b904a8e9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Processing documents:   0%|          | 0/46519 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b8fe14584dcd4d6391084046db672494"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T00:42:53.962392Z",
     "start_time": "2025-03-18T00:42:53.959599Z"
    }
   },
   "cell_type": "code",
   "source": "print(f\"Estimated doc count: {doc_count}\")",
   "id": "e29fd3e1001864f9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated doc count: 46519\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T00:42:54.001422Z",
     "start_time": "2025-03-18T00:42:53.975450Z"
    }
   },
   "cell_type": "code",
   "source": "has_matches = triad_components_labels_collection.count_documents({\"oak_text_annotations\": {\"$exists\": True}})",
   "id": "687fccdc1e6728d0",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T00:42:54.079098Z",
     "start_time": "2025-03-18T00:42:54.075844Z"
    }
   },
   "cell_type": "code",
   "source": "print(f\"Documents with 'matches' field: {has_matches}\")",
   "id": "4070929659ae887c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents with 'matches' field: 2343\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T00:42:54.210695Z",
     "start_time": "2025-03-18T00:42:54.167606Z"
    }
   },
   "cell_type": "code",
   "source": "needs_followup = triad_components_labels_collection.count_documents({\"matches\": {\"$exists\": False}, \"count\": {\"$gt\": 1}})",
   "id": "91f8fea21d926c92",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T00:42:54.288254Z",
     "start_time": "2025-03-18T00:42:54.285137Z"
    }
   },
   "cell_type": "code",
   "source": "print(f\"Documents used at least twice, with no 'matches' field: {needs_followup}\")",
   "id": "ac8c8cb196b6a06f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents used at least twice, with no 'matches' field: 33393\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T00:42:54.367736Z",
     "start_time": "2025-03-18T00:42:54.365111Z"
    }
   },
   "cell_type": "code",
   "source": "# index!",
   "id": "fb657b320d475c01",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T00:42:54.576710Z",
     "start_time": "2025-03-18T00:42:54.531617Z"
    }
   },
   "cell_type": "code",
   "source": [
    "result = triad_components_labels_collection.aggregate([\n",
    "    {\"$project\": {\"count\": 1}},  # Only keep the 'count' field\n",
    "    {\"$sort\": {\"count\": -1}},  # Sort by 'count' in descending order\n",
    "    {\"$limit\": 1}  # Get the document with the highest count\n",
    "])\n"
   ],
   "id": "db3530f07de21b1a",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T00:42:54.582848Z",
     "start_time": "2025-03-18T00:42:54.580314Z"
    }
   },
   "cell_type": "code",
   "source": "highest_count = next(result, None)  # Fetch the result safely",
   "id": "567ae8496a2c4d41",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T00:42:54.662968Z",
     "start_time": "2025-03-18T00:42:54.659172Z"
    }
   },
   "cell_type": "code",
   "source": "highest_count",
   "id": "995db06206cd6863",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': ObjectId('67d8425749652e71179eb417'), 'count': 1309427}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T00:42:54.742720Z",
     "start_time": "2025-03-18T00:42:54.738718Z"
    }
   },
   "cell_type": "code",
   "source": "COMPONENT_COUNT_THRESHOLD",
   "id": "bcd78c0d6ebf7d4e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T00:42:55.204054Z",
     "start_time": "2025-03-18T00:42:54.821108Z"
    }
   },
   "cell_type": "code",
   "source": [
    "docs = list(\n",
    "    triad_components_labels_collection.find(\n",
    "        {\"count\": {\"$gte\": COMPONENT_COUNT_THRESHOLD}, \"oak_text_annotations\": {\"$exists\": False}},  # Filter criteria\n",
    "        {\"component_label\": 1}  # Projection (only fetch 'component_label')\n",
    "    )\n",
    ")\n"
   ],
   "id": "4cb8d253a798ff03",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T00:42:55.282759Z",
     "start_time": "2025-03-18T00:42:55.280617Z"
    }
   },
   "cell_type": "code",
   "source": "# todo: is this indexed yet?",
   "id": "f9a03427aa592eb3",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "It doesn't look like the OLS text search can tell us if a term is obsolete\n",
    "\n",
    "https://www.ebi.ac.uk/ols4/api/search?q=pyrene+degrading+sulfate+reducing+enrichment+cultutre+obtained+using+a+freshwater+lake+sediment\n",
    "\n",
    "https://www.ebi.ac.uk/ols4/ols3help\n",
    "\n",
    "This gets even fewer annotations than the initial OAK phase, but dosed give a hint to whether the OLS_LABEL_SEARCH_ONTS are really useful"
   ],
   "id": "67d242546fce2546"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T00:44:07.343614Z",
     "start_time": "2025-03-18T00:42:55.431545Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Iterate over documents with tqdm for progress tracking\n",
    "for doc in tqdm(docs, desc=\"Processing components\", unit=\"doc\"):\n",
    "    query = doc.get(\"component_label\", \"\").strip().lower()\n",
    "    # print(query)\n",
    "    if len(query) < MIN_LABEL_LEN:\n",
    "        continue  # Skip short labels\n",
    "\n",
    "    start = 0  # Start pagination at 0\n",
    "    rows = 1000  # Max per request (set to 100 for efficiency)\n",
    "    ols_hits = []  # Store matching results\n",
    "\n",
    "    while True:\n",
    "        params = {\n",
    "            \"q\": query,\n",
    "            \"exact\": OLS_REQ_EXACT_MATCH,\n",
    "            \"fieldList\": FIELDLIST,\n",
    "            \"ontology\": OLS_LABEL_SEARCH_ONTS,\n",
    "            \"queryFields\": QUERYFIELDS,\n",
    "            \"rows\": rows,\n",
    "            \"start\": start,\n",
    "        }\n",
    "\n",
    "        # # Create a Request object\n",
    "        # req = requests.Request('GET', OLS_SEARCH_URL, params=params)\n",
    "        #\n",
    "        # # Prepare it\n",
    "        # prepared_req = req.prepare()\n",
    "        #\n",
    "        # # Now you can see the URL\n",
    "        # print(prepared_req.url)\n",
    "\n",
    "        response = requests.get(OLS_SEARCH_URL, params=params)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "\n",
    "        # Extract results\n",
    "        results = data.get(\"response\", {}).get(\"docs\", [])\n",
    "\n",
    "        # If no results, break loop\n",
    "        if not results:\n",
    "            break\n",
    "\n",
    "        # Process results\n",
    "        for result in results:\n",
    "            # pprint.pprint(result)\n",
    "            if result.get(\"is_defining_ontology\", False):\n",
    "                label_lower = result.get(\"label\", \"\").lower()\n",
    "                label_lower_match = label_lower == query\n",
    "\n",
    "                temp_dict = {\n",
    "                    \"exact_label_match\": label_lower_match,\n",
    "                    \"label\": result.get(\"label\", \"\"),\n",
    "                    \"synonyms\": result.get(\"synonym\", []),\n",
    "                    \"obo_id\": result.get(\"obo_id\", \"\"),\n",
    "                    \"ontology_lc\": result.get(\"ontology_name\", \"\").lower(),\n",
    "                }\n",
    "                if OLS_REQ_EXACT_MATCH == \"true\":\n",
    "                    temp_dict['exact_something_match'] = True\n",
    "\n",
    "                ols_hits.append(temp_dict)\n",
    "\n",
    "        # Check if we need to fetch more results\n",
    "        num_found = data.get(\"response\", {}).get(\"numFound\", 0)\n",
    "        start += rows  # Move to the next page\n",
    "\n",
    "        if start >= num_found:  # Stop if we've retrieved all records\n",
    "            break\n",
    "\n",
    "    # Update the document with OLS hits if any\n",
    "    if ols_hits:\n",
    "        triad_components_labels_collection.update_one({\"_id\": doc[\"_id\"]}, {\"$set\": {\"ols_text_annotations\": ols_hits}})\n",
    "\n",
    "# 1.8 docs per second\n",
    "# OLS_LABEL_SEARCH_ONTS = \"envo,ncit,ncbitaxon,uberon,snomed,foodon,micro,genepio,po,obi,ohmi,agro,pco,exo,mco,pato\"\n",
    "# FIELDLIST = \"ontology_name,is_defining_ontology,obo_id,label,synonym\"\n",
    "# QUERYFIELDS = \"label,synonym\"\n",
    "# \"exact\": \"true\",\n",
    "# exact false brings it down to 1 docs/6 seconds, like bioportal (via OAK)?\n"
   ],
   "id": "72c0f1f75f8e25c9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Processing components:   0%|          | 0/31213 [00:00<?, ?doc/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "28e4de7e0dfb4aad989c3c3aee7a3128"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T00:44:07.442086Z",
     "start_time": "2025-03-18T00:44:07.438117Z"
    }
   },
   "cell_type": "code",
   "source": "triad_components_labels_collection.estimated_document_count()",
   "id": "36cef07aff9bddf1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46519"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T00:44:07.502598Z",
     "start_time": "2025-03-18T00:44:07.483203Z"
    }
   },
   "cell_type": "code",
   "source": "triad_components_labels_collection.count_documents({\"oak_text_annotations\": {\"$exists\": True}})",
   "id": "d5d093ec80047fb1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2343"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T00:44:07.610974Z",
     "start_time": "2025-03-18T00:44:07.592608Z"
    }
   },
   "cell_type": "code",
   "source": "triad_components_labels_collection.count_documents({\"ols_text_annotations\": {\"$exists\": True}})",
   "id": "1d55b3708465f141",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1912"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T00:44:07.732568Z",
     "start_time": "2025-03-18T00:44:07.688675Z"
    }
   },
   "cell_type": "code",
   "source": [
    "list(triad_components_labels_collection.aggregate([\n",
    "    {\"$unwind\": \"$ols_text_annotations\"},\n",
    "    {\"$group\": {\"_id\": \"$ols_text_annotations.ontology_lc\", \"count\": {\"$sum\": 1}}},\n",
    "    {\"$sort\": {\"count\": -1}}\n",
    "]))"
   ],
   "id": "ca0eaee8f29613a0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'_id': 'ncbitaxon', 'count': 748},\n",
       " {'_id': 'foodon', 'count': 628},\n",
       " {'_id': 'uberon', 'count': 602},\n",
       " {'_id': 'envo', 'count': 288},\n",
       " {'_id': 'efo', 'count': 211},\n",
       " {'_id': 'mondo', 'count': 193},\n",
       " {'_id': 'po', 'count': 42},\n",
       " {'_id': 'ohmi', 'count': 10}]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T00:44:07.877909Z",
     "start_time": "2025-03-18T00:44:07.811825Z"
    }
   },
   "cell_type": "code",
   "source": [
    "no_oak_or_ols = list(triad_components_labels_collection.find(\n",
    "    {\n",
    "        \"$and\": [\n",
    "            {\"ols_text_annotations\": {\"$exists\": False}},\n",
    "            {\"oak_text_annotations\": {\"$exists\": False}}\n",
    "        ]\n",
    "    },\n",
    "    {\"component_label\": 1, \"count\": 1, \"_id\": 0}  # Only return needed fields\n",
    "))"
   ],
   "id": "9781e35b77bf7561",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T00:44:07.991657Z",
     "start_time": "2025-03-18T00:44:07.954562Z"
    }
   },
   "cell_type": "code",
   "source": "no_oak_or_ols_frame = pd.DataFrame(no_oak_or_ols)",
   "id": "74ad43e2d4848476",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T00:44:08.081468Z",
     "start_time": "2025-03-18T00:44:08.078177Z"
    }
   },
   "cell_type": "code",
   "source": "no_oak_or_ols_frame.shape",
   "id": "71d2555ed9306148",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42264, 2)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T00:44:08.164568Z",
     "start_time": "2025-03-18T00:44:08.159854Z"
    }
   },
   "cell_type": "code",
   "source": "no_oak_or_ols_frame[no_oak_or_ols_frame[\"count\"] == 1].shape[0]",
   "id": "32ae835bc1a6133e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12963"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T00:44:08.256619Z",
     "start_time": "2025-03-18T00:44:08.243891Z"
    }
   },
   "cell_type": "code",
   "source": "no_oak_or_ols_frame",
   "id": "f6378ff7f59d90db",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                       component_label  count\n",
       "0      homo sapiens associated habitat    246\n",
       "1                              aquatic  43833\n",
       "2                        pacific ocean    469\n",
       "3                       not determined    202\n",
       "4                  rainforest division      6\n",
       "...                                ...    ...\n",
       "42259                stream microbiome      2\n",
       "42260    glacier fed stream microbiome      2\n",
       "42261  regular clay like mood sediment      1\n",
       "42262   m minimal medium with glycerol     15\n",
       "42263  m minimal medium with succinate     15\n",
       "\n",
       "[42264 rows x 2 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>component_label</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>homo sapiens associated habitat</td>\n",
       "      <td>246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aquatic</td>\n",
       "      <td>43833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pacific ocean</td>\n",
       "      <td>469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>not determined</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rainforest division</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42259</th>\n",
       "      <td>stream microbiome</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42260</th>\n",
       "      <td>glacier fed stream microbiome</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42261</th>\n",
       "      <td>regular clay like mood sediment</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42262</th>\n",
       "      <td>m minimal medium with glycerol</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42263</th>\n",
       "      <td>m minimal medium with succinate</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42264 rows Ã— 2 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Done with OAK and OLS full match annotations\n",
    "\n",
    "Start caching all CURIes that have been inferred or asserted"
   ],
   "id": "662b4887a5c9adb6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T00:44:16.866211Z",
     "start_time": "2025-03-18T00:44:16.862719Z"
    }
   },
   "cell_type": "code",
   "source": [
    "target_collection = db[\"class_label_cache\"]\n",
    "target_collection.drop()"
   ],
   "id": "9a65bbd4ffaefbd9",
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T00:44:17.423409Z",
     "start_time": "2025-03-18T00:44:17.420421Z"
    }
   },
   "cell_type": "code",
   "source": "target_collection = db[\"class_label_cache\"]",
   "id": "3969c66dd4d47431",
   "outputs": [],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T00:44:17.967140Z",
     "start_time": "2025-03-18T00:44:17.897683Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Ensure unique index on 'curie' to enforce \"first one wins\"\n",
    "target_collection.create_index([(\"curie\", ASCENDING)], unique=True)"
   ],
   "id": "66200b0b017c1efb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'curie_1'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T00:44:23.203406Z",
     "start_time": "2025-03-18T00:44:23.200728Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# triad_components_labels_collection\n",
    "# triad_values_collection = db.unique_triad_values\n",
    "# triad_components_labels_collection = db.triad_components_labels"
   ],
   "id": "7dcc20a3abbccb73",
   "outputs": [],
   "execution_count": 44
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "start collecting a cache of curies with their labels and synonyms\n",
    "\n",
    "start with ols_text_annotations\n",
    "\n",
    "inconsistently including obsolete flag?"
   ],
   "id": "69bfe33cc5ccc18f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T00:44:25.969440Z",
     "start_time": "2025-03-18T00:44:25.169140Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Iterate through source collection\n",
    "for doc in triad_components_labels_collection.find({}):\n",
    "    hits = doc.get(\"ols_text_annotations\", [])  # Get list or empty list\n",
    "    for hit in hits:\n",
    "        curie = hit.get(\"obo_id\")\n",
    "        label = hit.get(\"label\")\n",
    "        synonyms = hit.get(\"synonyms\", [])\n",
    "\n",
    "        try:\n",
    "            target_collection.insert_one({\n",
    "                \"curie\": curie,\n",
    "                \"label\": label,\n",
    "                \"synonyms\": synonyms,\n",
    "            })\n",
    "\n",
    "        except DuplicateKeyError:\n",
    "            # Ignore duplicates and continue\n",
    "            pass\n"
   ],
   "id": "e5f8d5f3c5549e80",
   "outputs": [],
   "execution_count": 45
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "start keeping track  of unlabelled curies anywhere in the database, as an in-memory set",
   "id": "ca2b71143f61aa28"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T00:44:26.649090Z",
     "start_time": "2025-03-18T00:44:26.646560Z"
    }
   },
   "cell_type": "code",
   "source": "unlabelleds = set()",
   "id": "55ec5b4936f6a0c2",
   "outputs": [],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T00:44:27.317285Z",
     "start_time": "2025-03-18T00:44:27.314721Z"
    }
   },
   "cell_type": "code",
   "source": "# is this indexed yet?",
   "id": "f48a63f99696527c",
   "outputs": [],
   "execution_count": 47
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "include oak_text_annotations in unlabeleds because the OAK text annotator does not return the matched term's label, only information about which of its annotations was matched (label, synonym, etc)",
   "id": "135919b51a54f884"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T00:44:28.919957Z",
     "start_time": "2025-03-18T00:44:28.533906Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for doc in triad_components_labels_collection.find({}, {\"oak_text_annotations.curie\": 1}):\n",
    "    annotations = doc.get(\"oak_text_annotations\", [])  # Get list or empty list\n",
    "    if isinstance(annotations, list):\n",
    "        for annotation in annotations:\n",
    "            curie = annotation.get(\"curie\")\n",
    "            if curie:\n",
    "                unlabelleds.add(curie)"
   ],
   "id": "b45c4c0eacb90c7",
   "outputs": [],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T00:44:29.152042Z",
     "start_time": "2025-03-18T00:44:29.147843Z"
    }
   },
   "cell_type": "code",
   "source": "len(unlabelleds)",
   "id": "b917a4afb4fb9b52",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2229"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 49
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "now add asserted curies discovered during parsing, if their prefix suggest that the term is present in Bioportal",
   "id": "9ba075dfaaa965e0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T00:44:31.851242Z",
     "start_time": "2025-03-18T00:44:30.463323Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Iterate through source collection and insert CURIes from parsed_annotations[].repaired_curie\n",
    "for doc in triad_values_collection.find({},\n",
    "                                        {\"parsed_annotations.repaired_curie\": 1, \"parsed_annotations.bioportal_prefix\": 1}):\n",
    "    annotations = doc.get(\"parsed_annotations\", [])  # Get list or empty list\n",
    "    if isinstance(annotations, list):\n",
    "        for annotation in annotations:\n",
    "            curie = annotation.get(\"repaired_curie\")\n",
    "            bioportal_prefix = annotation.get(\"bioportal_prefix\")\n",
    "\n",
    "            if curie and bioportal_prefix:  # Exclude if obo_prefix is present\n",
    "                unlabelleds.add(curie)  # Add to set (ensures uniqueness)\n",
    "\n"
   ],
   "id": "f855033fdcb7139d",
   "outputs": [],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T00:44:31.858652Z",
     "start_time": "2025-03-18T00:44:31.854493Z"
    }
   },
   "cell_type": "code",
   "source": "len(unlabelleds)",
   "id": "db4c0af7f8f2a648",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14109"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T00:44:32.106825Z",
     "start_time": "2025-03-18T00:44:32.103658Z"
    }
   },
   "cell_type": "code",
   "source": [
    "labelleds = []\n",
    "still_unlabelled_envo = []\n",
    "still_unlabelled_other = []"
   ],
   "id": "a790019410b1c7c1",
   "outputs": [],
   "execution_count": 52
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "TODO: add obsolete indicator",
   "id": "7a7dfa0d4185a208"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T00:44:33.454320Z",
     "start_time": "2025-03-18T00:44:33.450575Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def attempt_oak_labelling(unlabelled, adapter, labelleds):\n",
    "    # todo include obsoletes?\n",
    "    label = adapter.label(unlabelled)\n",
    "    if label:\n",
    "        # todo include obsoletes?\n",
    "        aliases = adapter.entity_aliases(unlabelled) or []\n",
    "        if not isinstance(aliases, list):\n",
    "            print(aliases)\n",
    "        aliases = [i for i in aliases if i != label]\n",
    "        labelleds.append({\"curie\": unlabelled, \"label\": label, \"synonyms\": aliases})\n",
    "        return True  # Indicates that labeling was successful\n",
    "    return False  # Indicates that the CURIE remains unlabelled\n"
   ],
   "id": "2244a21234ea674c",
   "outputs": [],
   "execution_count": 53
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "now try to find labels for the items in the unlabelled set with the EnvO or PO OAK annotators\n",
    "\n",
    "if no label is found, then add the curie to either an unlabelled EnvO term list (which is probably all bogus curies)\n",
    "\n",
    "or an unlabelled other list, which likely contains a lot or valid curies from other namespaces"
   ],
   "id": "42320ad74f8ab956"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T00:44:44.167272Z",
     "start_time": "2025-03-18T00:44:35.008641Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for unlabelled in unlabelleds:\n",
    "    labelled = attempt_oak_labelling(unlabelled, envo_adapter, labelleds)\n",
    "    labelled |= attempt_oak_labelling(unlabelled, po_adapter, labelleds)  # |= ensures labelled stays True if either succeeds\n",
    "\n",
    "    if not labelled:  # Only add to unlabelled lists if neither adapter provided a label\n",
    "        if \"envo\" in unlabelled.lower():\n",
    "            still_unlabelled_envo.append(unlabelled)\n",
    "        else:\n",
    "            still_unlabelled_other.append(unlabelled)\n",
    "\n",
    "# 10 seconds"
   ],
   "id": "41e8c6555706d4bc",
   "outputs": [],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T00:44:44.175139Z",
     "start_time": "2025-03-18T00:44:44.171001Z"
    }
   },
   "cell_type": "code",
   "source": "len(labelleds)",
   "id": "cdd4936a8e098f69",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4347"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T00:44:44.438992Z",
     "start_time": "2025-03-18T00:44:44.288094Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if labelleds:  # Ensure the list is not empty\n",
    "    try:\n",
    "        target_collection.insert_many(labelleds, ordered=False)  # Bulk insert, ignore order\n",
    "    except errors.BulkWriteError as e:\n",
    "        pass # todo\n"
   ],
   "id": "2ae5dc29bccf1a3",
   "outputs": [],
   "execution_count": 56
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T00:44:44.525744Z",
     "start_time": "2025-03-18T00:44:44.523573Z"
    }
   },
   "cell_type": "code",
   "source": "# todo: index",
   "id": "e1e2812b8477e30f",
   "outputs": [],
   "execution_count": 57
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T00:44:44.701688Z",
     "start_time": "2025-03-18T00:44:44.697846Z"
    }
   },
   "cell_type": "code",
   "source": "len(still_unlabelled_envo)",
   "id": "61261e6d57137c0e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5248"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 58
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T00:44:44.749733Z",
     "start_time": "2025-03-18T00:44:44.746307Z"
    }
   },
   "cell_type": "code",
   "source": "len(still_unlabelled_other)",
   "id": "796662866050f946",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4544"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 59
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T00:44:44.842782Z",
     "start_time": "2025-03-18T00:44:44.836141Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Function to get the label etc from BioPortal safely, using a term URI and prefix as input\n",
    "def get_bioportal_info(uri, prefix, BIOPORTAL_API_KEY):\n",
    "    temp_dict = {\n",
    "        \"label\": None,\n",
    "        \"obsolete\": None,\n",
    "        \"synonyms\": None,\n",
    "        \"status\": None\n",
    "    }\n",
    "    if not isinstance(uri, str) or not uri.startswith((\"http://\", \"https://\")):\n",
    "        temp_dict[\"status\"] = \"non-string URI\"\n",
    "        return temp_dict  # todo better handling/reporting\n",
    "\n",
    "    if not isinstance(prefix, str):\n",
    "        temp_dict[\"status\"] = \"non-string ontology slug\"\n",
    "        return temp_dict  # todo better handling/reporting\n",
    "\n",
    "    # Upper-case the ontology prefix\n",
    "    ontology = prefix.upper()\n",
    "\n",
    "    # URL-encode the inferred URI\n",
    "    encoded_uri = urllib.parse.quote(uri, safe=\"\")\n",
    "\n",
    "    # Correct API request URL format\n",
    "    url = f\"https://data.bioontology.org/ontologies/{ontology}/classes/{encoded_uri}?apikey={BIOPORTAL_API_KEY}\"\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url, headers={\"Authorization\": f\"apikey {BIOPORTAL_API_KEY}\"})\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            pref_label = data.get(\"prefLabel\", \"\")\n",
    "            obsolete = data.get(\"obsolete\", False)  # Default to False if missing\n",
    "            if not obsolete:\n",
    "                obsolete = False\n",
    "            synonyms = data.get(\"synonym\", [])  # Default to False if missing\n",
    "\n",
    "            # todo GET MAPPINGS\n",
    "\n",
    "            if not synonyms:\n",
    "                synonyms = []\n",
    "\n",
    "            links = data.get(\"links\", {})  # Default to False if missing\n",
    "            mappings_link = links.get(\"mappings\", {})\n",
    "\n",
    "            temp_dict = {\n",
    "                \"label\": pref_label,\n",
    "                \"obsolete\": obsolete,\n",
    "                \"synonyms\": synonyms,\n",
    "                \"status\": \"success\",\n",
    "                \"ontology_lc\": prefix.lower(),\n",
    "                \"mappings_link\": mappings_link\n",
    "            }\n",
    "\n",
    "            return temp_dict\n",
    "        else:\n",
    "            temp_dict[\"status\"] = f\"response: {response.status_code}\"\n",
    "            return temp_dict  # todo better handling/reporting\n",
    "    except Exception as e:\n",
    "        temp_dict[\"status\"] = f\"exception: {e}\"\n",
    "        return temp_dict  # todo better handling/reporting"
   ],
   "id": "8eeca0e7b6bec8a2",
   "outputs": [],
   "execution_count": 60
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T00:44:45.011676Z",
     "start_time": "2025-03-18T00:44:45.008853Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Function to safely expand CURIEs, ignoring invalid ones\n",
    "def safe_expand(curie):\n",
    "    if isinstance(curie, str) and \":\" in curie:  # Ensure it's a CURIE\n",
    "        return converter.expand(curie.upper())\n",
    "    return None  # Return None for invalid CURIEs"
   ],
   "id": "db3919682b7341bb",
   "outputs": [],
   "execution_count": 61
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "using the Bioportal API requires an API key",
   "id": "8ae96b44f2a0d392"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T00:44:45.105604Z",
     "start_time": "2025-03-18T00:44:45.101599Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load variables into a dictionary\n",
    "env_vars = dotenv_values(env_path)\n",
    "BIOPORTAL_API_KEY = env_vars[bioportal_api_key_name]"
   ],
   "id": "1fa4ce0fd27edc66",
   "outputs": [],
   "execution_count": 62
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "create a CURIe/URI converted prioritizing Bioportal style",
   "id": "e103288d3c3011ec"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T00:44:47.821567Z",
     "start_time": "2025-03-18T00:44:47.149237Z"
    }
   },
   "cell_type": "code",
   "source": "converter: Converter = load_converter([\"bioportal\", \"obo\"])",
   "id": "4ce878344bc91228",
   "outputs": [],
   "execution_count": 63
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "try to get the label, synonyms, etc. for the unlabeled other asserted curies from Bioportal",
   "id": "234c76fdef8bc215"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T00:49:36.895750Z",
     "start_time": "2025-03-18T00:44:48.795028Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for curie in tqdm(still_unlabelled_other, desc=\"Processing CURIEs\"):\n",
    "\n",
    "    # split the curie into the prefix and the local_id\n",
    "    onto_slug = curie.split(\":\")[0].upper()\n",
    "    term_uri = safe_expand(curie)\n",
    "    term_info = get_bioportal_info(term_uri, onto_slug, BIOPORTAL_API_KEY)\n",
    "    term_info['curie'] = curie\n",
    "\n",
    "    if term_info[\"status\"] == \"success\":\n",
    "        del term_info[\"status\"]\n",
    "        try:\n",
    "            # Attempt to insert into MongoDB\n",
    "            target_collection.insert_one(term_info)\n",
    "\n",
    "        except DuplicateKeyError:\n",
    "            pass  # todo better handling/reporting\n",
    "\n",
    "        except Exception as e:\n",
    "            pass  # todo better handling/reporting\n",
    "\n",
    "# 50 minutes without cache\n",
    "# 7 minutes with cache\n",
    "# retrieved 3768 from 4519"
   ],
   "id": "cee69c657d023de1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Processing CURIEs:   0%|          | 0/4544 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3170e57018ed405293e352954c6f5ed8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 64
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T00:49:36.992104Z",
     "start_time": "2025-03-18T00:49:36.989506Z"
    }
   },
   "cell_type": "code",
   "source": "preferred_ontologies = set(small_high_impact_targets_lc) | set(other_targets_lc)",
   "id": "e3929feda2222eec",
   "outputs": [],
   "execution_count": 65
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T00:49:37.004799Z",
     "start_time": "2025-03-18T00:49:37.001486Z"
    }
   },
   "cell_type": "code",
   "source": "preferred_ontologies",
   "id": "76af4c68c5e01eef",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'efo', 'envo', 'foodon', 'mondo', 'ncbitaxon', 'ohmi', 'po', 'uberon'}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 66
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Fetch documents where mappings_link exists and ontology_lc is in preferred ontologies",
   "id": "2dfdf83370502c58"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T00:49:37.117396Z",
     "start_time": "2025-03-18T00:49:37.093795Z"
    }
   },
   "cell_type": "code",
   "source": [
    "docs = list(target_collection.find(\n",
    "    {\n",
    "        \"mappings_link\": {\"$exists\": True, \"$ne\": None},\n",
    "        \"ontology_lc\": {\"$nin\": list(preferred_ontologies)}  # Ensure lowercase matching\n",
    "    }\n",
    "))\n",
    "# .limit(100))"
   ],
   "id": "9ebfbbf076dc6b62",
   "outputs": [],
   "execution_count": 67
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T00:49:37.294047Z",
     "start_time": "2025-03-18T00:49:37.288422Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Function to fetch mappings from BioPortal\n",
    "def fetch_mappings(mappings_url):\n",
    "    \"\"\"Fetch mappings from BioPortal using mappings_link.\"\"\"\n",
    "    try:\n",
    "\n",
    "        # Properly append the API key based on the existing URL structure\n",
    "        if \"?\" in mappings_url:\n",
    "            mappings_url += f\"&apikey={BIOPORTAL_API_KEY}\"\n",
    "        else:\n",
    "            mappings_url += f\"?apikey={BIOPORTAL_API_KEY}\"\n",
    "\n",
    "        response = requests.get(mappings_url, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        mappings_obj = response.json()\n",
    "\n",
    "        mappings_list = []\n",
    "        for item in mappings_obj:\n",
    "            if item.get(\"source\") == \"LOOM\":\n",
    "                for cls in item.get(\"classes\", []):\n",
    "                    # ontology_slug = cls[\"links\"][\"ontology\"].split(\"/\")[-1].lower()\n",
    "                    #\n",
    "                    # # Only store CURIE if mapped ontology is in the preferred list\n",
    "                    # if ontology_slug in preferred_ontologies:\n",
    "                    curie = converter.compress(cls[\"@id\"])\n",
    "                    if curie:\n",
    "                        curie_prefix = curie.split(\":\")[0].lower()\n",
    "                        if curie_prefix and curie_prefix in preferred_ontologies:  # Ensure CURIE conversion was successful\n",
    "                            mappings_list.append(curie)\n",
    "\n",
    "        return set(mappings_list)  # Return list of valid CURIE mappings\n",
    "\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Failed to fetch mappings from {mappings_url}: {e}\")\n",
    "        return []"
   ],
   "id": "83b92e6a9cad0eea",
   "outputs": [],
   "execution_count": 68
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Fetch mappings from asserted CURIes to CURIes from preferred ontologies",
   "id": "f827d11ca2c47f01"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T00:49:44.215854Z",
     "start_time": "2025-03-18T00:49:37.387999Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Iterate through docs and fetch mappings where needed\n",
    "for doc in docs:\n",
    "    if doc.get(\"mappings_link\"):\n",
    "        temp_mappings = fetch_mappings(doc[\"mappings_link\"])\n",
    "        # print(f\"from {doc['curie']}/{doc['label']} to {temp_mappings}\")\n",
    "        if temp_mappings:\n",
    "            target_collection.update_one({\"_id\": doc[\"_id\"]},\n",
    "                                         {\"$set\": {\"preferred_mappings_curies\": list(temp_mappings)}})  # Update in DB\n",
    "\n",
    "# 45 minutes without cache\n",
    "# todo add tqdm\n",
    "# 7 seconds with cache"
   ],
   "id": "a90a77c656158637",
   "outputs": [],
   "execution_count": 69
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "start to find the curies, from mapping asserted curies into preferred ontologies, that don't already have labels in the `target_collection` \"class_label_cache\"",
   "id": "df4f2a06226cfcaa"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T00:49:44.250983Z",
     "start_time": "2025-03-18T00:49:44.220488Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create a set of lowercase curies from the class_label_cache collection (where label exists)\n",
    "labelled_curies_set = {\n",
    "    doc[\"curie\"].lower() for doc in target_collection.find(\n",
    "        {\"label\": {\"$exists\": True, \"$ne\": \"\"}}, {\"curie\": 1}\n",
    "    ) if \"curie\" in doc\n",
    "}"
   ],
   "id": "4c66bf6645ea4eb7",
   "outputs": [],
   "execution_count": 70
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T00:49:44.344723Z",
     "start_time": "2025-03-18T00:49:44.340666Z"
    }
   },
   "cell_type": "code",
   "source": "len(labelled_curies_set)",
   "id": "bc0a76c504375c7f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10177"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 71
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T00:49:44.465494Z",
     "start_time": "2025-03-18T00:49:44.452749Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create a set of lowercase curies from the \"preferred_mappings_curies\" field\n",
    "preferred_mappings_curies_set = {\n",
    "    curie.lower() for doc in target_collection.find(\n",
    "        {\"preferred_mappings_curies\": {\"$exists\": True, \"$ne\": []}}, {\"preferred_mappings_curies\": 1}\n",
    "    ) for curie in doc[\"preferred_mappings_curies\"]\n",
    "}"
   ],
   "id": "c29a91f138e0985e",
   "outputs": [],
   "execution_count": 72
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T00:49:44.568063Z",
     "start_time": "2025-03-18T00:49:44.564902Z"
    }
   },
   "cell_type": "code",
   "source": "len(preferred_mappings_curies_set)",
   "id": "913e46351eded3f0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "677"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 73
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T00:49:44.656975Z",
     "start_time": "2025-03-18T00:49:44.654390Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Find values in preferred_mappings_curies that are NOT in curies_set\n",
    "# todo are we redefining unlabelleds here?\n",
    "unlabelleds = preferred_mappings_curies_set - labelled_curies_set"
   ],
   "id": "1c26ed8812f90af8",
   "outputs": [],
   "execution_count": 74
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T00:49:44.822753Z",
     "start_time": "2025-03-18T00:49:44.818965Z"
    }
   },
   "cell_type": "code",
   "source": "len(unlabelleds)",
   "id": "80bff2e6ba48843c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "407"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 75
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Use the Bioportal API to get the label, synonyms, etc for the unlabelled CURIes mapped from the asserted curies\n",
    "\n",
    "Previous experience shows that these are almost all NON EnvO UCRIes"
   ],
   "id": "eb7cb2065663985d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T00:49:49.225494Z",
     "start_time": "2025-03-18T00:49:44.867905Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# almost 100% duplicated code\n",
    "for curie in tqdm(unlabelleds, desc=\"Processing CURIEs\"):\n",
    "\n",
    "    # split the curie into the prefix and the local_id\n",
    "    onto_slug = curie.split(\":\")[0].upper()\n",
    "    term_uri = safe_expand(curie)\n",
    "    term_info = get_bioportal_info(term_uri, onto_slug, BIOPORTAL_API_KEY)\n",
    "    term_info['curie'] = converter.compress(term_uri)\n",
    "\n",
    "    if term_info[\"status\"] == \"success\":\n",
    "        del term_info[\"status\"]\n",
    "        try:\n",
    "            # Attempt to insert into MongoDB\n",
    "            target_collection.insert_one(term_info)\n",
    "\n",
    "        except DuplicateKeyError:\n",
    "            pass  # todo better handling/reporting\n",
    "\n",
    "        except Exception as e:\n",
    "            pass  # todo better handling/reporting\n"
   ],
   "id": "c13c0df2b77a76d3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Processing CURIEs:   0%|          | 0/407 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0ec160837ac74a5bbd6892c5dda37efb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 76
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "now create an oak lexical index from classes with precedent and do a non-whole word match",
   "id": "65099a2f90a00148"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T00:50:40.475907Z",
     "start_time": "2025-03-18T00:50:40.473033Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Normalize text: lowercase and remove excess whitespace\n",
    "# todo this probably duplicates some other previous function\n",
    "def normalize(text):\n",
    "    return re.sub(r'\\s+', ' ', text.strip().lower())"
   ],
   "id": "304f27c6aa367a1b",
   "outputs": [],
   "execution_count": 77
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T00:50:43.930643Z",
     "start_time": "2025-03-18T00:50:43.927768Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize index structure\n",
    "lexical_index = {\n",
    "    \"groupings\": {},\n",
    "    \"pipelines\": {\n",
    "        \"default\": {\n",
    "            \"name\": \"default\",\n",
    "            \"transformations\": [\n",
    "                {\"type\": \"CaseNormalization\"},\n",
    "                {\"type\": \"WhitespaceNormalization\"}\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "}"
   ],
   "id": "187570553c7ea1ad",
   "outputs": [],
   "execution_count": 78
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Populate the lexical_index dict's groupings with label, synonyms in `target_collection` \"class_label_cache\"\n",
    "\n",
    "TODO would ideally instantiate the index directly instead of treating it as a dict and yaml file first"
   ],
   "id": "8b558b60283115c4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T00:50:48.923598Z",
     "start_time": "2025-03-18T00:50:48.763602Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Process each document in MongoDB\n",
    "for doc in target_collection.find():\n",
    "    curie = doc[\"curie\"]\n",
    "    label = normalize(doc[\"label\"])\n",
    "    synonyms = [normalize(s) for s in doc.get(\"synonyms\", [])]\n",
    "\n",
    "    # Ensure label is in the groupings\n",
    "    if label not in lexical_index[\"groupings\"]:\n",
    "        lexical_index[\"groupings\"][label] = {\n",
    "            \"term\": label,\n",
    "            \"relationships\": []\n",
    "        }\n",
    "\n",
    "    # Add label relationship\n",
    "    lexical_index[\"groupings\"][label][\"relationships\"].append({\n",
    "        \"predicate\": \"rdfs:label\",\n",
    "        \"element\": curie,\n",
    "        \"element_term\": label,\n",
    "        \"pipeline\": [\"default\"],\n",
    "        \"synonymized\": False\n",
    "    })\n",
    "\n",
    "    # Process synonyms\n",
    "    for synonym in synonyms:\n",
    "        if synonym not in lexical_index[\"groupings\"]:\n",
    "            lexical_index[\"groupings\"][synonym] = {\n",
    "                \"term\": synonym,\n",
    "                \"relationships\": []\n",
    "            }\n",
    "\n",
    "        lexical_index[\"groupings\"][synonym][\"relationships\"].append({\n",
    "            \"predicate\": \"oio:hasRelatedSynonym\",\n",
    "            \"element\": curie,\n",
    "            \"element_term\": synonym,\n",
    "            \"pipeline\": [\"default\"],\n",
    "            \"synonymized\": False\n",
    "        })"
   ],
   "id": "6467e1bb783e730b",
   "outputs": [],
   "execution_count": 79
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T00:50:52.251216Z",
     "start_time": "2025-03-18T00:50:52.248609Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# todo would ideally instantiate the index directly instead of treating it as a dict and yaml file first\n",
    "\n",
    "biosamples_env_triads_precedent_lexical_index_yaml = \"biosamples_env_triads_precedent_lexical_index.yaml\"\n",
    "\n",
    "biosamples_env_triads_precedent_lexical_index_second_pass_filtered_yaml = \"biosamples_env_triads_precedent_lexical_index_second_pass_filtered.yaml\""
   ],
   "id": "65ac5ff5d483fe8f",
   "outputs": [],
   "execution_count": 80
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "save the initial lexical index based on the documents in the `target_collection` \"class_label_cache\"",
   "id": "81ee1c1d5167865a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T00:51:08.315985Z",
     "start_time": "2025-03-18T00:50:55.876613Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open(biosamples_env_triads_precedent_lexical_index_yaml, \"w\") as f:\n",
    "    yaml.dump(lexical_index, f, default_flow_style=False, sort_keys=True)\n",
    "# 15 seconds"
   ],
   "id": "408e7a016c0061a7",
   "outputs": [],
   "execution_count": 81
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "All annotations so far have been full matches",
   "id": "145d57731b52f4b1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# or biosamples_env_triads_precedent_lexical_index_second_pass_filtered_yaml for a second pass\n",
    "\n",
    "biosamples_env_triads_precedent_lexical_index = load_lexical_index(biosamples_env_triads_precedent_lexical_index_second_pass_filtered_yaml)\n",
    "# 20 seconds"
   ],
   "id": "f4a50d496e64f1af",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "create an initial TextAnnotatorInterface",
   "id": "2972923e6db3f5c2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Initialize the TextAnnotatorInterface\n",
    "biosamples_env_triads_precedent_interface = TextAnnotatorInterface()\n",
    "biosamples_env_triads_precedent_interface.lexical_index = biosamples_env_triads_precedent_lexical_index\n"
   ],
   "id": "78ff234357d76fcd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def optimize_annotations(annotations, preferred_ontologies, min_length=3, text=\"\"):\n",
    "    \"\"\"\n",
    "    Selects the minimal set of annotations that maximizes coverage of input text.\n",
    "    Returns the optimized annotations, uncovered text segments, and percent coverage.\n",
    "    \"\"\"\n",
    "    # Sort by longest span first (descending order)\n",
    "    annotations.sort(key=lambda a: (a.subject_end - a.subject_start), reverse=True)\n",
    "\n",
    "    selected_annotations = []\n",
    "    covered_intervals = []\n",
    "\n",
    "    for a in annotations:\n",
    "        prefix_of_mapped = a.object_id.split(\":\")[0].lower()\n",
    "        annotation_length = a.subject_end - a.subject_start\n",
    "\n",
    "        if prefix_of_mapped in preferred_ontologies and annotation_length >= min_length:\n",
    "            # Check if this annotation overlaps with already selected ones\n",
    "            overlap = any(start < a.subject_end and a.subject_start < end for start, end in covered_intervals)\n",
    "            if not overlap:\n",
    "                annotation_dict = {k: v for k, v in vars(a).items() if v}\n",
    "                selected_annotations.append(annotation_dict)\n",
    "                covered_intervals.append((a.subject_start, a.subject_end))\n",
    "\n",
    "    # SIMPLIFIED APPROACH: Ignore single-character uncovered segments for coverage calculation\n",
    "    uncovered_text = []\n",
    "\n",
    "    # Create a set of covered positions\n",
    "    covered_positions = set()\n",
    "    for start, end in covered_intervals:\n",
    "        covered_positions.update(range(start, end))\n",
    "\n",
    "    # Find uncovered non-whitespace positions and ignore isolated characters\n",
    "    non_whitespace_positions = set()\n",
    "    for i, char in enumerate(text):\n",
    "        if char.strip():  # Non-whitespace character\n",
    "            non_whitespace_positions.add(i)\n",
    "\n",
    "    uncovered_positions = non_whitespace_positions - covered_positions\n",
    "\n",
    "    # Only consider segments of two or more consecutive characters as \"uncovered\"\n",
    "    # (This ignores isolated characters like the \"h\", \"a\", \"h\" in your example)\n",
    "    if uncovered_positions:\n",
    "        sorted_positions = sorted(uncovered_positions)\n",
    "        current_segment = [sorted_positions[0]]\n",
    "\n",
    "        for pos in sorted_positions[1:]:\n",
    "            if pos == current_segment[-1] + 1:\n",
    "                current_segment.append(pos)\n",
    "            else:\n",
    "                # Only add segments with length >= 2\n",
    "                if len(current_segment) >= 2:\n",
    "                    segment_text = ''.join(text[i] for i in current_segment)\n",
    "                    uncovered_text.append(segment_text)\n",
    "                current_segment = [pos]\n",
    "\n",
    "        # Don't forget the last segment\n",
    "        if current_segment and len(current_segment) >= 2:\n",
    "            segment_text = ''.join(text[i] for i in current_segment)\n",
    "            uncovered_text.append(segment_text)\n",
    "\n",
    "    # Adjust coverage calculation to ignore single character \"gaps\"\n",
    "    single_char_positions = set()\n",
    "    for pos in uncovered_positions:\n",
    "        # Check if this is an isolated character\n",
    "        is_isolated = (pos-1 not in uncovered_positions) and (pos+1 not in uncovered_positions)\n",
    "        if is_isolated:\n",
    "            single_char_positions.add(pos)\n",
    "\n",
    "    # Consider single characters as \"covered\" for percentage calculation\n",
    "    adjusted_uncovered = uncovered_positions - single_char_positions\n",
    "    total_characters = len(non_whitespace_positions)\n",
    "    covered_characters = total_characters - len(adjusted_uncovered)\n",
    "    percent_coverage = (covered_characters / total_characters * 100) if total_characters > 0 else 0\n",
    "\n",
    "    return selected_annotations, uncovered_text, round(percent_coverage, 2)"
   ],
   "id": "24dd4edf4429204c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "annotate the `triad_components_labels_collection` \"triad_components_labels\" documents that don't have any oak_text_annotations or ols_text_annotations with the initial lexical index text annotator and find the best coverage terms",
   "id": "12e02a8be178e696"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Process triad_components_labels collection for missing annotations\n",
    "for doc in triad_components_labels_collection.find(\n",
    "        {\"oak_text_annotations\": {\"$exists\": False}, \"ols_text_annotations\": {\"$exists\": False}}):\n",
    "    component_label = doc.get(\"component_label\", \"\")\n",
    "\n",
    "    if component_label:\n",
    "        annotations = list(biosamples_env_triads_precedent_interface.annotate_text(component_label))\n",
    "        optimized_annotations, uncovered_segments, percent_coverage = optimize_annotations(annotations,\n",
    "                                                                                           preferred_ontologies,\n",
    "                                                                                           text=component_label)\n",
    "        if len(optimized_annotations) > 0:\n",
    "            # Update the document with the new field\n",
    "            triad_components_labels_collection.update_one(\n",
    "                {\"_id\": doc[\"_id\"]},\n",
    "                {\"$set\": {\n",
    "                    \"partial_matches_vs_precedent\": {\n",
    "                        \"partial_matches_vs_precedent\": optimized_annotations,\n",
    "                        \"uncovered_text_segments\": uncovered_segments,\n",
    "                        \"percent_coverage\": percent_coverage, }\n",
    "                }}\n",
    "            )\n",
    "\n",
    "# 3 minutes"
   ],
   "id": "a4186616d5948263",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "fetch the spans that are still not annotated",
   "id": "5cb4481c1d9faf84"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Retrieve all uncovered_text_segments from the collection\n",
    "cursor = triad_components_labels_collection.find(\n",
    "    {\"partial_matches_vs_precedent.uncovered_text_segments\": {\"$exists\": True}},\n",
    "    {\"partial_matches_vs_precedent.uncovered_text_segments\": 1}\n",
    ")"
   ],
   "id": "6ba05b2eecfcba8e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "do some stopword removal. see https://github.com/igorbrigadir/stopwords/blob/master/en_stopwords.csv\n",
    "\n",
    "may not want to remove negaters"
   ],
   "id": "5648ac2db753c353"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Set frequency threshold (change this value as needed)\n",
    "min_word_frequency = 3\n",
    "min_word_len = 3\n",
    "stopwords_url = \"https://raw.githubusercontent.com/igorbrigadir/stopwords/master/en/lexisnexis.txt\""
   ],
   "id": "3fea33e0f6802775",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Fetch the stopword list from the URL\n",
    "response = requests.get(stopwords_url)"
   ],
   "id": "46684b0b24a179b3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Check if request was successful\n",
    "if response.status_code == 200:\n",
    "    # Process the stopwords: split by lines and remove empty entries\n",
    "    stop_words = set(response.text.splitlines())\n",
    "    stop_words.discard(\"\")  # Remove any empty strings from the set\n",
    "else:\n",
    "    print(\"Failed to fetch stopwords. HTTP Status Code:\", response.status_code)"
   ],
   "id": "923efa13886592c7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Flatten all uncovered text segments/spans into a single list of words",
   "id": "68a5acf3f55b46e1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "all_uncovered_words = []",
   "id": "7735a72037adf1b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for doc in cursor:\n",
    "    uncovered_segments = doc.get(\"partial_matches_vs_precedent\", {}).get(\"uncovered_text_segments\", [])\n",
    "    for segment in uncovered_segments:\n",
    "        words = segment.split()\n",
    "        for w in words:\n",
    "            if len(w) >= min_word_len and w not in stop_words:\n",
    "                all_uncovered_words.extend(words)"
   ],
   "id": "a4cd1d4277853e50",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Create a word frequency table",
   "id": "d779d18e34d178c6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "word_frequencies = Counter(all_uncovered_words)",
   "id": "c3b6e9f2db5eac75",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Filter out words below the frequency threshold\n",
    "\n",
    "Create a dict of words from relevant uncovered spans, with their counts"
   ],
   "id": "4a903e7cb767ae5f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "filtered_frequencies = {word: count for word, count in word_frequencies.items() if count > min_word_frequency}\n",
   "id": "d3ddbac3f21b6a72",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "filtered_frequencies",
   "id": "5d12292f00990d2b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Convert dictionary to DataFrame\n",
    "df = pd.DataFrame(list(filtered_frequencies.items()), columns=['Term', 'Frequency'])"
   ],
   "id": "963cfbe5b2c857f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "absent_from_lexical_index_first_pass_tsv = \"absent_from_lexical_index_first_pass.tsv\"\n",
    "absent_from_lexical_index_second_pass_tsv = \"absent_from_lexical_index_second_pass.tsv\""
   ],
   "id": "edbfb5204e18767a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Save as TSV\n",
    "df.to_csv(absent_from_lexical_index_second_pass_tsv, sep='\\t', index=False)"
   ],
   "id": "9615ab26ae231ad",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "get annotations of the uncovered words from OLS",
   "id": "f96a28e3dad35b23"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "ols_hits_for_frequent_uncovered_words = []",
   "id": "148e819035d874a0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# todo highly duplicative\n",
    "for query in tqdm(filtered_frequencies, desc=\"Processing frequent words\", unit=\"word\"):\n",
    "    query = query.strip().lower()\n",
    "    if len(query) < MIN_LABEL_LEN:\n",
    "        continue  # Skip short labels\n",
    "\n",
    "    start = 0  # Start pagination at 0\n",
    "    ols_hits = []  # Store matching results\n",
    "\n",
    "    while True:\n",
    "        params = {\n",
    "            \"q\": query,\n",
    "            \"exact\": OLS_REQ_EXACT_MATCH,\n",
    "            \"fieldList\": FIELDLIST,\n",
    "            \"ontology\": OLS_LABEL_SEARCH_ONTS,\n",
    "            \"queryFields\": QUERYFIELDS,\n",
    "            \"rows\": rows,\n",
    "            \"start\": start,\n",
    "        }\n",
    "\n",
    "        response = requests.get(OLS_SEARCH_URL, params=params)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "\n",
    "        # Extract results\n",
    "        results = data.get(\"response\", {}).get(\"docs\", [])\n",
    "\n",
    "        # If no results, break loop\n",
    "        if not results:\n",
    "            break\n",
    "\n",
    "        # Process results\n",
    "        for result in results:\n",
    "            if result.get(\"is_defining_ontology\", False):\n",
    "                label_lower = result.get(\"label\", \"\").lower()\n",
    "                label_lower_match = label_lower == query\n",
    "\n",
    "                temp_dict = {\n",
    "                    \"query\": query,\n",
    "                    \"exact_label_match\": label_lower_match,\n",
    "                    \"label\": result.get(\"label\", \"\"),\n",
    "                    \"synonyms\": result.get(\"synonym\", []),\n",
    "                    \"obo_id\": result.get(\"obo_id\", \"\"),\n",
    "                    \"ontology_lc\": result.get(\"ontology_name\", \"\").lower(),\n",
    "                }\n",
    "                if OLS_REQ_EXACT_MATCH == \"true\":\n",
    "                    temp_dict['exact_something_match'] = True\n",
    "\n",
    "                ols_hits.append(temp_dict)\n",
    "\n",
    "        # Check if we need to fetch more results\n",
    "        num_found = data.get(\"response\", {}).get(\"numFound\", 0)\n",
    "        start += rows  # Move to the next page\n",
    "\n",
    "        if start >= num_found:  # Stop if we've retrieved all records\n",
    "            break\n",
    "\n",
    "    # Store results in output list if any\n",
    "    if ols_hits:\n",
    "        ols_hits_for_frequent_uncovered_words.append({\"query\": query, \"ols_text_annotations\": ols_hits})\n"
   ],
   "id": "cb36d5f64b2ec679",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "insert the annotations of words from uncovered spans into `target_collection` \"class_label_cache\"",
   "id": "95c43ebdc324d220"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# todo highly duplicative\n",
    "for doc in ols_hits_for_frequent_uncovered_words:\n",
    "    hits = doc.get(\"ols_text_annotations\", [])  # Get list or empty list\n",
    "    for hit in hits:\n",
    "        curie = hit.get(\"obo_id\")\n",
    "        label = hit.get(\"label\")\n",
    "        synonyms = hit.get(\"synonyms\", [])\n",
    "\n",
    "        try:\n",
    "            target_collection.insert_one({\n",
    "                \"curie\": curie,\n",
    "                \"label\": label,\n",
    "                \"synonyms\": synonyms,\n",
    "            })\n",
    "\n",
    "        except DuplicateKeyError:\n",
    "            # Ignore duplicates and continue\n",
    "            pass"
   ],
   "id": "d5021c9cff54c217",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "add the results from the last OLS annotations to the `lexical_index` dict",
   "id": "58ea66a1190395df"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "stop here unless more lexical index refinement is desired",
   "id": "5b1da43b6e17cfda"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# todo highly duplicative\n",
    "for doc in target_collection.find():\n",
    "    curie = doc[\"curie\"]\n",
    "    label = normalize(doc[\"label\"])\n",
    "    synonyms = [normalize(s) for s in doc.get(\"synonyms\", [])]\n",
    "\n",
    "    # Ensure label is in the groupings\n",
    "    if label not in lexical_index[\"groupings\"]:\n",
    "        lexical_index[\"groupings\"][label] = {\n",
    "            \"term\": label,\n",
    "            \"relationships\": []\n",
    "        }\n",
    "\n",
    "    # Add label relationship\n",
    "    lexical_index[\"groupings\"][label][\"relationships\"].append({\n",
    "        \"predicate\": \"rdfs:label\",\n",
    "        \"element\": curie,\n",
    "        \"element_term\": label,\n",
    "        \"pipeline\": [\"default\"],\n",
    "        \"synonymized\": False\n",
    "    })\n",
    "\n",
    "    # Process synonyms\n",
    "    for synonym in synonyms:\n",
    "        if synonym not in lexical_index[\"groupings\"]:\n",
    "            lexical_index[\"groupings\"][synonym] = {\n",
    "                \"term\": synonym,\n",
    "                \"relationships\": []\n",
    "            }\n",
    "\n",
    "        lexical_index[\"groupings\"][synonym][\"relationships\"].append({\n",
    "            \"predicate\": \"oio:hasRelatedSynonym\",\n",
    "            \"element\": curie,\n",
    "            \"element_term\": synonym,\n",
    "            \"pipeline\": [\"default\"],\n",
    "            \"synonymized\": False\n",
    "        })\n",
    "\n",
    "# 15 seconds"
   ],
   "id": "9b247caef082cf1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "type(lexical_index)",
   "id": "5bdf929ff7d8501f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "lexical_index.keys()",
   "id": "ba3004c010294aa5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "len(lexical_index['groupings'])",
   "id": "4f7f2d50acfcef3d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def get_prefix(element):\n",
    "    \"\"\"Extract the ontology prefix from an element ID (e.g., 'UBERON:0003201' -> 'uberon').\"\"\"\n",
    "    return element.split(\":\")[0].lower()"
   ],
   "id": "d3aae70fa215c5e0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Define the set of forbidden characters in terms\n",
    "FORBIDDEN_CHARS_PATTERN = re.compile(r\"[\\(\\)\\[\\]\\{\\}'\\\"!@#$%^&*=\\;:|\\\\<>?]\")\n",
    "\n",
    "def process_groupings(groupings, preferred_ontologies):\n",
    "    \"\"\"Modify groupings to remove elements not in preferred ontologies, delete invalid groupings,\n",
    "    deduplicate relationships, and remove groupings with non-ASCII keys.\"\"\"\n",
    "    processed_groupings = {}\n",
    "\n",
    "    for term, data in groupings.items():\n",
    "        # Skip groupings with forbidden characters in the term\n",
    "        if FORBIDDEN_CHARS_PATTERN.search(data[\"term\"]):\n",
    "            continue\n",
    "\n",
    "        # Skip groupings whose keys contain non-ASCII characters\n",
    "        if any(ord(char) > 127 for char in term):\n",
    "            continue\n",
    "\n",
    "        seen_elements = set()\n",
    "        filtered_relationships = []\n",
    "\n",
    "        for rel in data[\"relationships\"]:\n",
    "            element_id = rel[\"element\"]\n",
    "\n",
    "            # Only keep elements from preferred ontologies and ensure no duplicates\n",
    "            if get_prefix(element_id) in preferred_ontologies and element_id not in seen_elements:\n",
    "                seen_elements.add(element_id)\n",
    "                filtered_relationships.append(rel)\n",
    "\n",
    "        # Only keep non-empty groupings\n",
    "        if filtered_relationships:\n",
    "            processed_groupings[term] = {\n",
    "                \"relationships\": filtered_relationships,\n",
    "                \"term\": data[\"term\"]\n",
    "            }\n",
    "\n",
    "    return processed_groupings\n"
   ],
   "id": "4bc619c1585764d3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "filter the lexical index dict to remove duplicate relations, relations from non-preferred ontologies, and groupings that either have no relations at that point or groupings whose text contains suspicious punctuation characters\n",
    "\n",
    "this code may expect a real lexical index, not a lexical index dict"
   ],
   "id": "3a504549f15cf037"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Process the groupings\n",
    "lexical_index[\"groupings\"] = process_groupings(\n",
    "    lexical_index[\"groupings\"], preferred_ontologies)"
   ],
   "id": "329896fad1a5c0bd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "len(lexical_index['groupings'])",
   "id": "99ea04f4dde74c1b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# biosamples_env_triads_precedent_lexical_index_second_pass_filtered_yaml = \"biosamples_env_triads_precedent_lexical_index_second_pass_filtered.yaml\"",
   "id": "c67222b110bbc428",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Save the cleaned YAML file\n",
    "with open(biosamples_env_triads_precedent_lexical_index_second_pass_filtered_yaml, \"w\") as f:\n",
    "    yaml.dump(lexical_index, f, default_flow_style=False, sort_keys=True)"
   ],
   "id": "64990b89805ebaa9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "2c78e95b1ba591c6",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
