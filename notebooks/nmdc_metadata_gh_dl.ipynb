{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-18T21:16:14.184475Z",
     "start_time": "2025-02-18T21:16:14.180159Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import requests\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Replace with your GitHub username and personal access token (PAT)\n",
    "# Generate a PAT with \"repo\" scope (or finer-grained scopes if possible)\n",
    "GITHUB_USERNAME = \"turbomam\"\n",
    "GITHUB_TOKEN = \"\"\n",
    "\n",
    "# Replace with the repository you want to analyze\n",
    "REPO_OWNER = \"microbiomedata\"  # e.g., \"facebook\"\n",
    "REPO_NAME = \"nmdc-metadata\"  # e.g., \"react\""
   ],
   "id": "f44756e298facf58",
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-18T21:20:12.730146Z",
     "start_time": "2025-02-18T21:17:25.664338Z"
    }
   },
   "source": [
    "\n",
    "\n",
    "# Output directory\n",
    "OUTPUT_DIR = \"github_data\"\n",
    "\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)\n",
    "\n",
    "def download_data(api_url, data_type, filename):\n",
    "    \"\"\"Downloads issues, pull requests, or comments with enhanced status messages.\"\"\"\n",
    "\n",
    "    all_data = []\n",
    "    page = 1\n",
    "    start_time = datetime.now()\n",
    "\n",
    "    while True:\n",
    "        url_with_params = f\"{api_url}?page={page}&per_page=100&state=all\"\n",
    "        response = requests.get(url_with_params, headers=headers)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            if not data:\n",
    "                break\n",
    "\n",
    "            all_data.extend(data)\n",
    "\n",
    "            if data_type!= \"comments\":\n",
    "                now = datetime.now()\n",
    "                elapsed_time = now - start_time\n",
    "                items_downloaded = len(all_data)\n",
    "                rate = items_downloaded / elapsed_time.total_seconds() if elapsed_time.total_seconds() > 0 else 0\n",
    "                time_remaining = timedelta(seconds=(total_items - items_downloaded) / rate) if rate > 0 and total_items > items_downloaded else \"Unknown\"\n",
    "                print(\n",
    "                    f\"Downloaded page {page} of {data_type} ({items_downloaded} {data_type} so far). \"\n",
    "                    f\"Elapsed: {elapsed_time}, Rate: {rate:.2f} {data_type}/sec, Time Remaining: {time_remaining}.\"\n",
    "                )\n",
    "            page += 1\n",
    "\n",
    "        elif response.status_code == 403:  # rate limit handling\n",
    "            print(\"Rate limit hit. Waiting...\")\n",
    "            rate_limit_reset = int(response.headers.get(\"X-RateLimit-Reset\"))\n",
    "            wait_time = rate_limit_reset - time.time() + 10  # add 10 seconds buffer\n",
    "            if wait_time > 0:\n",
    "                print(f\"Waiting for {wait_time:.1f} seconds...\")\n",
    "                time.sleep(wait_time)\n",
    "                continue\n",
    "            else:\n",
    "                raise Exception(\"Rate limit reset time in the past\")\n",
    "\n",
    "        else:\n",
    "            print(f\"Error downloading {data_type}: {response.status_code} - {response.text}\")\n",
    "            return None\n",
    "\n",
    "    if data_type!= \"comments\":\n",
    "        for item in all_data:\n",
    "            comments_url = item.get(\"comments_url\")\n",
    "            if comments_url:\n",
    "                comments = download_data(comments_url, \"comments\", None)\n",
    "                if comments is not None:\n",
    "                    item[\"comments\"] = comments\n",
    "                else:\n",
    "                    print(f\"Failed to download comments for {data_type} #{item.get('number') or item.get('id')}\")\n",
    "\n",
    "    return all_data\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    headers = {\n",
    "        \"Authorization\": f\"token {GITHUB_TOKEN}\",\n",
    "        \"Accept\": \"application/vnd.github.v3+json\",\n",
    "    }\n",
    "\n",
    "    API_URL = f\"https://api.github.com/repos/{REPO_OWNER}/{REPO_NAME}/issues\"\n",
    "\n",
    "    # Use the search API to get the total count\n",
    "    search_url = f\"https://api.github.com/search/issues?q=repo:{REPO_OWNER}/{REPO_NAME}\"\n",
    "    total_items_response = requests.get(search_url, headers=headers)\n",
    "    if total_items_response.status_code == 200:\n",
    "        total_items = total_items_response.json()[\"total_count\"]\n",
    "    else:\n",
    "        total_items = 0\n",
    "        print(\"Could not retrieve total number of items. Progress estimation will not work.\")\n",
    "\n",
    "\n",
    "    # Download Issues\n",
    "    issues = download_data(API_URL, \"issues\", f\"{REPO_OWNER}_{REPO_NAME}_issues.json\")\n",
    "    if issues:\n",
    "        with open(os.path.join(OUTPUT_DIR, f\"{REPO_OWNER}_{REPO_NAME}_issues.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(issues, f, indent=4)\n",
    "        print(\"Issues and comments saved.\")\n",
    "    else:\n",
    "        print(\"Failed to download issues or comments.\")\n",
    "\n",
    "    # Download Pull Requests\n",
    "    pulls_url = f\"https://api.github.com/repos/{REPO_OWNER}/{REPO_NAME}/pulls\"\n",
    "    pulls = download_data(pulls_url, \"pull requests\", f\"{REPO_OWNER}_{REPO_NAME}_pulls.json\")\n",
    "    if pulls:\n",
    "        with open(os.path.join(OUTPUT_DIR, f\"{REPO_OWNER}_{REPO_NAME}_pulls.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(pulls, f, indent=4)\n",
    "        print(\"Pull requests and comments saved.\")\n",
    "    else:\n",
    "        print(\"Failed to download pull requests or comments.\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not retrieve total number of items. Progress estimation will not work.\n",
      "Downloaded page 1 of issues (100 issues so far). Elapsed: 0:00:00.635497, Rate: 157.36 issues/sec, Time Remaining: Unknown.\n",
      "Downloaded page 2 of issues (200 issues so far). Elapsed: 0:00:01.253279, Rate: 159.58 issues/sec, Time Remaining: Unknown.\n",
      "Downloaded page 3 of issues (300 issues so far). Elapsed: 0:00:01.804811, Rate: 166.22 issues/sec, Time Remaining: Unknown.\n",
      "Downloaded page 4 of issues (400 issues so far). Elapsed: 0:00:02.391352, Rate: 167.27 issues/sec, Time Remaining: Unknown.\n",
      "Downloaded page 5 of issues (433 issues so far). Elapsed: 0:00:02.736660, Rate: 158.22 issues/sec, Time Remaining: Unknown.\n",
      "Issues and comments saved.\n",
      "Downloaded page 1 of pull requests (100 pull requests so far). Elapsed: 0:00:00.752086, Rate: 132.96 pull requests/sec, Time Remaining: Unknown.\n",
      "Downloaded page 2 of pull requests (138 pull requests so far). Elapsed: 0:00:01.170873, Rate: 117.86 pull requests/sec, Time Remaining: Unknown.\n",
      "Pull requests and comments saved.\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "6e0a598b4a1a7b20"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
